{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0933365718304548", "dc:identifier": "doi:10.1016/j.artmed.2020.101836", "eid": "1-s2.0-S0933365718304548", "prism:doi": "10.1016/j.artmed.2020.101836", "pii": "S0933-3657(18)30454-8", "dc:title": "Reinforcement learning application in diabetes blood glucose control: A systematic review ", "prism:publicationName": "Artificial Intelligence in Medicine", "prism:aggregationType": "Journal", "prism:issn": "09333657", "prism:volume": "104", "prism:startingPage": "101836", "prism:pageRange": "101836", "articleNumber": "101836", "dc:format": "application/json", "prism:coverDate": "2020-04-30", "prism:coverDisplayDate": "April 2020", "prism:copyright": "\u00a9 2020 Elsevier B.V. All rights reserved.", "prism:publisher": "Elsevier B.V.", "dc:creator": [{"@_fa": "true", "$": "Tejedor, Miguel"}, {"@_fa": "true", "$": "Woldaregay, Ashenafi Zebene"}, {"@_fa": "true", "$": "Godtliebsen, Fred"}], "dc:description": "\n               Abstract\n               \n                  Background\n                  Reinforcement learning (RL) is a computational approach to understanding and automating goal-directed learning and decision-making. It is designed for problems which include a learning agent interacting with its environment to achieve a goal. For example, blood glucose (BG) control in diabetes mellitus (DM), where the learning agent and its environment are the controller and the body of the patient respectively. RL algorithms could be used to design a fully closed-loop controller, providing a truly personalized insulin dosage regimen based exclusively on the patient\u2019s own data.\n               \n               \n                  Objective\n                  In this review we aim to evaluate state-of-the-art RL approaches to designing BG control algorithms in DM patients, reporting successfully implemented RL algorithms in closed-loop, insulin infusion, decision support and personalized feedback in the context of DM.\n               \n               \n                  Methods\n                  An exhaustive literature search was performed using different online databases, analyzing the literature from 1990 to 2019. In a first stage, a set of selection criteria were established in order to select the most relevant papers according to the title, keywords and abstract. Research questions were established and answered in a second stage, using the information extracted from the articles selected during the preliminary selection.\n               \n               \n                  Results\n                  The initial search using title, keywords, and abstracts resulted in a total of 404 articles. After removal of duplicates from the record, 347 articles remained. An independent analysis and screening of the records against our inclusion and exclusion criteria defined in Methods section resulted in removal of 296 articles, leaving 51 relevant articles. A full-text assessment was conducted on the remaining relevant articles, which resulted in 29 relevant articles that were critically analyzed. The inter-rater agreement was measured using Cohen Kappa test, and disagreements were resolved through discussion.\n               \n               \n                  Conclusions\n                  The advances in health technologies and mobile devices have facilitated the implementation of RL algorithms for optimal glycemic regulation in diabetes. However, there exists few articles in the literature focused on the application of these algorithms to the BG regulation problem. Moreover, such algorithms are designed for control tasks as BG adjustment and their use have increased recently in the diabetes research area, therefore we foresee RL algorithms will be used more frequently for BG control in the coming years. Furthermore, in the literature there is a lack of focus on aspects that influence BG level such as meal intakes and physical activity (PA), which should be included in the control problem. Finally, there exists a need to perform clinical validation of the algorithms.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Reinforcement learning"}, {"@_fa": "true", "$": "Blood glucose control"}, {"@_fa": "true", "$": "Artificial pancreas"}, {"@_fa": "true", "$": "Closed-loop"}, {"@_fa": "true", "$": "Insulin infusion"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0933365718304548", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0933365718304548", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "85080919667", "scopus-eid": "2-s2.0-85080919667", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/85080919667", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20200221", "$": "2020-02-21"}}}}, "subfield": ["Treatment"], "classified": "None"}
10.1093/jnen/nlz122  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   The neuropathology associated with cognitive decline in military personnel exposed to traumatic brain injury (TBI) and chronic stress is incompletely understood. Few studies have examined clinicopathologic correlations between phosphorylated-tau neurofibrillary tangles, β-amyloid neuritic plaques, neuroinflammation, or white matter (WM) lesions, and neuropsychiatric disorders in veterans. We describe clinicopathologic findings in 4 military veterans with early-onset dementia (EOD) who had varying histories of blunt- and blast-TBI, cognitive decline, behavioral abnormalities, post-traumatic stress disorder, suicidal ideation, and suicide. We found that pathologic lesions in these military-EOD cases could not be categorized as classic Alzheimer's disease (AD), chronic traumatic encephalopathy, traumatic axonal injury, or other well-characterized clinicopathologic entities. Rather, we observed a mixture of polypathology with unusual patterns compared with pathologies found in AD or other dementias. Also, ultrahigh resolution ex vivo MRI in 2 of these 4 brains revealed unusual patterns of periventricular WM injury. These findings suggest that military-EOD cases are associated with atypical combinations of brain lesions and distribution rarely seen in nonmilitary populations. Future prospective studies that acquire neuropsychiatric data before and after deployments, as well as genetic and environmental exposure data, are needed to further elucidate clinicopathologic correlations in military-EOD. 
  |  https://academic.oup.com/jnen/article-lookup/doi/10.1093/jnen/nlz122  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31851313/  |  
------------------------------------------- 
10.1148/radiol.2020200905  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value&lt;0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases. 
  |  http://pubs.rsna.org/doi/10.1148/radiol.2020200905?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  
------------------------------------------- 
10.1016/j.mri.2019.09.006  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   One major thrust in radiology today is image standardization with a focus on rapidly acquired quantitative multi-contrast information. This is critical for multi-center trials, for the collection of big data and for the use of artificial intelligence in evaluating the data. Strategically acquired gradient echo (STAGE) imaging is one such method that can provide 8 qualitative and 7 quantitative pieces of information in 5 min or less at 3 T. STAGE provides qualitative images in the form of proton density weighted images, T1 weighted images, T2* weighted images and simulated double inversion recovery (DIR) images. STAGE also provides quantitative data in the form of proton spin density, T1, T2* and susceptibility maps as well as segmentation of white matter, gray matter and cerebrospinal fluid. STAGE uses vendors' product gradient echo sequences. It can be applied from 0.35 T to 7 T across all manufacturers producing similar results in contrast and quantification of the data. In this paper, we discuss the strengths and weaknesses of STAGE, demonstrate its contrast-to-noise (CNR) behavior relative to a large clinical data set and introduce a few new image contrasts derived from STAGE, including DIR images and a new concept referred to as true susceptibility weighted imaging (tSWI) linked to fluid attenuated inversion recovery (FLAIR) or tSWI-FLAIR for the evaluation of multiple sclerosis lesions. The robustness of STAGE T1 mapping was tested using the NIST/NIH phantom, while the reproducibility was tested by scanning a given individual ten times in one session and the same subject scanned once a week over a 12-week period. Assessment of the CNR for the enhanced T1W image (T1WE) showed a significantly better contrast between gray matter and white matter than conventional T1W images in both patients with Parkinson's disease and healthy controls. We also present some clinical cases using STAGE imaging in patients with stroke, metastasis, multiple sclerosis and a fetus with ventriculomegaly. Overall, STAGE is a comprehensive protocol that provides the clinician with numerous qualitative and quantitative images. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0730-725X(19)30382-0  |  
------------------------------------------- 
10.1007/s12149-020-01460-z  |  Treatment, Prognosis, Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objective:  The aim of the study was to investigate the outcomes and prognostic factors of high-dose <sup>131</sup>I-metaiodobenzylguanidine (<sup>131</sup>I-MIBG) therapy in patients with refractory or relapsed neuroblastoma (NBL) in Japan. 
  Methods:  We retrospectively analyzed 20 patients with refractory or relapsed high-risk NBL who underwent <sup>131</sup>I-MIBG therapy with an administration dose ranging from 444 to 666 MBq/kg at Kanazawa University Hospital, Japan, between September 2008 and September 2013. We focused on measurements regarding their initial responses, prognostic factors, survivals, and toxicities following <sup>131</sup>I-MIBG therapy using our hospital data and questionnaires from the hospitals that these patients were initially referred from. Furthermore, we performed Kaplan-Meier survival analysis to evaluate event-free survival (EFS) and overall survival (OS). 
  Results:  In 19 patients with complete follow-up data, the median age at first <sup>131</sup>I-MIBG treatment was 7.9 years (range 2.5-17.7 years). Following <sup>131</sup>I-MIBG therapy, 17 of the 19 patients underwent stem-cell transplantations, and their treatment response was either complete (CR) or partial (PR) in three and two cases, respectively. The EFS and OS rates at 1 year following <sup>131</sup>I-MIBG therapy were 42% and 58%, respectively, and those at 5 years following <sup>131</sup>I-MIBG therapy were 16% and 42%, respectively. Using the two-sample log-rank test, the OS time following <sup>131</sup>I-MIBG therapy was significantly longer for &lt; 3-year time interval between the initial diagnosis and <sup>131</sup>I-MIBG therapy (p = 0.017), Curie score &lt; 16 just before <sup>131</sup>I-MIBG therapy (p = 0.002), without pain (p = 0.002), without both vanillylmandelic acid (VMA) and homovanillic acid (HVA) elevation (p = 0.037) at <sup>131</sup>I-MIBG therapy, and with CR or PR following <sup>131</sup>I-MIBG therapy (p = 0.015). Although severe hematological toxicities were identified in all 19 patients, severe nonhematological toxicity was not recorded in any patient, except for one patient with grade 3 anorexia and nausea. 
  Conclusions:  High-dose <sup>131</sup>I-MIBG therapy in patients with refractory or relapsed high-risk NBL can provide a favorable prognosis without severe nonhematological toxicities. Better prognosis may be anticipated in patients with the initial good response, no pain at <sup>131</sup>I-MIBG therapy, no VMA and HVA elevation at <sup>131</sup>I-MIBG therapy, low Curie score (&lt; 16) just before <sup>131</sup>I-MIBG therapy, and short time interval (&lt; 3 years) between the initial diagnosis and <sup>131</sup>I-MIBG therapy. 
  |  https://dx.doi.org/10.1007/s12149-020-01460-z  |  
------------------------------------------- 
10.1007/s12350-018-1317-5  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Coronary PET shows promise in the detection of high-risk atherosclerosis, but there remains a need to optimize imaging and reconstruction techniques. We investigated the impact of reconstruction parameters and cardiac motion-correction in <sup>18</sup>F Sodium Fluoride (<sup>18</sup>F-NaF) PET. 
  Methods:  Twenty-two patients underwent <sup>18</sup>F-NaF PET within 22 days of an acute coronary syndrome. Optimal reconstruction parameters were determined in a subgroup of six patients. Motion-correction was performed on ECG-gated data of all patients with optimal reconstruction. Tracer uptake was quantified in culprit and reference lesions by computing signal-to-noise ratio (SNR) in diastolic, summed, and motion-corrected images. 
  Results:  Reconstruction using 24 subsets, 4 iterations, point-spread-function modelling, time of flight, and 5-mm post-filtering provided the highest median SNR (31.5) compared to 4 iterations 0-mm (22.5), 8 iterations 0-mm (21.1), and 8 iterations 5-mm (25.6; all P &lt; .05). Motion-correction improved SNR of culprit lesions (n = 33) (24.5[19.9-31.5]) compared to diastolic (15.7[12.4-18.1]; P &lt; .001) and summed data (22.1[18.9-29.2]; P &lt; .001). Motion-correction increased the SNR difference between culprit and reference lesions (10.9[6.3-12.6]) compared to diastolic (6.2[3.6-10.3]; P = .001) and summed data (7.1 [4.8-11.6]; P = .001). 
  Conclusions:  The number of iterations and extent of post-filtering has marked effects on coronary <sup>18</sup>F-NaF PET quantification. Cardiac motion-correction improves discrimination between culprit and reference lesions. 
  |  https://dx.doi.org/10.1007/s12350-018-1317-5  |  
------------------------------------------- 
10.3322/caac.21608  |  Smart Healthcare, Treatment  |  SubfieldA  |  Review  |  ResearchTypeA  |   Patient-generated health data (PGHD), or health-related data gathered from patients to help address a health concern, are used increasingly in oncology to make regulatory decisions and evaluate quality of care. PGHD include self-reported health and treatment histories, patient-reported outcomes (PROs), and biometric sensor data. Advances in wireless technology, smartphones, and the Internet of Things have facilitated new ways to collect PGHD during clinic visits and in daily life. The goal of the current review was to provide an overview of the current clinical, regulatory, technological, and analytic landscape as it relates to PGHD in oncology research and care. The review begins with a rationale for PGHD as described by the US Food and Drug Administration, the Institute of Medicine, and other regulatory and scientific organizations. The evidence base for clinic-based and remote symptom monitoring using PGHD is described, with an emphasis on PROs. An overview is presented of current approaches to digital phenotyping or device-based, real-time assessment of biometric, behavioral, self-report, and performance data. Analytic opportunities regarding PGHD are envisioned in the context of big data and artificial intelligence in medicine. Finally, challenges and solutions for the integration of PGHD into clinical care are presented. The challenges include electronic medical record integration of PROs and biometric data, analysis of large and complex biometric data sets, and potential clinic workflow redesign. In addition, there is currently more limited evidence for the use of biometric data relative to PROs. Despite these challenges, the potential benefits of PGHD make them increasingly likely to be integrated into oncology research and clinical care. 
  |  https://doi.org/10.3322/caac.21608  |  
------------------------------------------- 
10.1192/bjp.2019.127  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Schizophrenia is a complex mental disorder with high heritability and polygenic inheritance. Multimodal neuroimaging studies have also indicated that abnormalities of brain structure and function are a plausible neurobiological characterisation of schizophrenia. However, the polygenic effects of schizophrenia on these imaging endophenotypes have not yet been fully elucidated. 
  Aims:  To investigate the effects of polygenic risk for schizophrenia on the brain grey matter volume and functional connectivity, which are disrupted in schizophrenia. 
  Method:  Genomic and neuroimaging data from a large sample of Han Chinese patients with schizophrenia (N = 509) and healthy controls (N = 502) were included in this study. We examined grey matter volume and functional connectivity via structural and functional magnetic resonance imaging, respectively. Using the data from a recent meta-analysis of a genome-wide association study that comprised a large number of Chinese people, we calculated a polygenic risk score (PGRS) for each participant. 
  Results:  The imaging genetic analysis revealed that the individual PGRS showed a significantly negative correlation with the hippocampal grey matter volume and hippocampus-medial prefrontal cortex functional connectivity, both of which were lower in the people with schizophrenia than in the controls. We also found that the observed neuroimaging measures showed weak but similar changes in unaffected first-degree relatives of patients with schizophrenia. 
  Conclusions:  These findings suggested that genetically influenced brain grey matter volume and functional connectivity may provide important clues for understanding the pathological mechanisms of schizophrenia and for the early diagnosis of schizophrenia. 
  |  https://www.cambridge.org/core/product/identifier/S0007125019001272/type/journal_article  |  
------------------------------------------- 
10.1002/humu.23948  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   Primary microcephaly (PM) is characterized by a small head since birth and is vastly heterogeneous both genetically and phenotypically. While most cases are monogenic, genetic interactions between Aspm and Wdr62 have recently been described in a mouse model of PM. Here, we used two complementary, holistic in vivo approaches: high throughput DNA sequencing of multiple PM genes in human patients with PM, and genome-edited zebrafish modeling for the digenic inheritance of PM. Exomes of patients with PM showed a significant burden of variants in 75 PM genes, that persisted after removing monogenic causes of PM (e.g., biallelic pathogenic variants in CEP152). This observation was replicated in an independent cohort of patients with PM, where a PM gene panel showed in addition that the burden was carried by six centrosomal genes. Allelic frequencies were consistent with digenic inheritance. In zebrafish, non-centrosomal gene casc5 -/- produced a severe PM phenotype, that was not modified by centrosomal genes aspm or wdr62 invalidation. A digenic, quadriallelic PM phenotype was produced by aspm and wdr62. Our observations provide strong evidence for digenic inheritance of human PM, involving centrosomal genes. Absence of genetic interaction between casc5 and aspm or wdr62 further delineates centrosomal and non-centrosomal pathways in PM. 
  |  https://doi.org/10.1002/humu.23948  |  
------------------------------------------- 
10.1002/adma.201906493  |  Robotics, Smart Healthcare  |  SubfieldA  |  Research  |  ResearchTypeA  |   Development of stimuli-responsive materials with complex practical functions is significant for achieving bioinspired artificial intelligence. It is challenging to fabricate stimuli-responsive hydrogels showing simultaneous changes in fluorescence color, brightness, and shape in response to a single stimulus. Herein, a bilayer hydrogel strategy is designed by utilizing an aggregation-induced emission luminogen, tetra-(4-pyridylphenyl)ethylene (TPE-4Py), to fabricate hydrogels with the above capabilities. Bilayer hydrogel actuators with the ionomer of poly(acrylamide-r-sodium 4-styrenesulfonate) (PAS) as a matrix of both active and passive layers and TPE-4Py as the core function element in the active layer are prepared. At acidic pH, the protonation of TPE-4Py leads to fluorescence color and brightness changes of the actuators and the electrostatic interactions between the protonated TPE-4Py and benzenesulfonate groups of the PAS chains in the active layer cause the actuators to deform. The proposed TPE-4Py/PAS-based bilayer hydrogel actuators with such responsiveness to stimulus provide insights in the design of intelligent systems and are highly attractive material candidates in the fields of 3D/4D printing, soft robots, and smart wearable devices. 
  |  https://doi.org/10.1002/adma.201906493  |  
------------------------------------------- 
10.3390/ijerph17031093  |  Smart Healthcare  |  SubfieldA  |  Research  |  ResearchTypeA  |   <i>Background</i>: The primary care service in Catalonia has operated an asynchronous teleconsulting service between GPs and patients since 2015 (eConsulta), which has generated some 500,000 messages. New developments in big data analysis tools, particularly those involving natural language, can be used to accurately and systematically evaluate the impact of the service. <i>Objective</i>: The study was intended to assess the predictive potential of eConsulta messages through different combinations of vector representation of text and machine learning algorithms and to evaluate their performance. <i>Methodology</i>: Twenty machine learning algorithms (based on five types of algorithms and four text representation techniques) were trained using a sample of 3559 messages (169,102 words) corresponding to 2268 teleconsultations (1.57 messages per teleconsultation) in order to predict the three variables of interest (avoiding the need for a face-to-face visit, increased demand and type of use of the teleconsultation). The performance of the various combinations was measured in terms of precision, sensitivity, F-value and the ROC curve. <i>Results</i>: The best-trained algorithms are generally effective, proving themselves to be more robust when approximating the two binary variables "avoiding the need of a face-to-face visit" and "increased demand" (precision = 0.98 and 0.97, respectively) rather than the variable "type of query" (precision = 0.48). <i>Conclusion</i>: To the best of our knowledge, this study is the first to investigate a machine learning strategy for text classification using primary care teleconsultation datasets. The study illustrates the possible capacities of text analysis using artificial intelligence. The development of a robust text classification tool could be feasible by validating it with more data, making it potentially more useful for decision support for health professionals. 
  |  http://www.mdpi.com/resolver?pii=ijerph17031093  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32050435/  |  
------------------------------------------- 
10.2196/15510  |  Smart Healthcare, Diagnosis, Prognosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Artificial intelligence-enabled electronic health record (EHR) analysis can revolutionize medical practice from the diagnosis and prediction of complex diseases to making recommendations in patient care, especially for chronic conditions such as chronic kidney disease (CKD), which is one of the most frequent complications in patients with diabetes and is associated with substantial morbidity and mortality. 
  Objective:  The longitudinal prediction of health outcomes requires effective representation of temporal data in the EHR. In this study, we proposed a novel temporal-enhanced gradient boosting machine (GBM) model that dynamically updates and ensembles learners based on new events in patient timelines to improve the prediction accuracy of CKD among patients with diabetes. 
  Methods:  Using a broad spectrum of deidentified EHR data on a retrospective cohort of 14,039 adult patients with type 2 diabetes and GBM as the base learner, we validated our proposed Landmark-Boosting model against three state-of-the-art temporal models for rolling predictions of 1-year CKD risk. 
  Results:  The proposed model uniformly outperformed other models, achieving an area under receiver operating curve of 0.83 (95% CI 0.76-0.85), 0.78 (95% CI 0.75-0.82), and 0.82 (95% CI 0.78-0.86) in predicting CKD risk with automatic accumulation of new data in later years (years 2, 3, and 4 since diabetes mellitus onset, respectively). The Landmark-Boosting model also maintained the best calibration across moderate- and high-risk groups and over time. The experimental results demonstrated that the proposed temporal model can not only accurately predict 1-year CKD risk but also improve performance over time with additionally accumulated data, which is essential for clinical use to improve renal management of patients with diabetes. 
  Conclusions:  Incorporation of temporal information in EHR data can significantly improve predictive model performance and will particularly benefit patients who follow-up with their physicians as recommended. 
  |  https://medinform.jmir.org/2020/1/e15510/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32012067/  |  
------------------------------------------- 
10.1038/s41598-020-62676-7  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Generative Adversarial Network (GAN) requires extensive computing resources making its implementation in edge devices with conventional microprocessor hardware a slow and difficult, if not impossible task. In this paper, we propose to accelerate these intensive neural computations using memristive neural networks in analog domain. The implementation of Analog Memristive Deep Convolutional GAN (AM-DCGAN) using Generator as deconvolutional and Discriminator as convolutional memristive neural network is presented. The system is simulated at circuit level with 1.7 million memristor devices taking into account memristor non-idealities, device and circuit parameters. The design is modular with crossbar arrays having a minimum average power consumption per neural computation of 47nW. The design exclusively uses the principles of neural network dropouts resulting in regularization and lowering the power consumption. The SPICE level simulation of GAN is performed with 0.18 μm CMOS technology and WO<sub>x</sub> memristive devices with R<sub>ON</sub> = 40 kΩ and R<sub>OFF</sub> = 250 kΩ, threshold voltage 0.8 V and write voltage at 1.0 V. 
  |  http://dx.doi.org/10.1038/s41598-020-62676-7  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32246103/  |  
------------------------------------------- 
10.1098/rsta.2019.0163  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   This paper presents the design of an ultra-low energy neural network that uses time-mode signal processing). Handwritten digit classification using a single-layer artificial neural network (ANN) with a Softmin-based activation function is described as an implementation example. To realize time-mode operation, the presented design makes use of monostable multivibrator-based multiplying analogue-to-time converters, fixed-width pulse generators and basic digital gates. The time-mode digit classification ANN was designed in a standard CMOS 0.18 μm IC process and operates from a supply voltage of 0.6 V. The system operates on the MNIST database of handwritten digits with quantized neuron weights and has a classification accuracy of 88%, which is typical for single-layer ANNs, while dissipating 65.74 pJ per classification with a speed of 2.37 k classifications per second. This article is part of the theme issue 'Harmonizing energy-autonomous computing and intelligence'. 
  |  https://royalsocietypublishing.org/doi/full/10.1098/rsta.2019.0163?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  
------------------------------------------- 
10.1002/hbm.24968  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   There is an ongoing debate about whether, and to what extent, males differ from females in their language skills. In the case of handwriting, a composite language skill involving language and motor processes, behavioral observations consistently show robust sex differences but the mechanisms underlying the effect are unclear. Using functional magnetic resonance imaging (fMRI) in a copying task, the present study examined the neural basis of sex differences in handwriting in 53 healthy adults (ages 19-28, 27 males). Compared to females, males showed increased activation in the left posterior middle frontal gyrus (Exner's area), a region thought to support the conversion between orthographic and graphomotor codes. Functional connectivity between Exner's area and the right cerebellum was greater in males than in females. Furthermore, sex differences in brain activity related to handwriting were independent of language material. This study identifies a novel neural signature of sex differences in a hallmark of human behavior, and highlights the importance of considering sex as a factor in scientific research and clinical applications involving handwriting. 
  |  https://doi.org/10.1002/hbm.24968  |  
------------------------------------------- 
10.1136/gutjnl-2019-318860  |  Diagnosis, Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objective:  Pancreatic ductal adenocarcinoma (PDAC) is difficult to diagnose at resectable stage. Recent studies have suggested that extracellular vesicles (EVs) contain long RNAs. The aim of this study was to develop a diagnostic (d-)signature for the detection of PDAC based on EV long RNA (exLR) profiling. 
  Design:  We conducted a case-control study with 501 participants, including 284 patients with PDAC, 100 patients with chronic pancreatitis (CP) and 117 healthy subjects. The exLR profile of plasma samples was analysed by exLR sequencing. The d-signature was identified using a support vector machine algorithm and a training cohort (n=188) and was validated using an internal validation cohort (n=135) and an external validation cohort (n=178). 
  Results:  We developed a d-signature that comprised eight exLRs, including FGA, KRT19, HIST1H2BK, ITIH2, MARCH2, CLDN1, MAL2 and TIMP1, for PDAC detection. The d-signature showed high accuracy, with an area under the receiver operating characteristic curve (AUC) of 0.960, 0.950 and 0.936 in the training, internal validation and external validation cohort, respectively. The d-signature was able to identify resectable stage I/II cancer with an AUC of 0.949 in the combined three cohorts. In addition, the d-signature showed superior performance to carbohydrate antigen 19-9 in distinguishing PDAC from CP (AUC 0.931 vs 0.873, p=0.028). 
  Conclusion:  This study is the first to characterise the plasma exLR profile in PDAC and to report an exLR signature for the detection of pancreatic cancer. This signature may improve the prognosis of patients who would have otherwise missed the curative treatment window. 
  |  http://gut.bmj.com/cgi/pmidlookup?view=long&pmid=31562239  |  
------------------------------------------- 
10.1007/s11571-019-09560-x  |  Robotics, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Motor imagery (MI) is a mental representation of motor behavior and has been widely used in electroencephalogram based brain-computer interfaces (BCIs). Several studies have demonstrated the efficacy of MI-based BCI-feedback training in post-stroke rehabilitation. However, in the earliest stage of the training, calibration data typically contain insufficient discriminability, resulting in unreliable feedback, which may decrease subjects' motivation and even hinder their training. To improve the performance in the early stages of MI training, a novel hybrid BCI paradigm based on MI and P300 is proposed in this study. In this paradigm, subjects are instructed to imagine writing the Chinese character following the flash order of the desired Chinese character displayed on the screen. The event-related desynchronization/synchronization (ERD/ERS) phenomenon is produced with writing based on one's imagination. Simultaneously, the P300 potential is evoked by the flash of each stroke. Moreover, a fusion method of P300 and MI classification is proposed, in which unreliable P300 classifications are corrected by reliable MI classifications. Twelve healthy naïve MI subjects participated in this study. Results demonstrated that the proposed hybrid BCI paradigm yielded significantly better performance than the single-modality BCI paradigm. The recognition accuracy of the fusion method is significantly higher than that of P300 (<i>p</i> &lt; 0.05) and MI (<i>p</i> &lt; 0.01). Moreover, the training data size can be reduced through fusion of these two modalities. 
  |  https://dx.doi.org/10.1007/s11571-019-09560-x  |  
------------------------------------------- 
10.1016/j.ijporl.2019.109833  |  Diagnosis, Treatment, Drug Discovery  |  SubfieldA  |  Review  |  ResearchTypeA  |    Objective:  To summarize recently published key articles on the topics of biomedical engineering, biotechnology and new models in relation to otitis media (OM). 
  Data sources:  Electronic databases: PubMed, Ovid Medline, Cochrane Library and Clinical Evidence (BMJ Publishing). 
  Review methods:  Articles on biomedical engineering, biotechnology, material science, mechanical and animal models in OM published between May 2015 and May 2019 were identified and subjected to review. A total of 132 articles were ultimately included. 
  Results:  New imaging technologies for the tympanic membrane (TM) and the middle ear cavity are being developed to assess TM thickness, identify biofilms and differentiate types of middle ear effusions. Artificial intelligence (AI) has been applied to train software programs to diagnose OM with a high degree of certainty. Genetically modified mice models for OM have further investigated what predisposes some individuals to OM and consequent hearing loss. New vaccine candidates protecting against major otopathogens are being explored and developed, especially combined vaccines, targeting more than one pathogen. Transcutaneous vaccination against non-typeable Haemophilus influenzae has been successfully tried in a chinchilla model. In terms of treatment, novel technologies for trans-tympanic drug delivery are entering the clinical domain. Various growth factors and grafting materials aimed at improving healing of TM perforations show promising results in animal models. 
  Conclusion:  New technologies and AI applications to improve the diagnosis of OM have shown promise in pre-clinical models and are gradually entering the clinical domain. So are novel vaccines and drug delivery approaches that may allow local treatment of OM. 
  Implications for practice:  New diagnostic methods, potential vaccine candidates and the novel trans-tympanic drug delivery show promising results, but are not yet adapted to clinical use. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0165-5876(19)30586-5  |  
------------------------------------------- 
10.1016/j.msard.2020.102034  |  Robotics, Treatment  |  SubfieldA  |  Review  |  ResearchTypeA  |    Background:  Multiple sclerosis is a progressive disease responsible for gait disabilities and cognitive impairment, which affect functional performance. Robot-assisted gait training is an emerging training method to facilitate body-weight-supported treadmill training in many neurologic diseases. Through this study, we aimed to determine the efficacy of robot-assisted gait training in patients with multiple sclerosis. 
  Methods:  We performed a systematic review and meta-analysis of randomized controlled trials evaluating the effect of robot-assisted gait training for multiple sclerosis. We searched PubMed, EMBASE, the Cochrane Library, and ClinicalTrials.gov registry for articles published before May 2019. The primary outcome was walking performance (gait parameters, balance, and ambulation capability). The secondary outcomes were changes in perceived fatigue, severity of spasticity, global mobility, physical and mental quality of life, severity of pain, activities of daily living, and treatment acceptance. 
  Results:  We identified 10 studies (9 different trials) that included patients with multiple sclerosis undergoing robot-assisted gait training or conventional walk training. The meta-analysis showed comparable effectiveness between robot-assisted gait training and conventional walking therapy in walking performance, quality of life, pain, or activities of daily living. The robot-assisted gait training was even statistically superior to conventional walking therapy in improving perceived fatigue (pooled SMD: 0.34, 95% CI: 0.02-0.67), spasticity (pooled SMD: 0.70, 95% CI: 0.08-1.33, I² = 53%), and global mobility (borderline) after the intervention. 
  Conclusion:  Our results provide the most up-to-date evidence regarding the robot-assisted gait training on multiple sclerosis. In addition to the safety and good tolerance, its efficacy on multiple sclerosis is comparable to that of conventional walking training and is even superior in improving fatigue and spasticity. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S2211-0348(20)30110-3  |  
------------------------------------------- 
10.1001/jamanetworkopen.2020.0255  |  Smart Healthcare, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Importance:  Mobile applications (apps) may help improve hypertension self-management. 
  Objective:  To investigate the effect of an artificial intelligence smartphone coaching app to promote home monitoring and hypertension-related behaviors on systolic blood pressure level compared with a blood pressure tracking app. 
  Design, setting, and participants:  This was a 2-group, open, randomized clinical trial. Participants with uncontrolled hypertension were recruited in 2016 and 2017 and were followed up for 6 months. Data analysis was performed from April 2019 to December 2019. 
  Interventions:  Intervention group participants received a smartphone coaching app to promote home monitoring and behavioral changes associated with hypertension self-management plus a home blood pressure monitor. Control participants received a blood pressure tracking app plus a home blood pressure monitor. 
  Main outcomes and measures:  The primary study outcome was systolic blood pressure at 6 months. Secondary outcomes included self-reported antihypertensive medication adherence, home monitoring and self-management practices, measures of self-efficacy associated with blood pressure, weight, and self-reported health behaviors. 
  Results:  There were 333 participants randomized, and 297 completed the follow-up assessment. Among the participants who completed the study, the mean (SD) age was 58.9 (12.8) years, 182 (61.3%) were women, and 103 (34.7%) were black. Baseline mean (SD) systolic blood pressure was 140.6 (12.2) mm Hg among intervention participants and 141.8 (13.4) mm Hg among control participants. After 6 months, the corresponding mean (SD) systolic blood pressures were 132.3 (15.0) mm Hg and 135.0 (13.9) mm Hg, with a between-group adjusted difference of -2.0 mm Hg (95% CI, -4.9 mm Hg to 0.8 mm Hg; P = .16). At 6 months, self-confidence in controlling blood pressure was greater in the intervention group (0.36 point on a 5-point scale; 95% CI, 0.18 point to 0.54 point; P &lt; .001). There were no significant differences between the 2 groups in other secondary outcomes. The adjusted difference in self-reported physical activity was 26.7 minutes per week (95% CI, -5.4 minutes per week to 58.8 minutes per week; P = .10). Subgroup analysis raised the possibility that intervention effects differed by age. 
  Conclusions and relevance:  Among individuals with uncontrolled hypertension, those randomized to a smartphone coaching app plus home monitor had similar systolic blood pressure compared with those who received a blood pressure tracking app plus home monitor. Given the direction of the difference in systolic blood pressure between groups and the possibility for differences in treatment effects across subgroups, future studies are warranted. 
  Trial registration:  ClinicalTrials.gov Identifier: <a href="http://clinicaltrials.gov/show/NCT03288142" title="See in ClinicalTrials.gov">NCT03288142</a>. 
  |  https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2020.0255  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32119093/  |  
------------------------------------------- 
10.1212/WNL.0000000000009068  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objective:  Genetic diagnosis of muscular dystrophies (MDs) has classically been guided by clinical presentation, muscle biopsy, and muscle MRI data. Muscle MRI suggests diagnosis based on the pattern of muscle fatty replacement. However, patterns overlap between different disorders and knowledge about disease-specific patterns is limited. Our aim was to develop a software-based tool that can recognize muscle MRI patterns and thus aid diagnosis of MDs. 
  Methods:  We collected 976 pelvic and lower limbs T1-weighted muscle MRIs from 10 different MDs. Fatty replacement was quantified using Mercuri score and files containing the numeric data were generated. Random forest supervised machine learning was applied to develop a model useful to identify the correct diagnosis. Two thousand different models were generated and the one with highest accuracy was selected. A new set of 20 MRIs was used to test the accuracy of the model, and the results were compared with diagnoses proposed by 4 specialists in the field. 
  Results:  A total of 976 lower limbs MRIs from 10 different MDs were used. The best model obtained had 95.7% accuracy, with 92.1% sensitivity and 99.4% specificity. When compared with experts on the field, the diagnostic accuracy of the model generated was significantly higher in a new set of 20 MRIs. 
  Conclusion:  Machine learning can help doctors in the diagnosis of muscle dystrophies by analyzing patterns of muscle fatty replacement in muscle MRI. This tool can be helpful in daily clinics and in the interpretation of the results of next-generation sequencing tests. 
  Classification of evidence:  This study provides Class II evidence that a muscle MRI-based artificial intelligence tool accurately diagnoses muscular dystrophies. 
  |  http://www.neurology.org/cgi/pmidlookup?view=long&pmid=32029545  |  
------------------------------------------- 
10.3390/v12030268  |  Epidemiology, Drug Discovery  |  SubfieldA  |  Research  |  ResearchTypeA  |   Migration is associated with HIV-1 vulnerability. 
  Objectives:  To identify long-term trends in HIV-1 molecular epidemiology and antiretroviral drug resistance (ARV) among migrants followed up in Portugal Methods: 5177 patients were included between 2001 and 2017. Rega, Scuel, Comet, and jPHMM algorithms were used for subtyping. Transmitted drug resistance (TDR) and Acquired drug resistance (ADR) were defined as the presence of surveillance drug resistance mutations (SDRMs) and as mutations of the IAS-USA 2015 algorithm, respectively. Statistical analyses were performed. 
  Results:  HIV-1 subtypes infecting migrants were consistent with the ones prevailing in their countries of origin. Over time, overall TDR significantly increased and specifically for Non-nucleoside reverse transcriptase inhibitor (NNRTIs) and Nucleoside reverse transcriptase inhibitor (NRTIs). TDR was higher in patients from Mozambique. Country of origin Mozambique and subtype B were independently associated with TDR. Overall, ADR significantly decreased over time and specifically for NRTIs and Protease Inhibitors (PIs). Age, subtype B, and viral load were independently associated with ADR. 
  Conclusions:  HIV-1 molecular epidemiology in migrants suggests high levels of connectivity with their country of origin. The increasing levels of TDR in migrants could indicate an increase also in their countries of origin, where more efficient surveillance should occur. 
  |  http://www.mdpi.com/resolver?pii=v12030268  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32121161/  |  
------------------------------------------- 
10.1089/omi.2019.0220  |  Treatment, Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Precision/personalized medicine is a hot topic in health care. Often presented with the motto "the right drug, for the right patient, at the right dose, and the right time," precision medicine is a theory for rational therapeutics as well as practice to individualize health interventions (e.g., drugs, food, vaccines, medical devices, and exercise programs) using biomarkers. Yet, an alien visitor to planet Earth reading the contemporary textbooks on diagnostics might think precision medicine requires only two biomolecules omnipresent in the literature: nucleic acids (e.g., DNA) and proteins, known as the first and second alphabet of biology, respectively. However, the precision/personalized medicine community has tended to underappreciate the third alphabet of life, the "sugar code" (i.e., the information stored in glycans, glycoproteins, and glycolipids). This article brings together experts in precision/personalized medicine science, pharmacoglycomics, emerging technology governance, cultural studies, contemporary art, and responsible innovation to critically comment on the sociomateriality of the three alphabets of life together. First, the current transformation of targeted therapies with personalized glycomedicine and glycan biomarkers is examined. Next, we discuss the reasons as to why unraveling of the sugar code might have lagged behind the DNA and protein codes. While social scientists have historically noted the importance of constructivism (e.g., how people interpret technology and build their values, hopes, and expectations into emerging technologies), life scientists relied on the material properties of technologies in explaining why some innovations emerge rapidly and are more popular than others. The concept of sociomateriality integrates these two explanations by highlighting the inherent entanglement of the social and the material contributions to knowledge and what is presented to us as reality from everyday laboratory life. Hence, we present a hypothesis based on a sociomaterial conceptual lens: because materiality and synthesis of glycans are not directly driven by a template, and thus more complex and open ended than sequencing of a finite length genome, social construction of expectations from unraveling of the sugar code versus the DNA code might have evolved differently, as being future-uncertain versus future-proof, respectively, thus potentially explaining the "sugar lag" in precision/personalized medicine diagnostics over the past decades. We conclude by introducing systems scientists, physicians, and biotechnology industry to the concept, practice, and value of responsible innovation, while glycomedicine and other emerging biomarker technologies (e.g., metagenomics and pharmacomicrobiomics) transition to applications in health care, ecology, pharmaceutical/diagnostic industries, agriculture, food, and bioengineering, among others. 
  |  https://www.liebertpub.com/doi/full/10.1089/omi.2019.0220?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  
------------------------------------------- 
10.1016/j.annonc.2020.04.003  |  Diagnosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Preoperative evaluation of the number of lymph node metastasis (LNM) is the basis of individual treatment of locally advanced gastric cancer (LAGC). However, the routinely used preoperative determination method is not accurate enough. 
  Patients and methods:  We enrolled 730 LAGC patients from 5 centers in China and 1 center in Italy, and divided them into 1 primary cohort, 3 external validation cohorts, and 1 international validation cohort. A deep learning radiomic nomogram (DLRN) was built based on the images from multi-phase computed tomography (CT) for preoperatively determining the number of LNM in LAGC. We comprehensively tested the DLRN and compared it with three state-of-the-art methods. Moreover, we investigated the value of the DLRN in survival analysis. 
  Results:  The DLRN showed good discrimination of the number of LNM on all cohorts (overall C-indexes: 0.821, 95% CI: 0.785-0.858 in the primary cohort; 0.797, 95% CI: 0.771-0.823 in the external validation cohorts; and 0.822, 95% CI: 0.756-0.887 in the international validation cohort). The nomogram performed significantly better than the routinely used clinical N stages, tumor size, and clinical model (p&lt;0.05). Besides, DLRN is significantly associated with the overall survival of LAGC patients (n=271). 
  Conclusion:  A deep learning-based radiomic nomogram had good predictive value for LNM in LAGC. In staging-oriented treatment of gastric cancer, this preoperative nomogram could provide baseline information for individual treatment of LAGC. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0923-7534(20)39294-2  |  
------------------------------------------- 
10.1038/s41598-019-56881-2  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   The exposure of germ cells to radiation introduces mutations in the genomes of offspring, and a previous whole-genome sequencing study indicated that the irradiation of mouse sperm induces insertions/deletions (indels) and multisite mutations (clustered single nucleotide variants and indels). However, the current knowledge on the mutation spectra is limited, and the effects of radiation exposure on germ cells at stages other than the sperm stage remain unknown. Here, we performed whole-genome sequencing experiments to investigate the exposure of spermatogonia and mature oocytes. We compared de novo mutations in a total of 24 F1 mice conceived before and after the irradiation of their parents. The results indicated that radiation exposure, 4 Gy of gamma rays, induced 9.6 indels and 2.5 multisite mutations in spermatogonia and 4.7 indels and 3.1 multisite mutations in mature oocytes in the autosomal regions of each F1 individual. Notably, we found two types of deletions, namely, small deletions (mainly 1~12 nucleotides) in non-repeat sequences, many of which showed microhomology at the breakpoint junction, and single-nucleotide deletions in mononucleotide repeat sequences. The results suggest that these deletions and multisite mutations could be a typical signature of mutations induced by parental irradiation in mammals. 
  |  http://dx.doi.org/10.1038/s41598-019-56881-2  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31913321/  |  
------------------------------------------- 
10.1371/journal.pone.0229819  |  Treatment, Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   This large, retrospective case-control study of electronic health records from 56 million unique adult patients examined whether or not treatment with a Tumor Necrosis Factor (TNF) blocking agent is associated with lower risk for Alzheimer's disease (AD) in patients with rheumatoid arthritis (RA), psoriasis, and other inflammatory diseases which are mediated in part by TNF and for which a TNF blocker is an approved treatment. The analysis compared the diagnosis of AD as an outcome measure in patients receiving at least one prescription for a TNF blocking agent (etanercept, adalimumab, and infliximab) or for methotrexate. Adjusted odds ratios (AORs) were estimated using the Cochran-Mantel-Haenszel (CMH) method and presented with 95% confidence intervals (CIs) and p-values. RA was associated with a higher risk for AD (Adjusted Odds Ratio (AOR) = 2.06, 95% Confidence Interval: (2.02-2.10), P-value &lt;0.0001) as did psoriasis (AOR = 1.37 (1.31-1.42), P &lt;0.0001), ankylosing spondylitis (AOR = 1.57 (1.39-1.77), P &lt;0.0001), inflammatory bowel disease (AOR = 2.46 (2.33-2.59), P &lt; 0.0001), ulcerative colitis (AOR = 1.82 (1.74-1.91), P &lt;0.0001), and Crohn's disease (AOR = 2.33 (2.22-2.43), P &lt;0.0001). The risk for AD in patients with RA was lower among patients treated with etanercept (AOR = 0.34 (0.25-0.47), P &lt;0.0001), adalimumab (AOR = 0.28 (0.19-0.39), P &lt; 0.0001), or infliximab (AOR = 0.52 (0.39-0.69), P &lt;0.0001). Methotrexate was also associated with a lower risk for AD (AOR = 0.64 (0.61-0.68), P &lt;0.0001), while lower risk was found in patients with a prescription history for both a TNF blocker and methotrexate. Etanercept and adalimumab also were associated with lower risk for AD in patients with psoriasis: AOR = 0.47 (0.30-0.73 and 0.41 (0.20-0.76), respectively. There was no effect of gender or race, while younger patients showed greater benefit from a TNF blocker than did older patients. This study identifies a subset of patients in whom systemic inflammation contributes to risk for AD through a pathological mechanism involving TNF and who therefore may benefit from treatment with a TNF blocking agent. 
  |  http://dx.plos.org/10.1371/journal.pone.0229819  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32203525/  |  
------------------------------------------- 
10.1007/s00330-020-06699-8  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objectives:  To take advantage of the deep learning algorithms to detect and calculate clot burden of acute pulmonary embolism (APE) on computed tomographic pulmonary angiography (CTPA). 
  Materials and methods:  The training set in this retrospective study consisted of 590 patients (460 with APE and 130 without APE) who underwent CTPA. A fully deep learning convolutional neural network (DL-CNN), called U-Net, was trained for the segmentation of clot. Additionally, an in-house validation set consisted of 288 patients (186 with APE and 102 without APE). In this study, we set different probability thresholds to test the performance of U-Net for the clot detection and selected sensitivity, specificity, and area under the curve (AUC) as the metrics of performance evaluation. Furthermore, we investigated the relationship between the clot burden assessed by the Qanadli score, Mastora score, and other imaging parameters on CTPA and the clot burden calculated by the DL-CNN model. 
  Results:  There was no statistically significant difference in AUCs with the different probability thresholds. When the probability threshold for segmentation was 0.1, the sensitivity and specificity of U-Net in detecting clot respectively were 94.6% and 76.5% while the AUC was 0.926 (95% CI 0.884-0.968). Moreover, this study displayed that the clot burden measured with U-Net was significantly correlated with the Qanadli score (r = 0.819, p &lt; 0.001), Mastora score (r = 0.874, p &lt; 0.001), and right ventricular functional parameters on CTPA. 
  Conclusions:  DL-CNN achieved a high AUC for the detection of pulmonary emboli and can be applied to quantitatively calculate the clot burden of APE patients, which may contribute to reducing the workloads of clinicians. 
  Key points:  • Deep learning can detect APE with a good performance and efficiently calculate the clot burden to reduce the physicians' workload. • Clot burden measured with deep learning highly correlates with Qanadli and Mastora scores of CTPA. • Clot burden measured with deep learning correlates with parameters of right ventricular function on CTPA. 
  |  https://dx.doi.org/10.1007/s00330-020-06699-8  |  
------------------------------------------- 
10.3390/s20082376  |  Robotics, Smart Healthcare  |  SubfieldA  |  Research  |  ResearchTypeA  |   This paper presents a more detailed concept of Human-Robot Interaction systems architecture. One of the main differences between the proposed architecture and other ones is the methodology of information acquisition regarding the robot's interlocutor. In order to obtain as much information as possible before the actual interaction took place, a custom Internet-of-Things-based sensor subsystems connected to Smart Infrastructure was designed and implemented, in order to support the interlocutor identification and acquisition of initial interaction parameters. The Artificial Intelligence interaction framework of the developed robotic system (including humanoid Pepper with its sensors and actuators, additional local, remote and cloud computing services) is being extended with the use of custom external subsystems for additional knowledge acquisition: device-based human identification, visual identification and audio-based interlocutor localization subsystems. These subsystems were deeply introduced and evaluated in this paper, presenting the benefits of integrating them into the robotic interaction system. In this paper a more detailed analysis of one of the external subsystems-Bluetooth Human Identification Smart Subsystem-was also included. The idea, use case, and a prototype, integration of elements of Smart Infrastructure systems and the prototype implementation were performed in a small front office of the Weegree company as a decent test-bed application area. 
  |  http://www.mdpi.com/resolver?pii=s20082376  |  
------------------------------------------- 
10.1007/s11571-019-09541-0  |  Treatment, Robotics  |  SubfieldA  |  Research  |  ResearchTypeA  |   Many studies reported that ERP-based BCIs can provide communication for some people with amyotrophic lateral sclerosis (ALS). ERP-based BCIs often present characters within a matrix that occupies the center of the visual field. However, several studies have identified some concerns with the matrix-based approach. This approach may lead to fatigue and errors resulting from flashing adjacent stimuli, and is impractical for users who might want to use the BCI in tandem with other software or feedback in the center of the monitor. In this paper, we introduce and validate an alternate ERP-based BCI display approach. By presenting stimuli near the periphery of the display, we reduce the adjacency problem and leave the center of the display available for feedback or other applications. Two ERP-based display approaches were tested on 18 ALS patients to: (1) compare performance between a conventional matrix speller paradigm (Matrix-P, mean visual angle 6°) and a new speller paradigm with peripherally distributed stimuli (Peripheral-P, mean visual angle 8.8°); and (2) assess performance while spelling 42 characters online continuously, without a break. In the Peripheral-P condition, 12 subjects attained higher than 80% feedback accuracy during online performance, and 7 of these subjects obtained higher than 90% accuracy. The experimental results showed that the Peripheral-P condition yielded performance comparable to the conventional Matrix-P condition (<i>p </i>&gt; 0.05) in accuracy and information transfer rate. This paper introduces a new display approach that leaves the center of the monitor open for feedback and/or other display elements, such as movies, games, art, or displays from other AAC software or conventional software tools. 
  |  https://dx.doi.org/10.1007/s11571-019-09541-0  |  
------------------------------------------- 
10.1038/s41467-020-14695-1  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   One key aspect of domain-general thought is the ability to integrate information across different cognitive domains. Here, we tested whether kea (Nestor notabilis) can use relative quantities when predicting sampling outcomes, and then integrate both physical information about the presence of a barrier, and social information about the biased sampling of an experimenter, into their predictions. Our results show that kea exhibit three signatures of statistical inference, and therefore can integrate knowledge across different cognitive domains to flexibly adjust their predictions of sampling events. This result provides evidence that true statistical inference is found outside of the great apes, and that aspects of domain-general thinking can convergently evolve in brains with a highly different structure from primates. This has important implications not only for our understanding of how intelligence evolves, but also for research focused on how to create artificial domain-general thought processes. 
  |  http://dx.doi.org/10.1038/s41467-020-14695-1  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32127523/  |  
------------------------------------------- 
10.3390/cancers12020379  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Colorectal cancer treatment has advanced over the past decade. The drug 5-fluorouracil is still used with a wide percentage of patients who do not respond. Therefore, a challenge is the identification of predictive biomarkers. The protein kinase R (PKR also called EIF2AK2) and its regulator, the non-coding pre-mir-nc886, have multiple effects on cells in response to numerous types of stress, including chemotherapy. In this work, we performed an ambispective study with 197 metastatic colon cancer patients with unresectable metastases to determine the relative expression levels of both nc886 and PKR by qPCR, as well as the location of PKR by immunohistochemistry in tumour samples and healthy tissues (plasma and colon epithelium). As primary end point, the expression levels were related to the objective response to first-line chemotherapy following the response evaluation criteria in solid tumours (RECIST) and, as the second end point, with survival at 18 and 36 months. Hierarchical agglomerative clustering was performed to accommodate the heterogeneity and complexity of oncological patients' data. High expression levels of nc886 were related to the response to treatment and allowed to identify clusters of patients. Although the PKR mRNA expression was not associated with chemotherapy response, the absence of PKR location in the nucleolus was correlated with first-line chemotherapy response. Moreover, a relationship between survival and the expression of both PKR and nc886 in healthy tissues was found. Therefore, this work evaluated the best way to analyse the potential biomarkers PKR and nc886 in order to establish clusters of patients depending on the cancer outcomes using algorithms for complex and heterogeneous data. 
  |  http://www.mdpi.com/resolver?pii=cancers12020379  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32045987/  |  
------------------------------------------- 
10.1002/jcla.23054  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Centronuclear myopathy (CNM), a subtype of congenital myopathy (CM), is a group of clinical and genetically heterogeneous muscle disorders. Centronuclear myopathy is a kind of disease difficult to diagnose due to its genetic diversity. Since the discovery of the SPEG gene and disease-causing variants, only a few additional patients have been reported. 
  Methods:  A radiograph test, ultrasonic test, and biochemical tests were applied to clinical diagnosis of CNM. We performed trio medical exome sequencing of the family and conservation analysis to identify variants. 
  Results:  We report a pair of severe CNM twins with the same novel homozygous SPEG variant c. 8710A&gt;G (p.Thr2904Ala) identified by clinical trio medical exome sequencing of the family and conservation analysis. The twins showed clinical symptoms of facial weakness, hypotonia, arthrogryposis, strephenopodia, patent ductus arteriosus, and pulmonary arterial hypertension. 
  Conclusions:  Our report expands the clinical and molecular repertoire of CNM and enriches the variant spectrum of the SPEG gene in the Chinese population and helps us further understand the pathogenesis of CNM. 
  |  https://doi.org/10.1002/jcla.23054  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31625632/  |  
------------------------------------------- 
10.3390/nano10040708  |  Prognosis, Drug Discovery  |  SubfieldA  |  Review  |  ResearchTypeA  |   Transcriptomics data are relevant to address a number of challenges in Toxicogenomics (TGx). After careful planning of exposure conditions and data preprocessing, the TGx data can be used in predictive toxicology, where more advanced modelling techniques are applied. The large volume of molecular profiles produced by omics-based technologies allows the development and application of artificial intelligence (AI) methods in TGx. Indeed, the publicly available omics datasets are constantly increasing together with a plethora of different methods that are made available to facilitate their analysis, interpretation and the generation of accurate and stable predictive models. In this review, we present the state-of-the-art of data modelling applied to transcriptomics data in TGx. We show how the benchmark dose (BMD) analysis can be applied to TGx data. We review read across and adverse outcome pathways (AOP) modelling methodologies. We discuss how network-based approaches can be successfully employed to clarify the mechanism of action (MOA) or specific biomarkers of exposure. We also describe the main AI methodologies applied to TGx data to create predictive classification and regression models and we address current challenges. Finally, we present a short description of deep learning (DL) and data integration methodologies applied in these contexts. Modelling of TGx data represents a valuable tool for more accurate chemical safety assessment. This review is the third part of a three-article series on Transcriptomics in Toxicogenomics. 
  |  http://www.mdpi.com/resolver?pii=nano10040708  |  
-------------------------------------------
10.3390/s20030885  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   The prevalence of micro-holes is widespread in mechanical, electronic, optical, ornaments, micro-fluidic devices, etc. However, monitoring and detection tool wear and tool breakage are imperative to achieve improved hole quality and high productivity in micro-drilling. The various multi-sensor signals are used to monitor the condition of the tool. In this work, the vibration signals and cutting force signals have been applied individually as well as in combination to determine their effectiveness for tool-condition monitoring applications. Moreover, they have been used to determine the best strategies for tool-condition monitoring by prediction of hole quality during micro-drilling operations with 0.4 mm micro-drills. Furthermore, this work also developed an adaptive neuro fuzzy inference system (ANFIS) model using different time domains and wavelet packet features of these sensor signals for the prediction of the hole quality. The best prediction of hole quality was obtained by a combination of different sensor features in wavelet domain of vibration signal. The model's predicted results were found to exert a good agreement with the experimental results. 
  |  http://www.mdpi.com/resolver?pii=s20030885  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32046037/  |  
------------------------------------------- 
10.1016/bs.apcsb.2019.11.013  |  Drug Discovery  |  SubfieldA  |  Review  |  ResearchTypeA  |   In the era of big data, the interplay of artificial and human intelligence is the demanding job to address the concerns involving exchange of decisions between both sides. Drug discovery is one of the key sources of the big data, which involves synergy among various computational methods to achieve a clinical success. Rightful acquisition, mining and analysis of the data related to ligand and targets are crucial to accomplish reliable outcomes in the entire process. Novel designing and screening tactics are necessary to substantiate a potent and efficient lead compounds. Such methods are emphasized and portrayed in the current review targeting protein-ligand and protein-protein interactions involved in various diseases with potential applications. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S1876-1623(19)30094-X  |  
------------------------------------------- 
10.1111/ejn.14724  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   Astrocytes are key players in the regulation of brain development and function. They sense and respond to the surrounding activity by elevating their intracellular calcium (Ca<sup>2+</sup> ) levels. These astrocytic Ca<sup>2+</sup> elevations emerge from different sources and display complex spatio-temporal properties. Ca<sup>2+</sup> elevations are spatially distributed in global (soma and main processes) and/or focal regions (microdomains). The inositol 1,4,5-trisphosphate receptor type 2 knockout (IP<sub>3</sub> R2 KO) mouse model lacks global Ca<sup>2+</sup> elevations in astrocytes, and it has been used by different laboratories. However, the constitutive deletion of IP<sub>3</sub> R2 during development may trigger compensating phenotypes, which could bias the results of experiments using developing or adult mice. To address this issue, we performed a detailed neurodevelopmental evaluation of male and female IP<sub>3</sub> R2 KO mice, during the first 21 days of life, as well as an evaluation of motor function, strength and neurological reflexes in adult mice. Our results show that male and female IP<sub>3</sub> R2 KO mice display a normal acquisition of developmental milestones, as compared with wild-type (WT) mice. We also show that IP<sub>3</sub> R2 KO mice display normal motor coordination, strength and neurological reflexes in adulthood. To exclude a potential compensatory overexpression of other IP<sub>3</sub> Rs, we quantified the relative mRNA levels of all 3 subtypes, in brain tissue. We found that, along with the complete deletion of Itpr2, there is no compensatory expression of Itpr1 or Itrp3. Overall, our results show that the IP<sub>3</sub> R2 KO mouse is a reliable model to study the functional impact of global IP<sub>3</sub> R2-dependent astrocytic Ca<sup>2+</sup> elevations. 
  |  https://doi.org/10.1111/ejn.14724  |  
------------------------------------------- 
10.1007/s11548-019-02057-2  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |    Purpose:  Brain shift during tumor resection can progressively invalidate the accuracy of neuronavigation systems and affect neurosurgeons' ability to achieve optimal resections. This paper compares two methods that have been presented in the literature to compensate for brain shift: a thin-plate spline deformation model and a finite element method (FEM). For this comparison, both methods are driven by identical sparse data. Specifically, both methods are driven by displacements between automatically detected and matched feature points from intraoperative 3D ultrasound (iUS). Both methods have been shown to be fast enough for intraoperative brain shift correction (Machado et al. in Int J Comput Assist Radiol Surg 13(10):1525-1538, 2018; Luo et al. in J Med Imaging (Bellingham) 4(3):035003, 2017). However, the spline method requires no preprocessing and ignores physical properties of the brain while the FEM method requires significant preprocessing and incorporates patient-specific physical and geometric constraints. The goal of this work was to explore the relative merits of these methods on recent clinical data. 
  Methods:  Data acquired during 19 sequential tumor resections in Brigham and Women's Hospital's Advanced Multi-modal Image-Guided Operating Suite between December 2017 and October 2018 were considered for this retrospective study. Of these, 15 cases and a total of 24 iUS to iUS image pairs met inclusion requirements. Automatic feature detection (Machado et al. in Int J Comput Assist Radiol Surg 13(10):1525-1538, 2018) was used to detect and match features in each pair of iUS images. Displacements between matched features were then used to drive both the spline model and the FEM method to compensate for brain shift between image acquisitions. The accuracies of the resultant deformation models were measured by comparing the displacements of manually identified landmarks before and after deformation. 
  Results:  The mean initial subcortical registration error between preoperative MRI and the first iUS image averaged 5.3 ± 0.75 mm. The mean subcortical brain shift, measured using displacements between manually identified landmarks in pairs of iUS images, was 2.5 ± 1.3 mm. Our results showed that FEM was able to reduce subcortical registration error by a small but statistically significant amount (from 2.46 to 2.02 mm). A large variability in the results of the spline method prevented us from demonstrating either a statistically significant reduction in subcortical registration error after applying the spline method or a statistically significant difference between the results of the two methods. 
  Conclusions:  In this study, we observed less subcortical brain shift than has previously been reported in the literature (Frisken et al., in: Miller (ed) Biomechanics of the brain, Springer, Cham, 2019). This may be due to the fact that we separated out the initial misregistration between preoperative MRI and the first iUS image from our brain shift measurements or it may be due to modern neurosurgical practices designed to reduce brain shift, including reduced craniotomy sizes and better control of intracranial pressure with the use of mannitol and other medications. It appears that the FEM method and its use of geometric and biomechanical constraints provided more consistent brain shift correction and better correction farther from the driving feature displacements than the simple spline model. The spline-based method was simpler and tended to give better results for small deformations. However, large variability in the spline results and relatively small brain shift prevented this study from demonstrating a statistically significant difference between the results of the two methods. 
  |  https://dx.doi.org/10.1007/s11548-019-02057-2  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31444624/  |  
------------------------------------------- 
10.1126/science.aaz4439  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Venus has a thick atmosphere that rotates 60 times as fast as the surface, a phenomenon known as super-rotation. We use data obtained from the orbiting Akatsuki spacecraft to investigate how the super-rotation is maintained in the cloud layer, where the rotation speed is highest. A thermally induced latitudinal-vertical circulation acts to homogenize the distribution of the angular momentum around the rotational axis. Maintaining the super-rotation requires this to be counteracted by atmospheric waves and turbulence. Among those effects, thermal tides transport the angular momentum, which maintains the rotation peak, near the cloud top at low latitudes. Other planetary-scale waves and large-scale turbulence act in the opposite direction. We suggest that hydrodynamic instabilities adjust the angular-momentum distribution at mid-latitudes. 
  |  http://www.sciencemag.org/cgi/pmidlookup?view=long&pmid=32327594  |  
------------------------------------------- 
10.1111/aas.13527  |  Prognosis  |  SubfieldA  |  Review  |  ResearchTypeA  |    Background:  Mortality prediction models are applied in the intensive care unit (ICU) to stratify patients into different risk categories and to facilitate benchmarking. To ensure that the correct prediction models are applied for these purposes, the best performing models must be identified. As a first step, we aimed to establish a systematic review of mortality prediction models in critically ill patients. 
  Methods:  Mortality prediction models were searched in four databases using the following criteria: developed for use in adult ICU patients in high-income countries, with mortality as primary or secondary outcome. Characteristics and performance measures of the models were summarized. Performance was presented in terms of discrimination, calibration and overall performance measures presented in the original publication. 
  Results:  In total, 43 mortality prediction models were included in the final analysis. In all, 15 models were only internally validated (35%), 13 externally (30%) and 10 (23%) were both internally and externally validated by the original researchers. Discrimination was assessed in 42 models (98%). Commonly used calibration measures were the Hosmer-Lemeshow test (60%) and the calibration plot (28%). Calibration was not assessed in 11 models (26%). Overall performance was assessed in the Brier score (19%) and the Nagelkerke's R<sup>2</sup> (4.7%). 
  Conclusions:  Mortality prediction models have varying methodology, and validation and performance of individual models differ. External validation by the original researchers is often lacking and head-to-head comparisons are urgently needed to identify the best performing mortality prediction models for guiding clinical care and research in different settings and populations. 
  |  https://doi.org/10.1111/aas.13527  |  
------------------------------------------- 
10.1177/1073110520916994  |  Diagnosis, Prognosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Health care is transitioning from genetics to genomics, in which single-gene testing for diagnosis is being replaced by multi-gene panels, genome-wide sequencing, and other multi-genic tests for disease diagnosis, prediction, prognosis, and treatment. This health care transition is spurring a new set of increased or novel liability risks for health care providers and test laboratories. This article describes this transition in both medical care and liability, and addresses 11 areas of potential increased or novel liability risk, offering recommendations to both health care and legal actors to address and manage those liability risks. 
  |  http://journals.sagepub.com/doi/full/10.1177/1073110520916994?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  
------------------------------------------- 
10.1001/jamanetworkopen.2020.2142  |  Treatment, Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Importance:  Studies have shown that adverse events are associated with increasing inpatient care expenditures, but contemporary data on the association between expenditures and adverse events beyond inpatient care are limited. 
  Objective:  To evaluate whether hospital-specific adverse event rates are associated with hospital-specific risk-standardized 30-day episode-of-care Medicare expenditures for fee-for-service patients discharged with acute myocardial infarction (AMI), heart failure (HF), or pneumonia. 
  Design, setting, and participants:  This cross-sectional study used the 2011 to 2016 hospital-specific risk-standardized 30-day episode-of-care expenditure data from the Centers for Medicare &amp; Medicaid Services and medical record-abstracted in-hospital adverse event data from the Medicare Patient Safety Monitoring System. The setting was acute care hospitals treating at least 25 Medicare fee-for-service patients for AMI, HF, or pneumonia in the United States. Participants were Medicare fee-for-service patients 65 years or older hospitalized for AMI, HF, or pneumonia included in the Medicare Patient Safety Monitoring System in 2011 to 2016. The dates of analysis were July 16, 2017, to May 21, 2018. 
  Main outcomes and measures:  Hospitals' risk-standardized 30-day episode-of-care expenditures and the rate of occurrence of adverse events for which patients were at risk. 
  Results:  The final study sample from 2194 unique hospitals included 44 807 patients (26.1% AMI, 35.6% HF, and 38.3% pneumonia) with a mean (SD) age of 79.4 (8.6) years, and 52.0% were women. The patients represented 84 766 exposures for AMI, 96 917 exposures for HF, and 109 641 exposures for pneumonia. Patient characteristics varied by condition but not by expenditure category. The mean (SD) risk-standardized expenditures were $22 985 ($1579) for AMI, $16 020 ($1416) for HF, and $16 355 ($1995) for pneumonia per hospitalization. The mean risk-standardized rates of occurrence of adverse events for which patients were at risk were 3.5% (95% CI, 3.4%-3.6%) for AMI, 2.5% (95% CI, 2.5%-2.5%) for HF, and 3.0% (95% CI, 2.9%-3.0%) for pneumonia. An increase by 1 percentage point in the rate of occurrence of adverse events was associated with an increase in risk-standardized expenditures of $103 (95% CI, $57-$150) for AMI, $100 (95% CI, $29-$172) for HF, and $152 (95% CI, $73-$232) for pneumonia per discharge. 
  Conclusions and relevance:  Hospitals with high adverse event rates were more likely to have high 30-day episode-of-care Medicare expenditures for patients discharged with AMI, HF, or pneumonia. 
  |  https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2020.2142  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32259263/  |  
------------------------------------------- 
10.1007/s00415-019-09613-5  |  Diagnosis, Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objective:  Posterior circulation ischemic stroke (PCiS) constitutes 20-30% of ischemic stroke cases. Detailed information about differences between PCiS and anterior circulation ischemic stroke (ACiS) remains scarce. Such information might guide clinical decision making and prevention strategies. We studied risk factors and ischemic stroke subtypes in PCiS vs. ACiS and lesion location on magnetic resonance imaging (MRI) in PCiS. 
  Methods:  Out of 3,301 MRIs from 12 sites in the National Institute of Neurological Disorders and Stroke (NINDS) Stroke Genetics Network (SiGN), we included 2,381 cases with acute DWI lesions. The definition of ACiS or PCiS was based on lesion location. We compared the groups using Chi-squared and logistic regression. 
  Results:  PCiS occurred in 718 (30%) patients and ACiS in 1663 (70%). Diabetes and male sex were more common in PCiS vs. ACiS (diabetes 27% vs. 23%, p &lt; 0.05; male sex 68% vs. 58%, p &lt; 0.001). Both were independently associated with PCiS (diabetes, OR = 1.29; 95% CI 1.04-1.61; male sex, OR = 1.46; 95% CI 1.21-1.78). ACiS more commonly had large artery atherosclerosis (25% vs. 20%, p &lt; 0.01) and cardioembolic mechanisms (17% vs. 11%, p &lt; 0.001) compared to PCiS. Small artery occlusion was more common in PCiS vs. ACiS (20% vs. 14%, p &lt; 0.001). Small artery occlusion accounted for 47% of solitary brainstem infarctions. 
  Conclusion:  Ischemic stroke subtypes differ between the two phenotypes. Diabetes and male sex have a stronger association with PCiS than ACiS. Definitive MRI-based PCiS diagnosis aids etiological investigation and contributes additional insights into specific risk factors and mechanisms of injury in PCiS. 
  |  https://dx.doi.org/10.1007/s00415-019-09613-5  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31709475/  |  
------------------------------------------- 
10.1186/s12872-020-01455-8  |  Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Chest pain is one of the most common complaints among patients presenting to the emergency department (ED). Causes of chest pain can be benign or life threatening, making accurate risk stratification a critical issue in the ED. In addition to the use of established clinical scores, prior studies have attempted to create predictive models with heart rate variability (HRV). In this study, we proposed heart rate n-variability (HRnV), an alternative representation of beat-to-beat variation in electrocardiogram (ECG), and investigated its association with major adverse cardiac events (MACE) in ED patients with chest pain. 
  Methods:  We conducted a retrospective analysis of data collected from the ED of a tertiary hospital in Singapore between September 2010 and July 2015. Patients &gt; 20 years old who presented to the ED with chief complaint of chest pain were conveniently recruited. Five to six-minute single-lead ECGs, demographics, medical history, troponin, and other required variables were collected. We developed the HRnV-Calc software to calculate HRnV parameters. The primary outcome was 30-day MACE, which included all-cause death, acute myocardial infarction, and revascularization. Univariable and multivariable logistic regression analyses were conducted to investigate the association between individual risk factors and the outcome. Receiver operating characteristic (ROC) analysis was performed to compare the HRnV model (based on leave-one-out cross-validation) against other clinical scores in predicting 30-day MACE. 
  Results:  A total of 795 patients were included in the analysis, of which 247 (31%) had MACE within 30 days. The MACE group was older, with a higher proportion being male patients. Twenty-one conventional HRV and 115 HRnV parameters were calculated. In univariable analysis, eleven HRV and 48 HRnV parameters were significantly associated with 30-day MACE. The multivariable stepwise logistic regression identified 16 predictors that were strongly associated with MACE outcome; these predictors consisted of one HRV, seven HRnV parameters, troponin, ST segment changes, and several other factors. The HRnV model outperformed several clinical scores in the ROC analysis. 
  Conclusions:  The novel HRnV representation demonstrated its value of augmenting HRV and traditional risk factors in designing a robust risk stratification tool for patients with chest pain in the ED. 
  |  https://bmccardiovascdisord.biomedcentral.com/articles/10.1186/s12872-020-01455-8  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32276602/  |  
------------------------------------------- 
10.1039/d0cs00098a  |  Drug Discovery  |  SubfieldA  |  Review  |  ResearchTypeA  |   Prediction of chemical bioactivity and physical properties has been one of the most important applications of statistical and more recently, machine learning and artificial intelligence methods in chemical sciences. This field of research, broadly known as quantitative structure-activity relationships (QSAR) modeling, has developed many important algorithms and has found a broad range of applications in physical organic and medicinal chemistry in the past 55+ years. This Perspective summarizes recent technological advances in QSAR modeling but it also highlights the applicability of algorithms, modeling methods, and validation practices developed in QSAR to a wide range of research areas outside of traditional QSAR boundaries including synthesis planning, nanotechnology, materials science, biomaterials, and clinical informatics. As modern research methods generate rapidly increasing amounts of data, the knowledge of robust data-driven modelling methods professed within the QSAR field can become essential for scientists working both within and outside of chemical research. We hope that this contribution highlighting the generalizable components of QSAR modeling will serve to address this challenge. 
  |  https://doi.org/10.1039/d0cs00098a  |  
------------------------------------------- 
10.7554/eLife.52951  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   Clones of excitatory neurons derived from a common progenitor have been proposed to serve as elementary information processing modules in the neocortex. To characterize the cell types and circuit diagram of clonally related excitatory neurons, we performed multi-cell patch clamp recordings and Patch-seq on neurons derived from <i>Nestin</i>-positive progenitors labeled by tamoxifen induction at embryonic day 10.5. The resulting clones are derived from two radial glia on average, span cortical layers 2-6, and are composed of a random sampling of transcriptomic cell types. We find an interaction between shared lineage and connection type: related neurons are more likely to be connected vertically across cortical layers, but not laterally within the same layer. These findings challenge the view that related neurons show uniformly increased connectivity and suggest that integration of vertical <i>intra</i>-clonal input with lateral <i>inter</i>-clonal input may represent a developmentally programmed connectivity motif supporting the emergence of functional circuits. 
  |  https://doi.org/10.7554/eLife.52951  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32134385/  |  
------------------------------------------- 
10.1038/s41587-019-0364-z  |  Treatment, Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Tumor DNA sequencing data can be interpreted by computational methods that analyze genomic heterogeneity to infer evolutionary dynamics. A growing number of studies have used these approaches to link cancer evolution with clinical progression and response to therapy. Although the inference of tumor phylogenies is rapidly becoming standard practice in cancer genome analyses, standards for evaluating them are lacking. To address this need, we systematically assess methods for reconstructing tumor subclonality. First, we elucidate the main algorithmic problems in subclonal reconstruction and develop quantitative metrics for evaluating them. Then we simulate realistic tumor genomes that harbor all known clonal and subclonal mutation types and processes. Finally, we benchmark 580 tumor reconstructions, varying tumor read depth, tumor type and somatic variant detection. Our analysis provides a baseline for the establishment of gold-standard methods to analyze tumor heterogeneity. 
  |  https://dx.doi.org/10.1038/s41587-019-0364-z  |  
------------------------------------------- 
10.1016/j.media.2019.101561  |  Diagnosis  |  SubfieldA  |  Review  |  ResearchTypeA  |   Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on "Diabetic Retinopathy - Segmentation and Grading" was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI - 2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal sub-challenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(19)30103-3  |  
------------------------------------------- 
10.1148/radiol.2020201491  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Background COVID-19 and pneumonia of other etiology share similar CT characteristics, contributing to the challenges in differentiating them with high accuracy. Purpose To establish and evaluate an artificial intelligence (AI) system in differentiating COVID-19 and other pneumonia on chest CT and assess radiologist performance without and with AI assistance. Methods 521 patients with positive RT-PCR for COVID-19 and abnormal chest CT findings were retrospectively identified from ten hospitals from January 2020 to April 2020. 665 patients with non-COVID-19 pneumonia and definite evidence of pneumonia on chest CT were retrospectively selected from three hospitals between 2017 and 2019. To classify COVID-19 versus other pneumonia for each patient, abnormal CT slices were input into the EfficientNet B4 deep neural network architecture after lung segmentation, followed by two-layer fully-connected neural network to pool slices together. Our final cohort of 1,186 patients (132,583 CT slices) was divided into training, validation and test sets in a 7:2:1 and equal ratio. Independent testing was performed by evaluating model performance on separate hospitals. Studies were blindly reviewed by six radiologists without and then with AI assistance. Results Our final model achieved a test accuracy of 96% (95% CI: 90-98%), sensitivity 95% (95% CI: 83-100%) and specificity of 96% (95% CI: 88-99%) with Receiver Operating Characteristic (ROC) AUC of 0.95 and Precision-Recall (PR) AUC of 0.90. On independent testing, our model achieved an accuracy of 87% (95% CI: 82-90%), sensitivity of 89% (95% CI: 81-94%) and specificity of 86% (95% CI: 80-90%) with ROC AUC of 0.90 and PR AUC of 0.87. Assisted by the models' probabilities, the radiologists achieved a higher average test accuracy (90% vs. 85%, Δ=5, p&lt;0.001), sensitivity (88% vs. 79%, Δ=9, p&lt;0.001) and specificity (91% vs. 88%, Δ=3, p=0.001). Conclusion AI assistance improved radiologists' performance in distinguishing COVID-19 from non-COVID-19 pneumonia on chest CT. 
  |  http://pubs.rsna.org/doi/10.1148/radiol.2020201491?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  
------------------------------------------- 
10.2196/15022  |  Treatment, Smart Healthcare, Prognosisbiomarker-drug  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Alternative evidence-based cardiac rehabilitation (CR) delivery models that overcome significant barriers to access and delivery are needed to address persistent low utilization. Models utilizing contemporary digital technologies could significantly improve reach and fidelity as complementary alternatives to traditional center-based programs. 
  Objective:  The aim of this study is to compare the effects and costs of the innovative Smartphone Cardiac Rehabilitation, Assisted self-Management (SCRAM) intervention with usual care CR. 
  Methods:  In this investigator-, assessor-, and statistician-blinded parallel 2-arm randomized controlled trial, 220 adults (18+ years) with coronary heart disease are being recruited from 3 hospitals in metropolitan and regional Victoria, Australia. Participants are randomized (1:1) to receive advice to engage with usual care CR or the SCRAM intervention. SCRAM is a 24-week dual-phase intervention that includes 12 weeks of real-time remote exercise supervision and coaching from exercise physiologists, which is followed by 12 weeks of data-driven nonreal-time remote coaching via telephone. Both intervention phases include evidence- and theory-based multifactorial behavior change support delivered via smartphone push notifications. Outcomes assessed at baseline, 12 weeks, and 24 weeks include maximal aerobic exercise capacity (primary outcome at 24 weeks), modifiable cardiovascular risk factors, exercise adherence, secondary prevention self-management behaviors, health-related quality of life, and adverse events. Economic and process evaluations will determine cost-effectiveness and participant perceptions of the treatment arms, respectively. 
  Results:  The trial was funded in November 2017 and received ethical approval in June 2018. Recruitment began in November 2018. As of September 2019, 54 participants have been randomized into the trial. 
  Conclusions:  The innovative multiphase SCRAM intervention delivers real-time remote exercise supervision and evidence-based self-management behavioral support to participants, regardless of their geographic proximity to traditional center-based CR facilities. Our trial will provide unique and valuable information about effects of SCRAM on outcomes associated with cardiac and all-cause mortality, as well as acceptability and cost-effectiveness. These findings will be important to inform health care providers about the potential for innovative program delivery models, such as SCRAM, to be implemented at scale, as a complement to existing CR programs. The inclusion of a cohort comprising metropolitan-, regional-, and rural-dwelling participants will help to understand the role of this delivery model across health care contexts with diverse needs. 
  Trial registration:  Australian New Zealand Clinical Trials Registry (ACTRN): 12618001458224; anzctr.org.au/Trial/Registration/TrialReview.aspx?id=374508. 
  International registered report identifier (irrid):  DERR1-10.2196/15022. 
  |  https://www.researchprotocols.org/2020/1/e15022/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32012103/  |  
------------------------------------------- 
10.1038/s10038-020-0733-y  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Recently, a recessively inherited intronic repeat expansion in replication factor C1 (RFC1) was identified in cerebellar ataxia with neuropathy and bilateral vestibular areflexia syndrome (CANVAS). Here, we describe a Japanese case of genetically confirmed CANVAS with autonomic failure and auditory hallucination. The case showed impaired uptake of iodine-123-metaiodobenzylguanidine and <sup>123</sup>I-ioflupane in the cardiac sympathetic nerve and dopaminergic neurons, respectively, by single-photon emission computed tomography. Long-read sequencing identified biallelic pathogenic (AAGGG)n nucleotide repeat expansion in RFC1 and heterozygous benign (TAAAA)n and (TAGAA)n expansions in brain expressed, associated with NEDD4 (BEAN1). Enrichment of the repeat regions in RFC1 and BEAN1 using a Cas9-mediated system clearly distinguished between pathogenic and benign repeat expansions. The haplotype around RFC1 indicated that the (AAGGG)n expansion in our case was on the same ancestral allele as that of European cases. Thus, long-read sequencing facilitates precise genetic diagnosis of diseases with complex repeat structures and various expansions. 
  |  http://dx.doi.org/10.1038/s10038-020-0733-y  |  
------------------------------------------- 
10.1002/hbm.25023  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Alzheimer's disease (AD) is associated with disruptions in brain activity and networks. However, there is substantial inconsistency among studies that have investigated functional brain alterations in AD; such contradictions have hindered efforts to elucidate the core disease mechanisms. In this study, we aim to comprehensively characterize AD-associated functional brain alterations using one of the world's largest resting-state functional MRI (fMRI) biobank for the disorder. The biobank includes fMRI data from six neuroimaging centers, with a total of 252 AD patients, 221 mild cognitive impairment (MCI) patients and 215 healthy comparison individuals. Meta-analytic techniques were used to unveil reliable differences in brain function among the three groups. Relative to the healthy comparison group, AD was associated with significantly reduced functional connectivity and local activity in the default-mode network, basal ganglia and cingulate gyrus, along with increased connectivity or local activity in the prefrontal lobe and hippocampus (p &lt; .05, Bonferroni corrected). Moreover, these functional alterations were significantly correlated with the degree of cognitive impairment (AD and MCI groups) and amyloid-β burden. Machine learning models were trained to recognize key fMRI features to predict individual diagnostic status and clinical score. Leave-one-site-out cross-validation established that diagnostic status (mean area under the receiver operating characteristic curve: 0.85) and clinical score (mean correlation coefficient between predicted and actual Mini-Mental State Examination scores: 0.56, p &lt; .0001) could be predicted with high accuracy. Collectively, our findings highlight the potential for a reproducible and generalizable functional brain imaging biomarker to aid the early diagnosis of AD and track its progression. 
  |  None  |  
------------------------------------------- 
10.1038/s41598-020-59661-5  |  Diagnosis, Smart Healthcare  |  SubfieldA  |  Research  |  ResearchTypeA  |   With the advent of personalized medicine, there is a movement to develop "smaller" and "smarter" microdevices that are able to distinguish similar cancer subtypes. Tumor cells display major differences when compared to their natural counterparts, due to alterations in fundamental cellular processes such as glycosylation. Glycans are involved in tumor cell biology and they have been considered to be suitable cancer biomarkers. Thus, more selective cancer screening assays can be developed through the detection of specific altered glycans on the surface of circulating cancer cells. Currently, this is only possible through time-consuming assays. In this work, we propose the "intelligent" Lab on Fiber (iLoF) device, that has a high-resolution, and which is a fast and portable method for tumor single-cell type identification and isolation. We apply an Artificial Intelligence approach to the back-scattered signal arising from a trapped cell by a micro-lensed optical fiber. As a proof of concept, we show that iLoF is able to discriminate two human cancer cell models sharing the same genetic background but displaying a different surface glycosylation profile with an accuracy above 90% and a speed rate of 2.3 seconds. We envision the incorporation of the iLoF in an easy-to-operate microchip for cancer identification, which would allow further biological characterization of the captured circulating live cells. 
  |  http://dx.doi.org/10.1038/s41598-020-59661-5  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32081911/  |  
------------------------------------------- 
10.1056/NEJMoa1917130  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Nonophthalmologist physicians do not confidently perform direct ophthalmoscopy. The use of artificial intelligence to detect papilledema and other optic-disk abnormalities from fundus photographs has not been well studied. 
  Methods:  We trained, validated, and externally tested a deep-learning system to classify optic disks as being normal or having papilledema or other abnormalities from 15,846 retrospectively collected ocular fundus photographs that had been obtained with pharmacologic pupillary dilation and various digital cameras in persons from multiple ethnic populations. Of these photographs, 14,341 from 19 sites in 11 countries were used for training and validation, and 1505 photographs from 5 other sites were used for external testing. Performance at classifying the optic-disk appearance was evaluated by calculating the area under the receiver-operating-characteristic curve (AUC), sensitivity, and specificity, as compared with a reference standard of clinical diagnoses by neuro-ophthalmologists. 
  Results:  The training and validation data sets from 6779 patients included 14,341 photographs: 9156 of normal disks, 2148 of disks with papilledema, and 3037 of disks with other abnormalities. The percentage classified as being normal ranged across sites from 9.8 to 100%; the percentage classified as having papilledema ranged across sites from zero to 59.5%. In the validation set, the system discriminated disks with papilledema from normal disks and disks with nonpapilledema abnormalities with an AUC of 0.99 (95% confidence interval [CI], 0.98 to 0.99) and normal from abnormal disks with an AUC of 0.99 (95% CI, 0.99 to 0.99). In the external-testing data set of 1505 photographs, the system had an AUC for the detection of papilledema of 0.96 (95% CI, 0.95 to 0.97), a sensitivity of 96.4% (95% CI, 93.9 to 98.3), and a specificity of 84.7% (95% CI, 82.3 to 87.1). 
  Conclusions:  A deep-learning system using fundus photographs with pharmacologically dilated pupils differentiated among optic disks with papilledema, normal disks, and disks with nonpapilledema abnormalities. (Funded by the Singapore National Medical Research Council and the SingHealth Duke-NUS Ophthalmology and Visual Sciences Academic Clinical Program.). 
  |  http://www.nejm.org/doi/full/10.1056/NEJMoa1917130?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  
------------------------------------------- 
10.1038/s41746-020-0266-y  |  Diagnosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Pulmonary embolism (PE) is a life-threatening clinical problem and computed tomography pulmonary angiography (CTPA) is the gold standard for diagnosis. Prompt diagnosis and immediate treatment are critical to avoid high morbidity and mortality rates, yet PE remains among the diagnoses most frequently missed or delayed. In this study, we developed a deep learning model-PENet, to automatically detect PE on volumetric CTPA scans as an end-to-end solution for this purpose. The PENet is a 77-layer 3D convolutional neural network (CNN) pretrained on the Kinetics-600 dataset and fine-tuned on a retrospective CTPA dataset collected from a single academic institution. The PENet model performance was evaluated in detecting PE on data from two different institutions: one as a hold-out dataset from the same institution as the training data and a second collected from an external institution to evaluate model generalizability to an unrelated population dataset. PENet achieved an AUROC of 0.84 [0.82-0.87] on detecting PE on the hold out internal test set and 0.85 [0.81-0.88] on external dataset. PENet also outperformed current state-of-the-art 3D CNN models. The results represent successful application of an end-to-end 3D CNN model for the complex task of PE diagnosis without requiring computationally intensive and time consuming preprocessing and demonstrates sustained performance on data from an external institution. Our model could be applied as a triage tool to automatically identify clinically important PEs allowing for prioritization for diagnostic radiology interpretation and improved care pathways via more efficient diagnosis. 
  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32352039/  |  
------------------------------------------- 
10.1016/j.cmpb.2019.105153  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background and objectives:  Malignant lymphomas are cancers of the immune system and are characterized by enlarged lymph nodes that typically spread across many different sites. Many different histological subtypes exist, whose diagnosis is typically based on sampling (biopsy) of a single tumor site, whereas total body examinations with computed tomography and positron emission tomography, though not diagnostic, are able to provide a comprehensive picture of the patient. In this work, we exploit a data-driven approach based on multiple-instance learning algorithms and texture analysis features extracted from positron emission tomography, to predict differential diagnosis of the main malignant lymphomas subtypes. 
  Methods:  We exploit a multiple-instance learning setting where support vector machines and random forests are used as classifiers both at the level of single VOIs (instances) and at the level of patients (bags). We present results on two datasets comprising patients that suffer from four different types of malignant lymphomas, namely diffuse large B cell lymphoma, follicular lymphoma, Hodgkin's lymphoma, and mantle cell lymphoma. 
  Results:  Despite the complexity of the task, experimental results show that, with sufficient data samples, some cancer subtypes, such as the Hodgkin's lymphoma, can be identified from texture information: in particular, we achieve a 97.0% of sensitivity (recall) and a 94.1% of predictive positive value (precision) on a dataset that consists in 60 patients. 
  Conclusions:  The presented study indicates that texture analysis features extracted from positron emission tomography, combined with multiple-instance machine learning algorithms, can be discriminating for different malignant lymphomas subtypes. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)30205-6  |  
------------------------------------------- 
10.1002/advs.201902699  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Terahertz (THz) photon detection is of particular appealing for myriad applications, but it still lags behind efficient manipulation with electronics and photonics due to the lack of a suitable principle satisfying both high sensitivity and fast response at room temperature. Here, a new strategy is proposed to overcome these limitations by exploring the photothermoelectric (PTE) effect in an ultrashort (down to 30 nm) channel with black phosphorus as a photoactive material. The preferential flow of hot carriers is enabled by the asymmetric Cr/Au and Ti/Au metallization with the titled-angle evaporation technique. Most intriguingly, orders of magnitude field-enhancement beyond the skin-depth limit and photon absorption across a broadband frequency can be achieved. The PTE detector has excellent sensitivity of 297 V W<sup>-1</sup>, noise equivalent power less than 58 pW/Hz<sup>0.5</sup>, and response time below 0.8 ms, which is superior to other thermal-based detectors at room temperature. A rigorous comparison with existing THz detectors, together with verification by further optical-pumping and imaging experiments, substantiates the importance of the localized field effect in the skin-depth limit. The results allow solid understanding on the role of PTE effect played in the THz photoresponse, opening up new opportunities for developing highly sensitive THz detectors for addressing targeted applications. 
  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32154074/  |  
------------------------------------------- 
10.1002/cti2.1105  |  Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objectives:  T cells play an essential role in controlling the development of B-cell lymphoproliferative disorders (BLPDs), but the dysfunction of T cells in BLPDs largely remains elusive. 
  Methods:  Using multiplexed flow cytometry, we quantified all major subsets of CD4<sup>+</sup> helper T cells (Th) and CD8<sup>+</sup> cytotoxic T cells (Tc) in 94 BLPD patients and 66 healthy controls. Statistics was utilised to rank T-cell signatures that distinguished BLPDs from healthy controls and differentially presented between indolent and aggressive categories. 
  Results:  By comparing with healthy controls, we found that the indolent but not aggressive type of BLPDs demonstrated a high degree of T-cell activation, showing the increase in type I helper T (Th1) cells and follicular B-helper T (Tfh) cells, both of which strongly associated with the enhanced differentiation of exhaustion-like effector cytotoxic CD8<sup>+</sup> T cells expressing PD-1 (Tc exhaustion-like) in indolent BLPDs. Random forest modelling selected a module of T-cell immune signatures best performing binary classification of all BLPD patients. This signature module was composed of low naïve Th cells and high Th1, Tfh and Tc exhaustion-like cells which efficiently identified &gt; 85% indolent cases and was, therefore, assigned as the Indolent Dominant Module of T-cell immune signature. In indolent BLPD patients, a strong bias towards such signatures was found to associate with clinical characteristics of worse prognosis. 
  Conclusion:  Our study identified a prominent signature of T-cell dysregulation specifically for indolent BLPDs, suggesting Th1, Tfh and Tc exhaustion-like cells represent potential prognostic biomarkers and targets for immunotherapies. 
  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31993200/  |  
------------------------------------------- 
10.3988/jcn.2020.16.2.202  |  Diagnosis, Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background and purpose:  Mild cognitive impairment (MCI) is a condition with diverse clinical outcomes and subgroups. Here we investigated the topographic distribution of tau in vivo using the positron emission tomography (PET) tracer [¹⁸F]THK5351 in MCI subgroups. 
  Methods:  This study included 96 participants comprising 38 with amnestic MCI (aMCI), 21 with nonamnestic MCI (naMCI), and 37 with normal cognition (NC) who underwent 3.0-T MRI, [¹⁸F]THK5351 PET, and detailed neuropsychological tests. [¹⁸F]flutemetamol PET was also performed in 62 participants. The aMCI patients were further divided into three groups: 1) verbal-aMCI, only verbal memory impairment; 2) visual-aMCI, only visual memory impairment; and 3) both-aMCI, both visual and verbal memory impairment. Voxel-wise statistical analysis and region-of-interest -based analyses were performed to evaluate the retention of [¹⁸F]THK5351 in the MCI subgroups. Subgroup analysis of amyloid-positive and -negative MCI patients was also performed. Correlations between [¹⁸F]THK5351 retention and different neuropsychological tests were evaluated using statistical parametric mapping analyses. 
  Results:  [¹⁸F]THK5351 retention in the lateral temporal, mesial temporal, parietal, frontal, posterior cingulate cortices and precuneus was significantly greater in aMCI patients than in NC subjects, whereas it did not differ significantly between naMCI and NC participants. [¹⁸F] THK5351 retention was greater in the both-aMCI group than in the verbal-aMCI and visualaMCI groups, and greater in amyloid-positive than amyloid-negative MCI patients. The cognitive function scores were significantly correlated with cortical [¹⁸F]THK5351 retention. 
  Conclusions:  [¹⁸F]THK5351 PET might be useful for identifying distinct topographic patterns of [¹⁸F]THK5351 retention in subgroups of MCI patients who are at greater risk of the progression to Alzheimer's dementia. 
  |  https://thejcn.com/DOIx.php?id=10.3988/jcn.2020.16.2.202  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32319236/  |  
------------------------------------------- 
10.1210/clinem/dgz141  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Context:  Urine steroid metabolomics, combining mass spectrometry-based steroid profiling and machine learning, has been described as a novel diagnostic tool for detection of adrenocortical carcinoma (ACC). 
  Objective, design, setting:  This proof-of-concept study evaluated the performance of urine steroid metabolomics as a tool for postoperative recurrence detection after microscopically complete (R0) resection of ACC. 
  Patients and methods:  135 patients from 14 clinical centers provided postoperative urine samples, which were analyzed by gas chromatography-mass spectrometry. We assessed the utility of these urine steroid profiles in detecting ACC recurrence, either when interpreted by expert clinicians or when analyzed by random forest, a machine learning-based classifier. Radiological recurrence detection served as the reference standard. 
  Results:  Imaging detected recurrent disease in 42 of 135 patients; 32 had provided pre- and post-recurrence urine samples. 39 patients remained disease-free for ≥3 years. The urine "steroid fingerprint" at recurrence resembled that observed before R0 resection in the majority of cases. Review of longitudinally collected urine steroid profiles by 3 blinded experts detected recurrence by the time of radiological diagnosis in 50% to 72% of cases, improving to 69% to 92%, if a preoperative urine steroid result was available. Recurrence detection by steroid profiling preceded detection by imaging by more than 2 months in 22% to 39% of patients. Specificities varied considerably, ranging from 61% to 97%. The computational classifier detected ACC recurrence with superior accuracy (sensitivity = specificity = 81%). 
  Conclusion:  Urine steroid metabolomics is a promising tool for postoperative recurrence detection in ACC; availability of a preoperative urine considerably improves the ability to detect ACC recurrence. 
  |  https://academic.oup.com/jcem/article-lookup/doi/10.1210/clinem/dgz141  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31665449/  |  
------------------------------------------- 
10.1016/j.media.2020.101652  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Detection of early stages of Alzheimer's disease (AD) (i.e., mild cognitive impairment (MCI)) is important to maximize the chances to delay or prevent progression to AD. Brain connectivity networks inferred from medical imaging data have been commonly used to distinguish MCI patients from normal controls (NC). However, existing methods still suffer from limited performance, and classification remains mainly based on single modality data. This paper proposes a new model to automatically diagnosing MCI (early MCI (EMCI) and late MCI (LMCI)) and its earlier stages (i.e., significant memory concern (SMC)) by combining low-rank self-calibrated functional brain networks and structural brain networks for joint multi-task learning. Specifically, we first develop a new functional brain network estimation method. We introduce data quality indicators for self-calibration, which can improve data quality while completing brain network estimation, and perform correlation analysis combined with low-rank structure. Second, functional and structural connected neuroimaging patterns are integrated into our multi-task learning model to select discriminative and informative features for fine MCI analysis. Different modalities are best suited to undertake distinct classification tasks, and similarities and differences among multiple tasks are best determined through joint learning to determine most discriminative features. The learning process is completed by non-convex regularizer, which effectively reduces the penalty bias of trace norm and approximates the original rank minimization problem. Finally, the most relevant disease features classified using a support vector machine (SVM) for MCI identification. Experimental results show that our method achieves promising performance with high classification accuracy and can effectively discriminate between different sub-stages of MCI. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(20)30019-0  |  
------------------------------------------- 
10.1016/j.jcmg.2019.06.027  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objectives:  This study was conducted to investigate the influence of coronary artery calcium (CAC) score on the diagnostic performance of machine-learning-based coronary computed tomography (CT) angiography (cCTA)-derived fractional flow reserve (CT-FFR). 
  Background:  CT-FFR is used reliably to detect lesion-specific ischemia. Novel CT-FFR algorithms using machine-learning artificial intelligence techniques perform fast and require less complex computational fluid dynamics. Yet, influence of CAC score on diagnostic performance of the machine-learning approach has not been investigated. 
  Methods:  A total of 482 vessels from 314 patients (age 62.3 ± 9.3 years, 77% male) who underwent cCTA followed by invasive FFR were investigated from the MACHINE (Machine Learning based CT Angiography derived FFR: a Multi-center Registry) registry data. CAC scores were quantified using the Agatston convention. The diagnostic performance of CT-FFR to detect lesion-specific ischemia was assessed across all Agatston score categories (CAC 0, &gt;0 to &lt;100, 100 to &lt;400, and ≥400) on a per-vessel level with invasive FFR as the reference standard. 
  Results:  The diagnostic accuracy of CT-FFR versus invasive FFR was superior to cCTA alone on a per-vessel level (78% vs. 60%) and per patient level (83% vs. 73%) across all Agatston score categories. No statistically significant differences in the diagnostic accuracy, sensitivity, or specificity of CT-FFR were observed across the categories. CT-FFR showed good discriminatory power in vessels with high Agatston scores (CAC ≥400) and high performance in low-to-intermediate Agatston scores (CAC &gt;0 to &lt;400) with a statistically significant difference in the area under the receiver-operating characteristic curve (AUC) (AUC: 0.71 [95% confidence interval (CI): 0.57 to 0.85] vs. 0.85 [95% CI: 0.82 to 0.89], p = 0.04). CT-FFR showed superior diagnostic value over cCTA in vessels with high Agatston scores (CAC ≥ 400: AUC 0.71 vs. 0.55, p = 0.04) and low-to-intermediate Agatston scores (CAC &gt;0 to &lt;400: AUC 0.86 vs. 0.63, p &lt; 0.001). 
  Conclusions:  Machine-learning-based CT-FFR showed superior diagnostic performance over cCTA alone in CAC with a significant difference in the performance of CT-FFR as calcium burden/Agatston calcium score increased. (Machine Learning Based CT Angiography Derived FFR: a Multicenter, Registry [MACHINE] <a href="http://clinicaltrials.gov/show/NCT02805621" title="See in ClinicalTrials.gov">NCT02805621</a>). 
  |  https://linkinghub.elsevier.com/retrieve/pii/S1936-878X(19)30635-7  |  
------------------------------------------- 
10.1186/s13041-020-00587-4  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Aim:  A hallmark of classical conditioning is that conditioned stimulus (CS) must be tightly coupled with unconditioned stimulus (US), often requiring temporal overlap between the two, or a short gap of several seconds. In this study, we investigate the temporal requirements for fear conditioning association between a strong artificial CS, high-frequency optogenetic activation of inputs into the lateral amygdala of rats, and a foot-shock to the animal with delays up to many minutes. 
  Methods:  AAV-oChIEF-tdTomato viruses were injected into the auditory cortex and the medial geniculate nucleus of rats. An optical fiber was implanted just above the lateral amygdala of the animal. Optogenetic high-frequency stimuli (oHFS; containing five 1-s trains of 100 Hz laser pulses) were delivered to the lateral amygdala, before or after (with varying intervals) a foot-shock that elicits fear responses in the animal. Pre-trained lever-press behavior was used to assess the degree of fear recall by optogenetic test stimuli (OTS; 10 Hz for 2 min) 24 h after the association experiment. 
  Results:  In contrast to the tight temporal requirement for classical conditioning with paired optogenetic moderate-frequency stimuli (oMFS; 10 Hz for 20 s) and foot-shock, oHFS followed by foot-shock with a 5-min or even 1-h (but not 3-h) interval could successfully establish an association to be recalled by OTS the next day. Meanwhile, foot-shock followed by oHFS with a 5-min (but not 1-h) interval could also establish the conditioning. Thus, distant association may be formed between temporally distant stimuli when the CS is strong. 
  |  https://molecularbrain.biomedcentral.com/articles/10.1186/s13041-020-00587-4  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32197621/  |  
------------------------------------------- 
PMID:32060190  |  Smart Healthcare  |  SubfieldA  |  Review  |  ResearchTypeA  |    Objective:  To contrast how Brazil's and Canada's different jurisdictional and judicial realities have led to different types of telemedicine and how further scale and improvement can be achieved. 
  Composition of the committee:  A subgroup of the Besrour Centre of the College of Family Physicians of Canada and Canadian telemedicine experts developed connections with colleagues in Porto Alegre, Brazil, and collaborated to undertake a between-country comparison of their respective telemedicine programs. 
  Methods:  Following a literature review, the authors collectively reflected on their experiences in an attempt to explore the past and current state of telemedicine in Canada and Brazil. 
  Report:  Both Brazil and Canada share expansive geographies, creating substantial barriers to health for rural patients. Telemedicine is an important part of a universal health system. Both countries have achieved telemedicine programs that have scaled up across large regions and are showing important effects on health care costs and outcomes. However, each system is unique in design and implementation and faces unique challenges for further scale and improvement. Addressing regional differences, the normalization of telemedicine, and potential alignment of telemedicine and artificial intelligence technologies for health care are seen as promising approaches to scaling up and improving telemedicine in both countries. 
  Objectif:  Comparer la manière dont les différentes réalités territoriales et judiciaires du Brésil et du Canada ont mené à différents types de télémédecine et déterminer comment l’expansion à plus grande échelle, ainsi que des améliorations peuvent être réalisées. 
  Composition du comité:  Un sous-groupe du Centre Besrour du Collège des médecins de famille du Canada et des experts canadiens en télémédecine ont établi des liens avec des collègues de Porto Alegre, au Brésil, et ont collaboré pour entreprendre une comparaison entre les programmes de télémédecine des deux pays. 
  Méthodes:  Après une revue de la documentation, les auteurs ont fait une réflexion collective sur leurs expériences afin d’explorer l’état passé et actuel de la télémédecine au Canada et au Brésil. 
  Rapport:  Le Brésil et le Canada couvrent tous deux de vastes territoires géographiques, ce qui crée des obstacles importants à la santé des patients des zones rurales. La télémédecine est un élément important d’un système de santé universel. Les deux pays ont mis en place des programmes de télémédecine qui s’étendent sur de vastes régions et qui ont des effets importants sur les coûts des soins et la santé des populations. Toutefois, chaque système est unique dans sa conception et sa mise en œuvre et se heurte à des difficultés particulières qui entravent son expansion. La prise en compte des différences régionales, la normalisation de la télémédecine et l’harmonisation potentielle des technologies de télémédecine et d’intelligence artificielle pour les soins de santé sont considérées comme des approches prometteuses pour le développement et l’amélioration de la télémédecine dans ces deux pays. 
  |  http://www.cfp.ca/cgi/pmidlookup?view=long&pmid=32060190  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32060190/  |  
------------------------------------------- 
10.1155/2020/3658795  |  Smart Healthcare  |  SubfieldA  |  Research  |  ResearchTypeA  |   Recently, brain-machine interfacing is very popular that link humans and artificial devices through brain signals which lead to corresponding mobile application as supplementary. The Android platform has developed rapidly because of its good user experience and openness. Meanwhile, these characteristics of this platform, which cause the amazing pace of Android malware, pose a great threat to this platform and data correction during signal transmission of brain-machine interfacing. Many previous works employ various behavioral characteristics to analyze Android application (or app) and detect Android malware to protect signal data secure. However, with the development of Android app, category of Android app tends to be diverse, and the Android malware behavior tends to be complex. This situation makes existing Android malware detections complicated and inefficient. In this paper, we propose a broad analysis, gathering as many behavior characteristics of an app as possible and compare these behavior characteristics in several metrics. First, we extract static and dynamic behavioral characteristic from Android app in an automatic manner. Second, we explain the decision we made in each kind of behavioral characteristic we choose for Android app analysis and Android malware detection. Third, we design a detailed experiment, which compare the efficiency of each kind of behavior characteristic in different aspects. The results of experiment also show Android malware detection performance of these behavior characteristics combine with well-known machine learning algorithms. 
  |  https://doi.org/10.1155/2020/3658795  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32300372/  |  
------------------------------------------- 
10.1007/s10439-019-02332-y  |  Robotics, Surgery  |  SubfieldA  |  Review  |  ResearchTypeA  |   Robots in orthopedic surgery have been developed rapidly for decades and bring significant benefits to the patients and healthcare providers. However, robotics in fracture reduction remains at the infant stage. As essential components of the current robotic system, external fixators were used in fracture reduction, including the unilateral and Ilizarov-like ring fixators. With emerging of the industrial robots and mechanical arms, their sterilized variants were developed as the serial robots, including the traction device and robotic arm, for fracture reduction. Besides, parallel robots (e.g., Gough-Stewart platform) were devised for lower extremity traction and fracture reduction. After combining the advantages of the serial and parallel mechanisms, hybrid robots can fulfill specific clinical requirements (e.g., the joint fracture, including multiple major fragments). Furthermore, with the aid of intra-operative navigation systems, fracture reduction can be performed under real-time guidance. The paper presents a comprehensive overview of the advancement of the robots in fracture reduction and evaluates research challenges and future perspectives, including ergonomic and economic issues, operation time, artificial realities and intelligence, and telesurgery. 
  |  https://doi.org/10.1007/s10439-019-02332-y  |  
------------------------------------------- 
10.1021/acs.jcim.9b01030  |  Drug Discovery, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Farnesoid X receptor (FXR) agonists can reverse dysregulated bile acid metabolism, and thus, they are potential therapeutics to prevent and treat nonalcoholic fatty liver disease. The low success rate of FXR agonists' R&amp;D and the side effects of clinical candidates such as obeticholic acid make it urgent to discover new chemotypes. Unfortunately, structure-based virtual screening (SBVS) that can speed up drug discovery has rarely been reported with success for FXR, which was likely hindered by the failure in addressing protein flexibility. To address this issue, we devised human FXR (hFXR)-specific ensemble learning models based on pose filters from 24 agonist-bound hFXR crystal structures and coupled them to traditional SBVS approaches of the FRED docking plus Chemgauss4 scoring function. It turned out that the hFXR-specific pose filter ensemble (PFE) was able to improve ligand enrichment significantly, which rendered 3RUT-based SBVS with its PFE the ideal approach for FXR agonist discovery. By screening of the Specs chemical library and in vitro FXR transactivation bioassay, we identified a new class of FXR agonists with compound XJ034 as the representative, which would have been missed if the PFE was not coupled. Following that, we performed in-depth biological studies which demonstrated that XJ034 resulted in a downtrend of intracellular triglyceride in vitro, significantly decreased the serum/liver TG in high fat diet-induced C57BL/6J obese mice, and more importantly, showed metabolic stabilities in both plasma and liver microsomes. To provide insight into further structure-based lead optimization, we solved the crystal structure of hFXR complexed with compound XJ034, uncovering a unique hydrogen bond between compound XJ034 and residue Y375. The current work highlights the power of our pose filter-based ensemble learning approach in terms of scaffold hopping and provides a promising lead compound for further development. 
  |  https://dx.doi.org/10.1021/acs.jcim.9b01030  |  
------------------------------------------- 
10.1038/s41467-020-14649-7  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   Recent studies suggest that attention samples space rhythmically through oscillatory interactions in the frontoparietal network. How these attentional fluctuations coincide with spatial exploration/displacement and exploitation/selection by a dynamic attentional spotlight under top-down control is unclear. Here, we show a direct contribution of prefrontal attention selection mechanisms to a continuous space exploration. Specifically, we provide a direct high spatio-temporal resolution prefrontal population decoding of the covert attentional spotlight. We show that it continuously explores space at a 7-12 Hz rhythm. Sensory encoding and behavioral reports are increased at a specific optimal phase w/ to this rhythm. We propose that this prefrontal neuronal rhythm reflects an alpha-clocked sampling of the visual environment in the absence of eye movements. These attentional explorations are highly flexible, how they spatially unfold depending both on within-trial and across-task contingencies. These results are discussed in the context of exploration-exploitation strategies and prefrontal top-down attentional control. 
  |  http://dx.doi.org/10.1038/s41467-020-14649-7  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32066740/  |  
------------------------------------------- 
10.15252/emmm.201911622  |  Treatment, Drug Discovery  |  SubfieldA  |  Research  |  ResearchTypeA  |   Chemotherapy still constitutes the standard of care for the treatment of most neoplastic diseases. Certain chemotherapeutics from the oncological armamentarium are able to trigger pre-mortem stress signals that lead to immunogenic cell death (ICD), thus inducing an antitumor immune response and mediating long-term tumor growth reduction. Here, we used an established model, built on artificial intelligence to identify, among a library of 50,000 compounds, anticancer agents that, based on their molecular descriptors, were predicted to induce ICD. This algorithm led us to the identification of dactinomycin (DACT, best known as actinomycin D), a highly potent cytotoxicant and ICD inducer that mediates immune-dependent anticancer effects in vivo. Since DACT is commonly used as an inhibitor of DNA to RNA transcription, we investigated whether other experimentally established or algorithm-selected, clinically employed ICD inducers would share this characteristic. As a common leitmotif, a panel of pharmacological ICD stimulators inhibited transcription and secondarily translation. These results establish the inhibition of RNA synthesis as an initial event for ICD induction. 
  |  https://doi.org/10.15252/emmm.201911622  |  
------------------------------------------- 
10.1055/a-1111-2431  |  Epidemiology, Diagnosis, Prognosis, Treatment  |  SubfieldA  |  Review  |  ResearchTypeA  |   This review is intended to present the latest developments in the prevention and treatment of early breast cancer. The risk of breast cancer can be increasingly better characterised with large epidemiological studies on genetic and non-genetic risk factors. Through new analyses, the evidence for high-penetrance genes as well as for low-penetrance genes was able to be improved. New data on denosumab and atezolizumab are available in the neoadjuvant situation as is a pooled appraisal of numerous studies on capecitabine in the curative situation. There is also an update to the overall survival data of pertuzumab in the adjuvant situation with a longer follow-up observation period. Finally, digital medicine is steadily finding its way into science. A recently conducted study on automated breast cancer detection using artificial intelligence establishes the basis for a future review in clinical studies. 
  |  http://www.thieme-connect.com/DOI/DOI?10.1055/a-1111-2431  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32139917/  |  
------------------------------------------- 
10.1053/j.gastro.2020.02.036  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background &amp; aims:  Narrow-band imaging (NBI) can be used to determine whether colorectal polyps are adenomatous or hyperplastic. We investigated whether an artificial intelligence (AI) system can increase the accuracy of characterizations of polyps by endoscopists of different skill levels. 
  Methods:  We developed convolutional neural networks (CNNs) for evaluation of diminutive colorectal polyps, based on efficient neural architecture searches via parameter sharing with augmentation using narrow-band images of diminutive (≤5 mm) polyps, collected from October 2015 through October 2017 at the Seoul National University Hospital, Healthcare System Gangnam Center (training set). We trained the CNN using images from 1100 adenomatous polyps and 1050 hyperplastic polyps from 1379 patients. We then tested the system using 300 images of 180 adenomatous polyps and 120 hyperplastic polyps, obtained from January 2018 to May 2019. We compared the accuracy of 22 endoscopists of different skill levels (7 novices, 4 experts, and 11 NBI-trained experts) vs the CNN in evaluation of images (adenomatous vs hyperplastic) from 180 adenomatous and 120 hyperplastic polyps. The endoscopists then evaluated the polyp images with knowledge of the CNN-processed results. We conducted mixed-effect logistic and linear regression analyses to determine the effects of AI assistance on the accuracy of analysis of diminutive colorectal polyps by endoscopists (primary outcome). 
  Results:  The CNN distinguished adenomatous vs hyperplastic diminutive polyps with 86.7% accuracy, based on histologic analysis as the reference standard. Endoscopists distinguished adenomatous vs hyperplastic diminutive polyps with 82.5% overall accuracy (novices, 73.8% accuracy; experts, 83.8% accuracy; and NBI-trained experts, 87.6% accuracy). With knowledge of the CNN-processed results, the overall accuracy of the endoscopists increased to 88.5% (P&lt;.05). With knowledge of the CNN-processed results, the accuracy of novice endoscopists increased to 85.6% (P&lt;.05). The CNN-processed results significantly reduced endoscopist time of diagnosis (from 3.92 to 3.37 seconds per polyp, P=.042). 
  Conclusions:  We developed a CNN that significantly increases the accuracy of evaluation of diminutive colorectal polyps (as adenomatous vs hyperplastic) and reduces the time of diagnosis by endoscopists. This AI assistance system significantly increased the accuracy of analysis by novice endoscopists, who achieved near-expert levels of accuracy without extra training. The CNN assistance system can reduce the skill-level dependence of endoscopists and costs. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0016-5085(20)30263-8  |  
------------------------------------------- 
10.1016/j.ajo.2020.04.003  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Purpose:  o investigate the association between retinal microstructure and cone- and rod-function in geographic atrophy (GA) secondary to age-related macular degeneration (AMD) using artificial-intelligence-(AI) algorithms. Design; Prospective, observational case series METHODS: Forty-one eyes of 41 patients (75.8±8.4 years; 22 female) from a tertiary referral hospital were included (Directional-Spread-in-Geographic-Atrophy (DSGA) natural history study; <a href="http://clinicaltrials.gov/show/NCT02051998" title="See in ClinicalTrials.gov">NCT02051998</a>). Mesopic, dark-adapted (DA) cyan and red sensitivity were assessed using fundus-controlled perimetry ("microperimetry"); retinal microstructure using spectral-domain optical-coherence-tomography (SD-OCT), fundus autofluorescence (FAF) and near-infrared-reflectance (IR) imaging. Layer-thicknesses and -intensities and FAF- and IR-intensities were extracted for each test-point. We evaluated the cross-validated mean absolute error (MAE) for random-forest-based predictions of retinal sensitivity with and without patient-specific training-data and the increase mean-squared error (%IncMSE) as measure of feature-importance. 
  Results:  Retinal sensitivity was predicted with a MAE of 4.64 dB for mesopic, 4.89 dB for DA cyan and 4.40 dB for DA red testing in absence of patient-specific data. Partial addition of patient-specific sensitivity data to the training sets decreased the MAE to 2.89 dB, 2.86 dB and 2.77 dB. For all three types of testing, the outer nuclear layer-thickness constituted the most important predictive feature (35.0, 42.22 and 53.74 %IncMSE). Spatially-resolved mapping of "inferred sensitivity" revealed regions with differential degrees of mesopic and DA cyan sensitivity loss outside of the GA lesions. 
  Conclusions:  "Inferred sensitivity" accurately reflected retinal function in patients with GA. Mapping of "inferred sensitivity" could facilitate monitoring of disease progression and serve as "quasi functional" surrogate outcome in clinical trials, especially in consideration of retinal regions beyond areas of GA. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0002-9394(20)30170-7  |  
------------------------------------------- 
10.1016/j.cmpb.2019.105059  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background and objective:  With the rapid development of medical imaging and intelligent diagnosis, artificial intelligence methods have become a research hotspot of radiography processing technology in recent years. The low definition of knee magnetic resonance image texture seriously affects the diagnosis of knee osteoarthritis. This paper presents a super-resolution reconstruction method to address this problem. 
  Methods:  In this paper, we propose an efficient medical image super-resolution (EMISR) method, in which we mainly adopted three hidden layers of super-resolution convolution neural network (SRCNN) and a sub-pixel convolution layer of efficient sub-pixel convolution neural network (ESPCN). The addition of the efficient sub-pixel convolutional layer in the hidden layer and the small network replacement consisting of concatenated convolutions to address low-resolution images but not high-resolution images are important. The EMISR method also uses cascaded small convolution kernels to improve reconstruction speed and deepen the convolution neural network to improve reconstruction quality. 
  Results:  The proposed method is tested in the public dataset IDI, and the reconstruction quality of the algorithm is higher than that of the sparse coding-based network (SCN) method, the SRCNN method, and the ESPCN method (+ 2.306 dB, + 2.540 dB, + 1.089 dB improved); moreover, the reconstruction speed is faster than its counterparts (+ 4.272 s, + 1.967 s, and + 0.073 s improved). 
  Conclusion:  The experimental results show that our EMISR framework has improved performance and greatly reduces the number of parameters and training time. Furthermore, the reconstructed image presents more details, and the edges are more complete. Therefore, the EMISR technique provides a more powerful medical analysis in knee osteoarthritis examinations. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)31241-6  |  
------------------------------------------- 
10.1002/hbm.24856  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Thalamic atrophy is a common feature across all forms of FTD but little is known about specific nuclei involvement. We aimed to investigate in vivo atrophy of the thalamic nuclei across the FTD spectrum. A cohort of 402 FTD patients (age: mean(SD) 64.3(8.2) years; disease duration: 4.8(2.8) years) was compared with 104 age-matched controls (age: 62.5(10.4) years), using an automated segmentation of T1-weighted MRIs to extract volumes of 14 thalamic nuclei. Stratification was performed by clinical diagnosis (180 behavioural variant FTD (bvFTD), 85 semantic variant primary progressive aphasia (svPPA), 114 nonfluent variant PPA (nfvPPA), 15 PPA not otherwise specified (PPA-NOS), and 8 with associated motor neurone disease (FTD-MND), genetic diagnosis (27 MAPT, 28 C9orf72, 18 GRN), and pathological confirmation (37 tauopathy, 38 TDP-43opathy, 4 FUSopathy). The mediodorsal nucleus (MD) was the only nucleus affected in all FTD subgroups (16-33% smaller than controls). The laterodorsal nucleus was also particularly affected in genetic cases (28-38%), TDP-43 type A (47%), tau-CBD (44%), and FTD-MND (53%). The pulvinar was affected only in the C9orf72 group (16%). Both the lateral and medial geniculate nuclei were also affected in the genetic cases (10-20%), particularly the LGN in C9orf72 expansion carriers. Use of individual thalamic nuclei volumes provided higher accuracy in discriminating between FTD groups than the whole thalamic volume. The MD is the only structure affected across all FTD groups. Differential involvement of the thalamic nuclei among FTD forms is seen, with a unique pattern of atrophy in the pulvinar in C9orf72 expansion carriers. 
  |  https://doi.org/10.1002/hbm.24856  |  
------------------------------------------- 
10.1016/j.scitotenv.2020.137320  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Predictive capability of landslide susceptibilities is assumed to be varied with different sampling techniques, such as (a) the landslide scarp centroid, (b) centroid of landslide body, (c) samples of the scrap region representing the scarp polygon, and (d) samples of the landslide body representing the entire landslide body. However, new advancements in statistical and machine learning algorithms continuously being updated the landslide susceptibility paradigm. This paper explores the predictive performance power of different sampling techniques in landslide susceptibility mapping in the wake of increased usage of artificial intelligence. We used logistic regression (LR), neural network (NNET), and deep learning neural network (DNN) model for testing and validation of the models. The tests were applied to the 2018 Hokkaido Earthquake affected areas using a set of 11 predictor variables (seismic, topographic, and hydrological). We found that the prediction rates are inconsequential with the DNN model irrespective of the sampling technique (AUC: 0.904 - 0.919). Whereas, testing with LR (AUC: 0.825 - 0.785) and NNET (AUC: 0.882 - 0.858) produces larger differences in the accuracies between the four datasets. Nonetheless, the highest success rates were obtained for samples within the landslide scarp area. The analogy was then validated with a published landslide inventory from the 2015 Gorkha earthquake. We, therefore, suggest that DNN models as an appropriate technique to increase the predictive performance of landslide susceptibilities if the landslide scarp and body are not characterized properly in an inventory. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0048-9697(20)30830-5  |  
------------------------------------------- 
10.1002/adma.202000497  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Bioinspired elastomeric fibrillar surfaces have significant potential as reversible dry adhesives, but their adhesion performance is sensitive to the presence of liquids at the contact interface. Like their models in nature, many artificial mimics can effectively repel water, but fail when low-surface-tension liquids are introduced at the contact interface. A bioinspired fibrillar adhesive surface that is liquid-superrepellent even toward ultralow-surface-tension liquids while retaining its adhesive properties is proposed herein. This surface combines the effective adhesion principle of mushroom-shaped fibrillar arrays with liquid repellency based on double re-entrant fibril tip geometry. The adhesion performance of the proposed microfibril structures is retained even when low-surface-tension liquids are added to the contact interface. The extreme liquid repellency enables real-world applications of fibrillar adhesives for surfaces covered with water, oil, and other liquids. Moreover, fully elastomeric liquid-superrepellent surfaces are mechanically not brittle, highly robust against physical contact, and highly deformable and stretchable, which can increase the real-world uses of such antiwetting surfaces. 
  |  https://doi.org/10.1002/adma.202000497  |  
------------------------------------------- 
10.1038/s41598-020-59541-y  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Modern society characterized by a 24/7 lifestyle leads to misalignment between environmental cycles and endogenous circadian rhythms. Persisting circadian misalignment leads to deleterious effects on health and healthspan. However, the underlying mechanism remains not fully understood. Here, we subjected adult, wild-type mice to distinct chronic jet-lag paradigms, which showed that long-term circadian misalignment induced significant early mortality. Non-biased RNA sequencing analysis using liver and kidney showed marked activation of gene regulatory pathways associated with the immune system and immune disease in both organs. In accordance, we observed enhanced steatohepatitis with infiltration of inflammatory cells. The investigation of senescence-associated immune cell subsets from the spleens and mesenteric lymph nodes revealed an increase in PD-1<sup>+</sup>CD44<sup>high</sup> CD4 T cells as well as CD95<sup>+</sup>GL7<sup>+</sup> germinal center B cells, indicating that the long-term circadian misalignment exacerbates immune senescence and consequent chronic inflammation. Our results underscore immune homeostasis as a pivotal interventional target against clock-related disorders. 
  |  http://dx.doi.org/10.1038/s41598-020-59541-y  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32054990/  |  
------------------------------------------- 
10.2174/0929867327666200408115817  |  Other  |  SubfieldA  |  Review  |  ResearchTypeA  |   Background：Hydrogel has a three-dimensional network structure that is able to absorb large amount of water/liquid and maintain its original structure. Hemicellulose (HC) is the second most abundant polysaccharide after cellulose in plants and a heterogeneous polysaccharide consisting of various saccharide units. The unique physical and chemical properties of hemicellulose make it a promising material for hydrogels. 
  Methods:  This review first summarizes the three research hotspots on the hemicellulose-based hydrogels: intelligence, biodegradability and biocompatibility. Overviews the progress in the fabrication and applications of hemicellulose hydrogels in drug delivery system and tissue engineering (articular cartilage, cell immobilization, and wound dressing). 
  Results:  Hemicellulose-based hydrogels have many unique properties, such as stimuli-responsibility, biodegradability and biocompatibility. Interpenetrating networking can endow appropriate mechanical properties to hydrogels. These properties make the hemicellulose-based hydrogels promising materials in biomedical applications such as drug delivery system and tissue engineering (articular cartilage, cell immobilization, and wound dressing). 
  Conclusion:  Hydrogels have been widely used in biomedicine and tissue engineering areas, such as tissue fillers, drug release agents, enzyme encapsulation, protein electrophoresis, contact lenses, artificial plasma, artificial skin, and tissue engineering scaffold materials. This article reviews the recent progress in the fabrication and applications of hemicellulose-based hydrogels in the biomedical field. 
  |  http://www.eurekaselect.com/180789/article  |  
------------------------------------------- 
10.1002/mp.13986  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Purpose:  Beam orientation selection, whether manual or protocol-based, is the current clinical standard in radiation therapy treatment planning, but it is tedious and can yield suboptimal results. Many algorithms have been designed to optimize beam orientation selection because of its impact on treatment plan quality, but these algorithms suffer from slow calculation of the dose influence matrices of all candidate beams. We propose a fast beam orientation selection method, based on deep learning neural networks (DNN), capable of developing a plan comparable to those developed by the state-of-the-art column generation (CG) method. Our model's novelty lies in its supervised learning structure (using CG to teach the network), DNN architecture, and ability to learn from anatomical features to predict dosimetrically suitable beam orientations without using dosimetric information from the candidate beams. This may save hours of computation. 
  Methods:  A supervised DNN is trained to mimic the CG algorithm, which iteratively chooses beam orientations one-by-one by calculating beam fitness values based on Karush-Kush-Tucker optimality conditions at each iteration. The DNN learns to predict these values. The dataset contains 70 prostate cancer patients - 50 training, 7 validation, and 13 test patients - to develop and test the model. Each patient's data contains 6 contours: PTV, body, bladder, rectum, and left and right femoral heads. Column generation was implemented with a GPU-based Chambolle-Pock algorithm, a first-order primal-dual proximal-class algorithm, to create 6270 plans. The DNN trained over 400 epochs, each with 2500 steps and a batch size of 1, using the Adam optimizer at a learning rate of 1 × 10<sup>-5</sup> and a sixfold cross-validation technique. 
  Results:  The average and standard deviation of training, validation, and testing loss functions among the six folds were 0.62 ± 0.09%, 1.04 ± 0.06%, and 1.44 ± 0.11%, respectively. Using CG and supervised DNN, we generated two sets of plans for each scenario in the test set. The proposed method took at most 1.5 s to select a set of five beam orientations and 300 s to calculate the dose influence matrices for 5 beams and finally 20 s to solve the fluence map optimization (FMO). However, CG needed around 15 h to calculate the dose influence matrices of all beams and at least 400 s to solve both the beam orientation selection and FMO problems. The differences in the dose coverage of PTV between plans generated by CG and by DNN were 0.2%. The average dose differences received by organs at risk were between 1 and 6 percent: Bladder had the smallest average difference in dose received (0.956 ± 1.184%), then Rectum (2.44 ± 2.11%), Left Femoral Head (6.03 ± 5.86%), and Right Femoral Head (5.885 ± 5.515%). The dose received by Body had an average difference of 0.10 ± 0.1% between the generated treatment plans. 
  Conclusions:  We developed a fast beam orientation selection method based on a DNN that selects beam orientations in seconds and is therefore suitable for clinical routines. In the training phase of the proposed method, the model learns the suitable beam orientations based on patients' anatomical features and omits time intensive calculations of dose influence matrices for all possible candidate beams. Solving the FMO to get the final treatment plan requires calculating dose influence matrices only for the selected beams. 
  |  https://doi.org/10.1002/mp.13986  |  
------------------------------------------- 
10.1186/s41199-020-0047-y  |  Prognosis, Treatment  |  SubfieldA  |  Review  |  ResearchTypeA  |   For many years, head and neck squamous cell carcinoma (HNSCC) has been considered as a single entity. However, in the last decades HNSCC complexity and heterogeneity have been recognized. In parallel, high-throughput <i>omics</i> techniques had allowed picturing a larger spectrum of the behavior and characteristics of molecules in cancer and a large set of omics web-based tools and informative repository databases have been developed. The objective of the present review is to provide an overview on biological, prognostic and predictive molecular signatures in HNSCC. To contextualize the selected data, our literature survey includes a short summary of the main characteristics of omics data repositories and web-tools for data analyses. The timeframe of our analysis was fixed, encompassing papers published between January 2015 and January 2019. From more than 1000 papers evaluated, 61 omics studies were selected: 33 investigating mRNA signatures, 11 and 13 related to miRNA and other non-coding-RNA signatures and 4 analyzing DNA methylation signatures. More than half of identified signatures (36) had a prognostic value but only in 10 studies selection of a specific anatomical sub-site (8 oral cavity, 1 oropharynx and 1 both oral cavity and oropharynx) was performed. Noteworthy, although the sample size included in many studies was limited, about one-half of the retrieved studies reported an external validation on independent dataset(s), strengthening the relevance of the obtained data. Finally, we highlighted the development and exploitation of three gene-expression signatures, whose clinical impact on prognosis/prediction of treatment response could be high. Based on this overview on omics<i>-related</i> literature in HNSCC, we identified some limits and strengths. The major limits are represented by the low number of signatures associated to DNA methylation and to non-coding RNA (miRNA, lncRNA and piRNAs) and the availability of a single dataset with multiple omics on more than 500 HNSCC (i.e. TCGA). The major strengths rely on the integration of multiple datasets through meta-analysis approaches and on the growing integration among <i>omics</i> data obtained on the same cohort of patients. Moreover, new approaches based on artificial intelligence and informatic analyses are expected to be available in the next future. 
  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31988797/  |  
------------------------------------------- 
10.3171/2020.1.FOCUS19914  |  Diagnosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objective:  The semiology of cingulate gyrus epilepsy is varied and may involve the paracentral area, the adjacent limbic system, and/or the orbitofrontal gyrus. Invasive electroencephalography (iEEG) recording is usually required for patients with deeply located epileptogenic foci. This paper reports on the authors' experiences in the diagnosis and surgical treatment of patients with focal epilepsy originating in the cingulate gyrus. 
  Methods:  Eighteen patients (median age 24 years, range 5-53 years) with a mean seizure history of 23 years (range 2-32 years) were analyzed retrospectively. The results of presurgical evaluation, surgical strategy, and postoperative pathology are reported, as well as follow-up concerning functional morbidity and seizures (median follow-up 7 years, range 2-12 years). 
  Results:  Patients with cingulate gyrus epilepsy presented with a variety of semiologies and scalp EEG patterns. Prior to ictal onset, 11 (61%) of the patients presented with aura. Initial ictal symptoms included limb posturing in 12 (67%), vocalization in 5, and hypermotor movement in 4. In most patients (n = 16, 89%), ictal EEG presented as widespread patterns with bilateral hemispheric origin, as well as muscle artifacts obscuring the onset of EEG during the ictal period in 11 patients. Among the 18 patients who underwent resection, the pathology revealed mild malformation of cortical development in 2, focal cortical dysplasia (FCD) Ib in 4, FCD IIa in 4, FCD IIb in 4, astrocytoma in 1, ganglioglioma in 1, and gliosis in 2. The seizure outcome after surgery was satisfactory: Engel class IA in 12 patients, IIB in 3, IIIA in 1, IIIB in 1, and IVB in 1 at the 2-year follow-up. 
  Conclusions:  In this study, the authors exploited the improved access to the cingulate epileptogenic network made possible by the use of 3D electrodes implanted using stereoelectroencephalography methodology. Under iEEG recording and intraoperative neuromonitoring, epilepsy surgery on lesions in the cingulate gyrus can result in good outcomes in terms of seizure recurrence and the incidence of postoperative permanent deficits. 
  |  https://thejns.org/doi/10.3171/2020.1.FOCUS19914  |  
------------------------------------------- 
10.1007/s00330-019-06652-4  |  Prognosis, Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Purpose:  This study aimed to validate a deep learning model's diagnostic performance in using computed tomography (CT) to diagnose cervical lymph node metastasis (LNM) from thyroid cancer in a large clinical cohort and to evaluate the model's clinical utility for resident training. 
  Methods:  The performance of eight deep learning models was validated using 3838 axial CT images from 698 consecutive patients with thyroid cancer who underwent preoperative CT imaging between January and August 2018 (3606 and 232 images from benign and malignant lymph nodes, respectively). Six trainees viewed the same patient images (n = 242), and their diagnostic performance and confidence level (5-point scale) were assessed before and after computer-aided diagnosis (CAD) was included. 
  Results:  The overall area under the receiver operating characteristics (AUROC) of the eight deep learning algorithms was 0.846 (range 0.784-0.884). The best performing model was Xception, with an AUROC of 0.884. The diagnostic accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of Xception were 82.8%, 80.2%, 83.0%, 83.0%, and 80.2%, respectively. After introducing the CAD system, underperforming trainees received more help from artificial intelligence than the higher performing trainees (p = 0.046), and overall confidence levels significantly increased from 3.90 to 4.30 (p &lt; 0.001). 
  Conclusion:  The deep learning-based CAD system used in this study for CT diagnosis of cervical LNM from thyroid cancer was clinically validated with an AUROC of 0.884. This approach may serve as a training tool to help resident physicians to gain confidence in diagnosis. 
  Key points:  • A deep learning-based CAD system for CT diagnosis of cervical LNM from thyroid cancer was validated using data from a clinical cohort. The AUROC for the eight tested algorithms ranged from 0.784 to 0.884. • Of the eight models, the Xception algorithm was the best performing model for the external validation dataset with 0.884 AUROC. The accuracy, sensitivity, specificity, positive predictive value, and negative predictive value were 82.8%, 80.2%, 83.0%, 83.0%, and 80.2%, respectively. • The CAD system exhibited potential to improve diagnostic specificity and accuracy in underperforming trainees (3 of 6 trainees, 50.0%). This approach may have clinical utility as a training tool to help trainees to gain confidence in diagnoses. 
  |  https://dx.doi.org/10.1007/s00330-019-06652-4  |  
------------------------------------------- 
10.1158/1078-0432.CCR-19-1376  |  Diagnosis, Treatment, Drug Discovery  |  SubfieldA  |  Research  |  ResearchTypeA  |    Purpose:  Non-small cell lung cancer (NSCLC) is the most common cause of cancer-related deaths worldwide. There is an unmet need to develop novel clinically relevant models of NSCLC to accelerate identification of drug targets and our understanding of the disease. 
  Experimental design:  Thirty surgically resected NSCLC primary patient tissue and 35 previously established patient-derived xenograft (PDX) models were processed for organoid culture establishment. Organoids were histologically and molecularly characterized by cytology and histology, exome sequencing, and RNA-sequencing analysis. Tumorigenicity was assessed through subcutaneous injection of organoids in NOD/SCID mice. Organoids were subjected to drug testing using EGFR, FGFR, and MEK-targeted therapies. 
  Results:  We have identified cell culture conditions favoring the establishment of short-term and long-term expansion of NSCLC organoids derived from primary lung patient and PDX tumor tissue. The NSCLC organoids recapitulated the histology of the patient and PDX tumor. They also retained tumorigenicity, as evidenced by cytologic features of malignancy, xenograft formation, preservation of mutations, copy number aberrations, and gene expression profiles between the organoid and matched parental tumor tissue by whole-exome and RNA sequencing. NSCLC organoid models also preserved the sensitivity of the matched parental tumor to targeted therapeutics, and could be used to validate or discover biomarker-drug combinations. 
  Conclusions:  Our panel of NSCLC organoids closely recapitulates the genomics and biology of patient tumors, and is a potential platform for drug testing and biomarker validation. 
  |  http://clincancerres.aacrjournals.org/cgi/pmidlookup?view=long&pmid=31694835  |  
------------------------------------------- 
10.1186/s12859-020-3430-0  |  Diagnosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Methylated RNA immunoprecipitation sequencing (MeRIP-Seq) is a popular sequencing method for studying RNA modifications and, in particular, for N6-methyladenosine (m6A), the most abundant RNA methylation modification found in various species. The detection of enriched regions is a main challenge of MeRIP-Seq analysis, however current tools either require a long time or do not fully utilize features of RNA sequencing such as strand information which could cause ambiguous calling. On the other hand, with more attention on the treatment experiments of MeRIP-Seq, biologists need intuitive evaluation on the treatment effect from comparison. Therefore, efficient and user-friendly software that can solve these tasks must be developed. 
  Results:  We developed a software named "model-based analysis and inference of MeRIP-Seq (MoAIMS)" to detect enriched regions of MeRIP-Seq and infer signal proportion based on a mixture negative-binomial model. MoAIMS is designed for transcriptome immunoprecipitation sequencing experiments; therefore, it is compatible with different RNA sequencing protocols. MoAIMS offers excellent processing speed and competitive performance when compared with other tools. When MoAIMS is applied to studies of m6A, the detected enriched regions contain known biological features of m6A. Furthermore, signal proportion inferred from MoAIMS for m6A treatment datasets (perturbation of m6A methyltransferases) showed a decreasing trend that is consistent with experimental observations, suggesting that the signal proportion can be used as an intuitive indicator of treatment effect. 
  Conclusions:  MoAIMS is efficient and easy-to-use software implemented in R. MoAIMS can not only detect enriched regions of MeRIP-Seq efficiently but also provide intuitive evaluation on treatment effect for MeRIP-Seq treatment datasets. 
  |  https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-3430-0  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32171255/  |  
------------------------------------------- 
10.1016/j.healthplace.2019.102243  |  Epidemiology  |  SubfieldA  |  Research  |  ResearchTypeA  |   Spatial lifecourse epidemiology is an interdisciplinary field that utilizes advanced spatial, location-based, and artificial intelligence technologies to investigate the long-term effects of environmental, behavioural, psychosocial, and biological factors on health-related states and events and the underlying mechanisms. With the growing number of studies reporting findings from this field and the critical need for public health and policy decisions to be based on the strongest science possible, transparency and clarity in reporting in spatial lifecourse epidemiologic studies is essential. A task force supported by the International Initiative on Spatial Lifecourse Epidemiology (ISLE) identified a need for guidance in this area and developed a Spatial Lifecourse Epidemiology Reporting Standards (ISLE-ReSt) Statement. The aim is to provide a checklist of recommendations to improve and make more consistent reporting of spatial lifecourse epidemiologic studies. The STrengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement for cohort studies was identified as an appropriate starting point to provide initial items to consider for inclusion. Reporting standards for spatial data and methods were then integrated to form a single comprehensive checklist of reporting recommendations. The strength of our approach has been our international and multidisciplinary team of content experts and contributors who represent a wide range of relevant scientific conventions, and our adherence to international norms for the development of reporting guidelines. As spatial, location-based, and artificial intelligence technologies used in spatial lifecourse epidemiology continue to evolve at a rapid pace, it will be necessary to revisit and adapt the ISLE-ReSt at least every 2-3 years from its release. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S1353-8292(19)30635-5  |  
------------------------------------------- 
10.1038/s41746-019-0205-y  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Complex health problems require multi-strategy, multi-target interventions. We present a method that uses machine learning techniques to choose optimal interventions from a set of possible interventions within a case study aiming to increase General Practitioner (GP) discussions of physical activity (PA) with their patients. Interventions were developed based on a causal loop diagram with 26 GPs across 13 clinics in Geelong, Australia. GPs prioritised eight from more than 80 potential interventions to increase GP discussion of PA with patients. Following a 2-week baseline, a multi-arm bandit algorithm was used to assign optimal strategies to GP clinics with the target outcome being GP PA discussion rates. The algorithm was updated weekly and the process iterated until the more promising strategies emerged (a duration of seven weeks). The top three performing strategies were continued for 3 weeks to improve the power of the hypothesis test of effectiveness for each strategy compared to baseline. GPs recorded a total of 11,176 conversations about PA. GPs identified 15 factors affecting GP PA discussion rates with patients including GP skills and awareness, fragmentation of care and fear of adverse outcomes. The two most effective strategies were correctly identified within seven weeks of the algorithm-based assignment of strategies. These were clinic reception staff providing PA information to patients at check in and PA screening questionnaires completed in the waiting room. This study demonstrates an efficient way to test and identify optimal strategies from multiple possible solutions. 
  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31993505/  |  
------------------------------------------- 
10.1002/jmri.27104  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |    Grant support:  This project was funded by the Research Council of Norway. 
  Background:  Oxygen uptake through the gastrointestinal tract after oral administration of oxygenated water in humans is not well studied and is debated in the literature. Due to the paramagnetic properties of oxygen and deoxyhemoglobin, MRI as a technique might be able to detect changes in relaxometry values caused by increased oxygen levels in the blood. 
  Purpose:  To assess whether oxygen dissolved in water is absorbed from the gastrointestinal tract and transported into the bloodstream after oral administration. 
  Study type:  A randomized, double-blinded, placebo-controlled crossover trial. 
  Population/subjects:  Thirty healthy male volunteers age 20-35. 
  Field strength/sequence:  3T/Modified Look-Locker inversion recovery (MOLLI) T<sub>1</sub> -mapping and multi fast field echo (mFFE) T<sub>2</sub> *-mapping. 
  Assessment:  Each volunteer was scanned in two separate sessions. T<sub>1</sub> and T<sub>2</sub> * maps were acquired repeatedly covering the hepatic portal vein (HPV) and vena cava inferior (VCI, control vein) before and after intake of oxygenated or control water. Assessments were done by placing a region of interest in the HPV and VCI. 
  Statistical test:  A mixed linear model was performed to the compare control vs. oxygen group. 
  Results:  Drinking caused a mean 1.6% 95% CI (1.1-2.0% P &lt; 0.001) increase in T<sub>1</sub> of HPV blood and water oxygenation attributed another 0.70% 95% confidence interval (CI) (0.07-1.3% P = 0.028) increase. Oxygenation did not change T<sub>1</sub> in VCI blood. Mean T<sub>2</sub> * increased 9.6% 95% CI (1.7-17.5% P = 0.017) after ingestion of oxygenated water and 1.2% 95% CI (-4.3-6.8% P = 0.661) after ingestion of control water. The corresponding changes in VCI blood were not significant. 
  Data conclusion:  Ingestion of water caused changes in T<sub>1</sub> and T<sub>2</sub> * of HPV blood compatible with dilution due to water absorption. The effects were enhanced by oxygen. Assessment of oxygen enrichment of HPV blood was not possible due to the dilution effect. 
  Level of evidence:  2 TECHNICAL EFFICACY STAGE: 2. 
  |  https://doi.org/10.1002/jmri.27104  |  
------------------------------------------- 
10.2196/17125  |  Diagnosis, Epidemiology  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Coding of underlying causes of death from death certificates is a process that is nowadays undertaken mostly by humans with potential assistance from expert systems, such as the Iris software. It is, consequently, an expensive process that can, in addition, suffer from geospatial discrepancies, thus severely impairing the comparability of death statistics at the international level. The recent advances in artificial intelligence, specifically the rise of deep learning methods, has enabled computers to make efficient decisions on a number of complex problems that were typically considered out of reach without human assistance; they require a considerable amount of data to learn from, which is typically their main limiting factor. However, the CépiDc (Centre d'épidémiologie sur les causes médicales de Décès) stores an exhaustive database of death certificates at the French national scale, amounting to several millions of training examples available for the machine learning practitioner. 
  Objective:  This article investigates the application of deep neural network methods to coding underlying causes of death. 
  Methods:  The investigated dataset was based on data contained from every French death certificate from 2000 to 2015, containing information such as the subject's age and gender, as well as the chain of events leading to his or her death, for a total of around 8 million observations. The task of automatically coding the subject's underlying cause of death was then formulated as a predictive modelling problem. A deep neural network-based model was then designed and fit to the dataset. Its error rate was then assessed on an exterior test dataset and compared to the current state-of-the-art (ie, the Iris software). Statistical significance of the proposed approach's superiority was assessed via bootstrap. 
  Results:  The proposed approach resulted in a test accuracy of 97.8% (95% CI 97.7-97.9), which constitutes a significant improvement over the current state-of-the-art and its accuracy of 74.5% (95% CI 74.0-75.0) assessed on the same test example. Such an improvement opens up a whole field of new applications, from nosologist-level batch-automated coding to international and temporal harmonization of cause of death statistics. A typical example of such an application is demonstrated by recoding French overdose-related deaths from 2000 to 2010. 
  Conclusions:  This article shows that deep artificial neural networks are perfectly suited to the analysis of electronic health records and can learn a complex set of medical rules directly from voluminous datasets, without any explicit prior knowledge. Although not entirely free from mistakes, the derived algorithm constitutes a powerful decision-making tool that is able to handle structured medical data with an unprecedented performance. We strongly believe that the methods developed in this article are highly reusable in a variety of settings related to epidemiology, biostatistics, and the medical sciences in general. 
  |  https://medinform.jmir.org/2020/4/e17125/  |  
------------------------------------------- 
10.1002/mp.14129  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Purpose:  Image-based breast lesion detection is a powerful clinical diagnosis technology. In recent years, deep learning architectures have achieved considerable success in medical image analysis however, they always require large-scale samples. In mammography images, breast lesions are inconspicuous, multiscale, and have blurred edges. Moreover, few well-labeled images exist. Because of these factors, the detection accuracy of conventional deep learning methods is low. Therefore, we attempted to improve the accuracy of mammary lesion detection by introducing transfer learning (TL) into a deep learning framework for the few-shot learning task and thus provide a method that will further assist physicians in detecting breast lesions. 
  Methods:  In this paper, we propose a method called "few-shot learning with deformable convolution for multiscale lesion detection in mammography," named FDMNet. Deformable convolution is introduced for enhancing the network's ability to detect lesions, and the sensitivity of the multiscale feature space is reinforced by using a feature pyramid method. Furthermore, by introducing location information in the predictor, the sensitivity of the model to lesion location is also enhanced. The proposed method, through the TL technique that is applied mines the potentially common knowledge of features in the source domain and transfers it into the target domain to improve the accuracy of breast lesion detection in the few-shot learning task. 
  Results:  On the publicly available datasets for screening mammography CBIS-DDSM and Mini-MIAS, the proposed method performs better than five widely used detection methods. On the CBIS-DDSM dataset, its comprehensive scores, sensitivity, precision, and the mean dice similarity coefficient are 0.911, 0.949, 0.873, and 0.913, respectively, and on the Mini-MIAS dataset, these values are 0.931, 0.966, 0.882, and 0.941, respectively. 
  Conclusions:  To achieve the few-shot learning required for medical image analysis, the proposed method uses TL to execute feature knowledge transformation and includes deformable convolution to build a feature pyramid structure, which enhances the learning performance of the network for lesions. The results of comparative numerical experiments show that the proposed method outperforms some state-of-the-art methods. 
  |  https://doi.org/10.1002/mp.14129  |  
------------------------------------------- 
10.20900/jpbs.20200001  |  Treatment, Smart Healthcare  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  The majority of individuals with Opioid Use Disorder (OUD) do not receive any formal substance use treatment. Due to limited engagement and access to traditional treatment, there is increasing evidence that patients with OUDs turn to online social platforms to access peer support and obtain health-related information about addiction and recovery. Interacting with peers before and during recovery is a key component of many evidence-based addiction recovery programs, and may improve self-efficacy and treatment engagement as well as reduce relapse. Commonly-used online social platforms are limited in utility and scalability as an adjunct to addiction treatment; lack effective content moderation (e.g., misinformed advice, maliciousness or "trolling"); and lack common security and ethical safeguards inherent to clinical care. 
  Methods:  This present study will develop a novel, artificial-intelligence (AI) enabled, mobile treatment delivery method that fulfills the need for a robust, secure, technology-based peer support platform to support patients with OUD. Forty adults receiving outpatient buprenorphine treatment for OUD will be asked to pilot a smartphone-based mobile peer support application, the "Marigold App", for a duration of six weeks. The program will use (1) a prospective cohort study to obtain text message content and feasibility metrics, and (2) qualitative interviews to evaluate usability and acceptability of the mobile platform. 
  Anticipated findings and future directions:  The Marigold mobile platform will allow patients to access a tailored chat support group 24/7 as a complement to different forms of clinical OUD treatment. Marigold can keep groups safe and constructive by augmenting chats with AI tools capable of understanding the emotional sentiment in messages, automatically "flagging" critical or clinically relevant content. This project will demonstrate the robustness of these AI tools by adapting them to catch OUD-specific "flags" in peer messages while also examining the adoptability of the platform itself within OUD patients. 
  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32149192/  |  
------------------------------------------- 
10.2196/15963  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Bone marrow aspiration and biopsy remain the gold standard for the diagnosis of hematological diseases despite the development of flow cytometry (FCM) and molecular and gene analyses. However, the interpretation of the results is laborious and operator dependent. Furthermore, the obtained results exhibit inter- and intravariations among specialists. Therefore, it is important to develop a more objective and automated analysis system. Several deep learning models have been developed and applied in medical image analysis but not in the field of hematological histology, especially for bone marrow smear applications. 
  Objective:  The aim of this study was to develop a deep learning model (BMSNet) for assisting hematologists in the interpretation of bone marrow smears for faster diagnosis and disease monitoring. 
  Methods:  From January 1, 2016, to December 31, 2018, 122 bone marrow smears were photographed and divided into a development cohort (N=42), a validation cohort (N=70), and a competition cohort (N=10). The development cohort included 17,319 annotated cells from 291 high-resolution photos. In total, 20 photos were taken for each patient in the validation cohort and the competition cohort. This study included eight annotation categories: erythroid, blasts, myeloid, lymphoid, plasma cells, monocyte, megakaryocyte, and unable to identify. BMSNet is a convolutional neural network with the YOLO v3 architecture, which detects and classifies single cells in a single model. Six visiting staff members participated in a human-machine competition, and the results from the FCM were regarded as the ground truth. 
  Results:  In the development cohort, according to 6-fold cross-validation, the average precision of the bounding box prediction without consideration of the classification is 67.4%. After removing the bounding box prediction error, the precision and recall of BMSNet were similar to those of the hematologists in most categories. In detecting more than 5% of blasts in the validation cohort, the area under the curve (AUC) of BMSNet (0.948) was higher than the AUC of the hematologists (0.929) but lower than the AUC of the pathologists (0.985). In detecting more than 20% of blasts, the AUCs of the hematologists (0.981) and pathologists (0.980) were similar and were higher than the AUC of BMSNet (0.942). Further analysis showed that the performance difference could be attributed to the myelodysplastic syndrome cases. In the competition cohort, the mean value of the correlations between BMSNet and FCM was 0.960, and the mean values of the correlations between the visiting staff and FCM ranged between 0.952 and 0.990. 
  Conclusions:  Our deep learning model can assist hematologists in interpreting bone marrow smears by facilitating and accelerating the detection of hematopoietic cells. However, a detailed morphological interpretation still requires trained hematologists. 
  |  https://medinform.jmir.org/2020/4/e15963/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32267237/  |  
------------------------------------------- 
10.1055/a-1035-9088  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   <b>Background and study aims</b> Capsule endoscopy (CE) is the preferred method for small bowel (SB) exploration. With a mean number of 50,000 SB frames per video, SBCE reading is time-consuming and tedious (30 to 60 minutes per video). We describe a large, multicenter database named CAD-CAP (Computer-Assisted Diagnosis for CAPsule Endoscopy, CAD-CAP). This database aims to serve the development of CAD tools for CE reading. <b>Materials and methods</b> Twelve French endoscopy centers were involved. All available third-generation SB-CE videos (Pillcam, Medtronic) were retrospectively selected from these centers and deidentified. Any pathological frame was extracted and included in the database. Manual segmentation of findings within these frames was performed by two pre-med students trained and supervised by an expert reader. All frames were then classified by type and clinical relevance by a panel of three expert readers. An automated extraction process was also developed to create a dataset of normal, proofread, control images from normal, complete, SB-CE videos. <b>Results</b> Four-thousand-one-hundred-and-seventy-four SB-CE were included. Of them, 1,480 videos (35 %) containing at least one pathological finding were selected. Findings from 5,184 frames (with their short video sequences) were extracted and delimited: 718 frames with fresh blood, 3,097 frames with vascular lesions, and 1,369 frames with inflammatory and ulcerative lesions. Twenty-thousand normal frames were extracted from 206 SB-CE normal videos. CAD-CAP has already been used for development of automated tools for angiectasia detection and also for two international challenges on medical computerized analysis. 
  |  http://www.thieme-connect.com/DOI/DOI?10.1055/a-1035-9088  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32118115/  |  
------------------------------------------- 
10.3389/fonc.2020.00093  |  Diagnosis, Treatment  |  SubfieldA  |  Review  |  ResearchTypeA  |   <b>Background:</b> Neoadjuvant chemotherapy (NAC) is commonly utilized in preoperative treatment for local breast cancer, and it gives high clinical response rates and can result in pathologic complete response (pCR) in 6-25% of patients. In recent years, dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) has been increasingly used to assess the pathological response of breast cancer to NAC. In present analysis, we assess the diagnostic performance of DCE-MRI in evaluating the pathological response of breast cancer to NAC. <b>Materials and Methods:</b> A systematic search in PubMed, the Cochrane Library, and Web of Science for original studies was performed. The Quality Assessment of Diagnostic Accuracy Studies-2 tool was used to assess the methodological quality of the included studies. Patient, study, and imaging characteristics were extracted, and sufficient data to reconstruct 2 × 2 tables were obtained. Data pooling, heterogeneity testing, forest plot construction, meta-regression analysis and sensitivity analysis were performed using Stata version 12.0 (StataCorp LP, College Station, TX). <b>Results:</b> Eighteen studies (969 patients with breast cancer) were included in the present meta-analysis. The pooled sensitivity and specificity of DCE-MRI were 0.80 (95% confidence interval [CI]: 0.70, 0.88) and 0.84 (95% [CI]: 0.79, 0.88), respectively. Meta-regression analysis found no significant factors affecting heterogeneity. Sensitivity analysis showed that studies that set pathological complete response (pCR) (<i>n</i> = 14) as a responder showed a tendency for higher sensitivity compared with those that set pCR and near pCR together (<i>n</i> = 5) as a responder (0.83 vs. 0.72), and studies (<i>n</i> = 14) that used DCE-MRI to early predict the pathological response of breast cancer had a higher sensitivity (0.83 vs. 0.71) and equivalent specificity (0.80 vs. 0.86) compared to studies (<i>n</i> = 5) that assessed the response after NAC completion. <b>Conclusion:</b> Our results indicated that DCE-MRI could be considered an important auxiliary method for evaluating the pathological response of breast cancer to NAC and used as an effective method for dynamically monitoring the efficacy during NAC. DCE-MRI also performed well in predicting the pCR of breast cancer to NAC. However, due to the heterogeneity of the included studies, caution should be exercised in applying our results. 
  |  https://doi.org/10.3389/fonc.2020.00093  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32117747/  |  
------------------------------------------- 
10.1001/jamanetworkopen.2020.0265  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Importance:  Mammography screening currently relies on subjective human interpretation. Artificial intelligence (AI) advances could be used to increase mammography screening accuracy by reducing missed cancers and false positives. 
  Objective:  To evaluate whether AI can overcome human mammography interpretation limitations with a rigorous, unbiased evaluation of machine learning algorithms. 
  Design, setting, and participants:  In this diagnostic accuracy study conducted between September 2016 and November 2017, an international, crowdsourced challenge was hosted to foster AI algorithm development focused on interpreting screening mammography. More than 1100 participants comprising 126 teams from 44 countries participated. Analysis began November 18, 2016. 
  Main outcomes and measurements:  Algorithms used images alone (challenge 1) or combined images, previous examinations (if available), and clinical and demographic risk factor data (challenge 2) and output a score that translated to cancer yes/no within 12 months. Algorithm accuracy for breast cancer detection was evaluated using area under the curve and algorithm specificity compared with radiologists' specificity with radiologists' sensitivity set at 85.9% (United States) and 83.9% (Sweden). An ensemble method aggregating top-performing AI algorithms and radiologists' recall assessment was developed and evaluated. 
  Results:  Overall, 144 231 screening mammograms from 85 580 US women (952 cancer positive ≤12 months from screening) were used for algorithm training and validation. A second independent validation cohort included 166 578 examinations from 68 008 Swedish women (780 cancer positive). The top-performing algorithm achieved an area under the curve of 0.858 (United States) and 0.903 (Sweden) and 66.2% (United States) and 81.2% (Sweden) specificity at the radiologists' sensitivity, lower than community-practice radiologists' specificity of 90.5% (United States) and 98.5% (Sweden). Combining top-performing algorithms and US radiologist assessments resulted in a higher area under the curve of 0.942 and achieved a significantly improved specificity (92.0%) at the same sensitivity. 
  Conclusions and relevance:  While no single AI algorithm outperformed radiologists, an ensemble of AI algorithms combined with radiologist assessment in a single-reader screening environment improved overall accuracy. This study underscores the potential of using machine learning methods for enhancing mammography screening interpretation. 
  |  https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2020.0265  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32119094/  |  
------------------------------------------- 
10.1007/s00330-020-06856-z  |  Diagnosis, Prognosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objectives:  To develop and evaluate the performance of a deep learning-based system for automatic patellar height measurements using knee radiographs. 
  Methods:  The deep learning-based algorithm was developed with a data set consisting of 1018 left knee radiographs for the prediction of patellar height parameters, specifically the Insall-Salvati index (ISI), Caton-Deschamps index (CDI), modified Caton-Deschamps index (MCDI), and Keerati index (KI). The performance and generalizability of the algorithm were tested with 200 left knee and 200 right knee radiographs, respectively. The intra-class correlation coefficient (ICC), Pearson correlation coefficient, mean absolute difference (MAD), root mean square (RMS), and Bland-Altman plots for predictions by the system were evaluated in comparison with manual measurements as the reference standard. 
  Results:  Compared with the reference standard, the deep learning-based algorithm showed high accuracy in predicting the ISI, CDI, and KI (left knee ICC = 0.91-0.95, r = 0.84-0.91, MAD = 0.02-0.05, RMS = 0.02-0.07; right knee ICC = 0.87-0.96, r = 0.78-0.92, MAD = 0.02-0.06, RMS = 0.02-0.10), but not the MCDI (left knee ICC = 0.65, r = 0.50, MAD = 0.14, RMS = 0.18; right knee ICC = 0.62, r = 0.47, MAD = 0.15, RMS = 0.20). The performance of the algorithm met or exceeded that of manual determination of ISI, CDI, and KI by radiologists. 
  Conclusions:  In its current state, the developed system can predict the ISI, CDI, and KI for both left and right knee radiographs as accurately as radiologists. Training the system further with more data would increase its utility in helping radiologists measure patellar height in clinical practice. 
  Key points:  • Objective and reliable measurement of patellar height parameters is important for clinical diagnosis and the development of a treatment strategy. • Deep learning can be used to create an automatic patellar height measurement system based on knee radiographs. • The deep learning-based patellar height measurement system achieves comparable performance to radiologists in measuring ISI, CDI, and KI. 
  |  https://dx.doi.org/10.1007/s00330-020-06856-z  |  
------------------------------------------- 
10.3389/fonc.2020.00235  |  Prognosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   <b>Purpose:</b> The majority of patients with low-grade gliomas (LGGs) experience tumor-related epilepsy during the disease course. Our study aimed to build a radiomic prediction model for LGG-related epilepsy type based on magnetic resonance imaging (MRI) data. <b>Methods:</b> A total of 205 cases with LGG-related epilepsy were enrolled in the retrospective study and divided into training and validation cohorts (1:1) according to their surgery time. Seven hundred thirty-four radiomic features were extracted from T2-weighted imaging, including six location features. Pearson correlation coefficient, univariate area under curve (AUC) analysis, and least absolute shrinkage and selection operator regression were adopted to select the most relevant features for the epilepsy type to build a radiomic signature. Furthermore, a novel radiomic nomogram was developed for clinical application using the radiomic signature and clinical variables from all patients. <b>Results:</b> Four MRI-based features were selected from the 734 radiomic features, including one location feature. Good discriminative performances were achieved in both training (AUC = 0.859, 95% CI = 0.787-0.932) and validation cohorts (AUC = 0.839, 95% CI = 0.761-0.917) for the type of epilepsy. The accuracies were 80.4 and 80.6%, respectively. The radiomic nomogram also allowed for a high degree of discrimination. All models presented favorable calibration curves and decision curve analyses. <b>Conclusion:</b> Our results suggested that the MRI-based radiomic analysis may predict the type of LGG-related epilepsy to enable individualized therapy for patients with LGG-related epilepsy. 
  |  https://doi.org/10.3389/fonc.2020.00235  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32231995/  |  
------------------------------------------- 
10.1007/s11682-019-00252-y  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |   Vascular cognitive impairment, no dementia (VCIND) refers to cognitive deficits associated with underlying vascular causes that are insufficient to confirm a diagnosis of dementia. The default mode network (DMN) is a large-scale brain network of interacting brain regions involved in attention, working memory and executive function. The role of DMN white matter integrity in cognitive deficits of VCIND patients is unclear. Using diffusion tensor imaging (DTI), this study was carried out to investigate white matter microstructural changes in the DMN in VCIND patients and their contributions to cognitive deficits. Thirty-one patients with subcortical VCIND and twenty-two healthy elderly subjects were recruited. All patients underwent neuropsychological assessments and DTI examination. Voxel-based analyses were performed to extract fractional anisotropy (FA) and mean diffusivity (MD) measures in the DMN. Compared with the healthy elderly subjects, patients diagnosed with subcortical VCIND presented with abnormal white matter integrity in several key hubs of the DMN. The severity of damage in the white matter microstructure in the DMN significantly correlated with cognitive dysfunction. Mediation analyses demonstrated that DTI values could account for attention, executive and language impairments, and partly mediated global cognitive dysfunction in the subcortical VCIND patients. DMN integrity is significantly impaired in subcortical VCIND patients. The disrupted DMN connectivity could explain the attention, language and executive dysfunction, which indicates that the white matter integrity of the DMN may be a neuroimaging marker for VCIND. 
  |  https://dx.doi.org/10.1007/s11682-019-00252-y  |  
------------------------------------------- 
10.1038/s41586-020-2284-y  |  Epidemiology  |  SubfieldA  |  Research  |  ResearchTypeA  |   Sudden, large-scale, and diffuse human migration can amplify localized outbreaks into widespread epidemics.<sup>1-4</sup> Rapid and accurate tracking of aggregate population flows may therefore be epidemiologically informative. Here, we use mobile-phone-data-based counts of 11,478,484 people egressing or transiting through the prefecture of Wuhan between 1 January and 24 January 2020 as they moved to 296 prefectures throughout China. First, we document the efficacy of quarantine in ceasing movement. Second, we show that the distribution of population outflow from Wuhan accurately predicts the relative frequency and geographic distribution of COVID-19 infections through February 19, 2020, across all of China. Third, we develop a spatio-temporal "risk source" model that leverages population flow data (which operationalizes risk emanating from epidemic epicenters) to not only forecast confirmed cases, but also to identify high-transmission-risk locales at an early stage. Fourth, we use this risk source model to statistically derive the geographic spread of COVID-19 and the growth pattern based on the population outflow from Wuhan; the model yields a benchmark trend and an index for assessing COVID-19 community transmission risk over time for different locations. This approach can be used by policy-makers in any nation with available data to make rapid and accurate risk assessments and to plan allocation of limited resources ahead of ongoing outbreaks. 
  |  https://doi.org/10.1038/s41586-020-2284-y  |  
------------------------------------------- 
10.1016/j.brainres.2020.146693  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |   A direct measure of spoken lexical processing based on neuroimaging technology would provide us useful information to understand the neural mechanisms underlying speech or auditory language processing. The neural mechanisms of spoken word segmentation for English as a second language (ESL) learners remain elusive. The present study, using functional near-infrared spectroscopy (fNIRS), addresses this issue by measuring hemodynamic responses in the temporo-parietal junction (TPJ) and the prefrontal cortex (PFC) in a word-spotting task, designed with two task conditions (easy vs. difficult). Thirty participants, divided into a high listening proficiency group (HLG) and a low listening proficiency group (LLG), were tested. Results revealed significantly less TPJ activation in the HLG than in the LLG. Further analyses supported this result by showing that activation in the TPJ was in a negative correlation with listening proficiency. This association appears to be related to the more efficient use of processing resources in a bottom-up fashion for accurate and efficient sensory representations in high proficient language learners. In contrast, cortical activation in the PFC increased with listening proficiency and was stronger in the difficult task condition than in the easy task condition, implying that recruitment of top-down cognitive control functions might play a role in word segmentation. Our results suggest that the combination of the functions mediated via bottom-up sensory input processing (demonstrated in the TPJ activation) and top-down cognitive processing (demonstrated in the PFC activation) are crucial for ESL listeners' spoken word segmentation. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0006-8993(20)30049-4  |  
------------------------------------------- 
10.1186/s12864-020-6542-z  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Read coverage of RNA sequencing data reflects gene expression and RNA processing events. Single-cell RNA sequencing (scRNA-seq) methods, particularly "full-length" ones, provide read coverage of many individual cells and have the potential to reveal cellular heterogeneity in RNA transcription and processing. However, visualization tools suited to highlighting cell-to-cell heterogeneity in read coverage are still lacking. 
  Results:  Here, we have developed Millefy, a tool for visualizing read coverage of scRNA-seq data in genomic contexts. Millefy is designed to show read coverage of all individual cells at once in genomic contexts and to highlight cell-to-cell heterogeneity in read coverage. By visualizing read coverage of all cells as a heat map and dynamically reordering cells based on diffusion maps, Millefy facilitates discovery of "local" region-specific, cell-to-cell heterogeneity in read coverage. We applied Millefy to scRNA-seq data sets of mouse embryonic stem cells and triple-negative breast cancers and showed variability of transcribed regions including antisense RNAs, 3 <sup>'</sup> UTR lengths, and enhancer RNA transcription. 
  Conclusions:  Millefy simplifies the examination of cellular heterogeneity in RNA transcription and processing events using scRNA-seq data. Millefy is available as an R package (https://github.com/yuifu/millefy) and as a Docker image for use with Jupyter Notebook (https://hub.docker.com/r/yuifu/datascience-notebook-millefy). 
  |  https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-6542-z  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32122302/  |  
------------------------------------------- 
10.1089/ast.2019.2129  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   One of Saturn's largest moons, Enceladus, possesses a vast extraterrestrial ocean (<i>i.e.,</i> exo-ocean) that is increasingly becoming the hotspot of future research initiatives dedicated to the exploration of putative life. Here, a new bio-exploration concept design for Enceladus' exo-ocean is proposed, focusing on the potential presence of organisms across a wide range of sizes (<i>i.e.,</i> from uni- to multicellular and animal-like), according to state-of-the-art sensor and robotic platform technologies used in terrestrial deep-sea research. In particular, we focus on combined direct and indirect life-detection capabilities, based on optoacoustic imaging and passive acoustics, as well as molecular approaches. Such biologically oriented sampling can be accompanied by concomitant geochemical and oceanographic measurements to provide data relevant to exo-ocean exploration and understanding. Finally, we describe how this multidisciplinary monitoring approach is currently enabled in terrestrial oceans through cabled (fixed) observatories and their related mobile multiparametric platforms (<i>i.e.,</i> Autonomous Underwater and Remotely Operated Vehicles, as well as crawlers, rovers, and biomimetic robots) and how their modified design can be used for exo-ocean exploration. 
  |  https://www.liebertpub.com/doi/full/10.1089/ast.2019.2129?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  
------------------------------------------- 
10.2196/15411  |  Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Preeclampsia and intrauterine growth restriction are placental dysfunction-related disorders (PDDs) that require a referral decision be made within a certain time period. An appropriate prediction model should be developed for these diseases. However, previous models did not demonstrate robust performances and/or they were developed from datasets with highly imbalanced classes. 
  Objective:  In this study, we developed a predictive model of PDDs by machine learning that uses features at 24-37 weeks' gestation, including maternal characteristics, uterine artery (UtA) Doppler measures, soluble fms-like tyrosine kinase receptor-1 (sFlt-1), and placental growth factor (PlGF). 
  Methods:  A public dataset was taken from a prospective cohort study that included pregnant women with PDDs (66/95, 69%) and a control group (29/95, 31%). Preliminary selection of features was based on a statistical analysis using SAS 9.4 (SAS Institute). We used Weka (Waikato Environment for Knowledge Analysis) 3.8.3 (The University of Waikato, Hamilton, NZ) to automatically select the best model using its optimization algorithm. We also manually selected the best of 23 white-box models. Models, including those from recent studies, were also compared by interval estimation of evaluation metrics. We used the Matthew correlation coefficient (MCC) as the main metric. It is not overoptimistic to evaluate the performance of a prediction model developed from a dataset with a class imbalance. Repeated 10-fold cross-validation was applied. 
  Results:  The classification via regression model was chosen as the best model. Our model had a robust MCC (.93, 95% CI .87-1.00, vs .64, 95% CI .57-.71) and specificity (100%, 95% CI 100-100, vs 90%, 95% CI 90-90) compared to each metric of the best models from recent studies. The sensitivity of this model was not inferior (95%, 95% CI 91-100, vs 100%, 95% CI 92-100). The area under the receiver operating characteristic curve was also competitive (0.970, 95% CI 0.966-0.974, vs 0.987, 95% CI 0.980-0.994). Features in the best model were maternal weight, BMI, pulsatility index of the UtA, sFlt-1, and PlGF. The most important feature was the sFlt-1/PlGF ratio. This model used an M5P algorithm consisting of a decision tree and four linear models with different thresholds. Our study was also better than the best ones among recent studies in terms of the class balance and the size of the case class (66/95, 69%, vs 27/239, 11.3%). 
  Conclusions:  Our model had a robust predictive performance. It was also developed to deal with the problem of a class imbalance. In the context of clinical management, this model may improve maternal mortality and neonatal morbidity and reduce health care costs. 
  |  https://doi.org/10.2196/15411  |  
------------------------------------------- 
10.1016/j.drugalcdep.2019.107716  |  Other  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Data from controlled laboratory experiments in adults indicate that the subjective effects of cannabis vary by administration method (e.g., combustible, vaporized). Whether the subjective effects of cannabis experienced in the natural ecology and among adolescents differ by cannabis administration method is unknown. In this observational study, adolescents' retrospective reports of subjective effects after combustible, edible, and vaporized cannabis use were examined. 
  Methods:  Students from ten public schools in Los Angeles, CA, USA (M[SD] age = 16.1 [.43] years) who reported past 6-month use of combustible, edible, or vaporized cannabis (N = 584) were surveyed on subjective effects experienced after use (yes/no). They were provided with a 12 item self-report checklist of six positive (e.g., relaxed, energetic) and six negative (e.g., drowsy, lazy) subjective effects. For each method of administration, affirmative responses were summed in positive (range: 0-6) and negative (range: 0-6) effect composite scores. 
  Results:  Generalized estimating equations adjusted for demographics and recent cannabis use revealed a graded pattern of differences in positive subjective effects across products, with highest scores for combustible (M[SD] = 3.98[1.76]), followed by edible (M[SD] = 3.58 [2.04]) and vaporized (M[SD] = 3.11 [2.21]) cannabis (all pairwise cross-product contrasts p &lt; .01). Mean negative effect score was highest for edible (M[SD] = 2.27 [1.95]), followed by combustible (M[SD] = 1.94 [1.66]), and vaporized (M[SD] = 1.34 [1.73]) cannabis, respectively (all pairwise contrasts p &lt; .02). 
  Conclusion:  Adolescents' reports of subjective effects varied across cannabis administration methods. Combustible cannabis' more desirable subjective effects profile might be indicative of higher abuse liability. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0376-8716(19)30493-4  |  
------------------------------------------- 
10.3390/s20092489  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Under the conditions of low flow rate and strong noise, the current electromagnetic flowmeter (EMF) cannot satisfy the requirement for measurement or separate the actual flow signal and interference signal accurately. Correlation detection technology can reduce the bandwidth and suppress noise effectively using the periodic transmission of signal and noise randomness. As for the problem that the current anti-interference technology cannot suppress noise effectively, the noise and interference of the electromagnetic flowmeter were analyzed in this paper, and a design of the electromagnetic flowmeter based on differential correlation detection was proposed. Then, in order to verify the feasibility of the electromagnetic flow measurement system based on differential correlation, an experimental platform for the comparison between standard flow and measured flow was established and a verification experiment was carried out under special conditions and with flow calibration measurements. Finally, the data obtained in the experiment were analyzed. The research result showed that an electromagnetic flowmeter based on differential correlation detection satisfies the need for measurement completely. The lower limit of the flow rate of the electromagnetic flowmeter based on the differential correlation principle could reach 0.084 m/s. Under strong external interferences, the electromagnetic flowmeter based on differential correlation had a fluctuation range in output value of only 10 mV. This shows that the electromagnetic flowmeter based on the differential correlation principle has unique advantages in measurements taken under the conditions of strong noise, slurry flow, and low flow rate. 
  |  http://www.mdpi.com/resolver?pii=s20092489  |  
------------------------------------------- 
10.1002/ece3.6147  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Ecological camera traps are increasingly used by wildlife biologists to unobtrusively monitor an ecosystems animal population. However, manual inspection of the images produced is expensive, laborious, and time-consuming. The success of deep learning systems using camera trap images has been previously explored in preliminary stages. These studies, however, are lacking in their practicality. They are primarily focused on extremely large datasets, often millions of images, and there is little to no focus on performance when tasked with species identification in new locations not seen during training. Our goal was to test the capabilities of deep learning systems trained on camera trap images using modestly sized training data, compare performance when considering unseen background locations, and quantify the gradient of lower bound performance to provide a guideline of data requirements in correspondence to performance expectations. We use a dataset provided by Parks Canada containing 47,279 images collected from 36 unique geographic locations across multiple environments. Images represent 55 animal species and human activity with high-class imbalance. We trained, tested, and compared the capabilities of six deep learning computer vision networks using transfer learning and image augmentation: DenseNet201, Inception-ResNet-V3, InceptionV3, NASNetMobile, MobileNetV2, and Xception. We compare overall performance on "trained" locations where DenseNet201 performed best with 95.6% top-1 accuracy showing promise for deep learning methods for smaller scale research efforts. Using trained locations, classifications with &lt;500 images had low and highly variable recall of 0.750 ± 0.329, while classifications with over 1,000 images had a high and stable recall of 0.971 ± 0.0137. Models tasked with classifying species from untrained locations were less accurate, with DenseNet201 performing best with 68.7% top-1 accuracy. Finally, we provide an open repository where ecologists can insert their image data to train and test custom species detection models for their desired ecological domain. 
  |  https://doi.org/10.1002/ece3.6147  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32274005/  |  
------------------------------------------- 
10.1016/j.cmpb.2019.105162  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background and objective:  In most patients presenting with respiratory symptoms, the findings of chest radiography play a key role in the diagnosis, management, and follow-up of the disease. Consolidation is a common term in radiology, which indicates focally increased lung density. When the alveolar structures become filled with pus, fluid, blood cells or protein subsequent to a pulmonary pathological process, it may result in different types of lung opacity in chest radiograph. This study aims at detecting consolidations in chest x-ray radiographs, with a certain precision, using artificial intelligence and especially Deep Convolutional Neural Networks to assist radiologist for better diagnosis. 
  Methods:  Medical image datasets usually are relatively small to be used for training a Deep Convolutional Neural Network (DCNN), so transfer learning technique with well-known DCNNs pre-trained with ImageNet dataset are used to improve the accuracy of the models. ImageNet feature space is different from medical images and in the other side, the well-known DCNNs are designed to achieve the best performance on ImageNet. Therefore, they cannot show their best performance on medical images. To overcome this problem, we designed a problem-based architecture which preserves the information of images for detecting consolidation in Pediatric Chest X-ray dataset. We proposed a three-step pre-processing approach to enhance generalization of the models. To demonstrate the correctness of numerical results, an occlusion test is applied to visualize outputs of the model and localize the detected appropriate area. A different dataset as an extra validation is used in order to investigate the generalization of the proposed model. 
  Results:  The best accuracy to detect consolidation is 94.67% obtained by our problem based architecture for the understudy dataset which outperforms the previous works and the other architectures. 
  Conclusions:  The designed models can be employed as computer aided diagnosis tools in real practice. We critically discussed the datasets and the previous works based on them and show that without some considerations the results of them may be misleading. We believe, the output of AI should be only interpreted as focal consolidation. The clinical significance of the finding can not be interpreted without integration of clinical data. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)30696-0  |  
------------------------------------------- 
10.1111/den.13688  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objectives:  Detecting early gastric cancer is difficult, and it may even be overlooked by experienced endoscopists. Recently, artificial intelligence based on deep learning through convolutional neural networks (CNNs) has enabled significant advancements in the field of gastroenterology. However, it remains unclear whether a CNN can outperform endoscopists. In this study, we evaluated whether the performance of a CNN in detecting early gastric cancer is better than that of endoscopists. 
  Methods:  The CNN was constructed using 13,584 endoscopic images from 2,639 lesions of gastric cancer. Subsequently, its diagnostic ability was compared to that of 67 endoscopists using an independent test dataset (2,940 images from 140 cases). 
  Results:  The average diagnostic time for analyzing 2,940 test endoscopic images by the CNN and endoscopists were 45.5 ± 1.8 s and 173.0 ± 66.0 min, respectively. The sensitivity, specificity, and positive and negative predictive values for the CNN were 58.4%, 87.3%, 26.0%, and 96.5%, respectively. These values for the 67 endoscopists were 31.9%, 97.2%, 46.2%, and 94.9%, respectively. The CNN had a significantly higher sensitivity than the endoscopists (by 26.5%; 95% confidence interval, 14.9-32.5%). 
  Conclusion:  The CNN detected more early gastric cancer cases in a shorter time than the endoscopists. The CNN needs further training to achieve higher diagnostic accuracy. However, a diagnostic support tool for gastric cancer using a CNN will be realized in the near future. 
  |  https://doi.org/10.1111/den.13688  |  
------------------------------------------- 
10.3390/s20010293  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   To generate indoor as-built building information models (AB BIMs) automatically and economically is a great technological challenge. Many approaches have been developed to address this problem in recent years, but it is far from being settled, particularly for the point cloud segmentation and the extraction of the relationship among different elements due to the complicated indoor environment. This is even more difficult for the low-quality point cloud generated by low-cost scanning equipment. This paper proposes an automatic as-built BIMs generation framework that transforms the noisy 3D point cloud produced by a low-cost RGB-D sensor (about 708 USD for data collection equipment, 379 USD for the Structure sensor and 329 USD for iPad) to the as-built BIMs, without any manual intervention. The experiment results show that the proposed method has competitive robustness and accuracy, compared to the high-quality Terrestrial Lidar System (TLS), with the element extraction accuracy of 100%, mean dimension reconstruction accuracy of 98.6% and mean area reconstruction accuracy of 93.6%. Also, the proposed framework makes the BIM generation workflows more efficient in both data collection and data processing. In the experiments, the time consumption of data collection for a typical room, with an area of 45-67 m 2 , is reduced to 4-6 min with an RGB-D sensor from 50-60 min with TLS. The processing time to generate BIM models is about half minutes automatically, from around 10 min with a conventional semi-manual method. 
  |  http://www.mdpi.com/resolver?pii=s20010293  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31948010/  |  
------------------------------------------- 
10.1097/MLR.0000000000001221  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objective:  Experts cautioned that patients affected by the November 2010 withdrawal of the opioid analgesic propoxyphene might receive riskier prescriptions. To explore this, we compared drug receipts and outcomes among propoxyphene users before and aftermarket withdrawal. 
  Study design:  Using OptumLabs data, we studied 3 populations: commercial, Medicare Advantage (MA) aged (age 65+ y) and MA disabled (age below 65 y) enrollees. The exposed enrollees received propoxyphene in the 3 months before market withdrawal (n=13,622); historical controls (unexposed) received propoxyphene 1 year earlier (n=9971). Regression models estimated daily milligrams morphine equivalent (MME), daily prescription acetaminophen dose, potentially toxic acetaminophen doses, nonopioid prescription analgesics receipt, emergency room visits, and diagnosed falls, motor vehicle accidents, and hip fractures. 
  Principal findings:  Aged MA enrollees illustrate the experience of all 3 populations examined. Following the market withdrawal, propoxyphene users in the exposed cohort experienced an abrupt decline of 69% in average daily MME, compared with a 14% decline in the unexposed. Opioids were discontinued by 34% of the exposed cohort and 18% of the unexposed. Tramadol and hydrocodone were the most common opioids substituted for propoxyphene. The proportion of each group receiving ≥4 g of prescription acetaminophen per day decreased from 12% to 2% in the exposed group but increased from 6% to 8% among the unexposed. Adverse events were rare and not significantly different in exposed versus unexposed groups. 
  Conclusions:  After propoxyphene market withdrawal, many individuals experienced abrupt discontinuation of opioids. Policymakers might consider supporting appropriate treatment transitions and monitoring responses following drug withdrawals. 
  |  http://dx.doi.org/10.1097/MLR.0000000000001221  |  
------------------------------------------- 
10.1111/nyas.14320  |  Other  |  SubfieldA  |  Review  |  ResearchTypeA  |   Visual perception involves the rapid formation of a coarse image representation at the onset of visual processing, which is iteratively refined by late computational processes. These early versus late time windows approximately map onto feedforward and feedback processes, respectively. State-of-the-art convolutional neural networks, the main engine behind recent machine vision successes, are feedforward architectures. Their successes and limitations provide critical information regarding which visual tasks can be solved by purely feedforward processes and which require feedback mechanisms. We provide an overview of recent work in cognitive neuroscience and machine vision that highlights the possible role of feedback processes for both visual recognition and beyond. We conclude by discussing important open questions for future research. 
  |  https://doi.org/10.1111/nyas.14320  |  
------------------------------------------- 
PMID:32355515  |  Prognosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Colorectal cancer (CRC) is one of the most common malignancies, with varying prognoses and a high mortality. There is an urgent need to establish a new prediction model to predict the survival risk of CRC patients. The long non-coding RNAs (lncRNAs) expression profiles and corresponding clinical information of CRC patients were obtained from The Cancer Genome Atlas, TCGA. We identified a total of 1,176 lncRNAs differentially expressed between 480 CRC and 41 normal tissues. In the training test, we combined these differentially expressed lncRNAs with overall survival of CRC patients. Six lncRNAs (AL356270.1, LINC02257, AC020891.2, LINC01485, AC083967.1 and RBAKDN) were finally screened out by using LASSO regression mode to establish a novel prediction model as a prognostic indicator for CRC patients. The area under the curve (AUC) of 3- and 5-year ROC analysis in CRC were 0.6923 and 0.7328 for training set, and were 0.6803 and 0.7035 for testing set, respectively. K-M analysis revealed a significant difference between high risk and low risk in the training set (<i>P</i>-value = 5.0e-05) and testing set (<i>P</i>-value = 0.00052), respectively. Our study shows that the six lncRNAs model can improve the survival prediction mechanism of patients with CRC and provide help for patients through personalized treatment. 
  |  None  |  
------------------------------------------- 
10.1002/jum.15071  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Objectives:  To explore the value of ultrasomics in temporal monitoring of tumor changes in response to gene therapy in hepatocellular carcinoma compared with methods according to the Response Evaluation Criteria in Solid Tumors (RECIST) and modified RECIST (mRECIST). 
  Methods:  Hepatocellular carcinoma-bearing mice were injected intratumorally with microRNA-122 (miR-122) mimics and an miR-122 negative control in the treatment and control groups, respectively. The injections were performed every 3 days for 5 times (on days 0, 3, 6, 9, and 12). Before each injection and at the experiment ending, 2-dimensional ultrasound imaging was performed for tumor size measurement with RECIST and computing a quantitative imaging analysis with ultrasomics. To analyze the tumor perfusion by mRECIST, perfusion parameters were analyzed offline based on dynamic contrast-enhanced ultrasound image videos using SonoLiver software (TomTec, Unterschleissheim, Germany) on day 13. Tumor miR-122 expression was then analyzed by real-time reverse transcription-polymerase chain reaction experiments. 
  Results:  Tumors in mice treated with miR-122 mimics demonstrated a mean ± SD 763- ± 60-fold increase in miR-122 levels compared with tumors in the control group. With RECIST, a significant therapeutic response evaluated by tumor size changes was detected after day 9 (days 9, 12, and 13; P &lt; .001). With mRECIST, no parameters showed significant differences (P &gt; .05). Significant different features of the 2-dimensional ultrasound images between the groups were detected by the ultrasomics analysis, and the model could be successfully built. The ultrasomics score values between the groups were statistically significant after day 6 (days 6, 9, 12, and 13; P &lt; .05). 
  Conclusions:  Ultrasomics revealed significant changes after the second injection of miR-122, showing the potential as an important imaging biomarker for gene therapy. 
  |  https://doi.org/10.1002/jum.15071  |  
------------------------------------------- 
10.1158/2326-6066.CIR-19-0521  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   CD8<sup>+</sup> T cells can be polarized into several different subsets as defined by the cytokines they produce and the transcription factors that govern their differentiation. Here, we identified the polarizing conditions to induce an IL22-producing CD8<sup>+</sup> Tc22 subset, which is dependent on IL6 and the aryl hydrocarbon receptor transcription factor. Further characterization showed that this subset was highly cytolytic and expressed a distinct cytokine profile and transcriptome relative to other subsets. In addition, polarized Tc22 were able to control tumor growth as well as, if not better than, the traditional IFNγ-producing Tc1 subset. Tc22s were also found to infiltrate the tumors of human patients with ovarian cancer, comprising up to approximately 30% of expanded CD8<sup>+</sup> tumor-infiltrating lymphocytes (TIL). Importantly, IL22 production in these CD8<sup>+</sup> TILs correlated with improved recurrence-free survival. Given the antitumor properties of Tc22 cells, it may be prudent to polarize T cells to the Tc22 lineage when using chimeric antigen receptor (CAR)-T or T-cell receptor (TCR) transduction-based immunotherapies. 
  |  http://cancerimmunolres.aacrjournals.org/cgi/pmidlookup?view=long&pmid=31964625  |  
------------------------------------------- 
10.4070/kcj.2019.0105  |  Prognosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background and objectives:  We aim to explore the additional discriminative accuracy of a deep learning (DL) algorithm using repeated-measures data for identifying people at high risk for cardiovascular disease (CVD), compared to Cox hazard regression. 
  Methods:  Two CVD prediction models were developed from National Health Insurance Service-Health Screening Cohort (NHIS-HEALS): a Cox regression model and a DL model. Performance of each model was assessed in the internal and 2 external validation cohorts in Koreans (National Health Insurance Service-National Sample Cohort; NHIS-NSC) and in Europeans (Rotterdam Study). A total of 412,030 adults in the NHIS-HEALS; 178,875 adults in the NHIS-NSC; and the 4,296 adults in Rotterdam Study were included. 
  Results:  Mean ages was 52 years (46% women) and there were 25,777 events (6.3%) in NHIS-HEALS during the follow-up. In internal validation, the DL approach demonstrated a C-statistic of 0.896 (95% confidence interval, 0.886-0.907) in men and 0.921 (0.908-0.934) in women and improved reclassification compared with Cox regression (net reclassification index [NRI], 24.8% in men, 29.0% in women). In external validation with NHIS-NSC, DL demonstrated a C-statistic of 0.868 (0.860-0.876) in men and 0.889 (0.876-0.898) in women, and improved reclassification compared with Cox regression (NRI, 24.9% in men, 26.2% in women). In external validation applied to the Rotterdam Study, DL demonstrated a C-statistic of 0.860 (0.824-0.897) in men and 0.867 (0.830-0.903) in women, and improved reclassification compared with Cox regression (NRI, 36.9% in men, 31.8% in women). 
  Conclusions:  A DL algorithm exhibited greater discriminative accuracy than Cox model approaches. 
  Trial registration:  ClinicalTrials.gov Identifier: <a href="http://clinicaltrials.gov/show/NCT02931500" title="See in ClinicalTrials.gov">NCT02931500</a>. 
  |  https://e-kcj.org/DOIx.php?id=10.4070/kcj.2019.0105  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31456363/  |  
------------------------------------------- 
10.1186/s12916-020-01563-4  |  Smart Healthcare, Diagnosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Healthcare represents a paradox. While change is everywhere, performance has flatlined: 60% of care on average is in line with evidence- or consensus-based guidelines, 30% is some form of waste or of low value, and 10% is harm. The 60-30-10 Challenge has persisted for three decades. 
  Main body:  Current top-down or chain-logic strategies to address this problem, based essentially on linear models of change and relying on policies, hierarchies, and standardisation, have proven insufficient. Instead, we need to marry ideas drawn from complexity science and continuous improvement with proposals for creating a deep learning health system. This dynamic learning model has the potential to assemble relevant information including patients' histories, and clinical, patient, laboratory, and cost data for improved decision-making in real time, or close to real time. If we get it right, the learning health system will contribute to care being more evidence-based and less wasteful and harmful. It will need a purpose-designed digital backbone and infrastructure, apply artificial intelligence to support diagnosis and treatment options, harness genomic and other new data types, and create informed discussions of options between patients, families, and clinicians. While there will be many variants of the model, learning health systems will need to spread, and be encouraged to do so, principally through diffusion of innovation models and local adaptations. 
  Conclusion:  Deep learning systems can enable us to better exploit expanding health datasets including traditional and newer forms of big and smaller-scale data, e.g. genomics and cost information, and incorporate patient preferences into decision-making. As we envisage it, a deep learning system will support healthcare's desire to continually improve, and make gains on the 60-30-10 dimensions. All modern health systems are awash with data, but it is only recently that we have been able to bring this together, operationalised, and turned into useful information by which to make more intelligent, timely decisions than in the past. 
  |  None  |  
------------------------------------------- 
10.1016/j.cmpb.2020.105475  |  Diagnosis  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background and objective:  Skin cancer is among the most common cancer types in the white population and consequently computer aided methods for skin lesion classification based on dermoscopic images are of great interest. A promising approach for this uses transfer learning to adapt pre-trained convolutional neural networks (CNNs) for skin lesion diagnosis. Since pre-training commonly occurs with natural images of a fixed image resolution and these training images are usually significantly smaller than dermoscopic images, downsampling or cropping of skin lesion images is required. This however may result in a loss of useful medical information, while the ideal resizing or cropping factor of dermoscopic images for the fine-tuning process remains unknown. 
  Methods:  We investigate the effect of image size for skin lesion classification based on pre-trained CNNs and transfer learning. Dermoscopic images from the International Skin Imaging Collaboration (ISIC) skin lesion classification challenge datasets are either resized to or cropped at six different sizes ranging from 224 × 224 to 450 × 450. The resulting classification performance of three well established CNNs, namely EfficientNetB0, EfficientNetB1 and SeReNeXt-50 is explored. We also propose and evaluate a multi-scale multi-CNN (MSM-CNN) fusion approach based on a three-level ensemble strategy that utilises the three network architectures trained on cropped dermoscopic images of various scales. 
  Results:  Our results show that image cropping is a better strategy compared to image resizing delivering superior classification performance at all explored image scales. Moreover, fusing the results of all three fine-tuned networks using cropped images at all six scales in the proposed MSM-CNN approach boosts the classification performance compared to a single network or a single image scale. On the ISIC 2018 skin lesion classification challenge test set, our MSM-CNN algorithm yields a balanced multi-class accuracy of 86.2% making it the currently second ranked algorithm on the live leaderboard. 
  Conclusions:  We confirm that the image size has an effect on skin lesion classification performance when employing transfer learning of CNNs. We also show that image cropping results in better performance compared to image resizing. Finally, a straightforward ensembling approach that fuses the results from images cropped at six scales and three fine-tuned CNNs is shown to lead to the best classification performance. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)31146-0  |  
------------------------------------------- 
10.2196/17279  |  Smart Healthcare  |  SubfieldA  |  Research  |  ResearchTypeA  |    Background:  Interprofessional team training is needed to improve nurse-physician communication skills that are lacking in clinical practice. Using simulations has proven to be an effective learning approach for team training. Yet, it has logistical constraints that call for the exploration of virtual environments in delivering team training. 
  Objective:  This study aimed to evaluate a team training program using virtual reality vs conventional live simulations on medical and nursing students' communication skill performances and teamwork attitudes. 
  Methods:  In June 2018, the authors implemented nurse-physician communication team training using communication tools. A randomized controlled trial study was conducted with 120 undergraduate medical and nursing students who were randomly assigned to undertake team training using virtual reality or live simulations. The participants from both groups were tested on their communication performances through team-based simulation assessments. Their teamwork attitudes were evaluated using interprofessional attitude surveys that were administered before, immediately after, and 2 months after the study interventions. 
  Results:  The team-based simulation assessment revealed no significant differences in the communication performance posttest scores (P=.29) between the virtual and simulation groups. Both groups reported significant increases in the interprofessional attitudes posttest scores from the baseline scores, with no significant differences found between the groups over the 3 time points. 
  Conclusions:  Our study outcomes did not show an inferiority of team training using virtual reality when compared with live simulations, which supports the potential use of virtual reality to substitute conventional simulations for communication team training. Future studies can leverage the use of artificial intelligence technology in virtual reality to replace costly human-controlled facilitators to achieve better scalability and sustainability of team-based training in interprofessional education. 
  Trial registration:  ClinicalTrials.gov <a href="http://clinicaltrials.gov/show/NCT04330924" title="See in ClinicalTrials.gov">NCT04330924</a>; https://clinicaltrials.gov/ct2/show/NCT04330924. 
  |  https://www.jmir.org/2020/4/e17279/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32267235/  |  
------------------------------------------- 
10.1002/1878-0261.12635  |  Prognosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   In breast cancer (BC), the presence of cancer stem cells (CSCs) has been related to relapse, metastasis, and radioresistance. Radiotherapy (RT) is an extended BC treatment, but is not always effective. CSCs have several mechanisms of radioresistance in place, and some miRNAs are involved in the cellular response to ionizing radiation (IR). Here, we studied how IR affects the expression of miRNAs related to stemness in different molecular BC subtypes. Exposition of BC cells to radiation doses of 2, 4, or 6 Gy affected their phenotype, functional characteristics, pluripotency gene expression, and in vivo tumorigenic capacity. This held true for various molecular subtypes of BC cells (classified by ER, PR and HER-2 status), and for BC cells either plated in monolayer, or being in suspension as mammospheres. However, the effect of IR on the expression of eight stemness- and radioresistance-related miRNAs (miR-210, miR-10b, miR-182, miR-142, miR-221, miR-21, miR-93, miR-15b) varied, depending on cell line subpopulation and clinicopathological features of BC patients. Therefore, clinicopathological features and, potentially also, chemotherapy regimen should be both taken into consideration, for determining a potential miRNA signature by liquid biopsy in BC patients treated with RT. Personalized and precision RT dosage regimes could improve the prognosis, treatment, and survival of BC patients. 
  |  https://doi.org/10.1002/1878-0261.12635  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31930680/  |  
------------------------------------------- 
10.3390/s20092460  |  None  |  SubfieldA  |  Research  |  ResearchTypeA  |   Leaf area index (LAI) is an important biophysical parameter, which can be effectively applied in the estimation of vegetation growth status. At present, amounts of studies just focused on the LAI estimation of a single plant type, while plant types are usually mixed rather than single distribution. In this study, the suitability of GF-1 data for multi-species LAI estimation was evaluated by using Gaussian process regression (GPR), and a look-up table (LUT) combined with a PROSAIL radiative transfer model. Then, the performance of the LUT and GPR for multi-species LAI estimation was analyzed in term of 15 different band combinations and 10 published vegetation indices (VIs). Lastly, the effect of the different band combinations and published VIs on the accuracy of LAI estimation was discussed. The results indicated that GF-1 data exhibited a good potential for multi-species LAI retrieval. Then, GPR exhibited better performance than that of LUT for multi-species LAI estimation. What is more, modified soil adjusted vegetation index (MSAVI) was selected based on the GPR algorithm for multi-species LAI estimation with a lower root mean squared error (RMSE = 0.6448 m<sup>2</sup>/m<sup>2</sup>) compared to other band combinations and VIs. Then, this study can provide guidance for multi-species LAI estimation. 
  |  http://www.mdpi.com/resolver?pii=s20092460  |  
------------------------------------------- 
10.1016/j.canrad.2020.01.011  |  Diagnosis, Prognosis, Treatment  |  SubfieldA  |  Review  |  ResearchTypeA  |    Purpose:  Radiomics are a set of methods used to leverage medical imaging and extract quantitative features that can characterize a patient's phenotype. All modalities can be used with several different software packages. Specific informatics methods can then be used to create meaningful predictive models. In this review, we will explain the major steps of a radiomics analysis pipeline and then present the studies published in the context of radiation therapy. 
  Methods:  A literature review was performed on Medline using the search engine PubMed. The search strategy included the search terms "radiotherapy", "radiation oncology" and "radiomics". The search was conducted in July 2019 and reference lists of selected articles were hand searched for relevance to this review. 
  Results:  A typical radiomics workflow always includes five steps: imaging and segmenting, data curation and preparation, feature extraction, exploration and selection and finally modeling. In radiation oncology, radiomics studies have been published to explore different clinical outcome in lung (n=5), head and neck (n=5), esophageal (n=3), rectal (n=3), pancreatic (n=2) cancer and brain metastases (n=2). The quality of these retrospective studies is heterogeneous and their results have not been translated to the clinic. 
  Conclusion:  Radiomics has a great potential to predict clinical outcome and better personalize treatment. But the field is still young and constantly evolving. Improvement in bias reduction techniques and multicenter studies will hopefully allow more robust and generalizable models. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S1278-3218(20)30071-8  |  
------------------------------------------- 
10.1016/j.actbio.2020.02.007  |  Prognosis, Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   Throughout the process of aging, dynamic changes of bone material, micro- and macro-architecture result in a loss of strength and therefore in an increased likelihood of fragility fractures. To date, precise contributions of age-related changes in bone (re)modeling and (de)mineralization dynamics to this fragility increase are not completely understood. Here, we present an image-based deep learning approach to quantitatively describe the effects of short-term aging and adaptive response to cyclic loading applied to proximal mouse tibiae and fibulae. Our approach allowed us to perform an end-to-end age prediction based on μCT imaging to determine the dynamic biological process of aging during a two week period, therefore permitting short-term bone aging analysis with 95% accuracy in predicting time points. In a second application, our deep learning analysis reveals that two weeks of in vivo mechanical loading are associated with an underlying rejuvenating effect of 5 days. Additionally, by quantitatively analyzing the learning process, we could, for the first time, identify the localization of the age-relevant encoded information and demonstrate 89% load-induced similarity of these locations in the loaded tibia with younger control bones. These data therefore suggest that our method enables identifying a general prognostic phenotype of a certain skeletal age as well as a temporal and localized loading-treatment effect on this apparent skeletal age for the studied mouse tibia and fibula. Future translational applications of this method may provide an improved decision-support method for osteoporosis treatment at relatively low cost. STATEMENT OF SIGNIFICANCE: Bone is a highly complex and dynamic structure that undergoes changes during the course of aging as well as in response to external stimuli, such as loading. Automatic assessment of "age" and "state" of the bone may lead to early prognosis of deceases such as osteoporosis and enables evaluating the effects of certain treatments. Here, we present an artificial intelligence-based method capable of automatically predicting the skeletal age from μCT images with 95% accuracy. Additionally, we utilize it to demonstrate the rejuvenation effects of in-vivo loading treatment on bones. We further, for the first time, break down aging-related local changes in bone by quantitatively analyzing "what the age assessment model has learned" and use this information to investigate the structural details of rejuvenation process. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S1742-7061(20)30085-4  |  
------------------------------------------- 
10.1016/j.brainres.2020.146700  |  Treatment  |  SubfieldA  |  Research  |  ResearchTypeA  |   The central nervous system (CNS) has a limited auto-regeneration capacity, which makes it challenging for the development of new therapies. Previous studies from our lab have demonstrated the applicability of human bone marrow mesenchymal stem cells (hBM-MSCs) secretome as a possible therapeutic tool for CNS. Astrocytes, glial cells present in all brain regions, are important players in brain function through their vast influence in extracellular homeostasis, neuro-vascular regulation, synaptic modulation and neurogenesis. Thus, in the present work, we aimed to evaluate the specific impact of MSCs secretome on hippocampal proliferation and astrocyte morphology, in both WT and dnSNARE mice, a transgenic model that presents impaired astrocytic exocytosis and consequently impaired astrocytic function. Results demonstrated increased levels of proliferation for WT when treated with secretome. Additionally, it was possible to observe that dnSNARE animals injected with hBM-MSCs secretome disclosed increased levels of proliferating GFAP stained cells at the SGZ. Morphometrical evaluation found increased process hypertrophy and branching of dnSNARE astrocytes when treated with secretome. These results are closely related with the trophic factors present in the secretome, namely FGF-2, BDNF, GDNF, IGF-1, VEGF, CADH2, PEDF and miR-16. Moreover, the impaired exocytosis of astrocytes may also have implications for the response to the proliferative stimulus, given the established autocrine signaling through this mechanism. 
  |  https://linkinghub.elsevier.com/retrieve/pii/S0006-8993(20)30056-1  |  
------------------------------------------- 
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to install this libs only once by running this cell without #\n",
    "\n",
    "#!pip install nltk\n",
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import one specific JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('C:\\\\Users\\\\Admin\\\\Documents\\\\Teamprojekt- Ai knowlage base\\\\Project_git\\\\Extraction\\\\data\\\\https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fdoi%2F10.1016%2FS0933-3657%2801%2900089-6.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    description = data[\"coredata\"][\"dc:description\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to import all JSONs of a Directory. Option to load only the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "cat = []\n",
    "\n",
    "def openJSONFiles(fileString, onlyAbstract=False):\n",
    "    jsonReturn = []\n",
    "    path = Path(fileString)\n",
    "    for path in path.iterdir():\n",
    "        if path.is_file():\n",
    "            with open(path) as json_file:\n",
    "                if onlyAbstract:\n",
    "                    tempJson = json.load(json_file)\n",
    "                    jsonReturn.append(tempJson[\"coredata\"][\"dc:description\"])  \n",
    "                    # tempp !!\n",
    "                    cat.append(tempJson[\"subfield\"])\n",
    "                    #\n",
    "                else:\n",
    "                    jsonReturn.append(json.load(json_file))\n",
    "              \n",
    "    return jsonReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = openJSONFiles('C:\\\\Users\\\\Admin\\\\Documents\\\\Teamprojekt- Ai knowlage base\\\\Project_git\\\\Preprocessing_Clustering\\\\manual',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Epidemiology']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsons[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for tokenization, removment of stopwords and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re, string\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from collections import defaultdict\n",
    "from collections.abc import Iterable\n",
    "from nltk import ngrams\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def tokenize(text, sentenceSeperate=False, includePunctation= False, excludeSpecPuct =[]):\n",
    "    data = [] \n",
    "    #intern functions\n",
    "    def withPunctation(text):\n",
    "        temp = [] \n",
    "        #delete unwanted punctuation\n",
    "        for delPunct in excludeSpecPuct:\n",
    "            text = text.replace(delPunct, \" \")\n",
    "        #help tokenization with replacing some untokenized punctations\n",
    "        for puct in [\"-\",\"/\",\"—\"]:\n",
    "            text = text.replace(puct, \" \"+puct+\" \")\n",
    "         # tokenize the sentence into words \n",
    "        for j in word_tokenize(text): \n",
    "            temp.append(j)\n",
    "        return temp\n",
    "    def withoutPunctation(text):\n",
    "        token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\") # split on whitespace (and remove punctation)\n",
    "        return token_pattern.findall(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    if sentenceSeperate:\n",
    "        # iterate through each sentence in the file \n",
    "        for sentence in sent_tokenize(text): \n",
    "            if includePunctation:\n",
    "                data.append(withPunctation(sentence))\n",
    "            else:\n",
    "                data.append(withoutPunctation(sentence))\n",
    "    else:\n",
    "        if includePunctation:\n",
    "            data = withPunctation(text)\n",
    "        else:\n",
    "            data = withoutPunctation(text)\n",
    "    \n",
    "    return data\n",
    "     \n",
    "\n",
    "def removeStopwords(wordArray):\n",
    "    \n",
    "    my_stopwords = set(stopwords.words('english'))\n",
    "    withoutStopwords = []\n",
    "    \n",
    "    #test if its a list of words or a list of sentences with words\n",
    "    if isinstance(wordArray[0], Iterable)and not isinstance(wordArray[0], str):\n",
    "        for sentence in wordArray:\n",
    "            withoutStopwords.append(removeStopwords(sentence))\n",
    "            \n",
    "    else:        \n",
    "        for item in wordArray:\n",
    "            if item not in my_stopwords:\n",
    "                withoutStopwords.append(item)\n",
    "    return withoutStopwords\n",
    "\n",
    "def applyStemming(wordArray):\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = []\n",
    "    \n",
    "    #test if its a list of words or a list of sentences with words\n",
    "    if isinstance(wordArray[0], Iterable)and not isinstance(wordArray[0], str):\n",
    "        for sentence in wordArray:\n",
    "            stems.append(applyStemming(sentence))\n",
    "    else:       \n",
    "        for item in wordArray:\n",
    "            stems.append(stemmer.stem(item))\n",
    "    return stems\n",
    "\n",
    "\n",
    "def applyLemmatizing(wordArray):\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV   \n",
    "    \n",
    "    #intern function\n",
    "    def lemmazizeText(text):\n",
    "        temp = []\n",
    "        for token, tag in pos_tag(text):\n",
    "            temp.append(lemma_function.lemmatize(token, tag_map[tag[0]]))\n",
    "        return temp\n",
    "\n",
    "            \n",
    "    lemma_function = WordNetLemmatizer()\n",
    "    baseWords = []\n",
    "    if isinstance(wordArray[0], Iterable)and not isinstance(wordArray[0], str):\n",
    "        for sentence in wordArray:\n",
    "            baseWords.append(lemmazizeText(sentence))\n",
    "    else:\n",
    "        baseWords =lemmazizeText(wordArray)\n",
    "     \n",
    "    return baseWords\n",
    "\n",
    "def addNGram(wordArray, NGramLength=2):\n",
    "    holetext= wordArray\n",
    "    temp = []\n",
    "    if len(wordArray)>0 and isinstance(wordArray[0], Iterable)and not isinstance(wordArray[0], str):\n",
    "        print(\"drin\")\n",
    "        for sentence in wordArray:\n",
    "            temp.append(' '.join(sentence))\n",
    "        holetext = (' '.join(temp)).split()\n",
    "    nGrams = list(ngrams(holetext, NGramLength))\n",
    "    \n",
    "    # make nGram from two words to one \n",
    "    nGramsFull = pd.Series(nGrams).apply(lambda row: ' '.join(row))\n",
    "    wordArrayCopy = wordArray.copy()\n",
    "    wordArrayCopy.extend(nGramsFull)\n",
    "    return (wordArrayCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# firstTime = time.time()\n",
    "# print(\"Original Text:\\n\",description)\n",
    "\n",
    "# description_P1 = tokenize(description)\n",
    "# print(\"\\nAfter Tokenization:\\n\",description_P1)\n",
    "\n",
    "# description_P2 = removeStopwords(description_P1)\n",
    "# print(\"\\nAfter Stopword removal:\\n\",description_P2)\n",
    "\n",
    "# description_P3 = applyStemming(description_P2)\n",
    "# print(\"\\nAfter Stemming:\\n\",description_P3)\n",
    "\n",
    "# description_P3_1 = applyLemmatizing(description_P2)\n",
    "# print(\"\\nAfter Lemmatization (with previous stopword removal\\n\",description_P3_1)\n",
    "\n",
    "# description_P3_2 = removeStopwords(applyLemmatizing(description_P1))\n",
    "# print(\"\\nAfter Lemmatization (with subsequent stopword removal\\n\",description_P3_2)\n",
    "\n",
    "# description_P4 = addNGram(description_P3_2)\n",
    "# print(\"\\nAfter adding NGrams\\n\",description_P4)\n",
    "# print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44  out of  44  abstracts cound be found and are converted\n",
      "--- 0.1479 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "firstTime = time.time()\n",
    "abstractsPro = []\n",
    "abstractsUsed = []\n",
    "i=0\n",
    "for abstract in jsons:\n",
    "    if abstract is not None:\n",
    "        #abstractsPro.append(applyLemmatizing(removeStopwords(tokenize(abstract))))\n",
    "        abstractsPro.append(tokenize(abstract, includePunctation=True,excludeSpecPuct = [\"(\",\")\",\"[\",\"]\",\"{\",\"}\",'\"',\"’\", \"”\", \"“\",\"—\"]))\n",
    "        abstractsUsed.append(abstract)\n",
    "        i= i+1\n",
    "print(i,\" out of \",len(jsons),\" abstracts cound be found and are converted\")\n",
    "print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create wordlist of all inputs togehter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# Source: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 8806.10it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(abstractsPro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and the keyedVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 30.3281 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.models as g\n",
    "\n",
    "firstTime = time.time()\n",
    "#documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(abstractsPro)]\n",
    "modelLNK = \"C:\\\\Users\\\\Admin\\\\Downloads\\\\enwiki_dbow\\\\doc2vec.bin\"\n",
    "\n",
    "\n",
    "#inference hyper-parameters\n",
    "start_alpha=0.01\n",
    "infer_epoch=1000\n",
    " \n",
    "#load model\n",
    "\n",
    "model = g.Doc2Vec.load(modelLNK)\n",
    "#model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "#embeddings_index = KeyedVectors.load_word2vec_format(modelLNK, binary=True)\n",
    "embeddings_index = model.wv\n",
    "\n",
    "\n",
    "# # Save file and load it again\n",
    "# fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "\n",
    "# model.save(fname)\n",
    "# model = Doc2Vec.load(fname)  # you can continue training with the loaded model!\n",
    "# #delete traingmode (save memmory)\n",
    "# model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1d0b5c335c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compares the word of the embedding with the words of our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments\n",
    "import operator \n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 2357/2357 [00:00<00:00, 138738.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 98.13% of vocab\n",
      "Found embeddings for  99.32% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('esns', 5),\n",
       " ('ldct', 5),\n",
       " ('nlst', 5),\n",
       " ('dateness', 4),\n",
       " ('unclustered', 4),\n",
       " ('dbns', 4),\n",
       " ('svdd', 4),\n",
       " ('cnns', 4),\n",
       " ('fmultimoora', 3),\n",
       " ('2019.', 2),\n",
       " ('10,865', 2),\n",
       " ('0.758', 2),\n",
       " ('2020.', 1),\n",
       " ('multidisplinary', 1),\n",
       " ('reskill', 1),\n",
       " ('gmms', 1),\n",
       " ('531.', 1),\n",
       " ('ophtha', 1),\n",
       " ('inbreast', 1),\n",
       " ('microaneurysm', 1)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!  in the embedding:  True\n",
      "\"  in the embedding:  False\n",
      "#  in the embedding:  True\n",
      "$  in the embedding:  True\n",
      "%  in the embedding:  True\n",
      "&  in the embedding:  True\n",
      "'  in the embedding:  True\n",
      "(  in the embedding:  False\n",
      ")  in the embedding:  False\n",
      "*  in the embedding:  True\n",
      "+  in the embedding:  True\n",
      ",  in the embedding:  True\n",
      "-  in the embedding:  True\n",
      ".  in the embedding:  True\n",
      "/  in the embedding:  True\n",
      ":  in the embedding:  True\n",
      ";  in the embedding:  True\n",
      "<  in the embedding:  True\n",
      "=  in the embedding:  True\n",
      ">  in the embedding:  True\n",
      "?  in the embedding:  True\n",
      "@  in the embedding:  True\n",
      "[  in the embedding:  False\n",
      "\\  in the embedding:  True\n",
      "]  in the embedding:  False\n",
      "^  in the embedding:  True\n",
      "_  in the embedding:  True\n",
      "`  in the embedding:  True\n",
      "{  in the embedding:  False\n",
      "|  in the embedding:  True\n",
      "}  in the embedding:  False\n",
      "~  in the embedding:  True\n",
      "’  in the embedding:  False\n",
      "”  in the embedding:  False\n",
      "“  in the embedding:  False\n",
      "—  in the embedding:  False\n"
     ]
    }
   ],
   "source": [
    "punctuationList = string.punctuation \n",
    "punctuationList = punctuationList+\"’\" + \"”\" + \"“\"+\"—\"\n",
    "for punctuation in punctuationList:\n",
    "    print(punctuation, \" in the embedding: \",punctuation in embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      ",\n",
      ".\n",
      "of\n",
      "and\n",
      "in\n",
      "a\n",
      "to\n",
      "was\n",
      "''\n",
      "``\n",
      "is\n",
      "for\n",
      "-rrb-\n",
      "-lrb-\n",
      "as\n",
      "on\n",
      "with\n",
      "by\n",
      "he\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(embeddings_index.index2entity[i])\n",
    "#TODO: -LRB- and -RRB- are currently used instead of \"(\" and \")\" .... also  ” to \" .... also -- has to has a meaning (maybe a placehoder for numbers like in https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings/comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector = model.infer_vector([\"system\", \"und jetzt\"]) \n",
    "#model.docvecs.most_similar(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 148.2506 seconds ---\n"
     ]
    }
   ],
   "source": [
    "firstTime = time.time()\n",
    "vectors = []\n",
    "# for x,y in documents:\n",
    "#     vectors.append(model.docvecs[y[0]]) \n",
    "for text in abstractsPro:\n",
    "    vectors.append(model.infer_vector(text))\n",
    "print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.60376951e-02, -2.35308498e-01, -1.18354857e-01, -1.02248840e-01,\n",
       "       -5.22841476e-02,  9.46073458e-02,  4.57842015e-02, -3.23922047e-03,\n",
       "       -1.47295386e-01,  1.06221683e-01, -2.64518738e-01, -2.12970302e-01,\n",
       "       -7.18091428e-02, -2.32401431e-01,  8.43367726e-02,  1.38983846e-01,\n",
       "       -1.05704449e-01,  3.97593006e-02,  3.24011147e-02, -8.67493600e-02,\n",
       "        1.78713784e-01, -7.66739156e-03,  6.42504692e-02, -9.14003104e-02,\n",
       "        4.45874035e-02,  3.02400198e-02, -6.46890774e-02, -1.11423209e-02,\n",
       "       -1.39129207e-01, -2.49461681e-01, -3.26337099e-01,  1.42127663e-01,\n",
       "       -5.24813570e-02, -1.39265969e-01,  6.00566417e-02, -2.96140909e-01,\n",
       "        2.13818308e-02,  3.86159182e-01,  5.88212609e-02, -3.91192036e-03,\n",
       "       -4.20305990e-02,  7.99349919e-02,  3.35499048e-02,  1.10244542e-01,\n",
       "        2.61178464e-01, -4.65880334e-02,  8.04468840e-02,  2.47356459e-01,\n",
       "        2.46205796e-02, -5.98564111e-02, -1.92814648e-01,  8.30861703e-02,\n",
       "        6.16291203e-02, -1.25188306e-01,  3.48083004e-02, -6.66918457e-02,\n",
       "        3.14040184e-01, -3.68141159e-02, -4.27776217e-01,  5.21994568e-02,\n",
       "       -2.12565914e-01, -1.41474366e-01, -1.50974676e-01, -1.66182727e-01,\n",
       "        2.29947671e-01,  1.34606928e-01, -2.23249376e-01, -2.75682837e-01,\n",
       "        1.79573649e-03, -2.54231364e-01,  3.80471274e-02, -2.00299263e-01,\n",
       "       -1.97137639e-01,  1.33275732e-01, -7.00568408e-02,  1.92030370e-01,\n",
       "        1.06473953e-01,  1.61052465e-01,  3.45887765e-02, -1.18460052e-01,\n",
       "       -4.84021716e-02, -1.98630095e-01, -3.37927416e-02,  1.32541418e-01,\n",
       "       -3.22714210e-01, -9.05629545e-02, -1.48752972e-01, -1.50736332e-01,\n",
       "       -1.34437948e-01, -2.13459972e-02, -1.57272201e-02, -3.18891108e-02,\n",
       "        3.90483201e-01, -2.30986759e-01, -2.17209488e-01,  5.99982403e-02,\n",
       "       -1.54245019e-01, -6.11239038e-02,  1.60956595e-04, -2.03689680e-01,\n",
       "        2.97696646e-02,  5.99728934e-02, -7.27887973e-02, -4.56450880e-02,\n",
       "        2.90154189e-01, -1.24934800e-01,  6.75339177e-02,  1.52187929e-01,\n",
       "       -1.68662779e-02, -1.87817201e-01, -1.49638146e-01, -1.68956533e-01,\n",
       "        1.68028116e-01,  9.03105736e-02, -3.89740653e-02, -1.67891830e-01,\n",
       "       -2.41599441e-01,  2.84923590e-03,  1.85031414e-01, -5.89742325e-02,\n",
       "        9.11115110e-02, -3.60280722e-01, -9.88000724e-03,  1.30916715e-01,\n",
       "       -1.19587451e-01,  2.70470262e-01,  1.82287619e-01, -1.55394018e-01,\n",
       "        1.85854509e-01,  4.60865572e-02,  4.24030982e-02,  1.67928070e-01,\n",
       "        9.58088636e-02,  1.35783732e-01,  7.23542273e-02,  7.92102516e-02,\n",
       "       -1.65126652e-01, -2.31965840e-01,  9.33419988e-02,  4.54815961e-02,\n",
       "        1.55797735e-01,  1.80812210e-01,  2.47090496e-02,  1.70407206e-01,\n",
       "        7.51469880e-02,  1.66994870e-01, -3.14366698e-01,  5.88384271e-02,\n",
       "        3.53491575e-01,  1.99594602e-01, -2.84231156e-01,  1.26475971e-02,\n",
       "       -1.45793175e-02, -2.27565497e-01,  3.27120237e-02,  1.12663545e-01,\n",
       "        2.44137034e-01, -3.87706310e-01, -1.50471583e-01,  9.61964503e-02,\n",
       "        1.41736135e-01,  2.16264024e-01, -2.96522956e-02,  1.11765072e-01,\n",
       "        1.67843252e-02, -3.36115025e-02,  1.84437055e-02, -1.14074327e-01,\n",
       "       -9.64685623e-03,  4.02981527e-02,  1.38603330e-01, -3.65777873e-02,\n",
       "        9.17452946e-02, -2.53871709e-01,  2.79676855e-01,  4.47714962e-02,\n",
       "       -4.01275277e-01,  9.66775343e-02, -6.98588565e-02,  7.27252662e-02,\n",
       "       -1.25516742e-01,  4.74973917e-01,  2.57337205e-02, -2.35818177e-01,\n",
       "        1.94750637e-01, -1.72890708e-01,  8.65801498e-02, -5.71132936e-02,\n",
       "        1.07331246e-01,  3.32089216e-01, -7.17916042e-02, -3.67255539e-01,\n",
       "        1.18150733e-01,  2.14355990e-01,  6.39425963e-02, -3.83045763e-01,\n",
       "        1.65773526e-01,  1.08651496e-01, -1.41215310e-01, -2.59336442e-01,\n",
       "        1.01181872e-01, -2.38825306e-01,  1.71680138e-01, -3.81041206e-02,\n",
       "       -4.54584844e-02,  1.37077635e-02, -1.63812693e-02, -1.69037674e-02,\n",
       "       -9.49009582e-02, -1.55457491e-02,  3.65962684e-01,  3.34711671e-01,\n",
       "       -2.81666070e-01,  2.92662770e-01, -4.29508016e-02,  1.63881183e-01,\n",
       "        4.24227770e-03, -1.42451376e-01,  5.35437651e-02, -1.76024765e-01,\n",
       "        9.81142595e-02,  4.33759093e-02,  2.52261221e-01,  1.03031963e-01,\n",
       "       -1.03091687e-01, -1.24933891e-01, -1.57760605e-01, -1.23412624e-01,\n",
       "       -1.60872594e-01, -1.84141189e-01,  2.63086315e-02,  4.06042859e-02,\n",
       "        2.17591539e-01, -8.31449628e-02,  2.56246805e-01, -2.23869190e-01,\n",
       "        3.91808338e-02, -9.29102376e-02, -1.38354391e-01,  1.23508677e-01,\n",
       "        5.72843151e-03, -8.25334862e-02, -5.03422990e-02,  2.38371253e-01,\n",
       "        4.40361053e-02, -2.79551208e-01, -2.55236570e-02, -1.56241074e-01,\n",
       "       -6.52269423e-02, -8.64003599e-03, -2.39913657e-01, -6.41457411e-03,\n",
       "        5.10676801e-01, -2.40265429e-01,  1.31787790e-03,  1.81785211e-01,\n",
       "        2.76218802e-01, -1.75187141e-01,  7.30401054e-02,  1.09520182e-01,\n",
       "        8.30063075e-02,  5.29217385e-02,  2.02976670e-02, -2.43331119e-01,\n",
       "       -2.63228059e-01, -1.15456961e-01, -2.48750020e-02, -2.13319082e-02,\n",
       "       -1.35120139e-01, -6.11446127e-02,  1.36308715e-01,  7.79664591e-02,\n",
       "       -3.05876900e-02,  2.31605873e-01, -4.64396589e-02, -1.62105903e-01,\n",
       "        1.13390289e-01, -1.64507195e-01,  3.41117531e-01, -1.45716265e-01,\n",
       "       -6.17553331e-02,  1.22229666e-01, -1.06380768e-01,  2.33382955e-01,\n",
       "        2.22226128e-01,  8.29035863e-02, -1.78657010e-01, -7.68070221e-02,\n",
       "       -1.75349012e-01, -1.98322669e-01, -1.76946416e-01, -3.90286446e-02,\n",
       "       -3.31527352e-01, -1.64278582e-01, -6.26168922e-02,  1.10978563e-03,\n",
       "       -2.29002237e-02, -1.34042442e-01, -2.16753129e-02, -4.83312868e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import pandas as pd\n",
    "\n",
    "# tsne = TSNE(n_components=2, random_state=30)\n",
    "\n",
    "# matrix_2D = tsne.fit_transform(vectors)\n",
    "# points = pd.DataFrame(matrix_2D,columns=[\"x\",\"y\"])\n",
    "# points[\"word\"]= range(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c6d9b94a88>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# points.plot.scatter(\"x\",\"y\",s=10, figsize= (20,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calling bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Term Frequency (TF) and TF-IDF \n",
    "#useInverse = True = TF-IDF else TF\n",
    "\n",
    "def bagOfWords(docs, useInverse,preProcessFunc,min_df=0.1, max_df=0.3): #procentual or absolute is a valide input\n",
    "    if not useInverse:\n",
    "        vectorizer = TfidfVectorizer(use_idf=False, norm='l1',tokenizer = preProcessFunc,min_df=min_df, max_df=max_df)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(tokenizer = preProcessFunc,min_df=min_df, max_df=max_df)\n",
    "    matrix = vectorizer.fit_transform(docs)\n",
    "    return pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumPreprocessBoW(text):\n",
    "    return applyLemmatizing(removeStopwords(tokenize(text)))\n",
    "\n",
    "firstTime = time.time()\n",
    "vectorsBoW = bagOfWords(cutHotelData, True, sumPreprocessBoW)\n",
    "print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorsBoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.028 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "firstTime = time.time()\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(vectors)\n",
    "print (\"--- %s seconds ---\" % round(time.time()-firstTime,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 3 0 1 0 0 1 1 3 3 3 3 3 1 3 3 3 3 3 3 3 3 0 1 0 3 3 0 3 3 3 2 3 3 3 0\n",
      " 0 0 0 0 0 0 1] \n",
      "\n",
      "Ammmount of clusters:\n",
      " 4 \n",
      "\n",
      "Ammount of paper per cluster:\n",
      " 3    23\n",
      "0    14\n",
      "1     6\n",
      "2     1\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusterResults = kmeans.labels_\n",
    "print(clusterResults,\"\\n\")\n",
    "difCluster = pd.Series(clusterResults).value_counts()\n",
    "print(\"Ammmount of clusters:\\n\", len(difCluster),\"\\n\")\n",
    "print(\"Ammount of paper per cluster:\\n\", difCluster,\"\\n\")\n",
    "\n",
    "papersPerCluster = {}\n",
    "for cluster in range(len(difCluster)):\n",
    "    papersPerCluster[cluster] = pd.Series(abstractsUsed)[kmeans.labels_==cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     \\n               Abstract\\n               \\n  ...\n",
       "3     \\n               \\n                  Artificia...\n",
       "5     \\n               Abstract\\n               \\n  ...\n",
       "6     \\n               Abstract\\n               \\n  ...\n",
       "23    \\n               Abstract\\n               \\n  ...\n",
       "25    \\n               Abstract\\n               \\n  ...\n",
       "28    \\n               Abstract\\n               \\n  ...\n",
       "36    \\n               Abstract\\n               \\n  ...\n",
       "37    \\n               \\n                  The AUR A...\n",
       "38    \\n               \\n                  Artificia...\n",
       "39    \\n               Abstract\\n               \\n  ...\n",
       "40    \\n               Abstract\\n               \\n  ...\n",
       "41    \\n               Abstract\\n               \\n  ...\n",
       "42    \\n               Abstract\\n               \\n  ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papersPerCluster[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

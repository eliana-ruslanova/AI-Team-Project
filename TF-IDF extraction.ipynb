{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import sys  \n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\"A multi-context CNN ensemble for small lesion detection\",\n",
    "    \"The impact of machine learning on patient care: A systematic review \",\n",
    "    \"The role of medical smartphone apps in clinical decision-support: A literature review\",\n",
    "    \"Pharmacological therapy selection of type 2 diabetes based on the SWARA and modified MULTIMOORA methods under a fuzzy environment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Here print No. 0 kind of text tf-idf weight------\n",
      "[('and', 0.0), ('apps', 0.0), ('based', 0.0), ('care', 0.0), ('clinical', 0.0), ('cnn', 0.3535533905932738), ('context', 0.3535533905932738), ('decision', 0.0), ('detection', 0.3535533905932738), ('diabetes', 0.0), ('ensemble', 0.3535533905932738), ('environment', 0.0), ('for', 0.3535533905932738), ('fuzzy', 0.0), ('impact', 0.0), ('in', 0.0), ('learning', 0.0), ('lesion', 0.3535533905932738), ('literature', 0.0), ('machine', 0.0), ('medical', 0.0), ('methods', 0.0), ('modified', 0.0), ('multi', 0.3535533905932738), ('multimoora', 0.0), ('of', 0.0), ('on', 0.0), ('patient', 0.0), ('pharmacological', 0.0), ('review', 0.0), ('role', 0.0), ('selection', 0.0), ('small', 0.3535533905932738), ('smartphone', 0.0), ('support', 0.0), ('swara', 0.0), ('systematic', 0.0), ('the', 0.0), ('therapy', 0.0), ('type', 0.0), ('under', 0.0)]\n",
      "-------Here print No. 1 kind of text tf-idf weight------\n",
      "[('and', 0.0), ('apps', 0.0), ('based', 0.0), ('care', 0.35227855433326877), ('clinical', 0.0), ('cnn', 0.0), ('context', 0.0), ('decision', 0.0), ('detection', 0.0), ('diabetes', 0.0), ('ensemble', 0.0), ('environment', 0.0), ('for', 0.0), ('fuzzy', 0.0), ('impact', 0.35227855433326877), ('in', 0.0), ('learning', 0.35227855433326877), ('lesion', 0.0), ('literature', 0.0), ('machine', 0.35227855433326877), ('medical', 0.0), ('methods', 0.0), ('modified', 0.0), ('multi', 0.0), ('multimoora', 0.0), ('of', 0.2248548379595915), ('on', 0.2777404585521392), ('patient', 0.35227855433326877), ('pharmacological', 0.0), ('review', 0.2777404585521392), ('role', 0.0), ('selection', 0.0), ('small', 0.0), ('smartphone', 0.0), ('support', 0.0), ('swara', 0.0), ('systematic', 0.35227855433326877), ('the', 0.2248548379595915), ('therapy', 0.0), ('type', 0.0), ('under', 0.0)]\n",
      "-------Here print No. 2 kind of text tf-idf weight------\n",
      "[('and', 0.0), ('apps', 0.3095454064215631), ('based', 0.0), ('care', 0.0), ('clinical', 0.3095454064215631), ('cnn', 0.0), ('context', 0.0), ('decision', 0.3095454064215631), ('detection', 0.0), ('diabetes', 0.0), ('ensemble', 0.0), ('environment', 0.0), ('for', 0.0), ('fuzzy', 0.0), ('impact', 0.0), ('in', 0.3095454064215631), ('learning', 0.0), ('lesion', 0.0), ('literature', 0.3095454064215631), ('machine', 0.0), ('medical', 0.3095454064215631), ('methods', 0.0), ('modified', 0.0), ('multi', 0.0), ('multimoora', 0.0), ('of', 0.19757882319515144), ('on', 0.0), ('patient', 0.0), ('pharmacological', 0.0), ('review', 0.24404915390023788), ('role', 0.3095454064215631), ('selection', 0.0), ('small', 0.0), ('smartphone', 0.3095454064215631), ('support', 0.3095454064215631), ('swara', 0.0), ('systematic', 0.0), ('the', 0.19757882319515144), ('therapy', 0.0), ('type', 0.0), ('under', 0.0)]\n",
      "-------Here print No. 3 kind of text tf-idf weight------\n",
      "[('and', 0.25452286307967487), ('apps', 0.0), ('based', 0.25452286307967487), ('care', 0.0), ('clinical', 0.0), ('cnn', 0.0), ('context', 0.0), ('decision', 0.0), ('detection', 0.0), ('diabetes', 0.25452286307967487), ('ensemble', 0.0), ('environment', 0.25452286307967487), ('for', 0.0), ('fuzzy', 0.25452286307967487), ('impact', 0.0), ('in', 0.0), ('learning', 0.0), ('lesion', 0.0), ('literature', 0.0), ('machine', 0.0), ('medical', 0.0), ('methods', 0.25452286307967487), ('modified', 0.25452286307967487), ('multi', 0.0), ('multimoora', 0.25452286307967487), ('of', 0.16245864651939382), ('on', 0.2006687487336388), ('patient', 0.0), ('pharmacological', 0.25452286307967487), ('review', 0.0), ('role', 0.0), ('selection', 0.25452286307967487), ('small', 0.0), ('smartphone', 0.0), ('support', 0.0), ('swara', 0.25452286307967487), ('systematic', 0.0), ('the', 0.16245864651939382), ('therapy', 0.25452286307967487), ('type', 0.25452286307967487), ('under', 0.25452286307967487)]\n"
     ]
    }
   ],
   "source": [
    "vectorizer=CountVectorizer()         #This class converts the words in the text into a word frequency matrix. The matrix element a[I][j] represents the word frequency of j under the class I text \n",
    "transformer=TfidfTransformer()       #The class counts the tf-idf weight of each word  \n",
    "X=vectorizer.fit_transform(corpus)   #Converts text to word frequency matrix\n",
    "tfidf=transformer.fit_transform(X)   #count tf-idfï¼Œ  \n",
    "word=vectorizer.get_feature_names()  #Gets all the words in the word bag model\n",
    "weight=tfidf.toarray()               #The tf-idf matrix is extracted, and element a[I][j] represents the tf-idf weight of word j in class I text \n",
    "for i in range(len(weight)):         #Print the tf-idf word weight for each type of text\n",
    "    print(\"-------Here print No.\",i,u\"kind of text tf-idf weight------\" )\n",
    "    #for j in range(len(word)):  \n",
    "    print(list(zip(word,weight[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sallyqian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sallyqian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"A multi-context CNN ensemble for small lesion detection\"\n",
    "text2 = \"The impact of machine learning on patient care: A systematic review \"\n",
    "text3 = \"A novel method of motor imagery classification using eeg signal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    lower = text.lower()\n",
    "    remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "    no_punctuation = lower.translate(remove_punctuation_map)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list)) / (1 + n_containing(word, count_list))\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: multicontext, TF-IDF: 0.09155\n",
      "\tWord: cnn, TF-IDF: 0.09155\n",
      "\tWord: ensembl, TF-IDF: 0.09155\n",
      "\tWord: small, TF-IDF: 0.09155\n",
      "\tWord: lesion, TF-IDF: 0.09155\n",
      "Top words in document 2\n",
      "\tWord: impact, TF-IDF: 0.07847\n",
      "\tWord: machin, TF-IDF: 0.07847\n",
      "\tWord: learn, TF-IDF: 0.07847\n",
      "\tWord: patient, TF-IDF: 0.07847\n",
      "\tWord: care, TF-IDF: 0.07847\n",
      "Top words in document 3\n",
      "\tWord: novel, TF-IDF: 0.06866\n",
      "\tWord: method, TF-IDF: 0.06866\n",
      "\tWord: motor, TF-IDF: 0.06866\n",
      "\tWord: imageri, TF-IDF: 0.06866\n",
      "\tWord: classif, TF-IDF: 0.06866\n"
     ]
    }
   ],
   "source": [
    "def count_term(text):\n",
    "    tokens = get_tokens(text)\n",
    "    filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = stem_tokens(filtered, stemmer)\n",
    "    count = Counter(stemmed)\n",
    "    return count\n",
    "\n",
    "def main():\n",
    "    texts = [text1, text2, text3]\n",
    "    countlist = []\n",
    "    for text in texts:\n",
    "        countlist.append(count_term(text))\n",
    "    for i, count in enumerate(countlist):\n",
    "        print(\"Top words in document {}\".format(i + 1))\n",
    "        scores = {word: tfidf(word, count, countlist) for word in count}\n",
    "        sorted_words = sorted(scores.items(), key = lambda x: x[1], reverse=True)\n",
    "        for word, score in sorted_words[:5]:\n",
    "            print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

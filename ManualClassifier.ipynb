{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "%run Subfield.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(text, categories):\n",
    "    subfields = []\n",
    "    for category in categories:\n",
    "        for keyword in category.keywords:\n",
    "            if (text.__contains__(str(keyword))):\n",
    "                if not(subfields.__contains__(category.name)):\n",
    "                    subfields.append(category.name)\n",
    "    return subfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = Subfield(\"Diagnosis\", [\"diagnos\", \"detect\", \"tomograph\", \"medical imag\", \"radiolog\", \"histolog\", \"patholog\", \"audit\"])\n",
    "prognosis = Subfield(\"Prognosis\", [\"prognos\", \"predict\", \"prevention\"])\n",
    "drug_discovery = Subfield(\"Drug Discovery\", [\"drug discovery\", \"drug design\", \"drug development\", \"drug resistance\", \"drug testing\", \"biomedical engineering\", \"medicinal chemistry\",\n",
    "                                            \"toxicogenomic\", \"toxicology\"])\n",
    "treatment = Subfield(\"Treatment\", [\"treatment\", \"personali\", \"therap\", \"prescription\", \"patient care\", \"dosing\", \"individualiz\", \"individualis\", \"rehabilitation\",\n",
    "                                  \"intervention\", \"stimulus\", \"stimuli\"])\n",
    "#surgery = Subfield(\"Surgery\", [\"surg\"])\n",
    "epidemiology = Subfield(\"Epidemiology\", [\"epidemi\", \"pandemi\"])\n",
    "robotics = Subfield(\"Robotics\", [\"robot\", \"neuro-prosthetics\", \"brain computer interface\", \"brain-computer interface\", \"bci\"])\n",
    "smart_healthcare = Subfield(\"Smart Healthcare\", [\"smart\", \"analytics\", \"data process\", \"data manag\", \"data science\", \"Internet of Things\"\n",
    "                                                \"care data\", \"patient flow\", \"interoperability\", \"privacy\", \"digitali\", \"virtual\",\n",
    "                                                 \"e-health\", \"decision support\", \"data mining\", \"data security\", \"mobile app\", \"wearable\",\n",
    "                                                \"health system\", \"health care system\"])\n",
    "subfields = [diagnosis, prognosis, drug_discovery, treatment, epidemiology, robotics, smart_healthcare]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = Subfield(\"Review\", [\"review\", \"summar\", \"overview\"])\n",
    "literature_types = [review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fdoi%2F10.1016%2FS0933-3657%2801%2900089-6.json\n",
      "Subfield: None\n",
      "Classified as: None\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0009912018311974.json\n",
      "['Literature Review']\n",
      "Subfield: ['Smart Healthcare']\n",
      "Classified as: ['Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0022073619307046.json\n",
      "Subfield: ['Diagnosis']\n",
      "Classified as: ['Diagnosis', 'Prognosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS027263861930842X.json\n",
      "['Literature Review']\n",
      "Subfield: ['Prognosis', 'Treatment', 'Smart Healthcare']\n",
      "Classified as: ['Prognosis', 'Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0303846720300615.json\n",
      "Subfield: ['Diagnosis', 'Prognosis']\n",
      "Classified as: ['Prognosis', 'Surgery']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0303846720300755.json\n",
      "Subfield: ['Smart Healthcare', 'Diagnosis']\n",
      "Classified as: ['Diagnosis', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0378378220301481.json\n",
      "Subfield: None\n",
      "Classified as: ['Diagnosis', 'Treatment', 'Robotics']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0720048X19304243.json\n",
      "Subfield: ['Diagnosis']\n",
      "Classified as: ['Diagnosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0737080620300642.json\n",
      "Subfield: ['Surgery', 'Prognosis']\n",
      "Classified as: ['Diagnosis', 'Prognosis', 'Surgery']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365703001337.json\n",
      "Subfield: ['Epidemiology']\n",
      "Classified as: ['Epidemiology']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365704000429.json\n",
      "Subfield: None\n",
      "Classified as: None\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS093336571300002X.json\n",
      "Subfield: ['Smart Healthcare', 'Prognosis']\n",
      "Classified as: ['Prognosis', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365715000421.json\n",
      "Subfield: ['Diagnosis']\n",
      "Classified as: ['Diagnosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365715000925.json\n",
      "Subfield: ['Diagnosis', 'Smart Healthcare']\n",
      "Classified as: ['Diagnosis', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365716301063.json\n",
      "Subfield: ['Diagnosis', 'Prognosis']\n",
      "Classified as: ['Prognosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365717303482.json\n",
      "Subfield: ['Diagnosis', 'Smart Healthcare']\n",
      "Classified as: ['Diagnosis', 'Prognosis', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365717303913.json\n",
      "Subfield: ['Prognosis']\n",
      "Classified as: ['Prognosis', 'Treatment']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365717305225.json\n",
      "Subfield: ['Treatment']\n",
      "Classified as: ['Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365717305663.json\n",
      "['Literature Review']\n",
      "Subfield: ['Treatment', 'Diagnosis', 'Smart Healthcare']\n",
      "Classified as: ['Diagnosis', 'Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365718304548.json\n",
      "['Literature Review']\n",
      "Subfield: ['Treatment']\n",
      "Classified as: ['Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365718305918.json\n",
      "['Literature Review']\n",
      "Subfield: ['Treatment', 'Epidemiology']\n",
      "Classified as: ['Treatment', 'Epidemiology']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365718306481.json\n",
      "Subfield: ['Prognosis', 'Diagnosis', 'Smart Healthcare']\n",
      "Classified as: ['Diagnosis', 'Prognosis', 'Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365718306894.json\n",
      "Subfield: ['Treatment']\n",
      "Classified as: ['Treatment']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719301083.json\n",
      "Subfield: ['Smart Healthcare', 'Prognosis']\n",
      "Classified as: ['Diagnosis', 'Prognosis', 'Robotics']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719301204.json\n",
      "Subfield: ['Treatment', 'Prognosis']\n",
      "Classified as: ['Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS093336571930226X.json\n",
      "['Literature Review']\n",
      "Subfield: ['Smart Healthcare']\n",
      "Classified as: ['Diagnosis', 'Prognosis', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719302945.json\n",
      "Subfield: ['Treatment', 'Smart Healthcare', 'Diagnosis']\n",
      "Classified as: ['Diagnosis', 'Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719303082.json\n",
      "Subfield: ['Diagnosis']\n",
      "Classified as: ['Diagnosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719303951.json\n",
      "['Literature Review']\n",
      "Subfield: ['Treatment', 'Smart Healthcare']\n",
      "Classified as: ['Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719304816.json\n",
      "Subfield: ['Robotics']\n",
      "Classified as: ['Robotics']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719305858.json\n",
      "['Literature Review']\n",
      "Subfield: ['Diagnosis']\n",
      "Classified as: ['Diagnosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719305871.json\n",
      "Subfield: ['Diagnosis']\n",
      "Classified as: ['Diagnosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719306505.json\n",
      "['Literature Review']\n",
      "Subfield: None\n",
      "Classified as: ['Prognosis', 'Robotics']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719307304.json\n",
      "Subfield: ['Treatment', 'Prognosis']\n",
      "Classified as: ['Prognosis', 'Treatment']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719307663.json\n",
      "Subfield: ['Treatment']\n",
      "Classified as: ['Treatment']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS0933365719308553.json\n",
      "Subfield: ['Smart Healthcare', 'Prognosis']\n",
      "Classified as: ['Prognosis', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS1001929419300288.json\n",
      "Subfield: None\n",
      "Classified as: ['Diagnosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS1076633219304428.json\n",
      "['Literature Review']\n",
      "Subfield: ['Diagnosis']\n",
      "Classified as: ['Diagnosis', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS1076633219304581.json\n",
      "['Literature Review']\n",
      "Subfield: ['Diagnosis', 'Prognosis']\n",
      "Classified as: ['Diagnosis']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS1473050218301721.json\n",
      "['Literature Review']\n",
      "Subfield: ['Treatment', 'Smart Healthcare', 'Prognosis']\n",
      "Classified as: ['Prognosis', 'Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS1532046419302308.json\n",
      "Subfield: ['Smart Healthcare']\n",
      "Classified as: ['Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS2211883718301758.json\n",
      "['Literature Review']\n",
      "Subfield: ['Treatment', 'Diagnosis', 'Prognosis']\n",
      "Classified as: ['Diagnosis', 'Treatment']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS235208171930193X.json\n",
      "['Literature Review']\n",
      "Subfield: ['Smart Healthcare', 'Diagnosis', 'Treatment', 'Drug Discovery', 'Surgery', 'Epidemiology']\n",
      "Classified as: ['Diagnosis', 'Treatment', 'Smart Healthcare']\n",
      "https%3A%2F%2Fapi.elsevier.com%2Fcontent%2Farticle%2Fpii%2FS2452318620300192.json\n",
      "['Literature Review']\n",
      "Subfield: ['Smart Healthcare', 'Diagnosis', 'Prognosis', 'Treatment']\n",
      "Classified as: ['Diagnosis', 'Prognosis', 'Treatment', 'Smart Healthcare']\n"
     ]
    }
   ],
   "source": [
    "path_in = \"manual/\"\n",
    "path_out = \"automatic/\"\n",
    "for filename in os.listdir(path_in):\n",
    "    with open(os.path.join(path_in, filename), 'r') as f_in:\n",
    "        data = f_in.read()\n",
    "        obj = json.loads(data)\n",
    "        if(obj[\"coredata\"][\"dc:description\"] is None):\n",
    "            continue\n",
    "            \n",
    "        text = obj[\"coredata\"][\"dc:title\"]\n",
    "        text = text + obj[\"coredata\"][\"dc:description\"]\n",
    "        print(filename)\n",
    "       \n",
    "        assigned_lit_type = categorise(text.lower(), literature_types)\n",
    "        if(assigned_lit_type):\n",
    "            print(assigned_lit_type)\n",
    "            \n",
    "        assigned_subfields = categorise(text.lower(), subfields)\n",
    "        if assigned_subfields:\n",
    "            obj[\"classified\"] = assigned_subfields\n",
    "        print(\"Subfield: \" + str(obj[\"subfield\"]))\n",
    "        print(\"Classified as: \" + str(obj[\"classified\"]))\n",
    "        \n",
    "        #classified = {\"classified\":\"None\"}\n",
    "        #obj.update(classified)\n",
    "        \n",
    "        #with open(os.path.join(path_out, filename), 'w') as f_out:\n",
    "        #    json.dump(obj, f_out)\n",
    "        #    f_out.close()\n",
    "        #f_in.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \r\n",
      "10.3389/fgene.2019.01077  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Gene expression profiling has been widely used to characterize cell status to reflect the health of the body, to diagnose genetic diseases, etc. In recent years, although the cost of genome-wide expression profiling is gradually decreasing, the cost of collecting expression profiles for thousands of genes is still very high. Considering gene expressions are usually highly correlated in humans, the expression values of the remaining target genes can be predicted by analyzing the values of 943 landmark genes. Hence, we designed an algorithm for predicting gene expression values based on XGBoost, which integrates multiple tree models and has stronger interpretability. We tested the performance of XGBoost model on the GEO dataset and RNA-seq dataset and compared the result with other existing models. Experiments showed that the XGBoost model achieved a significantly lower overall error than the existing D-GEX algorithm, linear regression, and KNN methods. In conclusion, the XGBoost algorithm outperforms existing models and will be a significant contribution to the toolbox for gene expression value prediction. \r\n",
      "  |  https://doi.org/10.3389/fgene.2019.01077  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31781160/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/brainsci9080194  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Statistics plays three important roles in brain studies. They are (1) the study of differences between brains in distinctive populations; (2) the study of the variability in the structure and functioning of the brain; and (3) the study of data reduction on large-scale brain data. I discuss these concepts using examples from past and ongoing research in brain connectivity, brain information flow, information extraction from large-scale neuroimaging data, and neural predictive modeling. Having dispensed with the past, I attempt to present a few areas where statistical science facilitates brain decoding and to write prospectively, in the light of present knowledge and in the quest for artificial intelligence, about questions that statistical and neurobiological communities could work closely together to address in the future. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=brainsci9080194  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31398878/  |  \n",
      "------------------------------------------- \r\n",
      "10.3389/fcell.2019.00349  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Modern molecular high-throughput devices, e.g., next-generation sequencing, have transformed medical research. Resulting data sets are usually high-dimensional on a genomic-scale providing multi-factorial information from intertwined molecular and cellular activities of genes and their products. This genomics-revolution installed precision medicine offering breathtaking opportunities for patient's diagnosis and treatment. However, due to the speed of these developments the quality standards of the involved data analyses are lacking behind, as exemplified by the infamous Duke Saga. In this paper, we argue in favor of a two-stage cooperative serve model that couples data generation and data analysis in the most beneficial way from the perspective of a patient to ensure data analysis quality standards including reproducible research. \r\n",
      "  |  https://doi.org/10.3389/fcell.2019.00349  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31921859/  |  \n",
      "------------------------------------------- \r\n",
      "10.1109/JBHI.2019.2919916  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The dental disease is a common disease for a human. Screening and visual diagnosis that are currently performed in clinics possibly cost a lot in various manners. Along with the progress of the Internet of Things (IoT) and artificial intelligence, the internet-based intelligent system have shown great potential in applying home-based healthcare. Therefore, a smart dental health-IoT system based on intelligent hardware, deep learning, and mobile terminal is proposed in this paper, aiming at exploring the feasibility of its application on in-home dental healthcare. Moreover, a smart dental device is designed and developed in this study to perform the image acquisition of teeth. Based on the data set of 12 600 clinical images collected by the proposed device from 10 private dental clinics, an automatic diagnosis model trained by MASK R-CNN is developed for the detection and classification of 7 different dental diseases including decayed tooth, dental plaque, uorosis, and periodontal disease, with the diagnosis accuracy of them reaching up to 90%, along with high sensitivity and high specificity. Following the one-month test in ten clinics, compared with that last month when the platform was not used, the mean diagnosis time reduces by 37.5% for each patient, helping explain the increase in the number of treated patients by 18.4%. Furthermore, application software (APPs) on mobile terminal for client side and for dentist side are implemented to provide service of pre-examination, consultation, appointment, and evaluation. \r\n",
      "  |  https://dx.doi.org/10.1109/JBHI.2019.2919916  |  \n",
      "------------------------------------------- \r\n",
      "10.1038/s41380-019-0365-9  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Machine and deep learning methods, today's core of artificial intelligence, have been applied with increasing success and impact in many commercial and research settings. They are powerful tools for large scale data analysis, prediction and classification, especially in very data-rich environments (\"big data\"), and have started to find their way into medical applications. Here we will first give an overview of machine learning methods, with a focus on deep and recurrent neural networks, their relation to statistics, and the core principles behind them. We will then discuss and review directions along which (deep) neural networks can be, or already have been, applied in the context of psychiatry, and will try to delineate their future potential in this area. We will also comment on an emerging area that so far has been much less well explored: by embedding semantically interpretable computational models of brain dynamics or behavior into a statistical machine learning context, insights into dysfunction beyond mere prediction and classification may be gained. Especially this marriage of computational models with statistical inference may offer insights into neural and behavioral mechanisms that could open completely novel avenues for psychiatric treatment. \r\n",
      "  |  http://dx.doi.org/10.1038/s41380-019-0365-9  |  \n",
      "------------------------------------------- \r\n",
      "10.1021/acscombsci.8b00189  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   This is a report on the early years of combinatorial materials science and technology. High-throughput technologies (HTTs) are found in life- and materials-science laboratories. Although HTTs have long been the standard in life sciences in academia as well as in industry, HTTs in materials science have become the standard in industry but not in academia. In life science, successful drugs developed with HTTs have been reported, but there is no information on successful materials developed with HTTs that have made it to the market. Some initial development of HTTs in materials science is summarized, especially early applications of artificial intelligence. This outlook attempts to summarize the development of combinatorial materials sciences from the early years to today. \r\n",
      "  |  https://dx.doi.org/10.1021/acscombsci.8b00189  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/s19040753  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   High detection accuracy in piezoelectric-based force sensing in interactive displays has gained global attention. To achieve this, artificial neural networks (ANN)-successful and widely used machine learning algorithms-have been demonstrated to be potentially powerful tools, providing acceptable location detection accuracy of 95.2% and force level recognition of 93.3% in a previous study. While these values might be acceptable for conventional operations, e.g., opening a folder, they must be boosted for applications where intensive operations are performed. Furthermore, the relatively high computational cost reported prevents the popularity of ANN-based techniques in conventional artificial intelligence (AI) chip-free end-terminals. In this article, an ANN is designed and optimized for piezoelectric-based touch panels in interactive displays for the first time. The presented technique experimentally allows a conventional smart device to work smoothly with a high detection accuracy of above 97% for both location and force level detection with a low computational cost, thereby advancing the user experience, and serviced by piezoelectric-based touch interfaces in displays. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=s19040753  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30781752/  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s11948-019-00084-5  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   This paper examines the ethical pitfalls and challenges that non-ethicists, such as researchers and programmers in the fields of computer science, artificial intelligence and robotics, face when building moral machines. Whether ethics is \"computable\" depends on how programmers understand ethics in the first place and on the adequacy of their understanding of the ethical problems and methodological challenges in these fields. Researchers and programmers face at least two types of problems due to their general lack of ethical knowledge or expertise. The first type is so-called rookie mistakes, which could be addressed by providing these people with the necessary ethical knowledge. The second, more difficult methodological issue concerns areas of peer disagreement in ethics, where no easy solutions are currently available. This paper examines several existing approaches to highlight the ethical pitfalls and challenges involved. Familiarity with these and similar problems can help programmers to avoid pitfalls and build better moral machines. The paper concludes that ethical decisions regarding moral robots should be based on avoiding what is immoral (i.e. prohibiting certain immoral actions) in combination with a pluralistic ethical method of solving moral problems, rather than relying on a particular ethical approach, so as to avoid a normative bias. \r\n",
      "  |  https://dx.doi.org/10.1007/s11948-019-00084-5  |  \n",
      "------------------------------------------- \r\n",
      "10.1038/s41598-019-54961-x  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Transmitted light microscopy can readily visualize the morphology of living cells. Here, we introduce artificial-intelligence-powered transmitted light microscopy (AIM) for subcellular structure identification and labeling-free functional analysis of live cells. AIM provides accurate images of subcellular organelles; allows identification of cellular and functional characteristics (cell type, viability, and maturation stage); and facilitates live cell tracking and multimodality analysis of immune cells in their native form without labeling. \r\n",
      "  |  http://dx.doi.org/10.1038/s41598-019-54961-x  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31804589/  |  \n",
      "------------------------------------------- \r\n",
      "10.1103/PhysRevLett.123.213902  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Optical chirality occurs when materials interact differently with light in a specific circular polarization state. Chiroptical phenomena inspire wide interdisciplinary investigations, which require advanced designs to reach strong chirality for practical applications. The development of artificial intelligence provides a new vision for the manipulation of light-matter interaction beyond the theoretical interpretation. Here, we report a self-consistent framework named the Bayesian optimization and convolutional neural network that combines Bayesian optimization and deep convolutional neural network algorithms to calculate and optimize optical properties of metallic nanostructures. Both electric-field distributions at the near field and reflection spectra at the far field are calculated and self-learned to suggest better structure designs and provide possible explanations for the origin of the optimized properties, which enables wide applications for future nanostructure analysis and design. \r\n",
      "  |  http://link.aps.org/abstract/PRL/v123/p213902  |  \n",
      "------------------------------------------- \r\n",
      "10.1093/bioinformatics/bty511  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Motivation:  Understanding the mutational processes that act during cancer development is a key topic of cancer biology. Nevertheless, much remains to be learned, as a complex interplay of processes with dependencies on a range of genomic features creates highly heterogeneous cancer genomes. Accurate driver detection relies on unbiased models of the mutation rate that also capture rate variation from uncharacterized sources. \r\n",
      "  Results:  Here, we analyse patterns of observed-to-expected mutation counts across 505 whole cancer genomes, and find that genomic features missing from our mutation-rate model likely operate on a megabase length scale. We extend our site-specific model of the mutation rate to include the additional variance from these sources, which leads to robust significance evaluation of candidate cancer drivers. We thus present ncdDetect v.2, with greatly improved cancer driver detection specificity. Finally, we show that ranking candidates by their posterior mean value of their effect sizes offers an equivalent and more computationally efficient alternative to ranking by their P-values. \r\n",
      "  Availability and implementation:  ncdDetect v.2 is implemented as an R-package and is freely available at http://github.com/TobiasMadsen/ncdDetect2. \r\n",
      "  Supplementary information:  Supplementary data are available at Bioinformatics online. \r\n",
      "  |  https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bty511  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/29945188/  |  \n",
      "------------------------------------------- \r\n",
      "10.1177/0962280218805780  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Stochastic transmission dynamic models are needed to quantify the uncertainty in estimates and predictions during outbreaks of infectious diseases. We previously developed a calibration method for stochastic epidemic compartmental models, called Multiple Shooting for Stochastic Systems (MSS), and demonstrated its competitive performance against a number of existing state-of-the-art calibration methods. The existing MSS method, however, lacks a mechanism against filter degeneracy, a phenomenon that results in parameter posterior distributions that are weighted heavily around a single value. As such, when filter degeneracy occurs, the posterior distributions of parameter estimates will not yield reliable credible or prediction intervals for parameter estimates and predictions. In this work, we extend the MSS method by evaluating and incorporating two resampling techniques to detect and resolve filter degeneracy. Using simulation experiments, we demonstrate that an extended MSS method produces credible and prediction intervals with desired coverage in estimating key epidemic parameters (e.g. mean duration of infectiousness and <i>R</i><sub>0</sub>) and short- and long-term predictions (e.g. one and three-week forecasts, timing and number of cases at the epidemic peak, and final epidemic size). Applying the extended MSS approach to a humidity-based stochastic compartmental influenza model, we were able to accurately predict influenza-like illness activity reported by U.S. Centers for Disease Control and Prevention from 10 regions as well as city-level influenza activity using real-time, city-specific Google search query data from 119 U.S. cities between 2003 and 2014. \r\n",
      "  |  http://journals.sagepub.com/doi/full/10.1177/0962280218805780?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30428780/  |  \n",
      "------------------------------------------- \r\n",
      "10.1371/journal.pcbi.1007342  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Stochastic mechanistic epidemiological models largely contribute to better understand pathogen emergence and spread, and assess control strategies at various scales (from within-host to transnational scale). However, developing realistic models which involve multi-disciplinary knowledge integration faces three major challenges in predictive epidemiology: lack of readability once translated into simulation code, low reproducibility and reusability, and long development time compared to outbreak time scale. We introduce here EMULSION, an artificial intelligence-based software intended to address those issues and help modellers focus on model design rather than programming. EMULSION defines a domain-specific language to make all components of an epidemiological model (structure, processes, parameters…) explicit as a structured text file. This file is readable by scientists from other fields (epidemiologists, biologists, economists), who can contribute to validate or revise assumptions at any stage of model development. It is then automatically processed by EMULSION generic simulation engine, preventing any discrepancy between model description and implementation. The modelling language and simulation architecture both rely on the combination of advanced artificial intelligence methods (knowledge representation and multi-level agent-based simulation), allowing several modelling paradigms (from compartment- to individual-based models) at several scales (up to metapopulation). The flexibility of EMULSION and its capability to support iterative modelling are illustrated here through examples of progressive complexity, including late revisions of core model assumptions. EMULSION is also currently used to model the spread of several diseases in real pathosystems. EMULSION provides a command-line tool for checking models, producing model diagrams, running simulations, and plotting outputs. Written in Python 3, EMULSION runs on Linux, MacOS, and Windows. It is released under Apache-2.0 license. A comprehensive documentation with installation instructions, a tutorial and many examples are available from: https://sourcesup.renater.fr/www/emulsion-public. \r\n",
      "  |  http://dx.plos.org/10.1371/journal.pcbi.1007342  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31518349/  |  \n",
      "------------------------------------------- \r\n",
      "10.1093/bioinformatics/bty1035  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Motivation:  Accurate and wide-ranging prediction of thermodynamic parameters for biochemical reactions can facilitate deeper insights into the workings and the design of metabolic systems. \r\n",
      "  Results:  Here, we introduce a machine learning method with chemical fingerprint-based features for the prediction of the Gibbs free energy of biochemical reactions. From a large pool of 2D fingerprint-based features, this method systematically selects a small number of relevant ones and uses them to construct a regularized linear model. Since a manual selection of 2D structure-based features can be a tedious and time-consuming task, requiring expert knowledge about the structure-activity relationship of chemical compounds, the systematic feature selection step in our method offers a convenient means to identify relevant 2D fingerprint-based features. By comparing our method with state-of-the-art linear regression-based methods for the standard Gibbs free energy prediction, we demonstrated that its prediction accuracy and prediction coverage are most favorable. Our results show direct evidence that a number of 2D fingerprints collectively provide useful information about the Gibbs free energy of biochemical reactions and that our systematic feature selection procedure provides a convenient way to identify them. \r\n",
      "  Availability and implementation:  Our software is freely available for download at http://sfb.kaust.edu.sa/Pages/Software.aspx. \r\n",
      "  Supplementary information:  Supplementary data are available at Bioinformatics online. \r\n",
      "  |  https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bty1035  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30590445/  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s10620-019-05791-4  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Video capsule endoscopy became a reality in 2001. This device enabled us to directly view the mucosa of the small intestine for the first time. The main indications for the video capsule remain the detection of small intestinal bleeding and iron deficiency anemia, diagnosis and management of Crohn's disease, and detection of tumors. The device is extraordinarily safe and can be used in the very young to the very old. However, there remain several areas of controversy and difficulty. These are covered in this article and include details of indications and contraindications, whether to prepare patients, whether or not to use simethicone and prokinetics. Detection of location of the capsule remains a major engineering challenge. Reading the videos reliably and quickly remains challenging. However, artificial intelligence and machine learning are already on the horizon to provide assistance. New uses for capsule endoscopy promise more accurate diagnosis and hence improved management of acute gastrointestinal bleeding. The colon capsule may eventually help those who refuse conventional colonoscopy, and robotically controlled capsules may be helpful in screening for serious disease in patients with upper abdominal complaints. The advent of the broadening use of video capsule endoscopy is, though it will be controversial, embraced by some and derided by others; such is the nature of technological development. In the long run, if the use of the video capsule, based on sound evidence-based studies, can be shown to improve the care of our patients and reduce the cost of health care, its use will continue to expand. \r\n",
      "  |  https://doi.org/10.1007/s10620-019-05791-4  |  \n",
      "------------------------------------------- \r\n",
      "10.1111/den.13481  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The latest state of the art technological innovations have led to a palpable progression in endoscopic imaging and may facilitate standardisation of practice. One of the most rapidly evolving modalities is artificial intelligence with recent studies providing real-time diagnoses and encouraging results in the first randomised trials to conventional endoscopic imaging. Advances in functional hypoxia imaging offer novel opportunities to be used to detect neoplasia and the assessment of colitis. Three-dimensional volumetric imaging provides spatial information and has shown promise in the increased detection of small polyps. Studies to date of self-propelling colonoscopes demonstrate an increased caecal intubation rate and possibly offer patients a more comfortable procedure. Further development in robotic technology has introduced ex vivo automated locomotor upper gastrointestinal and small bowel capsule devices. Eye-tracking has the potential to revolutionise endoscopic training through the identification of differences in experts and non-expert endoscopist as trainable parameters. In this review, we discuss the latest innovations of all these technologies and provide perspective into the exciting future of diagnostic luminal endoscopy. \r\n",
      "  |  https://doi.org/10.1111/den.13481  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.medengphy.2019.08.005  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Computer technology is ubiquitous and relied upon in virtually all professional activities including neurosurgery, which is why it is surprising that it is not the case for orthopaedic surgery with fewer than 5% of surgeons using available computer technology in their procedures. In this review, we explore the evolution and background of Computer Assisted Orthopaedic Surgery (CAOS), delving into the basic principles behind the technology and the changes in the discussion on the subject throughout the years and the impact these discussions had on the field. We found evidence that industry had an important role in driving the discussion at least in knee arthroplasty-a leading field of CAOS-with the ratio between patents and publications increased from approximately 1:10 in 2004 to almost 1:3 in 2014. The adoption of CAOS is largely restrained by economics and ergonomics with sceptics challenging the accuracy and precision of navigation during the early years of CAOS moving to patient functional improvements and long term survivorship. Nevertheless, the future of CAOS remains positive with the prospect of new technologies such as improvements in image-guided surgery, enhanced navigation systems, robotics and artificial intelligence. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1350-4533(19)30160-2  |  \n",
      "------------------------------------------- \r\n",
      "10.1371/journal.pcbi.1006580  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   In crowding, perception of an object deteriorates in the presence of nearby elements. Although crowding is a ubiquitous phenomenon, since elements are rarely seen in isolation, to date there exists no consensus on how to model it. Previous experiments showed that the global configuration of the entire stimulus must be taken into account. These findings rule out simple pooling or substitution models and favor models sensitive to global spatial aspects. In order to investigate how to incorporate global aspects into models, we tested a large number of models with a database of forty stimuli tailored for the global aspects of crowding. Our results show that incorporating grouping like components strongly improves model performance. \r\n",
      "  |  http://dx.plos.org/10.1371/journal.pcbi.1006580  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31075131/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/s19010125  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   In the era of the Internet of Things and Artificial Intelligence, the Wi-Fi fingerprinting-based indoor positioning system (IPS) has been recognized as the most promising IPS for various applications. Fingerprinting-based algorithms critically rely on a fingerprint database built from machine learning methods. However, currently methods are based on single-feature Received Signal Strength (RSS), which is extremely unstable in performance in terms of precision and robustness. The reason for this is that single feature machines cannot capture the complete channel characteristics and are susceptible to interference. The objective of this paper is to exploit the Time of Arrival (TOA) feature and propose a heterogeneous features fusion model to enhance the precision and robustness of indoor positioning. Several challenges are addressed: (1) machine learning models based on heterogeneous features, (2) the optimization of algorithms for high precision and robustness, and (3) computational complexity. This paper provides several heterogeneous features fusion-based localization models. Their effectiveness and efficiency are thoroughly compared with state-of-the-art methods. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=s19010125  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30609715/  |  \n",
      "------------------------------------------- \r\n",
      "10.1021/acs.jpclett.9b02232  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   In this work, inspired by Phillips's ionicity theory in solid-state physics, we directly sort out the critical factors of the band gap's feature correlations in the machine learning architected with the Lasso algorithm. Even based on a small 2D materials data set, we can fundamentally approach an accurate and rational model about the band gap and exciton binding energy with robust transferability to other databases. Our machine learning outputs can reveal the exact physics pictures behind the predicted quantity as well as the \"secondary understanding\" of the correlation between the approximated physics models in exciton. This work stresses the significant value of physics endorsement on the machine learning (ML) algorithm and provides a symbolic regression solution for the \"few-shot\" training scheme for ML technology in materials science. Moreover, physics-inspired secondary understanding could be an essential supplement for ML in scientific research fields. \r\n",
      "  |  https://dx.doi.org/10.1021/acs.jpclett.9b02232  |  \n",
      "------------------------------------------- \r\n",
      "10.1177/1559325819876218  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Several investigations have focused on studying the suppressing influence of <i>Salvadora persica</i> (miswak) on oral microbes; however, studies regarding its fungicidal activity versus human aspergillosis-related illness are still scarce. The current research was designed to evaluate the fungicidal action of <i>S persica</i> aquatic root extract in terms of radial growth rate and inhibition zone (IZO) versus 3 pathogenic <i>Aspergillus</i> species, namely, <i>A nige</i>r, <i>A flavus</i>, and <i>A fumigatus</i> in vitro. The results revealed that the plant extract (50 and 100 mg/mL) exhibited a prohibiting influence on the growth of the tested fungal species. The high concentration (100 mg/mL) of the plant extract <i>was</i> efficient in prohibiting the growing rate of the tested <i>Aspergillus</i> species after 6 days exposure period. <i>Aspergillus niger</i> and <i>A flavus</i> showed the largest inhibition ratios (60% and 54.4%, respectively) and IZO (33.00 ± 0.05 mm and 25.50 ± 0.18 mm, respectively) versus the control counterparts. <i>Aspergillus fumigatus</i> showed the minimum inhibition ratio (39%) and IZO (20.31 ± 0.05). The present data showed that the extract of <i>S persica</i> possesses potential fungicidal influence versus the tested pathogenic <i>Aspergillus</i> species and this may support the utilization of this extract as a promising antifungal agent versus aspergillosis. \r\n",
      "  |  https://journals.sagepub.com/doi/10.1177/1559325819876218?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0www.ncbi.nlm.nih.gov  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31598116/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/jcm8101618  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  The field of implant dentistry education is rapidly evolving as new technologies permit innovative methods to teach the fundamentals of implant dentistry. \r\n",
      "  Methods:  Literature from the fields of active learning, blended learning, augmented reality, artificial intelligence, haptics, and mixed reality were reviewed and combined with the experience and opinions of expert authors. Both positive and negative aspects of the learning methods are presented. \r\n",
      "  Results and conclusion:  The fundamental objectives of teaching and learning remain unchanged, yet the opportunities to reach larger audiences and integrate their learning into active experiences are evolving due to the introduction of new teaching and learning methodologies. The ability to reach a global audience has never been more apparent. Nevertheless, as much as new technology can be alluring, each new method comes with unique limitations. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=jcm8101618  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31590228/  |  \n",
      "------------------------------------------- \r\n",
      "10.12701/yujm.2019.00206  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Medical education research subjects are incredibly diverse and have changed over time. This work in particular aims to compare and analyze research trends in medical education through the words used in the titles of these research papers. Academic Medicine (the journal of the Association of American Medical Colleges), Medical Teacher (the journal of the Association of Medical Education in Europe), the Korean Journal of Medical Education (KJME), and Korean Medical Education Review (KMER) were selected and analyzed for the purposes of this research. From 2009 to 2018, Academic Medicine and Medical Teacher published approximately 10 to 20 times more papers than the KJME and KMER. Frequently used words in these titles include \"medical,\" \"student,\" \"education,\" and \"learning.\" The words \"clinical\" and \"learning\" were used relatively often (7.80% to 13.66%) in Korean journals and Medical Teacher, but Academic Medicine used these phrases relatively less often (6.47% and 4.41%, respectively). Concern with such various topics as problem-based learning, team-based learning, program evaluations, burnout, e-learning, and digital indicates that Medical Teacher seems to primarily deal with teaching and learning methodologies, and Academic Medicine handles all aspects of medical education. The KJME and KMER did not cover all subjects, as they publish smaller papers. However, it is anticipated that research on new subjects, such as artificial intelligence in medical education, will occur in the near future. \r\n",
      "  |  http://e-yujm.org/journal/view.php?doi=10.12701/yujm.2019.00206  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31620617/  |  \n",
      "------------------------------------------- \r\n",
      "10.1103/PhysRevLett.123.260501  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   We report on the experimental measurement of the Hilbert-Schmidt distance between two two-qubit states by many-particle interference. We demonstrate that our three-step method for measuring distances in the Hilbert space is far less complex than reconstructing density matrices and that it can be applied in quantum-enhanced machine learning to reduce the complexity of calculating Euclidean distances between multidimensional points, which can be especially interesting for near term quantum technologies and quantum artificial intelligence research. Our results are also a novel example of applying mixed states in quantum information processing. Usually working with mixed states is undesired, but here it gives the possibility of encoding extra information as the degree of coherence between the given two dimensions of the density matrix. \r\n",
      "  |  http://link.aps.org/abstract/PRL/v123/p260501  |  \n",
      "------------------------------------------- \r\n",
      "10.1186/s12911-019-0980-z  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  Clinical Named Entity Recognition is to find the name of diseases, body parts and other related terms from the given text. Because Chinese language is quite different with English language, the machine cannot simply get the graphical and phonetic information form Chinese characters. The method for Chinese should be different from that for English. Chinese characters present abundant information with the graphical features, recent research on Chinese word embedding tries to use graphical information as subword. This paper uses both graphical and phonetic features to improve Chinese Clinical Named Entity Recognition based on the presence of phono-semantic characters. \r\n",
      "  Methods:  This paper proposed three different embedding models and tested them on the annotated data. The data have been divided into two sections for exploring the effect of the proportion of phono-semantic characters. \r\n",
      "  Results:  The model using primary radical and pinyin can improve Clinical Named Entity Recognition in Chinese and get the F-measure of 0.712. More phono-semantic characters does not give a better result. \r\n",
      "  Conclusions:  The paper proves that the use of the combination of graphical and phonetic features can improve the Clinical Named Entity Recognition in Chinese. \r\n",
      "  |  https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-0980-z  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31865903/  |  \n",
      "------------------------------------------- \r\n",
      "10.1109/TNB.2019.2919188  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   It is crucial for doctors to fully understand the interaction between drugs in prescriptions, especially when a patient takes multiple medications at the same time during treatment. The purpose of drug drug interaction (DDI) extraction is to automatically obtain the interaction between drugs from biomedical literature. Current state-of-the-art approaches for DDI extraction task are based on artificial intelligence and natural language processing. While such existing DDI extraction methods can provide more knowledge and enhance the performance through external resources such as biomedical databases or ontologies, due to the difficulty of updating, these external resources are delayed. In fact, user generated content (UGC) is another kind of external medical resources that can be quickly updated. We are trying to use UGC resources to provide more available information for our deep learning DDI extraction method. In this paper, we present a DDI extraction approach through a new attention mechanism called full-attention which can combine the UGC information with contextual information. We conducted a series of experiments on the DDI 2013 Evaluation dataset to evaluate our method. Experiments show improved performance compared with the state of the art and UGC-DDI model achieves a competitive F-score of 0.712. \r\n",
      "  |  https://dx.doi.org/10.1109/TNB.2019.2919188  |  \n",
      "------------------------------------------- \r\n",
      "10.32687/0869-866X-2019-27-si1-630-636  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   For the first time in Moscow and Russia, a program of selective lung cancer screening has been implemented with a comprehensive approach, including organizational, management, medical, technical and educational aspects and quality control. Unique ultra-low-dose protocols (ultra-LDCT) have been developed to implement the screening program. These protocols allow performing high-quality chest computed tomography for lung nodule detection with an effective dose of less than 1 mSv. The possibility of using neural networks (\"artificial intelligence\") for quality control of screening results has been proven for the first time. \r\n",
      "  |  None  |  \n",
      "------------------------------------------- \r\n",
      "10.3389/fgene.2019.01182  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The microbiome-wide association studies are to figure out the relationship between microorganisms and humans, with the goal of discovering relevant biomarkers to guide disease diagnosis. However, the microbiome data is complex, with high noise and dimensions. Traditional machine learning methods are limited by the models' representation ability and cannot learn complex patterns from the data. Recently, deep learning has been widely applied to fields ranging from text processing to image recognition due to its efficient flexibility and high capacity. But the deep learning models must be trained with enough data in order to achieve good performance, which is impractical in reality. In addition, deep learning is considered as black box and hard to interpret. These factors make deep learning not widely used in microbiome-wide association studies. In this work, we construct a sparse microbial interaction network and embed this graph into deep model to alleviate the risk of overfitting and improve the performance. Further, we explore a Graph Embedding Deep Feedforward Network (GEDFN) to conduct feature selection and guide meaningful microbial markers' identification. Based on the experimental results, we verify the feasibility of combining the microbial graph model with the deep learning model, and demonstrate the feasibility of applying deep learning and feature selection on microbial data. Our main contributions are: firstly, we utilize different methods to construct a variety of microbial interaction networks and combine the network <i>via</i> graph embedding deep learning. Secondly, we introduce a feature selection method based on graph embedding and validate the biological meaning of microbial markers. The code is available at https://github.com/MicroAVA/GEDFN.git. \r\n",
      "  |  https://doi.org/10.3389/fgene.2019.01182  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31824573/  |  \n",
      "------------------------------------------- \r\n",
      "10.1098/rsos.190868  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The filter bubble is an intermediate structure to provoke polarization and echo chambers in social networks, and it has become one of today's most urgent issues for social media. Previous studies usually equated filter bubbles with community structures and emphasized this exogenous isolation effect, but there is a lack of full discussion of the internal organization of filter bubbles. Here, we design an experiment for analysing filter bubbles taking advantage of social bots. We deployed 128 bots to Weibo (the largest microblogging network in China), and each bot consumed a specific topic (entertainment or sci-tech) and ran for at least two months. In total, we recorded about 1.3 million messages exposed to these bots and their social networks. By analysing the text received by the bots and motifs in their social networks, we found that a filter bubble is not only a dense community of users with the same preferences but also presents an endogenetic unidirectional star-like structure. The structure could spontaneously exclude non-preferred information and cause polarization. Moreover, our work proved that the felicitous use of artificial intelligence technology could provide a useful experimental approach that combines privacy protection and controllability in studying social media. \r\n",
      "  |  https://royalsocietypublishing.org/doi/full/10.1098/rsos.190868?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31827834/  |  \n",
      "------------------------------------------- \r\n",
      "10.1001/amajethics.2019.160  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   As capabilities of predictive algorithms improve, machine learning will become an important element of physician practice and patient care. Implementation of artificial intelligence (AI) raises complex legal questions regarding health care professionals' and technology manufacturers' liability, particularly if they cannot explain recommendations generated by AI technology. The limited literature on liability for innovation provides opportunities to consider possible implications of AI for medical malpractice and products liability and new legal solutions for addressing liability issues surrounding \"black-box\" medicine. \r\n",
      "  |  https://journalofethics.ama-assn.org/article/are-current-tort-liability-doctrines-adequate-addressing-injury-caused-ai/2019-02  |  \n",
      "------------------------------------------- \r\n",
      "10.26355/eurrev_201912_19686  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The global number of people over the age of 60 years is expected to increase from 970 million to 2.1 billion in 2050 and 3.1 billion in 2100. About 80% of the aging population will be in the developing countries. Aging population may suffer from various physical, cognitive, and social problems, due to aging process such as impairment of physical related functions (decreased mobility and walking speed, falls, frailty, decreased walking speed, difficulties in basic, and instrumental activities of daily living), cognitive related functions (memory-related issues), sensory functions (hearing loss, cataracts and refractive errors, presbyopia, decreased vestibular function), behavioural and psychological disorders, social isolation issues, and poor quality of life. Over the period of the last few decades, emerging technologies such as internet of things (IoT), artificial intelligence (AI), sensors, cloud computing, wireless communication technologies, and assistive robotics have given the vision to develop various ambient or active assisted living (AAL) approaches for supporting an elderly people to live safely and independently in their living environment and participate in their daily and community activities, as well as supporting them to maintain their physical, mental health, and quality of their life. The aim of this paper is to review the use of Ambient or Active Assisted Living for older adults with physical, cognitive impairments, and their social participation. \r\n",
      "  |  None  |  \n",
      "------------------------------------------- \r\n",
      "10.1093/nar/gkz328  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   MicroRNAs (miRNAs) are one class of important small non-coding RNA molecules and play critical roles in health and disease. Therefore, it is important and necessary to evaluate the functional relationship of miRNAs and then predict novel miRNA-disease associations. For this purpose, here we developed the updated web server MISIM (miRNA similarity) v2.0. Besides a 3-fold increase in data content compared with MISIM v1.0, MISIM v2.0 improved the original MISIM algorithm by implementing both positive and negative miRNA-disease associations. That is, the MISIM v2.0 scores could be positive or negative, whereas MISIM v1.0 only produced positive scores. Moreover, MISIM v2.0 achieved an algorithm for novel miRNA-disease prediction based on MISIM v2.0 scores. Finally, MISIM v2.0 provided network visualization and functional enrichment analysis for functionally paired miRNAs. The MISIM v2.0 web server is freely accessible at http://www.lirmed.com/misim/. \r\n",
      "  |  https://academic.oup.com/nar/article-lookup/doi/10.1093/nar/gkz328  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31069374/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.clinph.2019.06.005  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    |  https://linkinghub.elsevier.com/retrieve/pii/S1388-2457(19)30900-9  |  \n",
      "------------------------------------------- \r\n",
      "10.1109/JBHI.2019.2923773  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Salivary gland ultrasonography (SGUS) has shown good potential in the diagnosis of primary Sjögren's syndrome (pSS). However, a series of international studies have reported needs for improvements of the existing pSS scoring procedures in terms of inter/intra observer reliability before being established as standardized diagnostic tools. The present study aims to solve this problem by employing radiomics features and artificial intelligence (AI) algorithms to make the pSS scoring more objective and faster compared to human expert scoring. The assessment of AI algorithms was performed on a two-centric cohort, which included 600 SGUS images (150 patients) annotated using the original SGUS scoring system proposed in 1992 for pSS. For each image, we extracted 907 histogram-based and descriptive statistics features from segmented salivary glands. Optimal feature subsets were found using the genetic algorithm based wrapper approach. Among the considered algorithms (seven classifiers and five regressors), the best preforming was the multilayer perceptron (MLP) classifier (κ = 0.7). The MLP over-performed average score achieved by the clinicians (κ = 0.67) by the considerable margin, whereas its reliability was on the level of human intra-observer variability (κ = 0.71). The presented findings indicate that the continuously increasing HarmonicSS cohort will enable further advancements in AI-based pSS scoring methods by SGUS. In turn, this may establish SGUS as an effective noninvasive pSS diagnostic tool, with the final goal to supplement current diagnostic tests. \r\n",
      "  |  https://dx.doi.org/10.1109/JBHI.2019.2923773  |  http://eprints.whiterose.ac.uk/159091/  |  \n",
      "------------------------------------------- \r\n",
      "10.3389/fnhum.2019.00170  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Japanese martial arts, <i>Budo</i>, have been reported to improve cognitive function, especially attention. However, the underlying neural mechanisms of the effect of <i>Budo</i> on attention processing has not yet been investigated. <i>Kendo</i>, a type of fencing using bamboo swords, is one of the most popular forms of <i>Budo</i> worldwide. We investigated the difference in functional connectivity (FC) between <i>Kendo</i> players (KPs) and non-KPs (NKPs) during an attention-related auditory oddball paradigm and during rest. The analyses focused on the brain network related to \"motivation.\" Resting-state functional magnetic resonance imaging (rs-fMRI) and task-based fMRI using the oddball paradigm were performed in healthy male volunteers (14 KPs and 11 NKPs). Group differences in FC were tested using CONN-software within the motivation network, which consisted of 22 brain regions defined by a previous response-conflict task-based fMRI study with a reward cue. Daily general physical activities were assessed using the International Physical Activity Questionnaire (IPAQ). We also investigated the impact of major confounders, namely, smoking habits, alcohol consumption, IPAQ score, body mass index (BMI), and reaction time (RT) in the oddball paradigm. Resting-state fMRI revealed that KPs had a significantly lower FC than NKPs between the right nucleus accumbens and right frontal eye field (FEF) within the motivation network. Conversely, KPs exhibited a significantly higher FC than NKPs between the left intraparietal sulcus (IPS) and the left precentral gyrus (PCG) within the network during the auditory oddball paradigm [statistical thresholds, False Discovery Rate (FDR) &lt; 0.05]. These results remained significant after controlling for major covariates. Our results suggest that attenuated motivation network integrity at rest together with enhanced motivation network integrity during attentional demands might underlie the instantaneous concentration abilities of KPs. \r\n",
      "  |  https://doi.org/10.3389/fnhum.2019.00170  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31191277/  |  \n",
      "------------------------------------------- \r\n",
      "10.1259/bjr.20190610  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   In this article, we explore the evidence around the relative benefits and harms of breast cancer screening using a single radiologist to examine each female's mammograms for signs of cancer (single reading), or two radiologists (double reading). First, we briefly explore the historical evidence using film-screen mammography, before providing an in-depth description of evidence using digital mammography. We classify studies according to which exact version of double reading they use, because the evidence suggests that effectiveness of double reading is contingent on whether the two radiologists are blinded to one another's decisions, and how the decisions of the two radiologists are integrated. Finally, we explore the implications for future mammography, including using artificial intelligence as the second reader, and applications to more complex three-dimensional imaging techniques such as tomosynthesis. \r\n",
      "  |  http://www.birpublications.org/doi/full/10.1259/bjr.20190610?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/s19112525  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Internet of Things (IoT) technology has been attracted lots of interests over the recent years, due to its applicability across the various domains. In particular, an IoT-based robot with artificial intelligence may be utilized in various fields of surveillance. In this paper, we propose an IoT platform with an intelligent surveillance robot using machine learning in order to overcome the limitations of the existing closed-circuit television (CCTV) which is installed fixed type. The IoT platform with a surveillance robot provides the smart monitoring as a role of active CCTV. The intelligent surveillance robot, which has been built with its own IoT server, and can carry out line tracing and acquire contextual information through the sensors to detect abnormal status in an environment. In addition, photos taken by its camera can be compared with stored images of normal state. If an abnormal status is detected, the manager receives an alarm via a smart phone. For user convenience, the client is provided with an app to control the robot remotely. In the case of image context processing it is useful to apply convolutional neural network (CNN)-based machine learning (ML), which is introduced for the precise detection and recognition of images or patterns, and from which can be expected a high performance of recognition. We designed the CNN model to support contextually-aware services of the IoT platform and to perform experiments for learning accuracy of the designed CNN model using dataset of images acquired from the robot. Experimental results showed that the accuracy of learning is over 0.98, which means that we achieved enhanced learning in image context recognition. The contribution of this paper is not only to implement an IoT platform with active CCTV robot but also to construct a CNN model for image-and-context-aware learning and intelligence enhancement of the proposed IoT platform. The proposed IoT platform, with an intelligent surveillance robot using machine learning, can be used to detect abnormal status in various industrial fields such as factory, smart farms, logistics warehouses, and public places. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=s19112525  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31159503/  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s00221-018-5441-x  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The development of advanced and effective human-machine interfaces, especially for amputees to control their prostheses, is very high priority and a very active area of research. An intuitive control method should retain an adequate level of functionality for dexterous operation, provide robustness against confounding factors, and supply adaptability for diverse long-term usage, all of which are current problems being tackled by researchers. This paper reviews the state-of-the-art, as well as, the limitations of current myoelectric signal control (MSC) methods. To address the research topic on functionality, we review different approaches to prosthetic hand control (DOF configuration, discrete or simultaneous, etc.), and how well the control is performed (accuracy, response, intuitiveness, etc.). To address the research on robustness, we review the confounding factors (limb positions, electrode shift, force variance, and inadvertent activity) that affect the stability of the control performance. Lastly, to address adaptability, we review the strategies that can automatically adjust the classifier for different individuals and for long-term usage. This review provides a thorough overview of the current MSC methods and helps highlight the current areas of research focus and resulting clinic usability for the MSC methods for upper-limb prostheses. \r\n",
      "  |  https://dx.doi.org/10.1007/s00221-018-5441-x  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.neuroimage.2019.116333  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Decision-making plays an essential role in the interpersonal interactions and cognitive processing of individuals. There has been increasing interest in being able to predict an individual's decision-making response (i.e., acceptance or rejection). We proposed an electroencephalogram (EEG)-based computational intelligence framework to predict individual responses. Specifically, the discriminative spatial network pattern (DSNP), a supervised learning approach, was applied to single-trial EEG data to extract the DSNP feature from the single-trial brain network. A linear discriminate analysis (LDA) trained on the DSNP features was then used to predict the individual response trial-by-trial. To verify the performance of the proposed DSNP, we recruited two independent subject groups, and recorded the EEGs using two types of EEG systems. The performances of the trial-by-trial predictors achieved an accuracy of 0.88 ± 0.09 for the first dataset, and 0.90 ± 0.10 for the second dataset. These trial-by-trial prediction performances suggested that individual responses could be predicted trial-by-trial by using the specific pattern of single-trial EEG networks, and our proposed method has the potential to establish the biologically inspired artificial intelligence decision system. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1053-8119(19)30924-3  |  \n",
      "------------------------------------------- \r\n",
      "10.2196/13111  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  Physical rehabilitation is recommended after total knee arthroplasty (TKA). With the expected increase in TKA over the next few decades, it is important to find new ways of delivering cost-effective interventions. Technological interventions have been developed with this intent, but only preliminary evidence exists regarding their validity, with short follow-up times. \r\n",
      "  Objective:  This study aimed to present the follow-up results of a feasibility study comparing two different home-based programs after TKA: conventional face-to-face sessions and a digital intervention performed through the use of an artificial intelligence-powered biofeedback system under remote clinical monitoring. \r\n",
      "  Methods:  The digital intervention uses a motion tracker allowing 3D movement quantification, a mobile app and a Web portal. This study presents the results of the previous single-center, prospective, parallel-group, feasibility study including an 8-week active treatment stage and further assessments at 3 and 6 months post-TKA. Primary outcome was the Timed Up and Go score, and secondary outcomes were the Knee Osteoarthritis Outcome Scale (KOOS) score and knee range of motion. \r\n",
      "  Results:  A total of 59 patients completed the study (30 in the digital intervention group and 29 in the conventional rehabilitation group) and follow-up assessments. During the active treatment stage, patients in the digital intervention group demonstrated high engagement and satisfaction levels, with an 82% retention rate. Both groups attained clinically relevant improvements from baseline to 6 months post-TKA. At the end of the 8-week program, clinical outcomes were superior in the digital intervention group. At the 3- and 6-month assessments, the outcomes remained superior for the Timed Up and Go score (P&lt;.001) and all KOOS subscale scores (at 3 months, P&lt;.001 overall; at 6 months, KOOS Symptoms: P=.006, Pain: P=.002, Activities of Daily Living: P=.001, Sports: P=.003, and Quality of Life: P=.001). There was progressive convergence between both groups in terms of the knee range of motion, which remained higher for standing flexion in the digital intervention group than the conventional group at 6 months (P=.01). For the primary outcome, at 6 months, the median difference between groups was 4.87 seconds (95% CI 1.85-7.47), in favor of the digital intervention group. \r\n",
      "  Conclusions:  The present study demonstrates that this novel digital intervention for independent home-based rehabilitation after TKA is feasible, engaging, and capable of maximizing clinical outcomes in comparison to conventional rehabilitation in the short and medium term; in addition, this intervention is far less demanding in terms of human resources. \r\n",
      "  Trial registration:  ClinicalTrials.gov <a href=\"http://clinicaltrials.gov/show/NCT03047252\" title=\"See in ClinicalTrials.gov\">NCT03047252</a>; https://clinicaltrials.gov/ct2/show/NCT03047252. \r\n",
      "  |  https://rehab.jmir.org/2019/1/e13111/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30816849/  |  \n",
      "------------------------------------------- \r\n",
      "10.1371/journal.pone.0208308  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Optimization of an artificial neural network model through the use of optimization algorithms is the common method employed to search for an optimum solution for a broad variety of real-world problems. One such optimization algorithm is the kidney-inspired algorithm (KA) which has recently been proposed in the literature. The algorithm mimics the four processes performed by the kidneys: filtration, reabsorption, secretion, and excretion. However, a human with reduced kidney function needs to undergo additional treatment to improve kidney performance. In the medical field, the glomerular filtration rate (GFR) test is used to check the health of kidneys. The test estimates the amount of blood that passes through the glomeruli each minute. In this paper, we mimic this kidney function test and the GFR result is used to select a suitable step to add to the basic KA process. This novel imitation is designed for both minimization and maximization problems. In the proposed method, depends on GFR test result which is less than 15 or falls between 15 and 60 or is more than 60 a particular action is performed. These additional processes are applied as required with the aim of improving exploration of the search space and increasing the likelihood of the KA finding the optimum solution. The proposed method is tested on test functions and its results are compared with those of the basic KA. Its performance on benchmark classification and time series prediction problems is also examined and compared with that of other available methods in the literature. In addition, the proposed method is applied to a real-world water quality prediction problem. The statistical analysis of all these applications showed that the proposed method had a ability to improve the optimization outcome. \r\n",
      "  |  http://dx.plos.org/10.1371/journal.pone.0208308  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30608936/  |  \n",
      "------------------------------------------- \r\n",
      "10.1002/wcs.1488  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   ACT-R is a hybrid cognitive architecture. It is comprised of a set of programmable information processing mechanisms that can be used to predict and explain human behavior including cognition and interaction with the environment. We start by reviewing its history, which shapes its current form, contrasts and relates it to other architectures, and helps readers to anticipate where it is going. Based on this history, we then describe it as a theory of cognition that is realized as a computer program. After this, we briefly discuss tools for working with ACT-R, and also note several major accomplishments that have been gained by working with ACT-R in both basic and applied science, including summarizing some of the insights about human behavior. We conclude by discussing its future, which we believe will include adding emotions and physiology, increasing usability, and the use of nongenerative models. This article is categorized under: Computer Science &gt; Artificial Intelligence Psychology &gt; Reasoning and Decision Making Psychology &gt; Theory and Methods. \r\n",
      "  |  https://doi.org/10.1002/wcs.1488  |  \n",
      "------------------------------------------- \r\n",
      "PMID:30778510  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Words denoting abstract concepts constitute nearly half of human lexicon and serve as building blocks of the human culture. Since the advent of non-invasive neuroimaging techniques, great progress has been made in revealing the neurobiological foundation of concrete object and action concepts, yet it remains unclear how abstract concepts are stored and processed in the brain. Here we review recent development in this field, focusing on both theoretical perspectives and neuroimaging findings. We found that abstract concepts can be represented via linguistic and experiential information; the neural correlates of abstract concepts are partly in line with such a theoretical framework. Future studies are warranted to uncover the cognitive and neural mechanisms of language and experience in abstract word representation, which will help to deepen our understanding of general computational principles of the human conceptual system and to promote the development of the brain-like artificial intelligence. \r\n",
      "  |  http://www.actaps.com.cn/qikan/manage/wenzhang/2019-1-12.pdf  |  \n",
      "------------------------------------------- \r\n",
      "10.1038/s41598-019-41663-7  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Identifying progressive early chronic kidney disease (CKD) patients at a health checkup is a good opportunity to improve their prognosis. However, it is difficult to identify them using common health tests. This worksite-based cohort study for 7 years in Japan (n = 7465) was conducted to evaluate the progression of CKD. The outcome was aggravation of the KDIGO prognostic category of CKD 7 years later. The subjects were male, 59.1%; age, 50.1 ± 6.3 years; and eGFR, 79 ± 14.4 mL/min/1.73 m<sup>2</sup>. The number of subjects showing CKD progression started to increase from 3 years later. Vector analysis showed that CKD stage G1 A1 was more progressive than CKD stage G2 A1. Bayesian networks showed that the time-series changes in the prognostic category of CKD were related to the outcome. Support vector machines including time-series data of the prognostic category of CKD from 3 years later detected the high possibility of the outcome not only in subjects at very high risks but also in those at low risks at baseline. In conclusion, after the evaluation of kidney function at a health checkup, it is necessary to follow up not only patients at high risks but also patients at low risks at baseline for 3 years and longer. \r\n",
      "  |  http://dx.doi.org/10.1038/s41598-019-41663-7  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30911092/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.biopha.2019.109274  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   This study aims to identify the feature genes associated with vascular invasion in hepatocellular carcinoma (HCC). Here, the RNA sequencing data related to vascular invasion in The Cancer Genome Atlas (TCGA) database, including 292 HCC patients with complete clinical data were included in our study as the training dataset for construction and E-TABM-36, including 41 HCC patients with complete clinical data was used as the validation dataset. Following data normalization, differentially expressed mRNA and copy number (CN) were selected between with and without vascular invasion samples. A support vector machine (SVM) classifier was constructed and validated in GSE9828 and GSE20017 datasets. Total 59 feature genes were found by the SVM classifier. Using Cox regression analysis, three clinical features, including Patholigic T, Stage and vascular invasion and 6 optimal prognostic genes, including ANO1, EPHX2, GFRA1, OLFM2, SERPINA10 and TKT were significantly correlated with prognosis. A risk score formula was developed to assess the prognostic value of 6 optimal prognostic genes, which were identified to possess the most remarkable correlation with overall survival in HCC patients. By performing in vitro experiments, we observed TKT was significantly increased, but OLFM2 was decreased in high metastatic potential HCC cell lines (SK-HEP-1 and MHCC-97 H) compared with low metastatic potential cell line Huh7 and normal human liver cell line LO2 using western blotting analysis. Knockdown of TKT in MHCC-97H or overexpression of OLFM2 in SK-HEP-1 significantly suppressed cell migration and invasion using transwell assays. Our results demonstrated that TKT and OLFM2 might be novel independent biomarkers for predicting survival based on the presence of vascular invasion in patients with HCC. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0753-3322(19)30219-7  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/ijms20184462  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Apple skin russeting naturally occurs in many varieties, particularly in \"Golden Delicious\" and its pedigree, and is regarded as a non-invasive physiological disorder partly caused by excessive deposition of lignin. However, the understanding of its molecular mechanism is still limited. In this study, we used iTRAQ (isobaric tags for relative and absolute quantitation) and RNA-seq to detect the changes in the expression levels of genes and proteins in three developmental stages of russeting formation, in russeted (non-bagging) and non-russeted (bagging) skin of \"Golden Delicious\" apple. 2856 differentially expressed genes and 942 differentially expressed proteins in the comparison groups were detected at the transcript level and protein level, respectively. A correlation analysis of the transcriptomics and proteomics data revealed that four genes (MD03G1059200, MD08G1009200, MD17G1092400, and MD17G1225100) involved in lignin biosynthesis are significant changed during apple russeting formation. Additionally, 92 transcription factors, including 4 LIM transcription factors, may be involved in apple russeting formation. Among them, one LIM transcription factor (MD15G1068200) was capable of binding to the PAL-box like (CCACTTGAGTAC) element, which indicated it was potentially involved in lignin biosynthesis. This study will provide further views on the molecular mechanisms controlling apple russeting formation. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=ijms20184462  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31510041/  |  \n",
      "------------------------------------------- \r\n",
      "10.1371/journal.pone.0218946  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Neutrophil extracellular traps (NET) formation is part of the neutrophil response to infections, but excessive or inappropriate NETosis may trigger the production of autoantibodies and cause organ damage in autoimmune disorders. Spontaneously netting neutrophils are not frequent and induction of NET in vitro by selected stimuli is necessary to investigate their structure. In the present work, the protein composition and post-translational modifications of NET produced under different stimuli have been studied by means of proteomic analysis. Neutrophils from healthy donors were stimulated by PMA, A23187, Escherichia coli LPS or untreated; after three hours, cells were washed, treated with DNase and supernatants collected for mass spectrometry. Data were analyzed by unsupervised hierarchical clustering analyses. We identified proteins contained in NETs of any source or exclusive of one stimulus: LPS-induced and spontaneous NET diverge in protein composition, while PMA- and A23187-induced NET appear more similar. Among the post-translational modifications we examined, methionine sulfoxidation is frequent especially in PMA- and LPS-induced NETs. Myeloperoxidase is the protein more extensively modified. Thus, proteomic analysis indicates that NETs induced by different stimuli are heterogeneous in terms of both protein composition and post-translational modifications, suggesting that NET induced in different conditions may have different biological effects. \r\n",
      "  |  http://dx.plos.org/10.1371/journal.pone.0218946  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31283757/  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s00018-018-2970-1  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Thoracic aorta perivascular adipose tissue (T-PVAT) has critical roles in regulating vascular homeostasis. However, the developmental characteristics and cellular lineage of adipocyte in the T-PVAT remain unclear. We show that T-PVAT contains three long strip-shaped fat depots, anterior T-PVAT (A-T-PVAT), left lateral T-PVAT (LL-T-PVAT), and right lateral T-PVAT (RL-T-PVAT). A-T-PVAT displays a distinct transcriptional profile and developmental origin compared to the two lateral T-PVATs (L-T-PVAT). Lineage tracing studies indicate that A-T-PVAT adipocytes are primarily derived from SM22α<sup>+</sup> progenitors, whereas L-T-PVAT contains both SM22α<sup>+</sup> and Myf5<sup>+</sup> cells. We also show that L-T-PVAT contains more UCP1<sup>+</sup> brown adipocytes than A-T-PVAT, and L-T-PVAT exerts a greater relaxing effect on aorta than A-T-PVAT. Angiotensin II-infused hypertensive mice display greater macrophage infiltration into A-T-PVAT than L-T-PVAT. These combined results indicate that L-T-PVAT has a distinct development from A-T-PVAT with different cellular lineage, and suggest that L-T-PVAT and A-T-PVAT have different physiological and pathological functions. \r\n",
      "  |  https://doi.org/10.1007/s00018-018-2970-1  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.gene.2019.144150  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Ovarian cancer (OC) is the deadliest form of gynecologic malignancy, with the majority of patients being diagnosed only once the disease reaches an advanced stage owing to a lack of available biomarkers capable of accurately detecting the disease. Stable circular RNAs (circRNAs) can be found at high levels in exosomes, and there is evidence to suggest that they may be viable diagnostic biomarkers for certain cancers. However, circRNAs in the serum of OC patients have rarely been evaluated to date. We therefore sought to investigate serum circRNA profiles of OC patients, and to explore whether these sorts of circRNAs could be used to detect early OC, serving as biomarkers of disease that may allow for the earlier treatment thereof. Second-generation sequencing was used to screen differentially expressed circRNAs in OC patient serum and also in the serum obtained from healthy controls, and circRNA expression was confirmed by qPCR. A bioinformatics-based approach was then used to assess what biological functions might be affected be the altered regulation of these RNA molecules. We further conducted GO, KEGG, and network analyses to further explore the expression of circRNAs. We detected 178 differentially expressed circRNAs in OC patient serum, of which 175 were up-regulated and 3 were down-regulated. We validated 5 of these identified circRNAs by qPCR to confirm their expression, and further found these RNAs to be closely linked with FC gamma R-mediated phagocytosis, VEGF signaling, Transcriptional misregulation in cancer, Chemokine signaling, ErbB signaling, and TNF signaling based on conducted analyses. This study provides a profile of circRNAs in OC patient serum, revealing a pattern of dysregulation of these RNAs associated with OC. Our bioinformatics analysis suggested that these circRNAs are likely related to OC development, and as such they may be viable novel OC biomarkers. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0378-1119(19)30809-1  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s11033-018-4533-9  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   E2 (ubiquitin conjugating enzymes) is an important part of the ubiquitin-proteasome pathway. These enzymes have a significant role to play during plant growth and development, which can response to various stresses. To date, the E2 family has been reported in some high plants, but the genome-wide characterization of this gene family in potato remains unknown. In the present study, 57 putative StUBCs were identified, which were clustered into eight subgroups based on phylogeny. The introns varied in numbers 0 to 9. The highest numbers of introns were 5, which accounted for 31.57%. The analysis of gene duplication showed that 22 StUBC genes were involved in 13 segmental duplication events, while no tandem duplication was found in StUBC genes. According to gene ontology analysis (GO), StUBC family major function is protein binding and ion binding. The RNA sequencing data revealed that 15 StUBC genes were highly expressed in different organs and tubers. 27 StUBC genes were up-regulated under 50 µM ABA treatments. Moreover, the RNA-seq data and qRT-PCR analysis indicated that 17 StUBC genes responded to heat stress. 8 StUBC genes responded to salt stress according to qRT-PCR analysis, and StUBC2, StUBC12, StUBC30 and StUBC13 were predominant expression. The result of this research could provide valuable information to insight into potato E2 family and establish a foundation for further to elucidate function of E2 genes. \r\n",
      "  |  https://doi.org/10.1007/s11033-018-4533-9  |  \n",
      "------------------------------------------- \r\n",
      "10.1162/artl_a_00288  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   We propose an approach to open-ended evolution via the simulation of swarm dynamics. In nature, swarms possess remarkable properties, which allow many organisms, from swarming bacteria to ants and flocking birds, to form higher-order structures that enhance their behavior as a group. Swarm simulations highlight three important factors to create novelty and diversity: (a) communication generates combinatorial cooperative dynamics, (b) concurrency allows for separation of time scales, and (c) complexity and size increases push the system towards transitions in innovation. We illustrate these three components in a model computing the continuous evolution of a swarm of agents. The results, divided into three distinct applications, show how emergent structures are capable of filtering information through the bottleneck of their memory, to produce meaningful novelty and diversity within their simulated environment. \r\n",
      "  |  http://www.mitpressjournals.org/doi/full/10.1162/artl_a_00288?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/ijms20246108  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Petal senescence involves numerous programmed changes in biological and biochemical processes. Ubiquitination plays a critical role in protein degradation, a hallmark of organ senescence. Therefore, we investigated changes in the proteome and ubiquitome of senescing rose (<i>Rosa hybrida</i>) petals to better understand their involvement in petal senescence. Of 3859 proteins quantified in senescing petals, 1198 were upregulated, and 726 were downregulated during senescence. We identified 2208 ubiquitinated sites, including 384 with increased ubiquitination in 298 proteins and 1035 with decreased ubiquitination in 674 proteins. Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) analyses revealed that proteins related to peptidases in proteolysis and autophagy pathways were enriched in the proteome, suggesting that protein degradation and autophagy play important roles in petal senescence. In addition, many transporter proteins accumulated in senescing petals, and several transport processes were enriched in the ubiquitome, indicating that transport of substances is associated with petal senescence and regulated by ubiquitination. Moreover, several components of the brassinosteroid (BR) biosynthesis and signaling pathways were significantly altered at the protein and ubiquitination levels, implying that BR plays an important role in petal senescence. Our data provide a comprehensive view of rose petal senescence at the posttranslational level. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=ijms20246108  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31817087/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/ijms20020296  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The advancement of bioinformatics and machine learning has facilitated the discovery and validation of omics-based biomarkers. This study employed a novel approach combining multi-platform transcriptomics and cutting-edge algorithms to introduce novel signatures for accurate diagnosis of colorectal cancer (CRC). Different random forests (RF)-based feature selection methods including the area under the curve (AUC)-RF, Boruta, and Vita were used and the diagnostic performance of the proposed biosignatures was benchmarked using RF, logistic regression, naïve Bayes, and k-nearest neighbors models. All models showed satisfactory performance in which RF appeared to be the best. For instance, regarding the RF model, the following were observed: mean accuracy 0.998 (standard deviation (SD) &lt; 0.003), mean specificity 0.999 (SD &lt; 0.003), and mean sensitivity 0.998 (SD &lt; 0.004). Moreover, proposed biomarker signatures were highly associated with multifaceted hallmarks in cancer. Some biomarkers were found to be enriched in epithelial cell signaling in <i>Helicobacter pylori</i> infection and inflammatory processes. The overexpression of <i>TGFBI</i> and <i>S100A2</i> was associated with poor disease-free survival while the down-regulation of <i>NR5A2</i>, <i>SLC4A4</i>, and <i>CD177</i> was linked to worse overall survival of the patients. In conclusion, novel transcriptome signatures to improve the diagnostic accuracy in CRC are introduced for further validations in various clinical settings. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=ijms20020296  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30642095/  |  \n",
      "------------------------------------------- \r\n",
      "10.1371/journal.pone.0215901  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   ATP-binding cassette (ABC) transporter genes act as transporters for different molecules across biological membranes and are involved in a diverse range of biological processes. In this study, we performed a genome-wide identification and expression analysis of genes encoding ABC transporter proteins in three Capsicum species, i.e., Capsicum annuum, Capsicum baccatum and Capsicum chinense. Capsicum is a valuable horticultural crop worldwide as an important constituent of many foods while containing several medicinal compounds including capsaicin and dihydrocapsaicin. Our results identified the presence of a total of 200, 185 and 187 ABC transporter genes in C. annuum, C. baccatum and C. chinense genomes, respectively. Capsaicin and dihydrocapsaicin content were determined in green pepper fruits (16 dpa). Additionally, we conducted different bioinformatics analyses including ABC genes classification, gene chromosomal location, Cis elements, conserved motifs identification and gene ontology classification, as well as profile expression of selected genes. Based on phylogenetic analysis and domain organization, the Capsicum ABC gene family was grouped into eight subfamilies. Among them, members within the ABCG, ABCB and ABCC subfamilies were the most abundant, while ABCD and ABCE subfamilies were less abundant throughout all species. ABC members within the same subfamily showed similar motif composition. Furthermore, common cis-elements involved in the transcriptional regulation were also identified in the promoter regions of all Capsicum ABC genes. Gene expression data from RNAseq and reverse transcription-semi-quantitative PCR analysis revealed development-specific stage expression profiles in placenta tissues. It suggests that ABC transporters, specifically the ABCC and ABCG subfamilies, may be playing important roles in the transport of secondary metabolites such as capsaicin and dihydrocapsaicin to the placenta vacuoles, effecting on their content in pepper fruits. Our results provide a more comprehensive understanding of ABC transporter gene family in different Capsicum species while allowing the identification of important candidate genes related to capsaicin content for subsequent functional validation. \r\n",
      "  |  http://dx.plos.org/10.1371/journal.pone.0215901  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31039176/  |  \n",
      "------------------------------------------- \r\n",
      "10.1055/s-0038-1668122  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Although several studies highlight the advantages of robotic arm-assisted total knee arthroplasty (RA-TKA), few investigate its intraoperative outcome. Therefore, the purpose of this study was to analyze the RA-TKA's ability to assist with intraoperative correction of: (1) flexion and (2) extension gaps, as well as its ability to (3) accurately predict implant sizes. Additionally, in this RA-TKA cohort, length of stay, complications, and readmissions were assessed. A total of 335 patients who underwent RA-TKA were included. The robotic software virtually measured the intraoperative prebone cut extension and flexion gaps. Differences in medial versus lateral prebone cut extension and flexion gaps were calculated. A total of 155 patients (46%) had an extension gap difference of between -2 and 2 mm (mean, -0.3 mm), while 119 patients (36%) had a flexion gap difference of between -2 and 2 mm (mean, -0.6 mm). Postbone cut differences in medial versus lateral flexion and extension gaps were measured. Balanced knees were considered to have a medial and lateral flexion gap difference within 2 mm. The robot-predicted implant size was also compared with the final implant size. Additionally, lengths of stay, complications, and readmissions were assessed. All patients achieved a postbone cut extension gap difference between -1 and 1 mm (mean, -0.1 mm). A total of 332 patients (99%) achieved a postbone cut flexion gap difference of between -2 and 2 mm (mean, 0 mm). For 98% of prostheses, the robotic software predicted within 1 implant size the actual tibial or femoral implant size used.The mean length of stay was found to be 2 days. No patients suffered from superficial skin infection, pin site infections or fractures, soft tissue damage, and no robotic cases were converted to manual TKA due to intraoperative complications. A total of 8 patients (2.2%) were readmitted; however, none were directly related to robotic use. The robotic software and use of a preoperative computed tomography (CT) substantially helped with intraoperative planning and accurate prediction of implant sizes. Therefore, based on the results of this study, the RA-TKA device does, in fact, provide considerable intraoperative assistance. \r\n",
      "  |  http://www.thieme-connect.com/DOI/DOI?10.1055/s-0038-1668122  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.ijrobp.2019.07.011  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Purpose:  A noninvasive diagnostic method to predict the degree of malignancy accurately would be of great help in glioma management. This study aimed to create a highly accurate machine learning model to perform glioma grading. \r\n",
      "  Methods and materials:  Preoperative magnetic resonance imaging acquired for cases of glioma operated on at our institution from October 2014 through January 2018 were obtained retrospectively. Six types of magnetic resonance imaging sequences (T<sub>2</sub>-weighted image, diffusion-weighted image, apparent diffusion coefficient [ADC], fractional anisotropy, and mean kurtosis [MK]) were chosen for analysis; 476 features were extracted semiautomatically for each sequence (2856 features in total). Recursive feature elimination was used to select significant features for a machine learning model that distinguishes glioblastoma from lower-grade glioma (grades 2 and 3). \r\n",
      "  Results:  Fifty-five data sets from 54 cases were obtained (14 grade 2 gliomas, 12 grade 3 gliomas, and 29 glioblastomas), of which 44 and 11 data sets were used for machine learning and independent testing, respectively. We detected 504 features with significant differences (false discovery rate &lt;0.05) between glioblastoma and lower-grade glioma. The most accurate machine learning model was created using 6 features extracted from the ADC and MK images. In the logistic regression, the area under the curve was 0.90 ± 0.05, and the accuracy of the test data set was 0.91 (10 out of 11); using a support vector machine, they were 0.93 ± 0.03 and 0.91 (10 out of 11), respectively (kernel, radial basis function; c = 1.0). \r\n",
      "  Conclusions:  Our machine learning model accurately predicted glioma tumor grade. The ADC and MK sequences produced particularly useful features. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0360-3016(19)33493-5  |  \n",
      "------------------------------------------- \r\n",
      "10.1186/s12864-018-5400-8  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  Sugarcane smut is a fungal disease caused by Sporisorium scitamineum. Cultivation of smut-resistant sugarcane varieties is the most effective way to control this disease. The interaction between sugarcane and S. scitamineum is a complex network system. However, to date, there is no report on the identification of microRNA (miRNA) target genes of sugarcane in response to smut pathogen infection by degradome technology. \r\n",
      "  Results:  TaqMan qRT-PCR detection and enzyme activity determination showed that S. scitamineum rapidly proliferated and incurred significant enzyme activity changes in the reactive oxygen species metabolic pathway and phenylpropanoid metabolic pathway at 2 d and 5 d after inoculation, which was the best time points to study target gene degradation during sugarcane and S. scitamineum interaction. A total of 122.33 Mb of raw data was obtained from degradome sequencing analysis of YC05-179 (smut-resistant) and ROC22 (smut-susceptible) after inoculation. The Q30 of each sample was &gt; 93%, and the sequence used for degradation site analysis exactly matched the sugarcane reference sequence. A total of 309 target genes were predicted in sugarcane, corresponding to 97 known miRNAs and 112 novel miRNAs, and 337 degradation sites, suggesting that miRNAs can efficiently direct cleavage at multiple sites in the predicted target mRNAs. Gene Ontology (GO) annotation and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analysis indicated that the predicted target genes were involved in various regulatory processes, such as signal transduction mechanisms, inorganic ion transport and metabolism, defense mechanisms, translation, posttranslational modifications, energy production and conversion, and glycerolipid metabolism. qRT-PCR analysis of the expression level of 13 predicted target genes and their corresponding miRNAs revealed that there was no obvious negative regulatory relationship between miRNAs and their target genes. In addition, a number of putative resistance-related target genes regulated by miRNA-mediated cleavage were accumulated in sugarcane during S. scitamineum infection, suggesting that feedback regulation of miRNAs may be involved in the response of sugarcane to S. scitamineum infection. \r\n",
      "  Conclusions:  This study elucidates the underlying response of sugarcane to S. scitamineum infection, and also provides a resource for miRNAs and their predicted target genes for smut resistance improvement in sugarcane. \r\n",
      "  |  https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-5400-8  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30658590/  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s10142-018-0629-5  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Oligopeptide transporters (OPT) are integral cell membrane proteins that play a critical role in the transport of small peptides, secondary amino acids, glutathione conjugates, and mineral uptake. In the present study, 67 putative wheat yellow stripe-like transporter (YSL) proteins belonging to the subfamily of OPT transporters were identified. Phylogeny analysis resulted in the distribution of wheat YSLs into four discrete clades. The highest number of YSLs was present on the A genome and the chromosome 2 of hexaploid wheat. The identified wheat YSL genes showed differential expression in different tissues and during grain development suggesting the importance of this subfamily. Gene expression pattern of TaYSLs during iron starvation experiments suggested an early high transcript accumulation of TaYS1A, TaYS1B, TaYSL3, TaYSL5, and TaYSL6 in roots. In contrast, delayed expression was observed in shoots for TaYS1A, TaYS1B, TaYSL5, TaYSL12, and TaYSL19 as compared to control. Further, their expression under biotic and abiotic response emphasized their alternative functions during the plant growth and development. In conclusion, this work is the first comprehensive study of wheat YSL transporters and would be an important resource for prioritizing genes towards wheat biofortification. \r\n",
      "  |  https://dx.doi.org/10.1007/s10142-018-0629-5  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s10142-018-0635-7  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Elevated CO<sub>2</sub> along with drought is a serious global threat to crop productivity. Therefore, understanding the molecular mechanisms plants use to protect these stresses is the key for plant growth and development. In this study, we mimicked natural stress conditions under a controlled Soil-Plant-Atmosphere-Research (SPAR) system and provided the evidence for how miRNAs regulate target genes under elevated CO<sub>2</sub> and drought conditions. Significant physiological and biomass data supported the effective utilization of source-sink (leaf to root) under elevated CO<sub>2</sub>. Additionally, elevated CO<sub>2</sub> partially rescued the effect of drought on total biomass. We identified both known and novel miRNAs differentially expressed during drought, CO<sub>2</sub>, and combined stress, along with putative targets. A total of 32 conserved miRNAs belonged to 23 miRNA families, and 25 novel miRNAs were identified by deep sequencing. Using the existing sweet potato genome database and stringent analyses, a total of 42 and 22 potential target genes were predicted for the conserved and novel miRNAs, respectively. These target genes are involved in drought response, hormone signaling, photosynthesis, carbon fixation, sucrose and starch metabolism, etc. Gene ontology and KEGG ontology functional enrichment revealed that these miRNAs might target transcription factors (MYB, TCP, NAC), hormone signaling regulators (ARF, AP2/ERF), cold and drought factors (corA), carbon metabolism (ATP synthase, fructose-1,6-bisphosphate), and photosynthesis (photosystem I and II complex units). Our study is the first report identifying targets of miRNAs under elevated CO<sub>2</sub> levels and could support the molecular mechanisms under elevated CO<sub>2</sub> in sweet potato and other crops in the future. \r\n",
      "  |  https://dx.doi.org/10.1007/s10142-018-0635-7  |  \n",
      "------------------------------------------- \r\n",
      "10.3892/mmr.2018.9641  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Numerous studies have revealed that microRNAs (miRNAs) are functional non‑coding RNAs that serve roles in a variety of biological processes. However, the expression patterns and regulatory networks, as well as the miRNAs involved in liver fibrosis remain to be elucidated. In the present study, a mouse model of liver fibrosis was constructed by CCl4 intraperitoneal injection and the total RNAs were extracted from the liver of the mice. The total RNAs were then sequenced on an Illumina HiSeq 2000 platform and an integrated analysis of miRNA and mRNA expression profiles in CCl4‑induced liver fibrosis was performed. Compared with normal liver samples, 56 and 15 miRNAs were found to be upregulated and downregulated in fibrotic livers, respectively. To predict the potential functions of these miRNAs, bioinformatics analysis, including Gene Ontology and Kyoto Encyclopedia of Genes and Genomes pathway analysis, was used to assess target mRNAs. The results indicated that the mitogen‑activated protein kinase, phosphoinositide 3 kinase/protein kinase B and focal adhesion signaling pathways were the most significantly enriched. In addition, a regulatory network containing five dysregulated miRNAs and 22 target mRNAs was constructed based on their inverse correlation. Furthermore, the five dysregulated miRNAs were significantly upregulated and the expression of RELB, RAP1A, PPP3CB, MAP2K4, ARRB1, MAP3K4, FGF1 and PRKCB in the network was significantly decreased in LX‑2 cells following TGF‑β1 treatment which suggested that they were associated with the activation of human hepatic stellate cells. The miRNA‑mRNA regulatory network produced in the present study may provide novel insights into the role of miRNAs in liver fibrosis. \r\n",
      "  |  http://www.spandidos-publications.com/mmr/19/1/115  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30431126/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.ymeth.2018.11.015  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The regulation of gene expression occurs through complex relationships between transcription, processing, turnover, and translation, which are only beginning to be elucidated. We know that at least for certain messenger (m) RNAs, processing, modifications, and sequence elements can greatly influence their translational output through recognition by translation and turn-over machinery. Recently, we and others have combined high-throughput sequencing technologies with traditional biochemical methods of studying translation to extend our understanding of these relationships. Additionally, there is growing importance given to how these processes may be regulated across varied cell types as a means to achieve tissue-specific expression of proteins. Here, we provide an in-depth methodology for polysome profiling to dissect the composition of mRNAs and proteins that make up the translatome from both whole tissues and a specific cell type isolated from mammalian tissue. Also, we provide a detailed computational workflow for the analysis of the next-generation sequencing data generated from these experiments. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1046-2023(18)30226-3  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30500367/  |  \n",
      "------------------------------------------- \r\n",
      "10.3892/mmr.2019.10308  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The dental follicle develops into the periodontal ligament, cementum and alveolar bone. Human dental follicle cells (hDFCs) are the precursor cells of periodontal development. Long non‑coding RNAs (lncRNAs) have been revealed to be crucial factors that regulate a variety of biological processes; however, whether lncRNAs serve a role in human periodontal development remains unknown. Therefore, the present study used microarrays to detect the differentially expressed lncRNAs and mRNAs between hDFCs and human periodontal ligament cells (hPDLCs). A total of 845 lncRNAs and 1,012 mRNAs were identified to be differentially expressed in hDFCs and hPDLCs (fold change &gt;2.0 or &lt;‑2.0; P&lt;0.05). Microarray data were validated by reverse transcription‑quantitative polymerase chain reaction. Bioinformatics analyses, including gene ontology, pathway analysis and coding‑non‑coding gene co‑expression network analysis, were performed to determine the functions of the differentially expressed lncRNAs and mRNAs. Bioinformatics analysis identified that a number of pathways may be associated with periodontal development, including the p53 and calcium signaling pathways. This analysis also revealed a number of lncRNAs, including NR_033932, T152410, ENST00000512129, ENST00000540293, uc021sxs.1 and ENST00000609146, which may serve important roles in the biological process of hDFCs. In addition, the lncRNA termed maternally expressed 3 (MEG3) was identified to be differentially expressed in hDFCs by reverse transcription‑quantitative polymerase chain reaction. The knockdown of MEG3 was associated with a reduction of pluripotency makers in hDFCs. In conclusion, for the first time, to the best of our knowledge, the current study determined the different expression profiles of lncRNAs and mRNAs between hDFCs and hPDLCs. The observations made may provide a solid foundation for further research into the molecular mechanisms of lncRNAs in human periodontal development. \r\n",
      "  |  http://www.spandidos-publications.com/mmr/20/2/939  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31173189/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.jcmgh.2018.09.008  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background &amp; aims:  Our goal was to develop an initial study for the proof of concept whereby gastric cancer organoids are used as an approach to predict the tumor response in individual patients. \r\n",
      "  Methods:  Organoids were derived from resected gastric cancer tumors (huTGOs) or normal stomach tissue collected from sleeve gastrectomies (huFGOs). Organoid cultures were treated with standard-of-care chemotherapeutic drugs corresponding to patient treatment: epirubicin, oxaliplatin, and 5-fluorouracil. Organoid response to chemotherapeutic treatment was correlated with the tumor response in each patient from whom the huTGOs were derived. HuTGOs were orthotopically transplanted into the gastric mucosa of NOD scid gamma mice. \r\n",
      "  Results:  Whereas huFGOs exhibited a half maximal inhibitory concentration that was similar among organoid lines, divergent responses and varying half maximal inhibitory concentration values among the huTGO lines were observed in response to chemotherapeutic drugs. HuTGOs that were sensitive to treatment were derived from a patient with a near complete tumor response to chemotherapy. However, organoids resistant to treatment were derived from patients who exhibited no response to chemotherapy. Orthotropic transplantation of organoids resulted in the engraftment and development of human adenocarcinoma. RNA sequencing revealed that huTGOs closely resembled the patient's native tumor tissue and not commonly used gastric cancer cell lines and cell lines derived from the organoid cultures. \r\n",
      "  Conclusions:  The treatment of patient-derived organoids alongside patients from whom cultures were derived will ultimately test their usefulness to predict individual therapy response and patient outcome. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S2352-345X(18)30130-9  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30522949/  |  \n",
      "------------------------------------------- \r\n",
      "10.1038/s41440-018-0177-3  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Pre-emptive medicine is a novel medical concept proposed in Japan that aims to precisely predict the onset and progression of diseases and to provide therapeutic interventions during early stages, before symptoms appear. The concept of pre-emptive medicine considers the time-course of a disease in each individual and seeks medical interventions to prevent disease progression. Suitable and promising targets for pre-emptive medicine are non-communicable diseases, including hypertension. Recent advances in genomic analysis, information technology, and artificial intelligence should make this medical concept feasible in the near future. In this review, we focused on pre-emptive medicine for hypertension, referring to concrete plans for the future direction of this research. The ultimate goal of pre-emptive medicine is to completely prevent the onset and progression of hypertension by precisely predicting the elevation of blood pressure and performing interventions to avoid it. The diagnostic processes of hypertension, from the standpoint of pre-emptive medicine, should include the detection of abnormal blood pressure regulation as the earliest manifestation of the disease, the depiction of the present status of hypertension in an individual (\"nowcasting\"), and a prediction of the future trajectory of the disease (\"forecasting\"). Novel therapeutic strategies for hypertension, from the standpoint of pre-emptive medicine, should aim for the regression of hypertension through early treatments and the remission of hypertension through intermittent intensive therapies. An efficient modification of lifestyle and therapies, according to the progression of hypertension, should be required. If pre-emptive medicine for hypertension becomes established, it would greatly contribute to the extension of a healthy lifespan, which cannot yet be satisfactorily achieved. \r\n",
      "  |  http://dx.doi.org/10.1038/s41440-018-0177-3  |  \n",
      "------------------------------------------- \r\n",
      "10.1055/a-0740-8631  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The increase in life expectancy and Healthy Life Years in Europe is largely attributable to the success of cardiovascular medicine. Technical developments enable ever more detailed insights into disease processes and enable a precise, multimodal diagnosis of even complex diseases using digital imaging, cardiac biomarkers and genomic information. The rapid availability of this data, often in real time, allows optimized planning and performing of tailored interventional, surgical, or pharmacotherapies. But there are also completely new challenges due to the growing flood of data, the integration of which can no longer be achieved by the individual doctor. The active involvement and participation of the patient also requires new digital concepts and should include decision-making, treatment planning, (long-term) history, and feedback on success and adverse drug reactions. By using artificial intelligence, digital communication and decision support systems, economic benefits, quality improvements and acceleration of outpatient and inpatient treatment become possible.The DGK supports these developments in its own activities, both in project planning, communication with specialist groups, and in training and education. In this article you will find excerpts from current developments of digital cardiology. \r\n",
      "  Aktuelle entwicklungen der modernen medizin:  Künstliche Intelligenz, Big Data und mobile Sensorik transformieren derzeit die Kardiologie. Fortschrittliche digitale Konzepte spielen in vielen Bereichen der Kardiologie eine immer wichtigere Rolle und werden sich schnell als Partner von Arzt und Patient etablieren können. BIG DATA UND KüNSTLICHE INTELLIGENZ: Künstliche Intelligenz (KI) hält Einzug in den digitalen Arztalltag und ist keine Science-Fiction mehr. Spezielle Algorithmen kommen heute bereits im Rahmen diagnostischer Prozesse zum Einsatz und bieten großes Potenzial für die Zukunft. \r\n",
      "  Smartphones, apps und co:  Smartphones und Wearables können über die Anwendung von speziellen Apps im Bereich der Kardiologie eingesetzt werden. Die neue DSGVO erschwert die Entwicklung neuer Kommunikationskanäle unter Ärzten und zwischen Ärzten und Patienten. Neue Apps, Messenger und Verschlüsselungssysteme sollen die Sicherheit der sensiblen Daten gewährleisten. \r\n",
      "  |  http://www.thieme-connect.com/DOI/DOI?10.1055/a-0740-8631  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s00259-019-04437-x  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Purpose:  To improve the test-retest reproducibility of coronary plaque <sup>18</sup>F-sodium fluoride (<sup>18</sup>F-NaF) positron emission tomography (PET) uptake measurements. \r\n",
      "  Methods:  We recruited 20 patients with coronary artery disease who underwent repeated hybrid PET/CT angiography (CTA) imaging within 3 weeks. All patients had 30-min PET acquisition and CTA during a single imaging session. Five PET image-sets with progressive motion correction were reconstructed: (i) a static dataset (no-MC), (ii) end-diastolic PET (standard), (iii) cardiac motion corrected (MC), (iv) combined cardiac and gross patient motion corrected (2 × MC) and, (v) cardiorespiratory and gross patient motion corrected (3 × MC). In addition to motion correction, all datasets were corrected for variations in the background activities which are introduced by variations in the injection-to-scan delays (background blood pool clearance correction, BC). Test-retest reproducibility of PET target-to-background ratio (TBR) was assessed by Bland-Altman analysis and coefficient of reproducibility. \r\n",
      "  Results:  A total of 47 unique coronary lesions were identified on CTA. Motion correction in combination with BC improved the PET TBR test-retest reproducibility for all lesions (coefficient of reproducibility: standard = 0.437, no-MC = 0.345 (27% improvement), standard + BC = 0.365 (20% improvement), no-MC + BC = 0.341 (27% improvement), MC + BC = 0.288 (52% improvement), 2 × MC + BC = 0.278 (57% improvement) and 3 × C + BC = 0.254 (72% improvement), all p &lt; 0.001). Importantly, in a sub-analysis of <sup>18</sup>F-NaF-avid lesions with gross patient motion &gt; 10 mm following corrections, reproducibility was improved by 133% (coefficient of reproducibility: standard = 0.745, 3 × MC = 0.320). \r\n",
      "  Conclusion:  Joint corrections for cardiac, respiratory, and gross patient motion in combination with background blood pool corrections markedly improve test-retest reproducibility of coronary <sup>18</sup>F-NaF PET. \r\n",
      "  |  https://dx.doi.org/10.1007/s00259-019-04437-x  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.micpath.2019.04.033  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Caused by porcine epidemic diarrhea virus (PEDV), porcine epidemic diarrhea (PED) is an acute infectious disease which causes damage to the intestine including intestinal villus atrophy and shedding, leading to serious economic losses to the pig industry worldwide. In order to obtain detailed information about the pathogenesis and host immune response in a PEDV-infected host for first In vivo study we used high-throughput sequencing to analyze the gene expression differences of the small intestinal mucosa after infection with PEDV. Transcripts obtained were over 65,525,000 clean reads after reassembly were 22,605 genes detected, of which 22,248 were known genes and 371 new genes were predicted. Moreover, 3168 genes expression was up-regulated and 3876 genes down-regulated. (Gene Ontology) GO annotation and functional enrichment analysis indicated that all of the DEGs (differentially expressed genes) were annotated into biological process, cellular component and molecular function. Most of these unigenes are annotated in cellular processes, the cell and binding. KEGG analysis of the DEGs showed that a total of 7044 DEGs unigenes were annotated into 323 pathways classified into 6 main categories. Most of these unigenes are annotated were related to immune system response to the infectious diseases pathways. In addition, 20 DEGs were verified by quantitative real-time PCR. As the first, in vivo, RNAseq analysis of piglets and PEDV infection, our study provides knowledge about the transcriptomics of intestinal mucosa in PEDV-infected piglets, from which a complex molecular pathways and pathogenesis-related biological processes are involved in PEDV interaction with piglet intestinal mucosa. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0882-4010(19)30236-0  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31026494/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.scitotenv.2019.134230  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   A quantitative understanding of the hydro-environmental factors that influence the occurrence of agricultural drought events would enable more strategic climate change adaptation and drought management plans. Practical drought hazard mapping remains challenging due to possible exclusion of the most pertinent drought drivers, and to the use of inadequate predictive models that cannot describe drought adequately. This research aims to develop new approaches to map agricultural drought hazard with state-of-the-art machine learning models, including classification and regression trees (CART), boosted regression trees (BRT), random forests (RF), multivariate adaptive regression splines (MARS), flexible discriminant analysis (FDA) and support vector machines (SVM). Hydro-environmental datasets were used to calculate the relative departure of soil moisture (RDSM) for eight severe droughts for drought-prone southeast Queensland, Australia, over the period 1994-2013. RDSM was then used to generate an agricultural drought inventory map. Eight hydro-environmental factors were used as potential predictors of drought. The goodness-of-fit and predictive performance of all models were evaluated using different threshold-dependent and threshold-independent methods, including the true skill statistic (TSS), Efficiency (E), F-score, and the area under the receiver operating characteristic curve (AUC-ROC). The RF model (AUC-ROC = 97.7%, TSS = 0.873, E = 0.929, F-score = 0.898) yielded the highest accuracy, while the FDA model (with AUC-ROC = 73.9%, TSS = 0.424, E = 0.719, F-score = 0.512) showed the worst performance. The plant available water holding capacity (PAWC), mean annual precipitation, and clay content were the most important variables to be used for predicting the agricultural drought. About 21.2% of the area is in high or very high drought risk classes, and therefore, warrant drought and environmental protection policies. Importantly, the models do not require data on the precipitation anomaly for any given drought year; the spatial patterns in AGH were consistent for all drought events, despite very different spatial patterns in precipitation anomaly among events. Such machine-learning approaches are able to construct an overall risk map, thus assisting in the adoption of a robust drought contingency planning measure not only for this area, but also, in other regions where drought presents a pressing challenge, including its influence on key practical dimensions of social, environmental and economic sustainability. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0048-9697(19)34213-5  |  \n",
      "------------------------------------------- \r\n",
      "10.12659/MSM.917399  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   BACKGROUND Although the mortality rates of clear cell renal cell carcinoma (ccRCC) have decreased in recent years, the clinical outcome remains highly dependent on the individual patient. Therefore, identifying novel biomarkers for ccRCC patients is crucial. MATERIAL AND METHODS In this study, we obtained RNA sequencing data and clinical information from the TCGA database. Subsequently, we performed integrated bioinformatic analysis that includes differently expressed genes analysis, gene ontology and KEGG pathway analysis, protein-protein interaction analysis, and survival analysis. Moreover, univariate and multivariate Cox proportional hazards regression models were constructed. RESULTS As a result, we identified a total of 263 dysregulated genes that may participate in the metastasis of ccRCC, and established a predictive signature relying on the expression of OTX1, MATN4, PI3, ERVV-2, and NFE4, which could serve as significant progressive and prognostic biomarkers for ccRCC. CONCLUSIONS We identified differentially expressed genes that may be involved in the metastasis of ccRCC. Moreover, a predictive signature based on the expression of OTX1, MATN4, PI3, ERVV-2, and NFE4 could be an independent prognostic factor for ccRCC. \r\n",
      "  |  https://www.medscimonit.com/download/index/idArt/917399  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31194719/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.radonc.2019.11.023  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  In the clinical management of advanced gastric cancer (AGC), preoperative identification of early recurrence after curative resection is essential. Thus, we aimed to create a CT-based radiomic model to predict early recurrence in AGC patients preoperatively. \r\n",
      "  Materials and methods:  We enrolled 669 consecutive patients (302 in the training set, 219 in the internal test set and 148 in the external test set) with clinicopathologically confirmed AGC from two centers. Radiomic features were extracted from preoperative diagnostic CT images. Machine learning methods were applied to shrink feature size and build a predictive radiomic signature. We incorporated the radiomic signature and clinical risk factors into a nomogram using multivariable logistic regression analysis. The area under the curve (AUC) of operating characteristics (ROC), accuracy, and calibration curves were assessed to evaluate the nomogram's performance in discriminating early recurrence. \r\n",
      "  Results:  A radiomic signature, including three hand crafted features and six deep learning features, was significantly associated with early recurrence (p-value &lt;0.0001 for all sets). In addition, clinical N stage, carbohydrate antigen 199 levels, carcinoembryonic antigen levels, and Borrmann type were considered useful predictors for early recurrence. The nomogram, combining all these predictors, showed powerful prognostic ability in the training set and two test sets with AUCs of 0.831 (95% CI, 0.786-0.876), 0.826 (0.772-0.880) and 0.806 (0.732-0.881), respectively. The predicted risk yielded good agreement with the observed recurrence probability. \r\n",
      "  Conclusions:  By incorporating a radiomic signature and clinical risk factors, we created a radiomic nomogram to predict early recurrence in patients with AGC, preoperatively, which may serve as a potential tool to guide personalized treatment. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0167-8140(19)33493-0  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/s19214788  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   In an Internet of Things (IoT) system, it is essential that the data measured from the sensors are accurate so that the produced results are meaningful. For example, in AgriTalk, a smart farm platform for soil cultivation with a large number of sensors, the produced sensor data are used in several Artificial Intelligence (AI) models to provide precise farming for soil microbiome and fertility, disease regulation, irrigation regulation, and pest regulation. It is important that the sensor data are correctly used in AI modeling. Unfortunately, no sensor is perfect. Even for the sensors manufactured from the same factory, they may yield different readings. This paper proposes a solution called SensorTalk to automatically detect potential sensor failures and calibrate the aging sensors semi-automatically. Numerical examples are given to show the calibration tables for temperature and humidity sensors. When the sensors control the actuators, the SensorTalk solution can also detect whether a failure occurs within a detection delay. Both analytic and simulation models are proposed to appropriately select the detection delay so that, when a potential failure occurs, it is detected reasonably early without incurring too many false alarms. Specifically, our selection can limit the false detection probability to be less than 0.7%. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=s19214788  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31689904/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.ophtha.2019.12.004  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Purpose:  To quantify the central visual field (VF) loss patterns in glaucoma using artificial intelligence. \r\n",
      "  Design:  Retrospective study. \r\n",
      "  Participants:  VFs of 8712 patients with 13 951 Humphrey 10-2 test results from 13 951 eyes for cross-sectional analyses, and 824 patients with at least 5 reliable 10-2 test results at 6-month intervals or more from 1191 eyes for longitudinal analyses. \r\n",
      "  Methods:  Total deviation values were used to determine the central VF patterns using the most recent 10-2 test results. A 24-2 VF within a 3-month window of the 10-2 tests was used to stage eyes into mild, moderate, or severe functional loss using the Hodapp-Anderson-Parrish scale at baseline. Archetypal analysis was applied to determine the central VF patterns. Cross-validation was performed to determine the optimal number of patterns. Stepwise regression was applied to select the optimal feature combination of global indices, average baseline decomposition coefficients from central VFs archetypes, and other factors to predict central VF mean deviation (MD) slope based on the Bayesian information criterion (BIC). \r\n",
      "  Main outcome measures:  The central VF patterns stratified by severity stage based on 24-2 test results and a model to predict the central VF MD change over time using baseline test results. \r\n",
      "  Results:  From cross-sectional analysis, 17 distinct central VF patterns were determined for the 13 951 eyes across the spectrum of disease severity. These central VF patterns could be divided into isolated superior loss, isolated inferior loss, diffuse loss, and other loss patterns. Notably, 4 of the 5 patterns of diffuse VF loss preserved the less vulnerable inferotemporal zone, whereas they lost most of the remaining more vulnerable zone described by the Hood model. Inclusion of coefficients from central VF archetypical patterns strongly improved the prediction of central VF MD slope (BIC decrease, 35; BIC decrease of &gt;6 indicating strong prediction improvement) than using only the global indices of 2 baseline VF results. Eyes with baseline VF results with more superonasal and inferonasal loss were more likely to show worsening MD over time. \r\n",
      "  Conclusions:  We quantified central VF patterns in glaucoma, which were used to improve the prediction of central VF worsening compared with using only global indices. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0161-6420(19)32329-2  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/s19030613  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Thanks to the benefits of non-orthogonal multiple access (NOMA) in wireless communications, we evaluate a wireless sensor network deploying NOMA (WSN-NOMA), where the destination can receive two data symbols in a whole transmission process with two time slots. In this work, two relaying protocols, so-called time-switching-based relaying WSN-NOMA (TSR WSN-NOMA) and power-splitting-based relaying WSN-NOMA (PSR WSN-NOMA) are deployed to study energy-harvesting (EH). Regarding the system performance analysis, we obtain the closed-form expressions for the exact and approximate outage probability (OP) in both protocols, and the delay-limited throughput is also evaluated. We then compare the two protocols theoretically, and two optimization problems are formulated to reduce the impact of OP and optimize the data rate. Our numerical and simulation results are provided to prove the theoretical and analytical analysis. Thanks to these results, a great performance gain can be achieved for both TSR WSN-NOMA and PSR WSN-NOMA if optimal values of TS and PS ratios are found. In addition, the optimized TSR WSN-NOMA outperforms that of PSR WSN-NOMA in terms of OP. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=s19030613  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30717155/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.ijmedinf.2019.104068  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  The proper estimate of the risk of recurrences in early-stage oral tongue squamous cell carcinoma (OTSCC) is mandatory for individual treatment-decision making. However, this remains a challenge even for experienced multidisciplinary centers. \r\n",
      "  Objectives:  We compared the performance of four machine learning (ML) algorithms for predicting the risk of locoregional recurrences in patients with OTSCC. These algorithms were Support Vector Machine (SVM), Naive Bayes (NB), Boosted Decision Tree (BDT), and Decision Forest (DF). \r\n",
      "  Materials and methods:  The study cohort comprised 311 cases from the five University Hospitals in Finland and A.C. Camargo Cancer Center, São Paulo, Brazil. For comparison of the algorithms, we used the harmonic mean of precision and recall called F1 score, specificity, and accuracy values. These algorithms and their corresponding permutation feature importance (PFI) with the input parameters were externally tested on 59 new cases. Furthermore, we compared the performance of the algorithm that showed the highest prediction accuracy with the prognostic significance of depth of invasion (DOI). \r\n",
      "  Results:  The results showed that the average specificity of all the algorithms was 71% . The SVM showed an accuracy of 68% and F1 score of 0.63, NB an accuracy of 70% and F1 score of 0.64, BDT an accuracy of 81% and F1 score of 0.78, and DF an accuracy of 78% and F1 score of 0.70. Additionally, these algorithms outperformed the DOI-based approach, which gave an accuracy of 63%. With PFI-analysis, there was no significant difference in the overall accuracies of three of the algorithms; PFI-BDT accuracy increased to 83.1%, PFI-DF increased to 80%, PFI-SVM decreased to 64.4%, while PFI-NB accuracy increased significantly to 81.4%. \r\n",
      "  Conclusions:  Our findings show that the best classification accuracy was achieved with the boosted decision tree algorithm. Additionally, these algorithms outperformed the DOI-based approach. Furthermore, with few parameters identified in the PFI analysis, ML technique still showed the ability to predict locoregional recurrence. The application of boosted decision tree machine learning algorithm can stratify OTSCC patients and thus aid in their individual treatment planning. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1386-5056(19)30614-8  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s00330-019-06371-w  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Objectives:  To determine the integrative value of contrast-enhanced computed tomography (CECT), transcriptomics data and clinicopathological data for predicting the survival of bladder urothelial carcinoma (BLCA) patients. \r\n",
      "  Methods:  RNA sequencing data, radiomics features and clinical parameters of 62 BLCA patients were included in the study. Then, prognostic signatures based on radiomics features and gene expression profile were constructed by using least absolute shrinkage and selection operator (LASSO) Cox analysis. A multi-omics nomogram was developed by integrating radiomics, transcriptomics and clinicopathological data. More importantly, radiomics risk score-related genes were identified via weighted correlation network analysis and submitted to functional enrichment analysis. \r\n",
      "  Results:  The radiomics and transcriptomics signatures significantly stratified BLCA patients into high- and low-risk groups in terms of the progression-free interval (PFI). The two risk models remained independent prognostic factors in multivariate analyses after adjusting for clinical parameters. A nomogram was developed and showed an excellent predictive ability for the PFI in BLCA patients. Functional enrichment analysis suggested that the radiomics signature we developed could reflect the angiogenesis status of BLCA patients. \r\n",
      "  Conclusions:  The integrative nomogram incorporated CECT radiomics, transcriptomics and clinical features improved the PFI prediction in BLCA patients and is a feasible and practical reference for oncological precision medicine. \r\n",
      "  Key points:  • Our radiomics and transcriptomics models are proved robust for survival prediction in bladder urothelial carcinoma patients. • A multi-omics nomogram model which integrates radiomics, transcriptomics and clinical features for prediction of progression-free interval in bladder urothelial carcinoma is established. • Molecular functional enrichment analysis is used to reveal the potential molecular function of radiomics signature. \r\n",
      "  |  https://dx.doi.org/10.1007/s00330-019-06371-w  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.jbi.2019.103364  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Machine learning has become ubiquitous and a key technology on mining electronic health records (EHRs) for facilitating clinical research and practice. Unsupervised machine learning, as opposed to supervised learning, has shown promise in identifying novel patterns and relations from EHRs without using human created labels. In this paper, we investigate the application of unsupervised machine learning models in discovering latent disease clusters and patient subgroups based on EHRs. We utilized Latent Dirichlet Allocation (LDA), a generative probabilistic model, and proposed a novel model named Poisson Dirichlet Model (PDM), which extends the LDA approach using a Poisson distribution to model patients' disease diagnoses and to alleviate age and sex factors by considering both observed and expected observations. In the empirical experiments, we evaluated LDA and PDM on three patient cohorts, namely Osteoporosis, Delirium/Dementia, and Chronic Obstructive Pulmonary Disease (COPD)/Bronchiectasis Cohorts, with their EHR data retrieved from the Rochester Epidemiology Project (REP) medical records linkage system, for the discovery of latent disease clusters and patient subgroups. We compared the effectiveness of LDA and PDM in identifying disease clusters through the visualization of disease representations. We tested the performance of LDA and PDM in differentiating patient subgroups through survival analysis, as well as statistical analysis of demographics and Elixhauser Comorbidity Index (ECI) scores in those subgroups. The experimental results show that the proposed PDM could effectively identify distinguished disease clusters based on the latent patterns hidden in the EHR data by alleviating the impact of age and sex, and that LDA could stratify patients into differentiable subgroups with larger p-values than PDM. However, those subgroups identified by LDA are highly associated with patients' age and sex. The subgroups discovered by PDM might imply the underlying patterns of diseases of greater interest in epidemiology research due to the alleviation of age and sex. Both unsupervised machine learning approaches could be leveraged to discover patient subgroups using EHRs but with different foci. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1532-0464(19)30284-9  |  \n",
      "------------------------------------------- \r\n",
      "10.1080/09513590.2019.1650345  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   It is essential that fertility treatment is individualized based on a thorough diagnostic work-up, with treatment tailored to the patients' requirements. This individualization should be kept in mind during the main decision points that occur before and during treatment. Treatment customization must include consideration of both the woman and her partner involved in the process together, including their collective treatment goals. Once treatment goals have been agreed and diagnostic evaluations performed, personalization based on patient characteristics, together with an understanding of treatment goals and patient preferences, enables the selection of appropriate treatments, protocols, products and their dosing. Following treatment initiation, monitoring and adaptation of product and dose can then ensure optimal outcomes. Currently, it is not possible to base treatment decisions on every characteristic of the patient and personalization is based on biomarkers that have been identified as the most relevant. However, in the future, the use of artificial intelligence coupled with continuous monitoring should enable greater individualization and improve outcomes. This review considers the current state-of-the-art related to decision points during individualized treatment of female infertility, before looking at future developments that might further assist in making individualized treatment decisions, including the use of computer-assisted decision making. \r\n",
      "  |  http://www.tandfonline.com/doi/full/10.1080/09513590.2019.1650345  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.media.2019.101625  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The accurate diagnosis of Alzheimer's disease (AD) and its early stage, e.g., mild cognitive impairment (MCI), is essential for timely treatment or possible intervention to slow down AD progression. Recent studies have demonstrated that multiple neuroimaging and biological measures contain complementary information for diagnosis and prognosis. Therefore, information fusion strategies with multi-modal neuroimaging data, such as voxel-based measures extracted from structural MRI (VBM-MRI) and fluorodeoxyglucose positron emission tomography (FDG-PET), have shown their effectiveness for AD diagnosis. However, most existing methods are proposed to simply integrate the multi-modal data, but do not make full use of structure information across the different modalities. In this paper, we propose a novel multi-modal neuroimaging feature selection method with consistent metric constraint (MFCC) for AD analysis. First, the similarity is calculated for each modality (i.e. VBM-MRI or FDG-PET) individually by random forest strategy, which can extract pairwise similarity measures for multiple modalities. Then the group sparsity regularization term and the sample similarity constraint regularization term are used to constrain the objective function to conduct feature selection from multiple modalities. Finally, the multi-kernel support vector machine (MK-SVM) is used to fuse the features selected from different models for final classification. The experimental results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) show that the proposed method has better classification performance than the start-of-the-art multimodality-based methods. Specifically, we achieved higher accuracy and area under the curve (AUC) for AD versus normal controls (NC), MCI versus NC, and MCI converters (MCI-C) versus MCI non-converters (MCI-NC) on ADNI datasets. Therefore, the proposed model not only outperforms the traditional method in terms of AD/MCI classification, but also discovers the characteristics associated with the disease, demonstrating its promise for improving disease-related mechanistic understanding. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(19)30161-6  |  \n",
      "------------------------------------------- \r\n",
      "10.1038/s41598-019-44852-6  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Artificial intelligence capabilities have, recently, greatly improved. In the past few years, one of the deep learning algorithms, the recurrent neural network (RNN), has shown an outstanding ability in sequence labeling and prediction tasks for sequential data. We built a reliable visual field prediction algorithm using RNN and evaluated its performance in comparison with the conventional pointwise ordinary linear regression (OLR) method. A total of 1,408 eyes were used as a training dataset and another dataset, comprising 281 eyes, was used as a test dataset. Five consecutive visual field tests were provided to the constructed RNN as input and a 6<sup>th</sup> visual field test was compared with the output of the RNN. The performance of the RNN was compared with that of OLR by predicting the 6<sup>th</sup> visual field in the test dataset. The overall prediction performance of RNN was significantly better than OLR. The pointwise prediction error of the RNN was significantly smaller than that of the OLR in most areas known to be vulnerable to glaucomatous damage. The RNN was also more robust and reliable regarding worsening in the visual field examination. In clinical practice, the RNN model can therefore assist in decision-making for further treatment of glaucoma. \r\n",
      "  |  http://dx.doi.org/10.1038/s41598-019-44852-6  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31182763/  |  \n",
      "------------------------------------------- \r\n",
      "10.1037/xge0000630  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Creative thinking drives progress not only in the arts but also, and perhaps especially, in the fields of science, technology, engineering, and mathematics, and it is expected to become even more valuable than technical skill as artificial intelligence outpaces human cognition. Fostering creative thinkers has become a primary focus of educators. Educationally relevant anxieties, like math anxiety, have been shown to substantially impact specific forms of achievement and engagement, both in school and in career pursuits. Identifying these anxieties has led to promising interventions to enable affected individuals to reach their potential. Somewhat surprisingly, however, the possibility of anxiety specific to creative thinking is, to our knowledge, unexplored. In this article, across multiple samples, we tested the viability of creativity anxiety as a construct. We first created a new measure, the Creativity Anxiety Scale (CAS), demonstrating validity, internal reliability, and specificity. Applying the CAS revealed that creativity-specific anxiety predicted individual differences in creative achievement and attitudes toward creativity over and above effects of general anxiety. Moreover, across diverse content domains, from science to arts, anxiety was greater for situations that required creativity than similar situations that did not. Notably, this effect was especially pronounced in women. These findings suggest that creativity anxiety may have wide-reaching impacts and distinguish creativity anxiety from anxiety about noncreative aspects of performance. Establishing creativity anxiety as a novel construct, and the CAS as a valid measurement instrument, opens a new avenue of research that promises to deepen basic understanding of creative cognition and inform development of interventions to enable greater achievement of creative potential. (PsycINFO Database Record (c) 2019 APA, all rights reserved). \r\n",
      "  |  http://content.apa.org/journals/xge/149/1/42  |  \n",
      "------------------------------------------- \r\n",
      "10.1038/s41591-019-0543-y  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    |  http://dx.doi.org/10.1038/s41591-019-0543-y  |  \n",
      "------------------------------------------- \r\n",
      "10.1097/CCO.0000000000000563  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Purpose of review:  Immune checkpoint inhibitors (ICIs) are rapidly changing practice across different tumor settings. With this article, we reflect on how to assimilate the tsunami of ICIs data into clinical practice. \r\n",
      "  Recent findings:  A tremendous increase on approvals, number of publications, and clinical trials ongoing with ICIs on many different tumor types. \r\n",
      "  Summary:  ICIs are innovative treatments that are showing a significant benefit on different tumors. More approvals and an explosive increase of knowledge around the usage of ICI are to be expected in the near future, bringing new challenges on how to integrate this fast-growing evidence with ICI into clinical practice. To be updated, oncologists could follow approved guidelines from relevant societies and complement it with an appropriate search from publication databases. There are also some available courses, conferences and online material that are useful to improve knowledge in this so rapidly changing environment. In the future, we believe the integration of artificial intelligence and learning machines will play an important role to facilitate best clinical practices in different fields of medicine but particularly for oncology. \r\n",
      "  |  http://dx.doi.org/10.1097/CCO.0000000000000563  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/978-3-030-16391-4_8  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Pancreas cancer is an aggressive and fatal disease that will become one of the leading causes of cancer mortality by 2030. An all-out effort is underway to better understand the basic biologic mechanisms of this disease ranging from early development to metastatic disease. In order to change the course of this disease, diagnostic radiology imaging may play a vital role in providing a precise, noninvasive method for early diagnosis and assessment of treatment response. Recent progress in combining medical imaging, advanced image analysis and artificial intelligence, termed radiomics, can offer an innovate approach in detecting the earliest changes of tumor development as well as a rapid method for the detection of response. In this chapter, we introduce the principles of radiomics and demonstrate how it can provide additional information into tumor biology, early detection, and response assessments advancing the goals of precision imaging to deliver the right treatment to the right person at the right time. \r\n",
      "  |  https://dx.doi.org/10.1007/978-3-030-16391-4_8  |  \n",
      "------------------------------------------- \r\n",
      "10.3389/fbioe.2019.00330  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   MicroRNAs (miRNA) have been identified as oncogenic drivers and tumor suppressors in every major cancer type. In this work, we design an artificial intelligent signal amplification (AISA) system including double-stranded SQ (S, signal strand; Q, quencher strand) and FP (F, fuel strand; P, protect strand) according to thermodynamics principle for sensitive detection of miRNA <i>in vitro</i> and <i>in vivo</i>. In this AISA system for miRNA detection, strand S carries a quenched imaging marker inside the SQ. Target miRNA is constantly replaced by a reaction intermediate and circulatively participates in the reaction, similar to enzyme. Therefore, abundant fluorescent substances from S and SP are dissociated from excessive SQ for <i>in vitro and in vivo</i> visualization. The versatility and feasibility for disease diagnosis using this system were demonstrated by constructing two types of AISA system to detect Hsa-miR-484 and Hsa-miR-100, respectively. The minimum target concentration detected by the system <i>in vitro</i> (10 min after mixing) was 1/10th that of the control group. The precancerous lesions of liver cancer were diagnosed, and the detection accuracy were larger than 94% both in terms of location and concentration. The ability to establish this design framework for AISA system with high specificity provides a new way to monitor tumor progression and to assess therapeutic responses. \r\n",
      "  |  https://doi.org/10.3389/fbioe.2019.00330  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31824932/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/ma12182864  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Experimental research of cutting force components during dry face milling operations are presented in the paper. The study was provided when milling of ductile cast iron alloyed with copper and its austempered ductile iron after the proper austempering process. In the study, virtual instrumentation designed for cutting forces components monitoring was used. During the research, orthogonal cutting forces components versus time were monitored and relationship of cutting forces components versus speed, feed and depth of cut were determined by artificial neural network and response surface methodology. An analysis was made regarding the consistency of the measured cutting forces and the values obtained from the model supported by an artificial neural network for the investigated interval of the cutting regime. Based on the results, an analysis of the feasibility of the application of austempered ductile iron in the industrial sector with the aspect of machinability as well as the application of the models based on artificial intelligence, was given. At the end of the presentation, the influence of the aforementioned cutting regimes on cutting force components is presented as well. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=ma12182864  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31491929/  |  \n",
      "------------------------------------------- \r\n",
      "10.1016/j.neuroimage.2019.06.053  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Classic serotonergic psychedelics are remarkable for their capacity to induce reversible alterations in consciousness of the self and the surroundings, mediated by agonism at serotonin 5-HT<sub>2A</sub> receptors. The subjective effects elicited by dissociative drugs acting as N-methyl-D-aspartate (NMDA) antagonists (e.g. ketamine and phencyclidine) overlap in certain domains with those of serotonergic psychedelics, suggesting some potential similarities in the brain activity patterns induced by both classes of drugs, despite different pharmacological mechanisms of action. We investigated source-localized magnetoencephalography recordings to determine the frequency-specific changes in oscillatory activity and long-range functional coupling that are common to two serotonergic compounds (lysergic acid diethylamide [LSD] and psilocybin) and the NMDA-antagonist ketamine. Administration of the three drugs resulted in widespread and broadband spectral power reductions. We established their similarity by using different pairs of compounds to train and subsequently evaluate multivariate machine learning classifiers. After applying the same methodology to functional connectivity values, we observed a pattern of occipital, parietal and frontal decreases in the low alpha and theta bands that were specific to LSD and psilocybin, as well as decreases in the low beta band common to the three drugs. Our results represent a first effort in the direction of quantifying the similarity of large-scale brain activity patterns induced by drugs of different mechanism of action, confirming the link between changes in theta and alpha oscillations and 5-HT<sub>2A</sub> agonism, while also revealing the decoupling of activity in the beta band as an effect shared between NMDA antagonists and 5-HT<sub>2A</sub> agonists. We discuss how these frequency-specific convergences and divergences in the power and functional connectivity of brain oscillations might relate to the overlapping subjective effects of serotonergic psychedelics and glutamatergic dissociative compounds. \r\n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1053-8119(19)30550-6  |  \n",
      "------------------------------------------- \r\n",
      "10.12659/MSM.917299  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Thyroid-associated ophthalmopathy is the commonest orbital disease in adults. However, shortcomings still exist in treatments. The aim of this study was to identify the efficacy and potential mechanism of gypenosides in the treatment of thyroid-associated ophthalmopathy. The Traditional Chinese Medicine Systems Pharmacology Database and Analysis Platform was screened for active compounds of gypenosides, and targets were predicted using Swiss Target Prediction. The targets of thyroid-associated ophthalmopathy were obtained from Online Mendelian Inheritance in Man, Comparative Toxicogenomic Database and GeneCards Human gene database. Gene Ontology (GO), the Kyoto Encyclopedia of Genes and Genomes (KEGG) and Reactome Pathways were determined based on the common targets. Protein-protein interaction (PPI) network was constructed to further understand of relationship among target genes, compounds and proteins. Molecular docking was performed to investigate the binding ability between gypenosides and hub genes. A total of 70 targets for gypenosides and 804 targets for thyroid-associated ophthalmopathy were obtained with 8 common targets identified. GO analysis and KEGG pathway analysis revealed that the hub genes were enriched in JAK-STAT, while Reactome pathways analysis indicated genes enriched in interleukin pathways. PPI network showed STAT1, STAT3, and STAT4 were at the center. Additionally, molecular docking indicated that STAT1 and STAT3 display good binding forces with gypenosides. This study indicates that target genes mainly enriched in JAK-STAT signaling pathway, particularly in STATs, which can be combined with gypenosides. This may suggest that gypenosides have curative effect on thyroid-associated ophthalmopathy via the JAK-STAT pathway. \r\n",
      "  |  https://www.medscimonit.com/download/index/idArt/917299  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31268042/  |  \n",
      "------------------------------------------- \r\n",
      "10.1007/s11255-018-2044-1  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Purpose:  The purpose of the study was to assess the differences in the concentration and function of urinary proteins between patients with cystine stones (CYS) and healthy controls (HC). We postulated that CYS and HC groups would demonstrate different proteomic profiles. \r\n",
      "  Methods:  A pilot study was performed comparing urinary proteomes of 10 patients with CYS and 10 age- and gender-matched HC, using liquid chromatography-mass spectrometry. Proteins which met the selection criteria (i) ≥ 2 unique peptide identifications; (ii) ≥ twofold difference in protein abundance; and (iii) ≤ 0.05 p value for the Fisher's Exact Test were analyzed using Gene Ontology classifications. \r\n",
      "  Results:  Of the 2097 proteins identified by proteomic analysis, 398 proteins were significantly different between CYS and HC. Of those, 191 were involved in transport processes and 61 in inflammatory responses. The majority were vesicle-mediated transport proteins (78.5%), and 1/3 of them were down-regulated; of those, 12 proteins were involved in endosomal transport (including 6 charged multivesicular body proteins (CHMP) and 3 vacuolar sorting-associated proteins) and 9 in transmembrane transport. Myosin-2 and two actin-related proteins were significantly up-regulated in the vesicle-mediated transport group. \r\n",
      "  Conclusion:  We provide proteomic evidence of impaired endocytosis, dysregulation of actin and myosin cytoskeleton, and inflammation in CYS. Endosomal transport proteins were down-regulated mainly through defective CHMP. These findings may contribute to further understanding of the pathogenesis of CYS, potentially affecting its management. \r\n",
      "  |  https://doi.org/10.1007/s11255-018-2044-1  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30519981/  |  \n",
      "------------------------------------------- \r\n",
      "10.2214/AJR.18.20443  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Objective:  The purpose of this study is to evaluate the potential value of machine learning (ML)-based high-dimensional quantitative CT texture analysis in predicting the mutation status of the gene encoding the protein polybromo-1 (PBRM1) in patients with clear cell renal cell carcinoma (RCC). \r\n",
      "  Materials and methods:  In this retrospective study, 45 patients with clear cell RCC (29 without the PBRM1 mutation and 16 with the PBRM1 mutation) were identified in The Cancer Genome Atlas-Kidney Renal Clear Cell Carcinoma database. To create stable ML models and balanced classes, the data were augmented to a total of 161 labeled segmentations (87 without the PBRM1 mutation and 74 with the PBRM1 mutation) by obtaining three to five different samples per patient. Texture features were extracted from corticomedullary phase contrast-enhanced CT images with the use of an open-source software package for the extraction of radiomic data from medical images. Reproducibility analysis (intraclass correlation) was performed by two radiologists. Attribute selection and model optimization were done using a wrapper-based classifier-specific algorithm with nested cross-validation. ML classifiers were an artificial neural network (ANN) algorithm and a random forest (RF) algorithm. The models were validated using 10-fold cross-validation. The reference standard was the PBRM1 mutation status. The main performance metric was the AUC value. \r\n",
      "  Results:  Of 828 extracted texture features, 759 had excellent reproducibility. Using 10 selected features, the ANN algorithm correctly classified 88.2% (142 of 161) of the clear cell RCCs in terms of PBRM1 mutation status (AUC value, 0.925). Using five selected features, the RF algorithm correctly classified 95.0% (153 of 161) of the clear cell RCCs (AUC value, 0.987). Overall, the RF algorithm performed better than the ANN algorithm (z score = -2.677; p = 0.007). \r\n",
      "  Conclusion:  ML-based high-dimensional quantitative CT texture analysis might be a feasible and potential method for predicting PBRM1 mutation status in patients with clear cell RCC. \r\n",
      "  |  http://www.ajronline.org/doi/full/10.2214/AJR.18.20443  |  \n",
      "------------------------------------------- \r\n",
      "10.1111/nph.15692  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Biotrophic fungal plant pathogens can balance their virulence and form intricate relationships with their hosts. Sometimes, this leads to systemic host colonization over long time scales without macroscopic symptoms. However, how plant-pathogenic endophytes manage to establish their sustained systemic infection remains largely unknown. Here, we present a genomic and transcriptomic analysis of Thecaphora thlaspeos. This relative of the well studied grass smut Ustilago maydis is the only smut fungus adapted to Brassicaceae hosts. Its ability to overwinter with perennial hosts and its systemic plant infection including roots are unique characteristics among smut fungi. The T. thlaspeos genome was assembled to the chromosome level. It is a typical smut genome in terms of size and genome characteristics. In silico prediction of candidate effector genes revealed common smut effector proteins and unique members. For three candidates, we have functionally demonstrated effector activity. One of these, TtTue1, suggests a potential link to cold acclimation. On the plant side, we found evidence for a typical immune response as it is present in other infection systems, despite the absence of any macroscopic symptoms during infection. Our findings suggest that T. thlaspeos distinctly balances its virulence during biotrophic growth ultimately allowing for long-lived infection of its perennial hosts. \r\n",
      "  |  https://doi.org/10.1111/nph.15692  |  \n",
      "------------------------------------------- \r\n",
      "10.1371/journal.pone.0214857  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Myasthenia gravis (MG) is an autoimmune disease. In recent years, considerable evidence has indicated that Gene Ontology (GO) functions, especially GO-biological processes, have important effects on the mechanisms and treatments of different diseases. However, the roles of GO functions in the pathogenesis and treatment of MG have not been well studied. This study aimed to uncover the potential important roles of risk-related GO functions and to screen significant candidate drugs related to GO functions for MG. Based on MG risk genes, 238 risk GO functions and 42 drugs were identified. Through constructing a GO function network, we discovered that positive regulation of NF-kappaB transcription factor activity (GO:0051092) may be one of the most important GO functions in the mechanism of MG. Furthermore, we built a drug-GO function network to help evaluate the latent relationship between drugs and GO functions. According to the drug-GO function network, 5 candidate drugs showing promise for treating MG were identified. Indeed, 2 out of 5 candidate drugs have been investigated to treat MG. Through functional enrichment analysis, we found that the mechanisms between 5 candidate drugs and associated GO functions may involve two vital pathways, specifically hsa05332 (graft-versus-host disease) and hsa04940 (type I diabetes mellitus). More interestingly, most of the processes in these two pathways were consistent. Our study will not only reveal a new perspective on the mechanisms and novel treatment strategies of MG, but also will provide strong support for research on GO functions. \r\n",
      "  |  http://dx.plos.org/10.1371/journal.pone.0214857  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30947317/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/ijms20061309  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Oxidation of methionine to methionine sulfoxide is a type of posttranslational modification reversed by methionine sulfoxide reductases (Msrs), which present an exceptionally high number of gene copies in plants. The side-form general antioxidant function-specific role of each Msr isoform has not been fully studied. Thirty homologous genes of Msr type A (MsrA) and type B (MsrB) that originate from the genomes of <i>Arabidopsis thaliana</i>, <i>Populus trichocarpa,</i> and <i>Oryza sativa</i> were analyzed in silico. From 109 to 201 transcription factors and responsive elements were predicted for each gene. Among the species, 220 and 190 common transcription factors and responsive elements were detected for the <i>MsrA</i> and <i>MsrB</i> isoforms, respectively. In a comparison of 14 <i>MsrA</i> and 16 <i>MsrB</i> genes, 424 transcription factors and responsive elements were reported in both types of genes, with almost ten times fewer unique elements. The transcription factors mainly comprised plant growth and development regulators, transcription factors important in stress responses with significant overrepresentation of the myeloblastosis viral oncogene homolog (MYB) and no apical meristem, Arabidopsis transcription activation factor and cup-shaped cotyledon (NAC) families and responsive elements sensitive to ethylene, jasmonate, sugar, and prolamine. Gene Ontology term-based functional classification revealed that cellular, metabolic, and developmental process terms and the response to stimulus term dominated in the biological process category. Available experimental transcriptomic and proteomic data, in combination with a set of predictions, gave coherent results validating this research. Thus, new manners <i>Msr</i> gene expression regulation, as well as new putative roles of Msrs, are proposed. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=ijms20061309  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30875880/  |  \n",
      "------------------------------------------- \r\n",
      "10.12659/MSM.917375  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   BACKGROUND Osteosarcoma (OS) is a common primary malignant bone tumor for which the molecular mechanisms remain unclear. Studies on coding and non-coding RNAs are needed to determine the molecular mechanism. MATERIAL AND METHODS To explore the potential roles of miRNAs and mRNA in OS, we determined the miRNA and mRNA expression profile of 3 pairs of OS and paracancerous tissues from patients with OS by sequencing and bioinformatics analysis. The expression levels of critical miRNAs and mRNAs were verified in 10 pairs of OS and paracancerous tissues. An miRNA inhibitor and mimics were used to investigate the interactions between miRNAs and target genes. The cell counting kit-8 assay was performed to evaluate OS cell proliferation after miRNA interference. RESULTS A total of 184 miRNAs and 2501 mRNAs were identified (fold-change &gt;2.0 or &lt;2.0, P&lt;0.05), with up-regulation of 82 miRNAs and 1320 mRNAs and down-regulation of 102 miRNAs and 1181 mRNAs in OS tissue. The protein protein interaction network revealed that UQCRC1 (ubiquinol-cytochrome c reductase core protein 1) is a critical gene and a potential target gene of miR-214-3p. Both UQCRC1 and miR-214-3p were significantly differentially expressed in OS tissue and cell lines (down and up-regulated, respectively). Down-regulated miR-214-3p expression increased UQCRC1 expression and suppressed OS cell proliferation. In contrast, overexpression of miR-214-3p decreased UQCRC1 expression and promoted OS cell proliferation. CONCLUSIONS High miR-214-3p expression may promote OS cell proliferation by targeting UQCRC1, providing insight into a potential therapeutic target for preventing and treating OS. \r\n",
      "  |  https://www.medscimonit.com/download/index/idArt/917375  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31276465/  |  \n",
      "------------------------------------------- \r\n",
      "10.1186/s12967-018-1761-7  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  Hepatitis B virus (HBV) is one of the major risk factors of hepatocellular carcinoma (HCC). Increasing evidence indicates that microRNA (miRNA)-mRNA axis is involved in HCC. However, a comprehensive miRNA-mRNA regulatory network in HBV-related HCC is still absent. This study aims to identify potential miRNA-mRNA regulatory pathways contributing to pathogenesis of HBV-related HCC. \r\n",
      "  Methods:  Microarray GSE69580 was downloaded from Gene Expression Omnibus (GEO) database. GEO2R and 'R-limma' were used to conduct differential expression analysis. The common miRNAs appeared in the two analytic sets were screened as potential differentially expressed miRNAs (DE-miRNAs). The prognostic roles of screened DE-miRNAs in HCC were further evaluated using Kaplan-Meier plotter database. Target genes of DE-miRNAs were predicted by miRNet. Then, protein-protein interaction (PPI) networks were established for these targets via the STRING database, after which hub genes in the networks were identified by Cytoscape. Functional annotation and pathway enrichment analyses for the target genes were performed through DAVID database. Three enriched pathways related to HBV-related HCC were selected for further analysis and potential target genes commonly appeared in all three pathways were screened. Cytoscape was employed to construct miRNA-hub gene network. The expression and correlation of potential miRNAs and targets were further detected in clinical HBV-related HCC samples by qRT-PCR. \r\n",
      "  Results:  7 upregulated and 9 downregulated DE-miRNAs were accessed. 5 of 7 upregulated DE-miRNAs and 5 of 7 downregulated DE-miRNAs indicated significant prognostic roles in HCC. 2312 and 1175 target genes were predicted for the upregulated and downregulated DE-miRNAs, respectively. TP53 was identified as the hub gene in the PPI networks. Pathway enrichment analysis suggested that these predicted targets were linked to hepatitis B, pathways in cancer, microRNAs in cancer and viral carcinogenesis. Further analysis of these pathways screened 20 and 16 target genes for upregulated and downregulated DE-miRNAs, respectively. By detecting the expression of 36 target genes, six candidate target genes were identified. Finally, a potential miRNA-mRNA regulatory network was established based on the results of qRT-PCR and expression correlation analysis. \r\n",
      "  Conclusions:  In the study, potential miRNA-mRNA regulatory pathways were identified, exploring the underlying pathogenesis and effective therapy strategy of HBV-related HCC. \r\n",
      "  |  https://translational-medicine.biomedcentral.com/articles/10.1186/s12967-018-1761-7  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30602391/  |  \n",
      "------------------------------------------- \r\n",
      "10.1371/journal.pone.0223173  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Sugar transporters play a crucial role for plant productivity, as they coordinate sugar fluxes from source leaf towards sink organs (seed, fruit, root) and regulate the supply of carbon resources towards the microorganisms of the rhizosphere (bacteria and fungi). Thus, sugar fluxes mediated by SUT (sucrose transporters), MST (monosaccharide transporters) and SWEET (sugar will eventually be exported transporters) families are key determinants of crop yield and shape the microbial communities living in the soil. In this work, we performed a systematic search for sugar transporters in Fabaceae genomes, focusing on model and agronomical plants. Here, we update the inventory of sugar transporter families mining the latest version of the Medicago truncatula genome and identify for the first time SUT MST and SWEET families of the agricultural crop Pisum sativum. The sugar transporter families of these Fabaceae species comprise respectively 7 MtSUT 7 PsSUT, 72 MtMST 59 PsMST and 26 MtSWEET 22 PsSWEET. Our comprehensive phylogenetic analysis sets a milestone for the scientific community, as we propose a new and simple nomenclature to correctly name SUT MST and SWEET families. Then, we searched for transcriptomic data available for our gene repertoire. We show that several clusters of homologous genes are co-expressed in different organs, suggesting that orthologous sugar transporters may have a conserved function. We focused our analysis on gene candidates that may be involved in remobilizing resources during flowering, grain filling and in allocating carbon towards roots colonized by arbuscular mycorrhizal fungi and Rhizobia. Our findings open new perspectives for agroecological applications in legume crops, as for instance improving the yield and quality of seed productions and promoting the use of symbiotic microorganisms. \r\n",
      "  |  http://dx.plos.org/10.1371/journal.pone.0223173  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31568488/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/ijms20174231  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   Fibromyalgia (FM) is a chronic syndrome characterized by widespread musculoskeletal pain, and physical and emotional symptoms. Although its pathophysiology is largely unknown, immune-inflammatory pathways may be involved. We examined serum interleukin (IL)-6, high sensitivity C-reactive protein (hs-CRP), CXCL-8, and IL-10 in 67 female FM patients and 35 healthy women while adjusting for age, body mass index (BMI), and comorbid disorders. We scored the Fibromyalgia Severity Score, Widespread Pain Index (WPI), Symptom Severity Scale (SSS), Hospital Anxiety (HADS-A), and Depression Scale and the Perceived Stress Scale (PSS-10). Clinical rating scales were significantly higher in FM patients than in controls. After adjusting for covariates, IL-6, IL-10, and CXCL-8 were lower in FM than in HC, whereas hs-CRP did not show any difference. Binary regression analyses showed that the diagnosis FM was associated with lowered IL-10, quality of sleep, aerobic activities, and increased HADS-A and comorbidities. Neural networks showed that WPI was best predicted by quality of sleep, PSS-10, HADS-A, and the cytokines, while SSS was best predicted by PSS-10, HADS-A, and IL-10. Lowered levels of cytokines are associated with FM independently from confounders. Lowered IL-6 and IL-10 signaling may play a role in the pathophysiology of FM. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=ijms20174231  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31470635/  |  \n",
      "------------------------------------------- \r\n",
      "10.1038/s41467-019-09278-8  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The architecture of mouse and human antibody repertoires is defined by the sequence similarity networks of the clones that compose them. The major principles that define the architecture of antibody repertoires have remained largely unknown. Here, we establish a high-performance computing platform to construct large-scale networks from comprehensive human and murine antibody repertoire sequencing datasets (&gt;100,000 unique sequences). Leveraging a network-based statistical framework, we identify three fundamental principles of antibody repertoire architecture: reproducibility, robustness and redundancy. Antibody repertoire networks are highly reproducible across individuals despite high antibody sequence dissimilarity. The architecture of antibody repertoires is robust to the removal of up to 50-90% of randomly selected clones, but fragile to the removal of public clones shared among individuals. Finally, repertoire architecture is intrinsically redundant. Our analysis provides guidelines for the large-scale network analysis of immune repertoires and may be used in the future to define disease-associated and synthetic repertoires. \r\n",
      "  |  http://dx.doi.org/10.1038/s41467-019-09278-8  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30899025/  |  \n",
      "------------------------------------------- \r\n",
      "10.3390/s19071740  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |   The neuroimaging techniques such as dopaminergic imaging using Single Photon Emission Computed Tomography (SPECT) with <sup>99m</sup>Tc-TRODAT-1 have been employed to detect the stages of Parkinson's disease (PD). In this retrospective study, a total of 202 <sup>99m</sup>Tc-TRODAT-1 SPECT imaging were collected. All of the PD patient cases were separated into mild (HYS Stage 1 to Stage 3) and severe (HYS Stage 4 and Stage 5) PD, according to the Hoehn and Yahr Scale (HYS) standard. A three-dimensional method was used to estimate six features of activity distribution and striatal activity volume in the images. These features were skewness, kurtosis, Cyhelsky's skewness coefficient, Pearson's median skewness, dopamine transporter activity volume, and dopamine transporter activity maximum. Finally, the data were modeled using logistic regression (LR) and support vector machine (SVM) for PD classification. The results showed that SVM classifier method produced a higher accuracy than LR. The sensitivity, specificity, PPV, NPV, accuracy, and AUC with SVM method were 0.82, 1.00, 0.84, 0.67, 0.83, and 0.85, respectively. Additionally, the Kappa value was shown to reach 0.68. This claimed that the SVM-based model could provide further reference for PD stage classification in medical diagnosis. In the future, more healthy cases will be expected to clarify the false positive rate in this classification model. \r\n",
      "  |  http://www.mdpi.com/resolver?pii=s19071740  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30978990/  |  \n",
      "------------------------------------------- \r\n",
      "10.1186/s40644-019-0203-y  |  SubfieldM  |  SubfieldA  |  ResearchTypeM  |  ResearchTypeA  |    Background:  The purpose/aim of this study was to 1) use magnetic resonance diffusion tensor imaging (DTI), fibre bundle/tract-based spatial statistics (TBSS) and machine learning methods to study changes in the white matter (WM) structure and whole brain WM network in different periods of the nasopharyngeal carcinoma (NPC) patients after radiotherapy (RT), 2) identify the most discriminating WM regions and WM connections as biomarkers of radiation brain injury (RBI), and 3) supplement the understanding of the pathogenesis of RBI, which is useful for early diagnosis in the clinic. \r\n",
      "  Methods:  A DTI scan was performed in 77 patients and 67 normal controls. A fractional anisotropy map was generated by DTIFit. TBSS was used to find the region where the FA differed between the case and control groups. Each resulting FA value image is registered with each other to create an average FA value skeleton. Each resultant FA skeleton image was connected to feature vectors, and features with significant differences were extracted and classified using a support vector machine (SVM). Next, brain segmentation was performed on each subject's DTI image using automated anatomical labeling (AAL), and deterministic white matter fiber bundle tracking was performed to generate symmetrical brain matrix, select the upper triangular component as a classification feature. Two-sample t-test was used to extract the features with significant differences, then classified by SVM. Finally, we adopted a permutation test and ROC curves to evaluate the reliability of the classifier. \r\n",
      "  Results:  For FA, the accuracy of classification between the 0-6, 6-12 and &gt; 12 months post-RT groups and the control group was 84.5, 83.9 and 74.5%, respectively. In the case groups, the FA with discriminative ability was reduced, mainly in the bilateral cerebellum and bilateral temporal lobe, with prolonged time, the damage was aggravated. For WM connections, the SVM classifier classification recognition rates of the 0-6, 6-12 and &gt; 12 months post-RT groups reached 82.5, 78.4 and 76.3%, respectively. The WM connections with discriminative ability were reduced. \r\n",
      "  Conclusions:  RBI is a disease involving whole brain WM network anomalies. These brain discriminating WM regions and WM connection modes can supplement the understanding of RBI and be used as biomarkers for the early clinical diagnosis of RBI. \r\n",
      "  |  https://cancerimagingjournal.biomedcentral.com/articles/10.1186/s40644-019-0203-y  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/30909974/  |  \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(\"in/extract2019.txt\", 'r', encoding='utf8') as f_in:\n",
    "        \n",
    "        papers = f_in.read()\n",
    "        paperlist = papers.split(\"-------------------------------------------\")\n",
    "        del paperlist[-1]\n",
    "        text_out = \"\"\n",
    "        for paper in paperlist[101:200]:\n",
    "            paper_text = \"\"\n",
    "            data = paper.split(\"  |  \")\n",
    "            \n",
    "            #add fields for classification\n",
    "            data.insert(1, \"ResearchTypeA\")\n",
    "            data.insert(1, \"ResearchTypeM\")\n",
    "            data.insert(1, \"SubfieldA\")\n",
    "            data.insert(1, \"SubfieldM\")\n",
    "            \n",
    "            i = 0\n",
    "            for field in data:\n",
    "                if(i == len(data) - 1):\n",
    "                    break\n",
    "                paper_text = paper_text + data[i] + \"  |  \"\n",
    "                i+=1\n",
    "            paper_text = paper_text + \"\\n-------------------------------------------\"\n",
    "            text_out = text_out + paper_text\n",
    "        \n",
    "        f_out = codecs.open(\"out/extract2019-2.txt\", 'w', encoding='utf8')\n",
    "        print(text_out)\n",
    "        f_out.write(text_out)\n",
    "        f_out.close()\n",
    "        f_in.close()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 papers classified\n",
      "\n",
      "10.1093/jnen/nlz122  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   The neuropathology associated with cognitive decline in military personnel exposed to traumatic brain injury (TBI) and chronic stress is incompletely understood. Few studies have examined clinicopathologic correlations between phosphorylated-tau neurofibrillary tangles, β-amyloid neuritic plaques, neuroinflammation, or white matter (WM) lesions, and neuropsychiatric disorders in veterans. We describe clinicopathologic findings in 4 military veterans with early-onset dementia (EOD) who had varying histories of blunt- and blast-TBI, cognitive decline, behavioral abnormalities, post-traumatic stress disorder, suicidal ideation, and suicide. We found that pathologic lesions in these military-EOD cases could not be categorized as classic Alzheimer's disease (AD), chronic traumatic encephalopathy, traumatic axonal injury, or other well-characterized clinicopathologic entities. Rather, we observed a mixture of polypathology with unusual patterns compared with pathologies found in AD or other dementias. Also, ultrahigh resolution ex vivo MRI in 2 of these 4 brains revealed unusual patterns of periventricular WM injury. These findings suggest that military-EOD cases are associated with atypical combinations of brain lesions and distribution rarely seen in nonmilitary populations. Future prospective studies that acquire neuropsychiatric data before and after deployments, as well as genetic and environmental exposure data, are needed to further elucidate clinicopathologic correlations in military-EOD. \n",
      "  |  https://academic.oup.com/jnen/article-lookup/doi/10.1093/jnen/nlz122  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31851313/  |  \n",
      "------------------------------------------- \n",
      "10.1148/radiol.2020200905  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49±15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value&lt;0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases. \n",
      "  |  http://pubs.rsna.org/doi/10.1148/radiol.2020200905?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.mri.2019.09.006  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   One major thrust in radiology today is image standardization with a focus on rapidly acquired quantitative multi-contrast information. This is critical for multi-center trials, for the collection of big data and for the use of artificial intelligence in evaluating the data. Strategically acquired gradient echo (STAGE) imaging is one such method that can provide 8 qualitative and 7 quantitative pieces of information in 5 min or less at 3 T. STAGE provides qualitative images in the form of proton density weighted images, T1 weighted images, T2* weighted images and simulated double inversion recovery (DIR) images. STAGE also provides quantitative data in the form of proton spin density, T1, T2* and susceptibility maps as well as segmentation of white matter, gray matter and cerebrospinal fluid. STAGE uses vendors' product gradient echo sequences. It can be applied from 0.35 T to 7 T across all manufacturers producing similar results in contrast and quantification of the data. In this paper, we discuss the strengths and weaknesses of STAGE, demonstrate its contrast-to-noise (CNR) behavior relative to a large clinical data set and introduce a few new image contrasts derived from STAGE, including DIR images and a new concept referred to as true susceptibility weighted imaging (tSWI) linked to fluid attenuated inversion recovery (FLAIR) or tSWI-FLAIR for the evaluation of multiple sclerosis lesions. The robustness of STAGE T1 mapping was tested using the NIST/NIH phantom, while the reproducibility was tested by scanning a given individual ten times in one session and the same subject scanned once a week over a 12-week period. Assessment of the CNR for the enhanced T1W image (T1WE) showed a significantly better contrast between gray matter and white matter than conventional T1W images in both patients with Parkinson's disease and healthy controls. We also present some clinical cases using STAGE imaging in patients with stroke, metastasis, multiple sclerosis and a fetus with ventriculomegaly. Overall, STAGE is a comprehensive protocol that provides the clinician with numerous qualitative and quantitative images. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0730-725X(19)30382-0  |  \n",
      "------------------------------------------- \n",
      "10.1007/s12149-020-01460-z  |  Treatment, Prognosis, Diagnosis  |  Diagnosis, Prognosis, Treatment  |  Research  |  Research  |    Objective:  The aim of the study was to investigate the outcomes and prognostic factors of high-dose <sup>131</sup>I-metaiodobenzylguanidine (<sup>131</sup>I-MIBG) therapy in patients with refractory or relapsed neuroblastoma (NBL) in Japan. \n",
      "  Methods:  We retrospectively analyzed 20 patients with refractory or relapsed high-risk NBL who underwent <sup>131</sup>I-MIBG therapy with an administration dose ranging from 444 to 666 MBq/kg at Kanazawa University Hospital, Japan, between September 2008 and September 2013. We focused on measurements regarding their initial responses, prognostic factors, survivals, and toxicities following <sup>131</sup>I-MIBG therapy using our hospital data and questionnaires from the hospitals that these patients were initially referred from. Furthermore, we performed Kaplan-Meier survival analysis to evaluate event-free survival (EFS) and overall survival (OS). \n",
      "  Results:  In 19 patients with complete follow-up data, the median age at first <sup>131</sup>I-MIBG treatment was 7.9 years (range 2.5-17.7 years). Following <sup>131</sup>I-MIBG therapy, 17 of the 19 patients underwent stem-cell transplantations, and their treatment response was either complete (CR) or partial (PR) in three and two cases, respectively. The EFS and OS rates at 1 year following <sup>131</sup>I-MIBG therapy were 42% and 58%, respectively, and those at 5 years following <sup>131</sup>I-MIBG therapy were 16% and 42%, respectively. Using the two-sample log-rank test, the OS time following <sup>131</sup>I-MIBG therapy was significantly longer for &lt; 3-year time interval between the initial diagnosis and <sup>131</sup>I-MIBG therapy (p = 0.017), Curie score &lt; 16 just before <sup>131</sup>I-MIBG therapy (p = 0.002), without pain (p = 0.002), without both vanillylmandelic acid (VMA) and homovanillic acid (HVA) elevation (p = 0.037) at <sup>131</sup>I-MIBG therapy, and with CR or PR following <sup>131</sup>I-MIBG therapy (p = 0.015). Although severe hematological toxicities were identified in all 19 patients, severe nonhematological toxicity was not recorded in any patient, except for one patient with grade 3 anorexia and nausea. \n",
      "  Conclusions:  High-dose <sup>131</sup>I-MIBG therapy in patients with refractory or relapsed high-risk NBL can provide a favorable prognosis without severe nonhematological toxicities. Better prognosis may be anticipated in patients with the initial good response, no pain at <sup>131</sup>I-MIBG therapy, no VMA and HVA elevation at <sup>131</sup>I-MIBG therapy, low Curie score (&lt; 16) just before <sup>131</sup>I-MIBG therapy, and short time interval (&lt; 3 years) between the initial diagnosis and <sup>131</sup>I-MIBG therapy. \n",
      "  |  https://dx.doi.org/10.1007/s12149-020-01460-z  |  \n",
      "------------------------------------------- \n",
      "10.1007/s12350-018-1317-5  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background:  Coronary PET shows promise in the detection of high-risk atherosclerosis, but there remains a need to optimize imaging and reconstruction techniques. We investigated the impact of reconstruction parameters and cardiac motion-correction in <sup>18</sup>F Sodium Fluoride (<sup>18</sup>F-NaF) PET. \n",
      "  Methods:  Twenty-two patients underwent <sup>18</sup>F-NaF PET within 22 days of an acute coronary syndrome. Optimal reconstruction parameters were determined in a subgroup of six patients. Motion-correction was performed on ECG-gated data of all patients with optimal reconstruction. Tracer uptake was quantified in culprit and reference lesions by computing signal-to-noise ratio (SNR) in diastolic, summed, and motion-corrected images. \n",
      "  Results:  Reconstruction using 24 subsets, 4 iterations, point-spread-function modelling, time of flight, and 5-mm post-filtering provided the highest median SNR (31.5) compared to 4 iterations 0-mm (22.5), 8 iterations 0-mm (21.1), and 8 iterations 5-mm (25.6; all P &lt; .05). Motion-correction improved SNR of culprit lesions (n = 33) (24.5[19.9-31.5]) compared to diastolic (15.7[12.4-18.1]; P &lt; .001) and summed data (22.1[18.9-29.2]; P &lt; .001). Motion-correction increased the SNR difference between culprit and reference lesions (10.9[6.3-12.6]) compared to diastolic (6.2[3.6-10.3]; P = .001) and summed data (7.1 [4.8-11.6]; P = .001). \n",
      "  Conclusions:  The number of iterations and extent of post-filtering has marked effects on coronary <sup>18</sup>F-NaF PET quantification. Cardiac motion-correction improves discrimination between culprit and reference lesions. \n",
      "  |  https://dx.doi.org/10.1007/s12350-018-1317-5  |  \n",
      "------------------------------------------- \n",
      "10.3322/caac.21608  |  Smart Healthcare, Treatment  |  Treatment, Smart Healthcare  |  Review  |  Review  |   Patient-generated health data (PGHD), or health-related data gathered from patients to help address a health concern, are used increasingly in oncology to make regulatory decisions and evaluate quality of care. PGHD include self-reported health and treatment histories, patient-reported outcomes (PROs), and biometric sensor data. Advances in wireless technology, smartphones, and the Internet of Things have facilitated new ways to collect PGHD during clinic visits and in daily life. The goal of the current review was to provide an overview of the current clinical, regulatory, technological, and analytic landscape as it relates to PGHD in oncology research and care. The review begins with a rationale for PGHD as described by the US Food and Drug Administration, the Institute of Medicine, and other regulatory and scientific organizations. The evidence base for clinic-based and remote symptom monitoring using PGHD is described, with an emphasis on PROs. An overview is presented of current approaches to digital phenotyping or device-based, real-time assessment of biometric, behavioral, self-report, and performance data. Analytic opportunities regarding PGHD are envisioned in the context of big data and artificial intelligence in medicine. Finally, challenges and solutions for the integration of PGHD into clinical care are presented. The challenges include electronic medical record integration of PROs and biometric data, analysis of large and complex biometric data sets, and potential clinic workflow redesign. In addition, there is currently more limited evidence for the use of biometric data relative to PROs. Despite these challenges, the potential benefits of PGHD make them increasingly likely to be integrated into oncology research and clinical care. \n",
      "  |  https://doi.org/10.3322/caac.21608  |  \n",
      "------------------------------------------- \n",
      "10.1192/bjp.2019.127  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background:  Schizophrenia is a complex mental disorder with high heritability and polygenic inheritance. Multimodal neuroimaging studies have also indicated that abnormalities of brain structure and function are a plausible neurobiological characterisation of schizophrenia. However, the polygenic effects of schizophrenia on these imaging endophenotypes have not yet been fully elucidated. \n",
      "  Aims:  To investigate the effects of polygenic risk for schizophrenia on the brain grey matter volume and functional connectivity, which are disrupted in schizophrenia. \n",
      "  Method:  Genomic and neuroimaging data from a large sample of Han Chinese patients with schizophrenia (N = 509) and healthy controls (N = 502) were included in this study. We examined grey matter volume and functional connectivity via structural and functional magnetic resonance imaging, respectively. Using the data from a recent meta-analysis of a genome-wide association study that comprised a large number of Chinese people, we calculated a polygenic risk score (PGRS) for each participant. \n",
      "  Results:  The imaging genetic analysis revealed that the individual PGRS showed a significantly negative correlation with the hippocampal grey matter volume and hippocampus-medial prefrontal cortex functional connectivity, both of which were lower in the people with schizophrenia than in the controls. We also found that the observed neuroimaging measures showed weak but similar changes in unaffected first-degree relatives of patients with schizophrenia. \n",
      "  Conclusions:  These findings suggested that genetically influenced brain grey matter volume and functional connectivity may provide important clues for understanding the pathological mechanisms of schizophrenia and for the early diagnosis of schizophrenia. \n",
      "  |  https://www.cambridge.org/core/product/identifier/S0007125019001272/type/journal_article  |  \n",
      "------------------------------------------- \n",
      "10.1002/humu.23948  |  Other  |  None, Other  |  Research  |  Research  |   Primary microcephaly (PM) is characterized by a small head since birth and is vastly heterogeneous both genetically and phenotypically. While most cases are monogenic, genetic interactions between Aspm and Wdr62 have recently been described in a mouse model of PM. Here, we used two complementary, holistic in vivo approaches: high throughput DNA sequencing of multiple PM genes in human patients with PM, and genome-edited zebrafish modeling for the digenic inheritance of PM. Exomes of patients with PM showed a significant burden of variants in 75 PM genes, that persisted after removing monogenic causes of PM (e.g., biallelic pathogenic variants in CEP152). This observation was replicated in an independent cohort of patients with PM, where a PM gene panel showed in addition that the burden was carried by six centrosomal genes. Allelic frequencies were consistent with digenic inheritance. In zebrafish, non-centrosomal gene casc5 -/- produced a severe PM phenotype, that was not modified by centrosomal genes aspm or wdr62 invalidation. A digenic, quadriallelic PM phenotype was produced by aspm and wdr62. Our observations provide strong evidence for digenic inheritance of human PM, involving centrosomal genes. Absence of genetic interaction between casc5 and aspm or wdr62 further delineates centrosomal and non-centrosomal pathways in PM. \n",
      "  |  https://doi.org/10.1002/humu.23948  |  \n",
      "------------------------------------------- \n",
      "10.1002/adma.201906493  |  Robotics, Smart Healthcare  |  Treatment, Robotics, Smart Healthcare  |  Research  |  Research  |   Development of stimuli-responsive materials with complex practical functions is significant for achieving bioinspired artificial intelligence. It is challenging to fabricate stimuli-responsive hydrogels showing simultaneous changes in fluorescence color, brightness, and shape in response to a single stimulus. Herein, a bilayer hydrogel strategy is designed by utilizing an aggregation-induced emission luminogen, tetra-(4-pyridylphenyl)ethylene (TPE-4Py), to fabricate hydrogels with the above capabilities. Bilayer hydrogel actuators with the ionomer of poly(acrylamide-r-sodium 4-styrenesulfonate) (PAS) as a matrix of both active and passive layers and TPE-4Py as the core function element in the active layer are prepared. At acidic pH, the protonation of TPE-4Py leads to fluorescence color and brightness changes of the actuators and the electrostatic interactions between the protonated TPE-4Py and benzenesulfonate groups of the PAS chains in the active layer cause the actuators to deform. The proposed TPE-4Py/PAS-based bilayer hydrogel actuators with such responsiveness to stimulus provide insights in the design of intelligent systems and are highly attractive material candidates in the fields of 3D/4D printing, soft robots, and smart wearable devices. \n",
      "  |  https://doi.org/10.1002/adma.201906493  |  \n",
      "------------------------------------------- \n",
      "10.3390/ijerph17031093  |  Smart Healthcare  |  Prognosis, Smart Healthcare  |  Research  |  Research  |   <i>Background</i>: The primary care service in Catalonia has operated an asynchronous teleconsulting service between GPs and patients since 2015 (eConsulta), which has generated some 500,000 messages. New developments in big data analysis tools, particularly those involving natural language, can be used to accurately and systematically evaluate the impact of the service. <i>Objective</i>: The study was intended to assess the predictive potential of eConsulta messages through different combinations of vector representation of text and machine learning algorithms and to evaluate their performance. <i>Methodology</i>: Twenty machine learning algorithms (based on five types of algorithms and four text representation techniques) were trained using a sample of 3559 messages (169,102 words) corresponding to 2268 teleconsultations (1.57 messages per teleconsultation) in order to predict the three variables of interest (avoiding the need for a face-to-face visit, increased demand and type of use of the teleconsultation). The performance of the various combinations was measured in terms of precision, sensitivity, F-value and the ROC curve. <i>Results</i>: The best-trained algorithms are generally effective, proving themselves to be more robust when approximating the two binary variables \"avoiding the need of a face-to-face visit\" and \"increased demand\" (precision = 0.98 and 0.97, respectively) rather than the variable \"type of query\" (precision = 0.48). <i>Conclusion</i>: To the best of our knowledge, this study is the first to investigate a machine learning strategy for text classification using primary care teleconsultation datasets. The study illustrates the possible capacities of text analysis using artificial intelligence. The development of a robust text classification tool could be feasible by validating it with more data, making it potentially more useful for decision support for health professionals. \n",
      "  |  http://www.mdpi.com/resolver?pii=ijerph17031093  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32050435/  |  \n",
      "------------------------------------------- \n",
      "10.2196/15510  |  Smart Healthcare, Diagnosis, Prognosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Research  |  Research  |    Background:  Artificial intelligence-enabled electronic health record (EHR) analysis can revolutionize medical practice from the diagnosis and prediction of complex diseases to making recommendations in patient care, especially for chronic conditions such as chronic kidney disease (CKD), which is one of the most frequent complications in patients with diabetes and is associated with substantial morbidity and mortality. \n",
      "  Objective:  The longitudinal prediction of health outcomes requires effective representation of temporal data in the EHR. In this study, we proposed a novel temporal-enhanced gradient boosting machine (GBM) model that dynamically updates and ensembles learners based on new events in patient timelines to improve the prediction accuracy of CKD among patients with diabetes. \n",
      "  Methods:  Using a broad spectrum of deidentified EHR data on a retrospective cohort of 14,039 adult patients with type 2 diabetes and GBM as the base learner, we validated our proposed Landmark-Boosting model against three state-of-the-art temporal models for rolling predictions of 1-year CKD risk. \n",
      "  Results:  The proposed model uniformly outperformed other models, achieving an area under receiver operating curve of 0.83 (95% CI 0.76-0.85), 0.78 (95% CI 0.75-0.82), and 0.82 (95% CI 0.78-0.86) in predicting CKD risk with automatic accumulation of new data in later years (years 2, 3, and 4 since diabetes mellitus onset, respectively). The Landmark-Boosting model also maintained the best calibration across moderate- and high-risk groups and over time. The experimental results demonstrated that the proposed temporal model can not only accurately predict 1-year CKD risk but also improve performance over time with additionally accumulated data, which is essential for clinical use to improve renal management of patients with diabetes. \n",
      "  Conclusions:  Incorporation of temporal information in EHR data can significantly improve predictive model performance and will particularly benefit patients who follow-up with their physicians as recommended. \n",
      "  |  https://medinform.jmir.org/2020/1/e15510/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32012067/  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41598-020-62676-7  |  None  |  None, Other  |  Research  |  Research  |   Generative Adversarial Network (GAN) requires extensive computing resources making its implementation in edge devices with conventional microprocessor hardware a slow and difficult, if not impossible task. In this paper, we propose to accelerate these intensive neural computations using memristive neural networks in analog domain. The implementation of Analog Memristive Deep Convolutional GAN (AM-DCGAN) using Generator as deconvolutional and Discriminator as convolutional memristive neural network is presented. The system is simulated at circuit level with 1.7 million memristor devices taking into account memristor non-idealities, device and circuit parameters. The design is modular with crossbar arrays having a minimum average power consumption per neural computation of 47nW. The design exclusively uses the principles of neural network dropouts resulting in regularization and lowering the power consumption. The SPICE level simulation of GAN is performed with 0.18 μm CMOS technology and WO<sub>x</sub> memristive devices with R<sub>ON</sub> = 40 kΩ and R<sub>OFF</sub> = 250 kΩ, threshold voltage 0.8 V and write voltage at 1.0 V. \n",
      "  |  http://dx.doi.org/10.1038/s41598-020-62676-7  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32246103/  |  \n",
      "------------------------------------------- \n",
      "10.1098/rsta.2019.0163  |  None  |  None, Other  |  Research  |  Research  |   This paper presents the design of an ultra-low energy neural network that uses time-mode signal processing). Handwritten digit classification using a single-layer artificial neural network (ANN) with a Softmin-based activation function is described as an implementation example. To realize time-mode operation, the presented design makes use of monostable multivibrator-based multiplying analogue-to-time converters, fixed-width pulse generators and basic digital gates. The time-mode digit classification ANN was designed in a standard CMOS 0.18 μm IC process and operates from a supply voltage of 0.6 V. The system operates on the MNIST database of handwritten digits with quantized neuron weights and has a classification accuracy of 88%, which is typical for single-layer ANNs, while dissipating 65.74 pJ per classification with a speed of 2.37 k classifications per second. This article is part of the theme issue 'Harmonizing energy-autonomous computing and intelligence'. \n",
      "  |  https://royalsocietypublishing.org/doi/full/10.1098/rsta.2019.0163?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.1002/hbm.24968  |  Other  |  None, Other  |  Research  |  Research  |   There is an ongoing debate about whether, and to what extent, males differ from females in their language skills. In the case of handwriting, a composite language skill involving language and motor processes, behavioral observations consistently show robust sex differences but the mechanisms underlying the effect are unclear. Using functional magnetic resonance imaging (fMRI) in a copying task, the present study examined the neural basis of sex differences in handwriting in 53 healthy adults (ages 19-28, 27 males). Compared to females, males showed increased activation in the left posterior middle frontal gyrus (Exner's area), a region thought to support the conversion between orthographic and graphomotor codes. Functional connectivity between Exner's area and the right cerebellum was greater in males than in females. Furthermore, sex differences in brain activity related to handwriting were independent of language material. This study identifies a novel neural signature of sex differences in a hallmark of human behavior, and highlights the importance of considering sex as a factor in scientific research and clinical applications involving handwriting. \n",
      "  |  https://doi.org/10.1002/hbm.24968  |  \n",
      "------------------------------------------- \n",
      "10.1136/gutjnl-2019-318860  |  Diagnosis, Prognosis  |  Diagnosis, Prognosis, Treatment  |  Research  |  Research  |    Objective:  Pancreatic ductal adenocarcinoma (PDAC) is difficult to diagnose at resectable stage. Recent studies have suggested that extracellular vesicles (EVs) contain long RNAs. The aim of this study was to develop a diagnostic (d-)signature for the detection of PDAC based on EV long RNA (exLR) profiling. \n",
      "  Design:  We conducted a case-control study with 501 participants, including 284 patients with PDAC, 100 patients with chronic pancreatitis (CP) and 117 healthy subjects. The exLR profile of plasma samples was analysed by exLR sequencing. The d-signature was identified using a support vector machine algorithm and a training cohort (n=188) and was validated using an internal validation cohort (n=135) and an external validation cohort (n=178). \n",
      "  Results:  We developed a d-signature that comprised eight exLRs, including FGA, KRT19, HIST1H2BK, ITIH2, MARCH2, CLDN1, MAL2 and TIMP1, for PDAC detection. The d-signature showed high accuracy, with an area under the receiver operating characteristic curve (AUC) of 0.960, 0.950 and 0.936 in the training, internal validation and external validation cohort, respectively. The d-signature was able to identify resectable stage I/II cancer with an AUC of 0.949 in the combined three cohorts. In addition, the d-signature showed superior performance to carbohydrate antigen 19-9 in distinguishing PDAC from CP (AUC 0.931 vs 0.873, p=0.028). \n",
      "  Conclusion:  This study is the first to characterise the plasma exLR profile in PDAC and to report an exLR signature for the detection of pancreatic cancer. This signature may improve the prognosis of patients who would have otherwise missed the curative treatment window. \n",
      "  |  http://gut.bmj.com/cgi/pmidlookup?view=long&pmid=31562239  |  \n",
      "------------------------------------------- \n",
      "10.1007/s11571-019-09560-x  |  Robotics, Treatment  |  Treatment, Robotics  |  Research  |  Research  |   Motor imagery (MI) is a mental representation of motor behavior and has been widely used in electroencephalogram based brain-computer interfaces (BCIs). Several studies have demonstrated the efficacy of MI-based BCI-feedback training in post-stroke rehabilitation. However, in the earliest stage of the training, calibration data typically contain insufficient discriminability, resulting in unreliable feedback, which may decrease subjects' motivation and even hinder their training. To improve the performance in the early stages of MI training, a novel hybrid BCI paradigm based on MI and P300 is proposed in this study. In this paradigm, subjects are instructed to imagine writing the Chinese character following the flash order of the desired Chinese character displayed on the screen. The event-related desynchronization/synchronization (ERD/ERS) phenomenon is produced with writing based on one's imagination. Simultaneously, the P300 potential is evoked by the flash of each stroke. Moreover, a fusion method of P300 and MI classification is proposed, in which unreliable P300 classifications are corrected by reliable MI classifications. Twelve healthy naïve MI subjects participated in this study. Results demonstrated that the proposed hybrid BCI paradigm yielded significantly better performance than the single-modality BCI paradigm. The recognition accuracy of the fusion method is significantly higher than that of P300 (<i>p</i> &lt; 0.05) and MI (<i>p</i> &lt; 0.01). Moreover, the training data size can be reduced through fusion of these two modalities. \n",
      "  |  https://dx.doi.org/10.1007/s11571-019-09560-x  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.ijporl.2019.109833  |  Diagnosis, Treatment, Drug Discovery  |  Diagnosis, Drug Discovery, Treatment  |  Review  |  Review  |    Objective:  To summarize recently published key articles on the topics of biomedical engineering, biotechnology and new models in relation to otitis media (OM). \n",
      "  Data sources:  Electronic databases: PubMed, Ovid Medline, Cochrane Library and Clinical Evidence (BMJ Publishing). \n",
      "  Review methods:  Articles on biomedical engineering, biotechnology, material science, mechanical and animal models in OM published between May 2015 and May 2019 were identified and subjected to review. A total of 132 articles were ultimately included. \n",
      "  Results:  New imaging technologies for the tympanic membrane (TM) and the middle ear cavity are being developed to assess TM thickness, identify biofilms and differentiate types of middle ear effusions. Artificial intelligence (AI) has been applied to train software programs to diagnose OM with a high degree of certainty. Genetically modified mice models for OM have further investigated what predisposes some individuals to OM and consequent hearing loss. New vaccine candidates protecting against major otopathogens are being explored and developed, especially combined vaccines, targeting more than one pathogen. Transcutaneous vaccination against non-typeable Haemophilus influenzae has been successfully tried in a chinchilla model. In terms of treatment, novel technologies for trans-tympanic drug delivery are entering the clinical domain. Various growth factors and grafting materials aimed at improving healing of TM perforations show promising results in animal models. \n",
      "  Conclusion:  New technologies and AI applications to improve the diagnosis of OM have shown promise in pre-clinical models and are gradually entering the clinical domain. So are novel vaccines and drug delivery approaches that may allow local treatment of OM. \n",
      "  Implications for practice:  New diagnostic methods, potential vaccine candidates and the novel trans-tympanic drug delivery show promising results, but are not yet adapted to clinical use. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0165-5876(19)30586-5  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.msard.2020.102034  |  Robotics, Treatment  |  Treatment, Robotics  |  Review  |  Review  |    Background:  Multiple sclerosis is a progressive disease responsible for gait disabilities and cognitive impairment, which affect functional performance. Robot-assisted gait training is an emerging training method to facilitate body-weight-supported treadmill training in many neurologic diseases. Through this study, we aimed to determine the efficacy of robot-assisted gait training in patients with multiple sclerosis. \n",
      "  Methods:  We performed a systematic review and meta-analysis of randomized controlled trials evaluating the effect of robot-assisted gait training for multiple sclerosis. We searched PubMed, EMBASE, the Cochrane Library, and ClinicalTrials.gov registry for articles published before May 2019. The primary outcome was walking performance (gait parameters, balance, and ambulation capability). The secondary outcomes were changes in perceived fatigue, severity of spasticity, global mobility, physical and mental quality of life, severity of pain, activities of daily living, and treatment acceptance. \n",
      "  Results:  We identified 10 studies (9 different trials) that included patients with multiple sclerosis undergoing robot-assisted gait training or conventional walk training. The meta-analysis showed comparable effectiveness between robot-assisted gait training and conventional walking therapy in walking performance, quality of life, pain, or activities of daily living. The robot-assisted gait training was even statistically superior to conventional walking therapy in improving perceived fatigue (pooled SMD: 0.34, 95% CI: 0.02-0.67), spasticity (pooled SMD: 0.70, 95% CI: 0.08-1.33, I² = 53%), and global mobility (borderline) after the intervention. \n",
      "  Conclusion:  Our results provide the most up-to-date evidence regarding the robot-assisted gait training on multiple sclerosis. In addition to the safety and good tolerance, its efficacy on multiple sclerosis is comparable to that of conventional walking training and is even superior in improving fatigue and spasticity. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S2211-0348(20)30110-3  |  \n",
      "------------------------------------------- \n",
      "10.1001/jamanetworkopen.2020.0255  |  Smart Healthcare, Treatment  |  Treatment, Smart Healthcare  |  Research  |  Research  |    Importance:  Mobile applications (apps) may help improve hypertension self-management. \n",
      "  Objective:  To investigate the effect of an artificial intelligence smartphone coaching app to promote home monitoring and hypertension-related behaviors on systolic blood pressure level compared with a blood pressure tracking app. \n",
      "  Design, setting, and participants:  This was a 2-group, open, randomized clinical trial. Participants with uncontrolled hypertension were recruited in 2016 and 2017 and were followed up for 6 months. Data analysis was performed from April 2019 to December 2019. \n",
      "  Interventions:  Intervention group participants received a smartphone coaching app to promote home monitoring and behavioral changes associated with hypertension self-management plus a home blood pressure monitor. Control participants received a blood pressure tracking app plus a home blood pressure monitor. \n",
      "  Main outcomes and measures:  The primary study outcome was systolic blood pressure at 6 months. Secondary outcomes included self-reported antihypertensive medication adherence, home monitoring and self-management practices, measures of self-efficacy associated with blood pressure, weight, and self-reported health behaviors. \n",
      "  Results:  There were 333 participants randomized, and 297 completed the follow-up assessment. Among the participants who completed the study, the mean (SD) age was 58.9 (12.8) years, 182 (61.3%) were women, and 103 (34.7%) were black. Baseline mean (SD) systolic blood pressure was 140.6 (12.2) mm Hg among intervention participants and 141.8 (13.4) mm Hg among control participants. After 6 months, the corresponding mean (SD) systolic blood pressures were 132.3 (15.0) mm Hg and 135.0 (13.9) mm Hg, with a between-group adjusted difference of -2.0 mm Hg (95% CI, -4.9 mm Hg to 0.8 mm Hg; P = .16). At 6 months, self-confidence in controlling blood pressure was greater in the intervention group (0.36 point on a 5-point scale; 95% CI, 0.18 point to 0.54 point; P &lt; .001). There were no significant differences between the 2 groups in other secondary outcomes. The adjusted difference in self-reported physical activity was 26.7 minutes per week (95% CI, -5.4 minutes per week to 58.8 minutes per week; P = .10). Subgroup analysis raised the possibility that intervention effects differed by age. \n",
      "  Conclusions and relevance:  Among individuals with uncontrolled hypertension, those randomized to a smartphone coaching app plus home monitor had similar systolic blood pressure compared with those who received a blood pressure tracking app plus home monitor. Given the direction of the difference in systolic blood pressure between groups and the possibility for differences in treatment effects across subgroups, future studies are warranted. \n",
      "  Trial registration:  ClinicalTrials.gov Identifier: <a href=\"http://clinicaltrials.gov/show/NCT03288142\" title=\"See in ClinicalTrials.gov\">NCT03288142</a>. \n",
      "  |  https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2020.0255  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32119093/  |  \n",
      "------------------------------------------- \n",
      "10.1212/WNL.0000000000009068  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Objective:  Genetic diagnosis of muscular dystrophies (MDs) has classically been guided by clinical presentation, muscle biopsy, and muscle MRI data. Muscle MRI suggests diagnosis based on the pattern of muscle fatty replacement. However, patterns overlap between different disorders and knowledge about disease-specific patterns is limited. Our aim was to develop a software-based tool that can recognize muscle MRI patterns and thus aid diagnosis of MDs. \n",
      "  Methods:  We collected 976 pelvic and lower limbs T1-weighted muscle MRIs from 10 different MDs. Fatty replacement was quantified using Mercuri score and files containing the numeric data were generated. Random forest supervised machine learning was applied to develop a model useful to identify the correct diagnosis. Two thousand different models were generated and the one with highest accuracy was selected. A new set of 20 MRIs was used to test the accuracy of the model, and the results were compared with diagnoses proposed by 4 specialists in the field. \n",
      "  Results:  A total of 976 lower limbs MRIs from 10 different MDs were used. The best model obtained had 95.7% accuracy, with 92.1% sensitivity and 99.4% specificity. When compared with experts on the field, the diagnostic accuracy of the model generated was significantly higher in a new set of 20 MRIs. \n",
      "  Conclusion:  Machine learning can help doctors in the diagnosis of muscle dystrophies by analyzing patterns of muscle fatty replacement in muscle MRI. This tool can be helpful in daily clinics and in the interpretation of the results of next-generation sequencing tests. \n",
      "  Classification of evidence:  This study provides Class II evidence that a muscle MRI-based artificial intelligence tool accurately diagnoses muscular dystrophies. \n",
      "  |  http://www.neurology.org/cgi/pmidlookup?view=long&pmid=32029545  |  \n",
      "------------------------------------------- \n",
      "10.3390/v12030268  |  Epidemiology, Drug Discovery  |  Drug Discovery, Epidemiology  |  Research  |  Research  |   Migration is associated with HIV-1 vulnerability. \n",
      "  Objectives:  To identify long-term trends in HIV-1 molecular epidemiology and antiretroviral drug resistance (ARV) among migrants followed up in Portugal Methods: 5177 patients were included between 2001 and 2017. Rega, Scuel, Comet, and jPHMM algorithms were used for subtyping. Transmitted drug resistance (TDR) and Acquired drug resistance (ADR) were defined as the presence of surveillance drug resistance mutations (SDRMs) and as mutations of the IAS-USA 2015 algorithm, respectively. Statistical analyses were performed. \n",
      "  Results:  HIV-1 subtypes infecting migrants were consistent with the ones prevailing in their countries of origin. Over time, overall TDR significantly increased and specifically for Non-nucleoside reverse transcriptase inhibitor (NNRTIs) and Nucleoside reverse transcriptase inhibitor (NRTIs). TDR was higher in patients from Mozambique. Country of origin Mozambique and subtype B were independently associated with TDR. Overall, ADR significantly decreased over time and specifically for NRTIs and Protease Inhibitors (PIs). Age, subtype B, and viral load were independently associated with ADR. \n",
      "  Conclusions:  HIV-1 molecular epidemiology in migrants suggests high levels of connectivity with their country of origin. The increasing levels of TDR in migrants could indicate an increase also in their countries of origin, where more efficient surveillance should occur. \n",
      "  |  http://www.mdpi.com/resolver?pii=v12030268  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32121161/  |  \n",
      "------------------------------------------- \n",
      "10.1089/omi.2019.0220  |  Treatment, Diagnosis  |  Diagnosis, Treatment  |  Research  |  Research  |   Precision/personalized medicine is a hot topic in health care. Often presented with the motto \"the right drug, for the right patient, at the right dose, and the right time,\" precision medicine is a theory for rational therapeutics as well as practice to individualize health interventions (e.g., drugs, food, vaccines, medical devices, and exercise programs) using biomarkers. Yet, an alien visitor to planet Earth reading the contemporary textbooks on diagnostics might think precision medicine requires only two biomolecules omnipresent in the literature: nucleic acids (e.g., DNA) and proteins, known as the first and second alphabet of biology, respectively. However, the precision/personalized medicine community has tended to underappreciate the third alphabet of life, the \"sugar code\" (i.e., the information stored in glycans, glycoproteins, and glycolipids). This article brings together experts in precision/personalized medicine science, pharmacoglycomics, emerging technology governance, cultural studies, contemporary art, and responsible innovation to critically comment on the sociomateriality of the three alphabets of life together. First, the current transformation of targeted therapies with personalized glycomedicine and glycan biomarkers is examined. Next, we discuss the reasons as to why unraveling of the sugar code might have lagged behind the DNA and protein codes. While social scientists have historically noted the importance of constructivism (e.g., how people interpret technology and build their values, hopes, and expectations into emerging technologies), life scientists relied on the material properties of technologies in explaining why some innovations emerge rapidly and are more popular than others. The concept of sociomateriality integrates these two explanations by highlighting the inherent entanglement of the social and the material contributions to knowledge and what is presented to us as reality from everyday laboratory life. Hence, we present a hypothesis based on a sociomaterial conceptual lens: because materiality and synthesis of glycans are not directly driven by a template, and thus more complex and open ended than sequencing of a finite length genome, social construction of expectations from unraveling of the sugar code versus the DNA code might have evolved differently, as being future-uncertain versus future-proof, respectively, thus potentially explaining the \"sugar lag\" in precision/personalized medicine diagnostics over the past decades. We conclude by introducing systems scientists, physicians, and biotechnology industry to the concept, practice, and value of responsible innovation, while glycomedicine and other emerging biomarker technologies (e.g., metagenomics and pharmacomicrobiomics) transition to applications in health care, ecology, pharmaceutical/diagnostic industries, agriculture, food, and bioengineering, among others. \n",
      "  |  https://www.liebertpub.com/doi/full/10.1089/omi.2019.0220?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.annonc.2020.04.003  |  Diagnosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Research  |  Research  |    Background:  Preoperative evaluation of the number of lymph node metastasis (LNM) is the basis of individual treatment of locally advanced gastric cancer (LAGC). However, the routinely used preoperative determination method is not accurate enough. \n",
      "  Patients and methods:  We enrolled 730 LAGC patients from 5 centers in China and 1 center in Italy, and divided them into 1 primary cohort, 3 external validation cohorts, and 1 international validation cohort. A deep learning radiomic nomogram (DLRN) was built based on the images from multi-phase computed tomography (CT) for preoperatively determining the number of LNM in LAGC. We comprehensively tested the DLRN and compared it with three state-of-the-art methods. Moreover, we investigated the value of the DLRN in survival analysis. \n",
      "  Results:  The DLRN showed good discrimination of the number of LNM on all cohorts (overall C-indexes: 0.821, 95% CI: 0.785-0.858 in the primary cohort; 0.797, 95% CI: 0.771-0.823 in the external validation cohorts; and 0.822, 95% CI: 0.756-0.887 in the international validation cohort). The nomogram performed significantly better than the routinely used clinical N stages, tumor size, and clinical model (p&lt;0.05). Besides, DLRN is significantly associated with the overall survival of LAGC patients (n=271). \n",
      "  Conclusion:  A deep learning-based radiomic nomogram had good predictive value for LNM in LAGC. In staging-oriented treatment of gastric cancer, this preoperative nomogram could provide baseline information for individual treatment of LAGC. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0923-7534(20)39294-2  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41598-019-56881-2  |  Other  |  None, Other  |  Research  |  Research  |   The exposure of germ cells to radiation introduces mutations in the genomes of offspring, and a previous whole-genome sequencing study indicated that the irradiation of mouse sperm induces insertions/deletions (indels) and multisite mutations (clustered single nucleotide variants and indels). However, the current knowledge on the mutation spectra is limited, and the effects of radiation exposure on germ cells at stages other than the sperm stage remain unknown. Here, we performed whole-genome sequencing experiments to investigate the exposure of spermatogonia and mature oocytes. We compared de novo mutations in a total of 24 F1 mice conceived before and after the irradiation of their parents. The results indicated that radiation exposure, 4 Gy of gamma rays, induced 9.6 indels and 2.5 multisite mutations in spermatogonia and 4.7 indels and 3.1 multisite mutations in mature oocytes in the autosomal regions of each F1 individual. Notably, we found two types of deletions, namely, small deletions (mainly 1~12 nucleotides) in non-repeat sequences, many of which showed microhomology at the breakpoint junction, and single-nucleotide deletions in mononucleotide repeat sequences. The results suggest that these deletions and multisite mutations could be a typical signature of mutations induced by parental irradiation in mammals. \n",
      "  |  http://dx.doi.org/10.1038/s41598-019-56881-2  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31913321/  |  \n",
      "------------------------------------------- \n",
      "10.1371/journal.pone.0229819  |  Treatment, Diagnosis  |  Diagnosis, Treatment  |  Research  |  Research  |   This large, retrospective case-control study of electronic health records from 56 million unique adult patients examined whether or not treatment with a Tumor Necrosis Factor (TNF) blocking agent is associated with lower risk for Alzheimer's disease (AD) in patients with rheumatoid arthritis (RA), psoriasis, and other inflammatory diseases which are mediated in part by TNF and for which a TNF blocker is an approved treatment. The analysis compared the diagnosis of AD as an outcome measure in patients receiving at least one prescription for a TNF blocking agent (etanercept, adalimumab, and infliximab) or for methotrexate. Adjusted odds ratios (AORs) were estimated using the Cochran-Mantel-Haenszel (CMH) method and presented with 95% confidence intervals (CIs) and p-values. RA was associated with a higher risk for AD (Adjusted Odds Ratio (AOR) = 2.06, 95% Confidence Interval: (2.02-2.10), P-value &lt;0.0001) as did psoriasis (AOR = 1.37 (1.31-1.42), P &lt;0.0001), ankylosing spondylitis (AOR = 1.57 (1.39-1.77), P &lt;0.0001), inflammatory bowel disease (AOR = 2.46 (2.33-2.59), P &lt; 0.0001), ulcerative colitis (AOR = 1.82 (1.74-1.91), P &lt;0.0001), and Crohn's disease (AOR = 2.33 (2.22-2.43), P &lt;0.0001). The risk for AD in patients with RA was lower among patients treated with etanercept (AOR = 0.34 (0.25-0.47), P &lt;0.0001), adalimumab (AOR = 0.28 (0.19-0.39), P &lt; 0.0001), or infliximab (AOR = 0.52 (0.39-0.69), P &lt;0.0001). Methotrexate was also associated with a lower risk for AD (AOR = 0.64 (0.61-0.68), P &lt;0.0001), while lower risk was found in patients with a prescription history for both a TNF blocker and methotrexate. Etanercept and adalimumab also were associated with lower risk for AD in patients with psoriasis: AOR = 0.47 (0.30-0.73 and 0.41 (0.20-0.76), respectively. There was no effect of gender or race, while younger patients showed greater benefit from a TNF blocker than did older patients. This study identifies a subset of patients in whom systemic inflammation contributes to risk for AD through a pathological mechanism involving TNF and who therefore may benefit from treatment with a TNF blocking agent. \n",
      "  |  http://dx.plos.org/10.1371/journal.pone.0229819  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32203525/  |  \n",
      "------------------------------------------- \n",
      "10.1007/s00330-020-06699-8  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Objectives:  To take advantage of the deep learning algorithms to detect and calculate clot burden of acute pulmonary embolism (APE) on computed tomographic pulmonary angiography (CTPA). \n",
      "  Materials and methods:  The training set in this retrospective study consisted of 590 patients (460 with APE and 130 without APE) who underwent CTPA. A fully deep learning convolutional neural network (DL-CNN), called U-Net, was trained for the segmentation of clot. Additionally, an in-house validation set consisted of 288 patients (186 with APE and 102 without APE). In this study, we set different probability thresholds to test the performance of U-Net for the clot detection and selected sensitivity, specificity, and area under the curve (AUC) as the metrics of performance evaluation. Furthermore, we investigated the relationship between the clot burden assessed by the Qanadli score, Mastora score, and other imaging parameters on CTPA and the clot burden calculated by the DL-CNN model. \n",
      "  Results:  There was no statistically significant difference in AUCs with the different probability thresholds. When the probability threshold for segmentation was 0.1, the sensitivity and specificity of U-Net in detecting clot respectively were 94.6% and 76.5% while the AUC was 0.926 (95% CI 0.884-0.968). Moreover, this study displayed that the clot burden measured with U-Net was significantly correlated with the Qanadli score (r = 0.819, p &lt; 0.001), Mastora score (r = 0.874, p &lt; 0.001), and right ventricular functional parameters on CTPA. \n",
      "  Conclusions:  DL-CNN achieved a high AUC for the detection of pulmonary emboli and can be applied to quantitatively calculate the clot burden of APE patients, which may contribute to reducing the workloads of clinicians. \n",
      "  Key points:  • Deep learning can detect APE with a good performance and efficiently calculate the clot burden to reduce the physicians' workload. • Clot burden measured with deep learning highly correlates with Qanadli and Mastora scores of CTPA. • Clot burden measured with deep learning correlates with parameters of right ventricular function on CTPA. \n",
      "  |  https://dx.doi.org/10.1007/s00330-020-06699-8  |  \n",
      "------------------------------------------- \n",
      "10.3390/s20082376  |  Robotics, Smart Healthcare  |  Robotics, Smart Healthcare  |  Research  |  Research  |   This paper presents a more detailed concept of Human-Robot Interaction systems architecture. One of the main differences between the proposed architecture and other ones is the methodology of information acquisition regarding the robot's interlocutor. In order to obtain as much information as possible before the actual interaction took place, a custom Internet-of-Things-based sensor subsystems connected to Smart Infrastructure was designed and implemented, in order to support the interlocutor identification and acquisition of initial interaction parameters. The Artificial Intelligence interaction framework of the developed robotic system (including humanoid Pepper with its sensors and actuators, additional local, remote and cloud computing services) is being extended with the use of custom external subsystems for additional knowledge acquisition: device-based human identification, visual identification and audio-based interlocutor localization subsystems. These subsystems were deeply introduced and evaluated in this paper, presenting the benefits of integrating them into the robotic interaction system. In this paper a more detailed analysis of one of the external subsystems-Bluetooth Human Identification Smart Subsystem-was also included. The idea, use case, and a prototype, integration of elements of Smart Infrastructure systems and the prototype implementation were performed in a small front office of the Weegree company as a decent test-bed application area. \n",
      "  |  http://www.mdpi.com/resolver?pii=s20082376  |  \n",
      "------------------------------------------- \n",
      "10.1007/s11571-019-09541-0  |  Treatment, Robotics  |  Treatment, Robotics  |  Research  |  Research  |   Many studies reported that ERP-based BCIs can provide communication for some people with amyotrophic lateral sclerosis (ALS). ERP-based BCIs often present characters within a matrix that occupies the center of the visual field. However, several studies have identified some concerns with the matrix-based approach. This approach may lead to fatigue and errors resulting from flashing adjacent stimuli, and is impractical for users who might want to use the BCI in tandem with other software or feedback in the center of the monitor. In this paper, we introduce and validate an alternate ERP-based BCI display approach. By presenting stimuli near the periphery of the display, we reduce the adjacency problem and leave the center of the display available for feedback or other applications. Two ERP-based display approaches were tested on 18 ALS patients to: (1) compare performance between a conventional matrix speller paradigm (Matrix-P, mean visual angle 6°) and a new speller paradigm with peripherally distributed stimuli (Peripheral-P, mean visual angle 8.8°); and (2) assess performance while spelling 42 characters online continuously, without a break. In the Peripheral-P condition, 12 subjects attained higher than 80% feedback accuracy during online performance, and 7 of these subjects obtained higher than 90% accuracy. The experimental results showed that the Peripheral-P condition yielded performance comparable to the conventional Matrix-P condition (<i>p </i>&gt; 0.05) in accuracy and information transfer rate. This paper introduces a new display approach that leaves the center of the monitor open for feedback and/or other display elements, such as movies, games, art, or displays from other AAC software or conventional software tools. \n",
      "  |  https://dx.doi.org/10.1007/s11571-019-09541-0  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41467-020-14695-1  |  Other  |  Prognosis  |  Research  |  Research  |   One key aspect of domain-general thought is the ability to integrate information across different cognitive domains. Here, we tested whether kea (Nestor notabilis) can use relative quantities when predicting sampling outcomes, and then integrate both physical information about the presence of a barrier, and social information about the biased sampling of an experimenter, into their predictions. Our results show that kea exhibit three signatures of statistical inference, and therefore can integrate knowledge across different cognitive domains to flexibly adjust their predictions of sampling events. This result provides evidence that true statistical inference is found outside of the great apes, and that aspects of domain-general thinking can convergently evolve in brains with a highly different structure from primates. This has important implications not only for our understanding of how intelligence evolves, but also for research focused on how to create artificial domain-general thought processes. \n",
      "  |  http://dx.doi.org/10.1038/s41467-020-14695-1  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32127523/  |  \n",
      "------------------------------------------- \n",
      "10.3390/cancers12020379  |  Treatment  |  Prognosis, Treatment  |  Research  |  Research  |   Colorectal cancer treatment has advanced over the past decade. The drug 5-fluorouracil is still used with a wide percentage of patients who do not respond. Therefore, a challenge is the identification of predictive biomarkers. The protein kinase R (PKR also called EIF2AK2) and its regulator, the non-coding pre-mir-nc886, have multiple effects on cells in response to numerous types of stress, including chemotherapy. In this work, we performed an ambispective study with 197 metastatic colon cancer patients with unresectable metastases to determine the relative expression levels of both nc886 and PKR by qPCR, as well as the location of PKR by immunohistochemistry in tumour samples and healthy tissues (plasma and colon epithelium). As primary end point, the expression levels were related to the objective response to first-line chemotherapy following the response evaluation criteria in solid tumours (RECIST) and, as the second end point, with survival at 18 and 36 months. Hierarchical agglomerative clustering was performed to accommodate the heterogeneity and complexity of oncological patients' data. High expression levels of nc886 were related to the response to treatment and allowed to identify clusters of patients. Although the PKR mRNA expression was not associated with chemotherapy response, the absence of PKR location in the nucleolus was correlated with first-line chemotherapy response. Moreover, a relationship between survival and the expression of both PKR and nc886 in healthy tissues was found. Therefore, this work evaluated the best way to analyse the potential biomarkers PKR and nc886 in order to establish clusters of patients depending on the cancer outcomes using algorithms for complex and heterogeneous data. \n",
      "  |  http://www.mdpi.com/resolver?pii=cancers12020379  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32045987/  |  \n",
      "------------------------------------------- \n",
      "10.1002/jcla.23054  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background:  Centronuclear myopathy (CNM), a subtype of congenital myopathy (CM), is a group of clinical and genetically heterogeneous muscle disorders. Centronuclear myopathy is a kind of disease difficult to diagnose due to its genetic diversity. Since the discovery of the SPEG gene and disease-causing variants, only a few additional patients have been reported. \n",
      "  Methods:  A radiograph test, ultrasonic test, and biochemical tests were applied to clinical diagnosis of CNM. We performed trio medical exome sequencing of the family and conservation analysis to identify variants. \n",
      "  Results:  We report a pair of severe CNM twins with the same novel homozygous SPEG variant c. 8710A&gt;G (p.Thr2904Ala) identified by clinical trio medical exome sequencing of the family and conservation analysis. The twins showed clinical symptoms of facial weakness, hypotonia, arthrogryposis, strephenopodia, patent ductus arteriosus, and pulmonary arterial hypertension. \n",
      "  Conclusions:  Our report expands the clinical and molecular repertoire of CNM and enriches the variant spectrum of the SPEG gene in the Chinese population and helps us further understand the pathogenesis of CNM. \n",
      "  |  https://doi.org/10.1002/jcla.23054  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31625632/  |  \n",
      "------------------------------------------- \n",
      "10.3390/nano10040708  |  Prognosis, Drug Discovery  |  Prognosis, Drug Discovery  |  Review  |  Review  |   Transcriptomics data are relevant to address a number of challenges in Toxicogenomics (TGx). After careful planning of exposure conditions and data preprocessing, the TGx data can be used in predictive toxicology, where more advanced modelling techniques are applied. The large volume of molecular profiles produced by omics-based technologies allows the development and application of artificial intelligence (AI) methods in TGx. Indeed, the publicly available omics datasets are constantly increasing together with a plethora of different methods that are made available to facilitate their analysis, interpretation and the generation of accurate and stable predictive models. In this review, we present the state-of-the-art of data modelling applied to transcriptomics data in TGx. We show how the benchmark dose (BMD) analysis can be applied to TGx data. We review read across and adverse outcome pathways (AOP) modelling methodologies. We discuss how network-based approaches can be successfully employed to clarify the mechanism of action (MOA) or specific biomarkers of exposure. We also describe the main AI methodologies applied to TGx data to create predictive classification and regression models and we address current challenges. Finally, we present a short description of deep learning (DL) and data integration methodologies applied in these contexts. Modelling of TGx data represents a valuable tool for more accurate chemical safety assessment. This review is the third part of a three-article series on Transcriptomics in Toxicogenomics. \n",
      "  |  http://www.mdpi.com/resolver?pii=nano10040708  |  \n",
      "-------------------------------------------\n",
      "10.3390/s20030885  |  None  |  Diagnosis, Prognosis  |  Research  |  Research  |   The prevalence of micro-holes is widespread in mechanical, electronic, optical, ornaments, micro-fluidic devices, etc. However, monitoring and detection tool wear and tool breakage are imperative to achieve improved hole quality and high productivity in micro-drilling. The various multi-sensor signals are used to monitor the condition of the tool. In this work, the vibration signals and cutting force signals have been applied individually as well as in combination to determine their effectiveness for tool-condition monitoring applications. Moreover, they have been used to determine the best strategies for tool-condition monitoring by prediction of hole quality during micro-drilling operations with 0.4 mm micro-drills. Furthermore, this work also developed an adaptive neuro fuzzy inference system (ANFIS) model using different time domains and wavelet packet features of these sensor signals for the prediction of the hole quality. The best prediction of hole quality was obtained by a combination of different sensor features in wavelet domain of vibration signal. The model's predicted results were found to exert a good agreement with the experimental results. \n",
      "  |  http://www.mdpi.com/resolver?pii=s20030885  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32046037/  |  \n",
      "------------------------------------------- \n",
      "10.1016/bs.apcsb.2019.11.013  |  Drug Discovery  |  Drug Discovery  |  Review  |  Review  |   In the era of big data, the interplay of artificial and human intelligence is the demanding job to address the concerns involving exchange of decisions between both sides. Drug discovery is one of the key sources of the big data, which involves synergy among various computational methods to achieve a clinical success. Rightful acquisition, mining and analysis of the data related to ligand and targets are crucial to accomplish reliable outcomes in the entire process. Novel designing and screening tactics are necessary to substantiate a potent and efficient lead compounds. Such methods are emphasized and portrayed in the current review targeting protein-ligand and protein-protein interactions involved in various diseases with potential applications. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1876-1623(19)30094-X  |  \n",
      "------------------------------------------- \n",
      "10.1111/ejn.14724  |  Other  |  None, Other  |  Research  |  Research  |   Astrocytes are key players in the regulation of brain development and function. They sense and respond to the surrounding activity by elevating their intracellular calcium (Ca<sup>2+</sup> ) levels. These astrocytic Ca<sup>2+</sup> elevations emerge from different sources and display complex spatio-temporal properties. Ca<sup>2+</sup> elevations are spatially distributed in global (soma and main processes) and/or focal regions (microdomains). The inositol 1,4,5-trisphosphate receptor type 2 knockout (IP<sub>3</sub> R2 KO) mouse model lacks global Ca<sup>2+</sup> elevations in astrocytes, and it has been used by different laboratories. However, the constitutive deletion of IP<sub>3</sub> R2 during development may trigger compensating phenotypes, which could bias the results of experiments using developing or adult mice. To address this issue, we performed a detailed neurodevelopmental evaluation of male and female IP<sub>3</sub> R2 KO mice, during the first 21 days of life, as well as an evaluation of motor function, strength and neurological reflexes in adult mice. Our results show that male and female IP<sub>3</sub> R2 KO mice display a normal acquisition of developmental milestones, as compared with wild-type (WT) mice. We also show that IP<sub>3</sub> R2 KO mice display normal motor coordination, strength and neurological reflexes in adulthood. To exclude a potential compensatory overexpression of other IP<sub>3</sub> Rs, we quantified the relative mRNA levels of all 3 subtypes, in brain tissue. We found that, along with the complete deletion of Itpr2, there is no compensatory expression of Itpr1 or Itrp3. Overall, our results show that the IP<sub>3</sub> R2 KO mouse is a reliable model to study the functional impact of global IP<sub>3</sub> R2-dependent astrocytic Ca<sup>2+</sup> elevations. \n",
      "  |  https://doi.org/10.1111/ejn.14724  |  \n",
      "------------------------------------------- \n",
      "10.1007/s11548-019-02057-2  |  Other  |  Diagnosis  |  Research  |  Research  |    Purpose:  Brain shift during tumor resection can progressively invalidate the accuracy of neuronavigation systems and affect neurosurgeons' ability to achieve optimal resections. This paper compares two methods that have been presented in the literature to compensate for brain shift: a thin-plate spline deformation model and a finite element method (FEM). For this comparison, both methods are driven by identical sparse data. Specifically, both methods are driven by displacements between automatically detected and matched feature points from intraoperative 3D ultrasound (iUS). Both methods have been shown to be fast enough for intraoperative brain shift correction (Machado et al. in Int J Comput Assist Radiol Surg 13(10):1525-1538, 2018; Luo et al. in J Med Imaging (Bellingham) 4(3):035003, 2017). However, the spline method requires no preprocessing and ignores physical properties of the brain while the FEM method requires significant preprocessing and incorporates patient-specific physical and geometric constraints. The goal of this work was to explore the relative merits of these methods on recent clinical data. \n",
      "  Methods:  Data acquired during 19 sequential tumor resections in Brigham and Women's Hospital's Advanced Multi-modal Image-Guided Operating Suite between December 2017 and October 2018 were considered for this retrospective study. Of these, 15 cases and a total of 24 iUS to iUS image pairs met inclusion requirements. Automatic feature detection (Machado et al. in Int J Comput Assist Radiol Surg 13(10):1525-1538, 2018) was used to detect and match features in each pair of iUS images. Displacements between matched features were then used to drive both the spline model and the FEM method to compensate for brain shift between image acquisitions. The accuracies of the resultant deformation models were measured by comparing the displacements of manually identified landmarks before and after deformation. \n",
      "  Results:  The mean initial subcortical registration error between preoperative MRI and the first iUS image averaged 5.3 ± 0.75 mm. The mean subcortical brain shift, measured using displacements between manually identified landmarks in pairs of iUS images, was 2.5 ± 1.3 mm. Our results showed that FEM was able to reduce subcortical registration error by a small but statistically significant amount (from 2.46 to 2.02 mm). A large variability in the results of the spline method prevented us from demonstrating either a statistically significant reduction in subcortical registration error after applying the spline method or a statistically significant difference between the results of the two methods. \n",
      "  Conclusions:  In this study, we observed less subcortical brain shift than has previously been reported in the literature (Frisken et al., in: Miller (ed) Biomechanics of the brain, Springer, Cham, 2019). This may be due to the fact that we separated out the initial misregistration between preoperative MRI and the first iUS image from our brain shift measurements or it may be due to modern neurosurgical practices designed to reduce brain shift, including reduced craniotomy sizes and better control of intracranial pressure with the use of mannitol and other medications. It appears that the FEM method and its use of geometric and biomechanical constraints provided more consistent brain shift correction and better correction farther from the driving feature displacements than the simple spline model. The spline-based method was simpler and tended to give better results for small deformations. However, large variability in the spline results and relatively small brain shift prevented this study from demonstrating a statistically significant difference between the results of the two methods. \n",
      "  |  https://dx.doi.org/10.1007/s11548-019-02057-2  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31444624/  |  \n",
      "------------------------------------------- \n",
      "10.1126/science.aaz4439  |  None  |  None, Other  |  Research  |  Research  |   Venus has a thick atmosphere that rotates 60 times as fast as the surface, a phenomenon known as super-rotation. We use data obtained from the orbiting Akatsuki spacecraft to investigate how the super-rotation is maintained in the cloud layer, where the rotation speed is highest. A thermally induced latitudinal-vertical circulation acts to homogenize the distribution of the angular momentum around the rotational axis. Maintaining the super-rotation requires this to be counteracted by atmospheric waves and turbulence. Among those effects, thermal tides transport the angular momentum, which maintains the rotation peak, near the cloud top at low latitudes. Other planetary-scale waves and large-scale turbulence act in the opposite direction. We suggest that hydrodynamic instabilities adjust the angular-momentum distribution at mid-latitudes. \n",
      "  |  http://www.sciencemag.org/cgi/pmidlookup?view=long&pmid=32327594  |  \n",
      "------------------------------------------- \n",
      "10.1111/aas.13527  |  Prognosis  |  Prognosis  |  Review  |  Review  |    Background:  Mortality prediction models are applied in the intensive care unit (ICU) to stratify patients into different risk categories and to facilitate benchmarking. To ensure that the correct prediction models are applied for these purposes, the best performing models must be identified. As a first step, we aimed to establish a systematic review of mortality prediction models in critically ill patients. \n",
      "  Methods:  Mortality prediction models were searched in four databases using the following criteria: developed for use in adult ICU patients in high-income countries, with mortality as primary or secondary outcome. Characteristics and performance measures of the models were summarized. Performance was presented in terms of discrimination, calibration and overall performance measures presented in the original publication. \n",
      "  Results:  In total, 43 mortality prediction models were included in the final analysis. In all, 15 models were only internally validated (35%), 13 externally (30%) and 10 (23%) were both internally and externally validated by the original researchers. Discrimination was assessed in 42 models (98%). Commonly used calibration measures were the Hosmer-Lemeshow test (60%) and the calibration plot (28%). Calibration was not assessed in 11 models (26%). Overall performance was assessed in the Brier score (19%) and the Nagelkerke's R<sup>2</sup> (4.7%). \n",
      "  Conclusions:  Mortality prediction models have varying methodology, and validation and performance of individual models differ. External validation by the original researchers is often lacking and head-to-head comparisons are urgently needed to identify the best performing mortality prediction models for guiding clinical care and research in different settings and populations. \n",
      "  |  https://doi.org/10.1111/aas.13527  |  \n",
      "------------------------------------------- \n",
      "10.1177/1073110520916994  |  Diagnosis, Prognosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Research  |  Research  |   Health care is transitioning from genetics to genomics, in which single-gene testing for diagnosis is being replaced by multi-gene panels, genome-wide sequencing, and other multi-genic tests for disease diagnosis, prediction, prognosis, and treatment. This health care transition is spurring a new set of increased or novel liability risks for health care providers and test laboratories. This article describes this transition in both medical care and liability, and addresses 11 areas of potential increased or novel liability risk, offering recommendations to both health care and legal actors to address and manage those liability risks. \n",
      "  |  http://journals.sagepub.com/doi/full/10.1177/1073110520916994?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.1001/jamanetworkopen.2020.2142  |  Treatment, Prognosis  |  Treatment  |  Research  |  Research  |    Importance:  Studies have shown that adverse events are associated with increasing inpatient care expenditures, but contemporary data on the association between expenditures and adverse events beyond inpatient care are limited. \n",
      "  Objective:  To evaluate whether hospital-specific adverse event rates are associated with hospital-specific risk-standardized 30-day episode-of-care Medicare expenditures for fee-for-service patients discharged with acute myocardial infarction (AMI), heart failure (HF), or pneumonia. \n",
      "  Design, setting, and participants:  This cross-sectional study used the 2011 to 2016 hospital-specific risk-standardized 30-day episode-of-care expenditure data from the Centers for Medicare &amp; Medicaid Services and medical record-abstracted in-hospital adverse event data from the Medicare Patient Safety Monitoring System. The setting was acute care hospitals treating at least 25 Medicare fee-for-service patients for AMI, HF, or pneumonia in the United States. Participants were Medicare fee-for-service patients 65 years or older hospitalized for AMI, HF, or pneumonia included in the Medicare Patient Safety Monitoring System in 2011 to 2016. The dates of analysis were July 16, 2017, to May 21, 2018. \n",
      "  Main outcomes and measures:  Hospitals' risk-standardized 30-day episode-of-care expenditures and the rate of occurrence of adverse events for which patients were at risk. \n",
      "  Results:  The final study sample from 2194 unique hospitals included 44 807 patients (26.1% AMI, 35.6% HF, and 38.3% pneumonia) with a mean (SD) age of 79.4 (8.6) years, and 52.0% were women. The patients represented 84 766 exposures for AMI, 96 917 exposures for HF, and 109 641 exposures for pneumonia. Patient characteristics varied by condition but not by expenditure category. The mean (SD) risk-standardized expenditures were $22 985 ($1579) for AMI, $16 020 ($1416) for HF, and $16 355 ($1995) for pneumonia per hospitalization. The mean risk-standardized rates of occurrence of adverse events for which patients were at risk were 3.5% (95% CI, 3.4%-3.6%) for AMI, 2.5% (95% CI, 2.5%-2.5%) for HF, and 3.0% (95% CI, 2.9%-3.0%) for pneumonia. An increase by 1 percentage point in the rate of occurrence of adverse events was associated with an increase in risk-standardized expenditures of $103 (95% CI, $57-$150) for AMI, $100 (95% CI, $29-$172) for HF, and $152 (95% CI, $73-$232) for pneumonia per discharge. \n",
      "  Conclusions and relevance:  Hospitals with high adverse event rates were more likely to have high 30-day episode-of-care Medicare expenditures for patients discharged with AMI, HF, or pneumonia. \n",
      "  |  https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2020.2142  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32259263/  |  \n",
      "------------------------------------------- \n",
      "10.1007/s00415-019-09613-5  |  Diagnosis, Prognosis  |  Diagnosis, Prognosis  |  Research  |  Research  |    Objective:  Posterior circulation ischemic stroke (PCiS) constitutes 20-30% of ischemic stroke cases. Detailed information about differences between PCiS and anterior circulation ischemic stroke (ACiS) remains scarce. Such information might guide clinical decision making and prevention strategies. We studied risk factors and ischemic stroke subtypes in PCiS vs. ACiS and lesion location on magnetic resonance imaging (MRI) in PCiS. \n",
      "  Methods:  Out of 3,301 MRIs from 12 sites in the National Institute of Neurological Disorders and Stroke (NINDS) Stroke Genetics Network (SiGN), we included 2,381 cases with acute DWI lesions. The definition of ACiS or PCiS was based on lesion location. We compared the groups using Chi-squared and logistic regression. \n",
      "  Results:  PCiS occurred in 718 (30%) patients and ACiS in 1663 (70%). Diabetes and male sex were more common in PCiS vs. ACiS (diabetes 27% vs. 23%, p &lt; 0.05; male sex 68% vs. 58%, p &lt; 0.001). Both were independently associated with PCiS (diabetes, OR = 1.29; 95% CI 1.04-1.61; male sex, OR = 1.46; 95% CI 1.21-1.78). ACiS more commonly had large artery atherosclerosis (25% vs. 20%, p &lt; 0.01) and cardioembolic mechanisms (17% vs. 11%, p &lt; 0.001) compared to PCiS. Small artery occlusion was more common in PCiS vs. ACiS (20% vs. 14%, p &lt; 0.001). Small artery occlusion accounted for 47% of solitary brainstem infarctions. \n",
      "  Conclusion:  Ischemic stroke subtypes differ between the two phenotypes. Diabetes and male sex have a stronger association with PCiS than ACiS. Definitive MRI-based PCiS diagnosis aids etiological investigation and contributes additional insights into specific risk factors and mechanisms of injury in PCiS. \n",
      "  |  https://dx.doi.org/10.1007/s00415-019-09613-5  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31709475/  |  \n",
      "------------------------------------------- \n",
      "10.1186/s12872-020-01455-8  |  Prognosis  |  Prognosis  |  Research  |  Research  |    Background:  Chest pain is one of the most common complaints among patients presenting to the emergency department (ED). Causes of chest pain can be benign or life threatening, making accurate risk stratification a critical issue in the ED. In addition to the use of established clinical scores, prior studies have attempted to create predictive models with heart rate variability (HRV). In this study, we proposed heart rate n-variability (HRnV), an alternative representation of beat-to-beat variation in electrocardiogram (ECG), and investigated its association with major adverse cardiac events (MACE) in ED patients with chest pain. \n",
      "  Methods:  We conducted a retrospective analysis of data collected from the ED of a tertiary hospital in Singapore between September 2010 and July 2015. Patients &gt; 20 years old who presented to the ED with chief complaint of chest pain were conveniently recruited. Five to six-minute single-lead ECGs, demographics, medical history, troponin, and other required variables were collected. We developed the HRnV-Calc software to calculate HRnV parameters. The primary outcome was 30-day MACE, which included all-cause death, acute myocardial infarction, and revascularization. Univariable and multivariable logistic regression analyses were conducted to investigate the association between individual risk factors and the outcome. Receiver operating characteristic (ROC) analysis was performed to compare the HRnV model (based on leave-one-out cross-validation) against other clinical scores in predicting 30-day MACE. \n",
      "  Results:  A total of 795 patients were included in the analysis, of which 247 (31%) had MACE within 30 days. The MACE group was older, with a higher proportion being male patients. Twenty-one conventional HRV and 115 HRnV parameters were calculated. In univariable analysis, eleven HRV and 48 HRnV parameters were significantly associated with 30-day MACE. The multivariable stepwise logistic regression identified 16 predictors that were strongly associated with MACE outcome; these predictors consisted of one HRV, seven HRnV parameters, troponin, ST segment changes, and several other factors. The HRnV model outperformed several clinical scores in the ROC analysis. \n",
      "  Conclusions:  The novel HRnV representation demonstrated its value of augmenting HRV and traditional risk factors in designing a robust risk stratification tool for patients with chest pain in the ED. \n",
      "  |  https://bmccardiovascdisord.biomedcentral.com/articles/10.1186/s12872-020-01455-8  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32276602/  |  \n",
      "------------------------------------------- \n",
      "10.1039/d0cs00098a  |  Drug Discovery  |  Prognosis, Drug Discovery  |  Review  |  Review  |   Prediction of chemical bioactivity and physical properties has been one of the most important applications of statistical and more recently, machine learning and artificial intelligence methods in chemical sciences. This field of research, broadly known as quantitative structure-activity relationships (QSAR) modeling, has developed many important algorithms and has found a broad range of applications in physical organic and medicinal chemistry in the past 55+ years. This Perspective summarizes recent technological advances in QSAR modeling but it also highlights the applicability of algorithms, modeling methods, and validation practices developed in QSAR to a wide range of research areas outside of traditional QSAR boundaries including synthesis planning, nanotechnology, materials science, biomaterials, and clinical informatics. As modern research methods generate rapidly increasing amounts of data, the knowledge of robust data-driven modelling methods professed within the QSAR field can become essential for scientists working both within and outside of chemical research. We hope that this contribution highlighting the generalizable components of QSAR modeling will serve to address this challenge. \n",
      "  |  https://doi.org/10.1039/d0cs00098a  |  \n",
      "------------------------------------------- \n",
      "10.7554/eLife.52951  |  Other  |  None, Other  |  Research  |  Research  |   Clones of excitatory neurons derived from a common progenitor have been proposed to serve as elementary information processing modules in the neocortex. To characterize the cell types and circuit diagram of clonally related excitatory neurons, we performed multi-cell patch clamp recordings and Patch-seq on neurons derived from <i>Nestin</i>-positive progenitors labeled by tamoxifen induction at embryonic day 10.5. The resulting clones are derived from two radial glia on average, span cortical layers 2-6, and are composed of a random sampling of transcriptomic cell types. We find an interaction between shared lineage and connection type: related neurons are more likely to be connected vertically across cortical layers, but not laterally within the same layer. These findings challenge the view that related neurons show uniformly increased connectivity and suggest that integration of vertical <i>intra</i>-clonal input with lateral <i>inter</i>-clonal input may represent a developmentally programmed connectivity motif supporting the emergence of functional circuits. \n",
      "  |  https://doi.org/10.7554/eLife.52951  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32134385/  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41587-019-0364-z  |  Treatment, Diagnosis  |  Diagnosis, Treatment  |  Research  |  Research  |   Tumor DNA sequencing data can be interpreted by computational methods that analyze genomic heterogeneity to infer evolutionary dynamics. A growing number of studies have used these approaches to link cancer evolution with clinical progression and response to therapy. Although the inference of tumor phylogenies is rapidly becoming standard practice in cancer genome analyses, standards for evaluating them are lacking. To address this need, we systematically assess methods for reconstructing tumor subclonality. First, we elucidate the main algorithmic problems in subclonal reconstruction and develop quantitative metrics for evaluating them. Then we simulate realistic tumor genomes that harbor all known clonal and subclonal mutation types and processes. Finally, we benchmark 580 tumor reconstructions, varying tumor read depth, tumor type and somatic variant detection. Our analysis provides a baseline for the establishment of gold-standard methods to analyze tumor heterogeneity. \n",
      "  |  https://dx.doi.org/10.1038/s41587-019-0364-z  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.media.2019.101561  |  Diagnosis  |  Diagnosis, Treatment  |  Review  |  Research  |   Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on \"Diabetic Retinopathy - Segmentation and Grading\" was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI - 2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal sub-challenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(19)30103-3  |  \n",
      "------------------------------------------- \n",
      "10.1148/radiol.2020201491  |  Diagnosis  |  Diagnosis  |  Research  |  Review  |   Background COVID-19 and pneumonia of other etiology share similar CT characteristics, contributing to the challenges in differentiating them with high accuracy. Purpose To establish and evaluate an artificial intelligence (AI) system in differentiating COVID-19 and other pneumonia on chest CT and assess radiologist performance without and with AI assistance. Methods 521 patients with positive RT-PCR for COVID-19 and abnormal chest CT findings were retrospectively identified from ten hospitals from January 2020 to April 2020. 665 patients with non-COVID-19 pneumonia and definite evidence of pneumonia on chest CT were retrospectively selected from three hospitals between 2017 and 2019. To classify COVID-19 versus other pneumonia for each patient, abnormal CT slices were input into the EfficientNet B4 deep neural network architecture after lung segmentation, followed by two-layer fully-connected neural network to pool slices together. Our final cohort of 1,186 patients (132,583 CT slices) was divided into training, validation and test sets in a 7:2:1 and equal ratio. Independent testing was performed by evaluating model performance on separate hospitals. Studies were blindly reviewed by six radiologists without and then with AI assistance. Results Our final model achieved a test accuracy of 96% (95% CI: 90-98%), sensitivity 95% (95% CI: 83-100%) and specificity of 96% (95% CI: 88-99%) with Receiver Operating Characteristic (ROC) AUC of 0.95 and Precision-Recall (PR) AUC of 0.90. On independent testing, our model achieved an accuracy of 87% (95% CI: 82-90%), sensitivity of 89% (95% CI: 81-94%) and specificity of 86% (95% CI: 80-90%) with ROC AUC of 0.90 and PR AUC of 0.87. Assisted by the models' probabilities, the radiologists achieved a higher average test accuracy (90% vs. 85%, Δ=5, p&lt;0.001), sensitivity (88% vs. 79%, Δ=9, p&lt;0.001) and specificity (91% vs. 88%, Δ=3, p=0.001). Conclusion AI assistance improved radiologists' performance in distinguishing COVID-19 from non-COVID-19 pneumonia on chest CT. \n",
      "  |  http://pubs.rsna.org/doi/10.1148/radiol.2020201491?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.2196/15022  |  Treatment, Smart Healthcare, Prognosisbiomarker-drug  |  Prognosis, Treatment, Smart Healthcare  |  Research  |  Review  |    Background:  Alternative evidence-based cardiac rehabilitation (CR) delivery models that overcome significant barriers to access and delivery are needed to address persistent low utilization. Models utilizing contemporary digital technologies could significantly improve reach and fidelity as complementary alternatives to traditional center-based programs. \n",
      "  Objective:  The aim of this study is to compare the effects and costs of the innovative Smartphone Cardiac Rehabilitation, Assisted self-Management (SCRAM) intervention with usual care CR. \n",
      "  Methods:  In this investigator-, assessor-, and statistician-blinded parallel 2-arm randomized controlled trial, 220 adults (18+ years) with coronary heart disease are being recruited from 3 hospitals in metropolitan and regional Victoria, Australia. Participants are randomized (1:1) to receive advice to engage with usual care CR or the SCRAM intervention. SCRAM is a 24-week dual-phase intervention that includes 12 weeks of real-time remote exercise supervision and coaching from exercise physiologists, which is followed by 12 weeks of data-driven nonreal-time remote coaching via telephone. Both intervention phases include evidence- and theory-based multifactorial behavior change support delivered via smartphone push notifications. Outcomes assessed at baseline, 12 weeks, and 24 weeks include maximal aerobic exercise capacity (primary outcome at 24 weeks), modifiable cardiovascular risk factors, exercise adherence, secondary prevention self-management behaviors, health-related quality of life, and adverse events. Economic and process evaluations will determine cost-effectiveness and participant perceptions of the treatment arms, respectively. \n",
      "  Results:  The trial was funded in November 2017 and received ethical approval in June 2018. Recruitment began in November 2018. As of September 2019, 54 participants have been randomized into the trial. \n",
      "  Conclusions:  The innovative multiphase SCRAM intervention delivers real-time remote exercise supervision and evidence-based self-management behavioral support to participants, regardless of their geographic proximity to traditional center-based CR facilities. Our trial will provide unique and valuable information about effects of SCRAM on outcomes associated with cardiac and all-cause mortality, as well as acceptability and cost-effectiveness. These findings will be important to inform health care providers about the potential for innovative program delivery models, such as SCRAM, to be implemented at scale, as a complement to existing CR programs. The inclusion of a cohort comprising metropolitan-, regional-, and rural-dwelling participants will help to understand the role of this delivery model across health care contexts with diverse needs. \n",
      "  Trial registration:  Australian New Zealand Clinical Trials Registry (ACTRN): 12618001458224; anzctr.org.au/Trial/Registration/TrialReview.aspx?id=374508. \n",
      "  International registered report identifier (irrid):  DERR1-10.2196/15022. \n",
      "  |  https://www.researchprotocols.org/2020/1/e15022/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32012103/  |  \n",
      "------------------------------------------- \n",
      "10.1038/s10038-020-0733-y  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   Recently, a recessively inherited intronic repeat expansion in replication factor C1 (RFC1) was identified in cerebellar ataxia with neuropathy and bilateral vestibular areflexia syndrome (CANVAS). Here, we describe a Japanese case of genetically confirmed CANVAS with autonomic failure and auditory hallucination. The case showed impaired uptake of iodine-123-metaiodobenzylguanidine and <sup>123</sup>I-ioflupane in the cardiac sympathetic nerve and dopaminergic neurons, respectively, by single-photon emission computed tomography. Long-read sequencing identified biallelic pathogenic (AAGGG)n nucleotide repeat expansion in RFC1 and heterozygous benign (TAAAA)n and (TAGAA)n expansions in brain expressed, associated with NEDD4 (BEAN1). Enrichment of the repeat regions in RFC1 and BEAN1 using a Cas9-mediated system clearly distinguished between pathogenic and benign repeat expansions. The haplotype around RFC1 indicated that the (AAGGG)n expansion in our case was on the same ancestral allele as that of European cases. Thus, long-read sequencing facilitates precise genetic diagnosis of diseases with complex repeat structures and various expansions. \n",
      "  |  http://dx.doi.org/10.1038/s10038-020-0733-y  |  \n",
      "------------------------------------------- \n",
      "10.1002/hbm.25023  |  Diagnosis  |  Diagnosis, Prognosis  |  Research  |  Research  |   Alzheimer's disease (AD) is associated with disruptions in brain activity and networks. However, there is substantial inconsistency among studies that have investigated functional brain alterations in AD; such contradictions have hindered efforts to elucidate the core disease mechanisms. In this study, we aim to comprehensively characterize AD-associated functional brain alterations using one of the world's largest resting-state functional MRI (fMRI) biobank for the disorder. The biobank includes fMRI data from six neuroimaging centers, with a total of 252 AD patients, 221 mild cognitive impairment (MCI) patients and 215 healthy comparison individuals. Meta-analytic techniques were used to unveil reliable differences in brain function among the three groups. Relative to the healthy comparison group, AD was associated with significantly reduced functional connectivity and local activity in the default-mode network, basal ganglia and cingulate gyrus, along with increased connectivity or local activity in the prefrontal lobe and hippocampus (p &lt; .05, Bonferroni corrected). Moreover, these functional alterations were significantly correlated with the degree of cognitive impairment (AD and MCI groups) and amyloid-β burden. Machine learning models were trained to recognize key fMRI features to predict individual diagnostic status and clinical score. Leave-one-site-out cross-validation established that diagnostic status (mean area under the receiver operating characteristic curve: 0.85) and clinical score (mean correlation coefficient between predicted and actual Mini-Mental State Examination scores: 0.56, p &lt; .0001) could be predicted with high accuracy. Collectively, our findings highlight the potential for a reproducible and generalizable functional brain imaging biomarker to aid the early diagnosis of AD and track its progression. \n",
      "  |  None  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41598-020-59661-5  |  Diagnosis, Smart Healthcare  |  Diagnosis, Treatment, Smart Healthcare  |  Research  |  Research  |   With the advent of personalized medicine, there is a movement to develop \"smaller\" and \"smarter\" microdevices that are able to distinguish similar cancer subtypes. Tumor cells display major differences when compared to their natural counterparts, due to alterations in fundamental cellular processes such as glycosylation. Glycans are involved in tumor cell biology and they have been considered to be suitable cancer biomarkers. Thus, more selective cancer screening assays can be developed through the detection of specific altered glycans on the surface of circulating cancer cells. Currently, this is only possible through time-consuming assays. In this work, we propose the \"intelligent\" Lab on Fiber (iLoF) device, that has a high-resolution, and which is a fast and portable method for tumor single-cell type identification and isolation. We apply an Artificial Intelligence approach to the back-scattered signal arising from a trapped cell by a micro-lensed optical fiber. As a proof of concept, we show that iLoF is able to discriminate two human cancer cell models sharing the same genetic background but displaying a different surface glycosylation profile with an accuracy above 90% and a speed rate of 2.3 seconds. We envision the incorporation of the iLoF in an easy-to-operate microchip for cancer identification, which would allow further biological characterization of the captured circulating live cells. \n",
      "  |  http://dx.doi.org/10.1038/s41598-020-59661-5  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32081911/  |  \n",
      "------------------------------------------- \n",
      "10.1056/NEJMoa1917130  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background:  Nonophthalmologist physicians do not confidently perform direct ophthalmoscopy. The use of artificial intelligence to detect papilledema and other optic-disk abnormalities from fundus photographs has not been well studied. \n",
      "  Methods:  We trained, validated, and externally tested a deep-learning system to classify optic disks as being normal or having papilledema or other abnormalities from 15,846 retrospectively collected ocular fundus photographs that had been obtained with pharmacologic pupillary dilation and various digital cameras in persons from multiple ethnic populations. Of these photographs, 14,341 from 19 sites in 11 countries were used for training and validation, and 1505 photographs from 5 other sites were used for external testing. Performance at classifying the optic-disk appearance was evaluated by calculating the area under the receiver-operating-characteristic curve (AUC), sensitivity, and specificity, as compared with a reference standard of clinical diagnoses by neuro-ophthalmologists. \n",
      "  Results:  The training and validation data sets from 6779 patients included 14,341 photographs: 9156 of normal disks, 2148 of disks with papilledema, and 3037 of disks with other abnormalities. The percentage classified as being normal ranged across sites from 9.8 to 100%; the percentage classified as having papilledema ranged across sites from zero to 59.5%. In the validation set, the system discriminated disks with papilledema from normal disks and disks with nonpapilledema abnormalities with an AUC of 0.99 (95% confidence interval [CI], 0.98 to 0.99) and normal from abnormal disks with an AUC of 0.99 (95% CI, 0.99 to 0.99). In the external-testing data set of 1505 photographs, the system had an AUC for the detection of papilledema of 0.96 (95% CI, 0.95 to 0.97), a sensitivity of 96.4% (95% CI, 93.9 to 98.3), and a specificity of 84.7% (95% CI, 82.3 to 87.1). \n",
      "  Conclusions:  A deep-learning system using fundus photographs with pharmacologically dilated pupils differentiated among optic disks with papilledema, normal disks, and disks with nonpapilledema abnormalities. (Funded by the Singapore National Medical Research Council and the SingHealth Duke-NUS Ophthalmology and Visual Sciences Academic Clinical Program.). \n",
      "  |  http://www.nejm.org/doi/full/10.1056/NEJMoa1917130?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41746-020-0266-y  |  Diagnosis, Treatment  |  Diagnosis, Treatment  |  Research  |  Research  |   Pulmonary embolism (PE) is a life-threatening clinical problem and computed tomography pulmonary angiography (CTPA) is the gold standard for diagnosis. Prompt diagnosis and immediate treatment are critical to avoid high morbidity and mortality rates, yet PE remains among the diagnoses most frequently missed or delayed. In this study, we developed a deep learning model-PENet, to automatically detect PE on volumetric CTPA scans as an end-to-end solution for this purpose. The PENet is a 77-layer 3D convolutional neural network (CNN) pretrained on the Kinetics-600 dataset and fine-tuned on a retrospective CTPA dataset collected from a single academic institution. The PENet model performance was evaluated in detecting PE on data from two different institutions: one as a hold-out dataset from the same institution as the training data and a second collected from an external institution to evaluate model generalizability to an unrelated population dataset. PENet achieved an AUROC of 0.84 [0.82-0.87] on detecting PE on the hold out internal test set and 0.85 [0.81-0.88] on external dataset. PENet also outperformed current state-of-the-art 3D CNN models. The results represent successful application of an end-to-end 3D CNN model for the complex task of PE diagnosis without requiring computationally intensive and time consuming preprocessing and demonstrates sustained performance on data from an external institution. Our model could be applied as a triage tool to automatically identify clinically important PEs allowing for prioritization for diagnostic radiology interpretation and improved care pathways via more efficient diagnosis. \n",
      "  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32352039/  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.cmpb.2019.105153  |  Diagnosis  |  Diagnosis, Prognosis  |  Research  |  Research  |    Background and objectives:  Malignant lymphomas are cancers of the immune system and are characterized by enlarged lymph nodes that typically spread across many different sites. Many different histological subtypes exist, whose diagnosis is typically based on sampling (biopsy) of a single tumor site, whereas total body examinations with computed tomography and positron emission tomography, though not diagnostic, are able to provide a comprehensive picture of the patient. In this work, we exploit a data-driven approach based on multiple-instance learning algorithms and texture analysis features extracted from positron emission tomography, to predict differential diagnosis of the main malignant lymphomas subtypes. \n",
      "  Methods:  We exploit a multiple-instance learning setting where support vector machines and random forests are used as classifiers both at the level of single VOIs (instances) and at the level of patients (bags). We present results on two datasets comprising patients that suffer from four different types of malignant lymphomas, namely diffuse large B cell lymphoma, follicular lymphoma, Hodgkin's lymphoma, and mantle cell lymphoma. \n",
      "  Results:  Despite the complexity of the task, experimental results show that, with sufficient data samples, some cancer subtypes, such as the Hodgkin's lymphoma, can be identified from texture information: in particular, we achieve a 97.0% of sensitivity (recall) and a 94.1% of predictive positive value (precision) on a dataset that consists in 60 patients. \n",
      "  Conclusions:  The presented study indicates that texture analysis features extracted from positron emission tomography, combined with multiple-instance machine learning algorithms, can be discriminating for different malignant lymphomas subtypes. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)30205-6  |  \n",
      "------------------------------------------- \n",
      "10.1002/advs.201902699  |  None  |  Diagnosis  |  Research  |  Research  |   Terahertz (THz) photon detection is of particular appealing for myriad applications, but it still lags behind efficient manipulation with electronics and photonics due to the lack of a suitable principle satisfying both high sensitivity and fast response at room temperature. Here, a new strategy is proposed to overcome these limitations by exploring the photothermoelectric (PTE) effect in an ultrashort (down to 30 nm) channel with black phosphorus as a photoactive material. The preferential flow of hot carriers is enabled by the asymmetric Cr/Au and Ti/Au metallization with the titled-angle evaporation technique. Most intriguingly, orders of magnitude field-enhancement beyond the skin-depth limit and photon absorption across a broadband frequency can be achieved. The PTE detector has excellent sensitivity of 297 V W<sup>-1</sup>, noise equivalent power less than 58 pW/Hz<sup>0.5</sup>, and response time below 0.8 ms, which is superior to other thermal-based detectors at room temperature. A rigorous comparison with existing THz detectors, together with verification by further optical-pumping and imaging experiments, substantiates the importance of the localized field effect in the skin-depth limit. The results allow solid understanding on the role of PTE effect played in the THz photoresponse, opening up new opportunities for developing highly sensitive THz detectors for addressing targeted applications. \n",
      "  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32154074/  |  \n",
      "------------------------------------------- \n",
      "10.1002/cti2.1105  |  Prognosis  |  Prognosis, Treatment  |  Research  |  Research  |    Objectives:  T cells play an essential role in controlling the development of B-cell lymphoproliferative disorders (BLPDs), but the dysfunction of T cells in BLPDs largely remains elusive. \n",
      "  Methods:  Using multiplexed flow cytometry, we quantified all major subsets of CD4<sup>+</sup> helper T cells (Th) and CD8<sup>+</sup> cytotoxic T cells (Tc) in 94 BLPD patients and 66 healthy controls. Statistics was utilised to rank T-cell signatures that distinguished BLPDs from healthy controls and differentially presented between indolent and aggressive categories. \n",
      "  Results:  By comparing with healthy controls, we found that the indolent but not aggressive type of BLPDs demonstrated a high degree of T-cell activation, showing the increase in type I helper T (Th1) cells and follicular B-helper T (Tfh) cells, both of which strongly associated with the enhanced differentiation of exhaustion-like effector cytotoxic CD8<sup>+</sup> T cells expressing PD-1 (Tc exhaustion-like) in indolent BLPDs. Random forest modelling selected a module of T-cell immune signatures best performing binary classification of all BLPD patients. This signature module was composed of low naïve Th cells and high Th1, Tfh and Tc exhaustion-like cells which efficiently identified &gt; 85% indolent cases and was, therefore, assigned as the Indolent Dominant Module of T-cell immune signature. In indolent BLPD patients, a strong bias towards such signatures was found to associate with clinical characteristics of worse prognosis. \n",
      "  Conclusion:  Our study identified a prominent signature of T-cell dysregulation specifically for indolent BLPDs, suggesting Th1, Tfh and Tc exhaustion-like cells represent potential prognostic biomarkers and targets for immunotherapies. \n",
      "  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31993200/  |  \n",
      "------------------------------------------- \n",
      "10.3988/jcn.2020.16.2.202  |  Diagnosis, Prognosis  |  Diagnosis  |  Research  |  Research  |    Background and purpose:  Mild cognitive impairment (MCI) is a condition with diverse clinical outcomes and subgroups. Here we investigated the topographic distribution of tau in vivo using the positron emission tomography (PET) tracer [¹⁸F]THK5351 in MCI subgroups. \n",
      "  Methods:  This study included 96 participants comprising 38 with amnestic MCI (aMCI), 21 with nonamnestic MCI (naMCI), and 37 with normal cognition (NC) who underwent 3.0-T MRI, [¹⁸F]THK5351 PET, and detailed neuropsychological tests. [¹⁸F]flutemetamol PET was also performed in 62 participants. The aMCI patients were further divided into three groups: 1) verbal-aMCI, only verbal memory impairment; 2) visual-aMCI, only visual memory impairment; and 3) both-aMCI, both visual and verbal memory impairment. Voxel-wise statistical analysis and region-of-interest -based analyses were performed to evaluate the retention of [¹⁸F]THK5351 in the MCI subgroups. Subgroup analysis of amyloid-positive and -negative MCI patients was also performed. Correlations between [¹⁸F]THK5351 retention and different neuropsychological tests were evaluated using statistical parametric mapping analyses. \n",
      "  Results:  [¹⁸F]THK5351 retention in the lateral temporal, mesial temporal, parietal, frontal, posterior cingulate cortices and precuneus was significantly greater in aMCI patients than in NC subjects, whereas it did not differ significantly between naMCI and NC participants. [¹⁸F] THK5351 retention was greater in the both-aMCI group than in the verbal-aMCI and visualaMCI groups, and greater in amyloid-positive than amyloid-negative MCI patients. The cognitive function scores were significantly correlated with cortical [¹⁸F]THK5351 retention. \n",
      "  Conclusions:  [¹⁸F]THK5351 PET might be useful for identifying distinct topographic patterns of [¹⁸F]THK5351 retention in subgroups of MCI patients who are at greater risk of the progression to Alzheimer's dementia. \n",
      "  |  https://thejcn.com/DOIx.php?id=10.3988/jcn.2020.16.2.202  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32319236/  |  \n",
      "------------------------------------------- \n",
      "10.1210/clinem/dgz141  |  Diagnosis  |  Diagnosis  |  Research  |  Review  |    Context:  Urine steroid metabolomics, combining mass spectrometry-based steroid profiling and machine learning, has been described as a novel diagnostic tool for detection of adrenocortical carcinoma (ACC). \n",
      "  Objective, design, setting:  This proof-of-concept study evaluated the performance of urine steroid metabolomics as a tool for postoperative recurrence detection after microscopically complete (R0) resection of ACC. \n",
      "  Patients and methods:  135 patients from 14 clinical centers provided postoperative urine samples, which were analyzed by gas chromatography-mass spectrometry. We assessed the utility of these urine steroid profiles in detecting ACC recurrence, either when interpreted by expert clinicians or when analyzed by random forest, a machine learning-based classifier. Radiological recurrence detection served as the reference standard. \n",
      "  Results:  Imaging detected recurrent disease in 42 of 135 patients; 32 had provided pre- and post-recurrence urine samples. 39 patients remained disease-free for ≥3 years. The urine \"steroid fingerprint\" at recurrence resembled that observed before R0 resection in the majority of cases. Review of longitudinally collected urine steroid profiles by 3 blinded experts detected recurrence by the time of radiological diagnosis in 50% to 72% of cases, improving to 69% to 92%, if a preoperative urine steroid result was available. Recurrence detection by steroid profiling preceded detection by imaging by more than 2 months in 22% to 39% of patients. Specificities varied considerably, ranging from 61% to 97%. The computational classifier detected ACC recurrence with superior accuracy (sensitivity = specificity = 81%). \n",
      "  Conclusion:  Urine steroid metabolomics is a promising tool for postoperative recurrence detection in ACC; availability of a preoperative urine considerably improves the ability to detect ACC recurrence. \n",
      "  |  https://academic.oup.com/jcem/article-lookup/doi/10.1210/clinem/dgz141  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31665449/  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.media.2020.101652  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   Detection of early stages of Alzheimer's disease (AD) (i.e., mild cognitive impairment (MCI)) is important to maximize the chances to delay or prevent progression to AD. Brain connectivity networks inferred from medical imaging data have been commonly used to distinguish MCI patients from normal controls (NC). However, existing methods still suffer from limited performance, and classification remains mainly based on single modality data. This paper proposes a new model to automatically diagnosing MCI (early MCI (EMCI) and late MCI (LMCI)) and its earlier stages (i.e., significant memory concern (SMC)) by combining low-rank self-calibrated functional brain networks and structural brain networks for joint multi-task learning. Specifically, we first develop a new functional brain network estimation method. We introduce data quality indicators for self-calibration, which can improve data quality while completing brain network estimation, and perform correlation analysis combined with low-rank structure. Second, functional and structural connected neuroimaging patterns are integrated into our multi-task learning model to select discriminative and informative features for fine MCI analysis. Different modalities are best suited to undertake distinct classification tasks, and similarities and differences among multiple tasks are best determined through joint learning to determine most discriminative features. The learning process is completed by non-convex regularizer, which effectively reduces the penalty bias of trace norm and approximates the original rank minimization problem. Finally, the most relevant disease features classified using a support vector machine (SVM) for MCI identification. Experimental results show that our method achieves promising performance with high classification accuracy and can effectively discriminate between different sub-stages of MCI. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(20)30019-0  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.jcmg.2019.06.027  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Objectives:  This study was conducted to investigate the influence of coronary artery calcium (CAC) score on the diagnostic performance of machine-learning-based coronary computed tomography (CT) angiography (cCTA)-derived fractional flow reserve (CT-FFR). \n",
      "  Background:  CT-FFR is used reliably to detect lesion-specific ischemia. Novel CT-FFR algorithms using machine-learning artificial intelligence techniques perform fast and require less complex computational fluid dynamics. Yet, influence of CAC score on diagnostic performance of the machine-learning approach has not been investigated. \n",
      "  Methods:  A total of 482 vessels from 314 patients (age 62.3 ± 9.3 years, 77% male) who underwent cCTA followed by invasive FFR were investigated from the MACHINE (Machine Learning based CT Angiography derived FFR: a Multi-center Registry) registry data. CAC scores were quantified using the Agatston convention. The diagnostic performance of CT-FFR to detect lesion-specific ischemia was assessed across all Agatston score categories (CAC 0, &gt;0 to &lt;100, 100 to &lt;400, and ≥400) on a per-vessel level with invasive FFR as the reference standard. \n",
      "  Results:  The diagnostic accuracy of CT-FFR versus invasive FFR was superior to cCTA alone on a per-vessel level (78% vs. 60%) and per patient level (83% vs. 73%) across all Agatston score categories. No statistically significant differences in the diagnostic accuracy, sensitivity, or specificity of CT-FFR were observed across the categories. CT-FFR showed good discriminatory power in vessels with high Agatston scores (CAC ≥400) and high performance in low-to-intermediate Agatston scores (CAC &gt;0 to &lt;400) with a statistically significant difference in the area under the receiver-operating characteristic curve (AUC) (AUC: 0.71 [95% confidence interval (CI): 0.57 to 0.85] vs. 0.85 [95% CI: 0.82 to 0.89], p = 0.04). CT-FFR showed superior diagnostic value over cCTA in vessels with high Agatston scores (CAC ≥ 400: AUC 0.71 vs. 0.55, p = 0.04) and low-to-intermediate Agatston scores (CAC &gt;0 to &lt;400: AUC 0.86 vs. 0.63, p &lt; 0.001). \n",
      "  Conclusions:  Machine-learning-based CT-FFR showed superior diagnostic performance over cCTA alone in CAC with a significant difference in the performance of CT-FFR as calcium burden/Agatston calcium score increased. (Machine Learning Based CT Angiography Derived FFR: a Multicenter, Registry [MACHINE] <a href=\"http://clinicaltrials.gov/show/NCT02805621\" title=\"See in ClinicalTrials.gov\">NCT02805621</a>). \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1936-878X(19)30635-7  |  \n",
      "------------------------------------------- \n",
      "10.1186/s13041-020-00587-4  |  Treatment  |  Diagnosis, Treatment  |  Research  |  Research  |    Aim:  A hallmark of classical conditioning is that conditioned stimulus (CS) must be tightly coupled with unconditioned stimulus (US), often requiring temporal overlap between the two, or a short gap of several seconds. In this study, we investigate the temporal requirements for fear conditioning association between a strong artificial CS, high-frequency optogenetic activation of inputs into the lateral amygdala of rats, and a foot-shock to the animal with delays up to many minutes. \n",
      "  Methods:  AAV-oChIEF-tdTomato viruses were injected into the auditory cortex and the medial geniculate nucleus of rats. An optical fiber was implanted just above the lateral amygdala of the animal. Optogenetic high-frequency stimuli (oHFS; containing five 1-s trains of 100 Hz laser pulses) were delivered to the lateral amygdala, before or after (with varying intervals) a foot-shock that elicits fear responses in the animal. Pre-trained lever-press behavior was used to assess the degree of fear recall by optogenetic test stimuli (OTS; 10 Hz for 2 min) 24 h after the association experiment. \n",
      "  Results:  In contrast to the tight temporal requirement for classical conditioning with paired optogenetic moderate-frequency stimuli (oMFS; 10 Hz for 20 s) and foot-shock, oHFS followed by foot-shock with a 5-min or even 1-h (but not 3-h) interval could successfully establish an association to be recalled by OTS the next day. Meanwhile, foot-shock followed by oHFS with a 5-min (but not 1-h) interval could also establish the conditioning. Thus, distant association may be formed between temporally distant stimuli when the CS is strong. \n",
      "  |  https://molecularbrain.biomedcentral.com/articles/10.1186/s13041-020-00587-4  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32197621/  |  \n",
      "------------------------------------------- \n",
      "PMID:32060190  |  Smart Healthcare  |  Smart Healthcare  |  Review  |  Review  |    Objective:  To contrast how Brazil's and Canada's different jurisdictional and judicial realities have led to different types of telemedicine and how further scale and improvement can be achieved. \n",
      "  Composition of the committee:  A subgroup of the Besrour Centre of the College of Family Physicians of Canada and Canadian telemedicine experts developed connections with colleagues in Porto Alegre, Brazil, and collaborated to undertake a between-country comparison of their respective telemedicine programs. \n",
      "  Methods:  Following a literature review, the authors collectively reflected on their experiences in an attempt to explore the past and current state of telemedicine in Canada and Brazil. \n",
      "  Report:  Both Brazil and Canada share expansive geographies, creating substantial barriers to health for rural patients. Telemedicine is an important part of a universal health system. Both countries have achieved telemedicine programs that have scaled up across large regions and are showing important effects on health care costs and outcomes. However, each system is unique in design and implementation and faces unique challenges for further scale and improvement. Addressing regional differences, the normalization of telemedicine, and potential alignment of telemedicine and artificial intelligence technologies for health care are seen as promising approaches to scaling up and improving telemedicine in both countries. \n",
      "  Objectif:  Comparer la manière dont les différentes réalités territoriales et judiciaires du Brésil et du Canada ont mené à différents types de télémédecine et déterminer comment l’expansion à plus grande échelle, ainsi que des améliorations peuvent être réalisées. \n",
      "  Composition du comité:  Un sous-groupe du Centre Besrour du Collège des médecins de famille du Canada et des experts canadiens en télémédecine ont établi des liens avec des collègues de Porto Alegre, au Brésil, et ont collaboré pour entreprendre une comparaison entre les programmes de télémédecine des deux pays. \n",
      "  Méthodes:  Après une revue de la documentation, les auteurs ont fait une réflexion collective sur leurs expériences afin d’explorer l’état passé et actuel de la télémédecine au Canada et au Brésil. \n",
      "  Rapport:  Le Brésil et le Canada couvrent tous deux de vastes territoires géographiques, ce qui crée des obstacles importants à la santé des patients des zones rurales. La télémédecine est un élément important d’un système de santé universel. Les deux pays ont mis en place des programmes de télémédecine qui s’étendent sur de vastes régions et qui ont des effets importants sur les coûts des soins et la santé des populations. Toutefois, chaque système est unique dans sa conception et sa mise en œuvre et se heurte à des difficultés particulières qui entravent son expansion. La prise en compte des différences régionales, la normalisation de la télémédecine et l’harmonisation potentielle des technologies de télémédecine et d’intelligence artificielle pour les soins de santé sont considérées comme des approches prometteuses pour le développement et l’amélioration de la télémédecine dans ces deux pays. \n",
      "  |  http://www.cfp.ca/cgi/pmidlookup?view=long&pmid=32060190  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32060190/  |  \n",
      "------------------------------------------- \n",
      "10.1155/2020/3658795  |  Smart Healthcare  |  Diagnosis, Smart Healthcare  |  Research  |  Research  |   Recently, brain-machine interfacing is very popular that link humans and artificial devices through brain signals which lead to corresponding mobile application as supplementary. The Android platform has developed rapidly because of its good user experience and openness. Meanwhile, these characteristics of this platform, which cause the amazing pace of Android malware, pose a great threat to this platform and data correction during signal transmission of brain-machine interfacing. Many previous works employ various behavioral characteristics to analyze Android application (or app) and detect Android malware to protect signal data secure. However, with the development of Android app, category of Android app tends to be diverse, and the Android malware behavior tends to be complex. This situation makes existing Android malware detections complicated and inefficient. In this paper, we propose a broad analysis, gathering as many behavior characteristics of an app as possible and compare these behavior characteristics in several metrics. First, we extract static and dynamic behavioral characteristic from Android app in an automatic manner. Second, we explain the decision we made in each kind of behavioral characteristic we choose for Android app analysis and Android malware detection. Third, we design a detailed experiment, which compare the efficiency of each kind of behavior characteristic in different aspects. The results of experiment also show Android malware detection performance of these behavior characteristics combine with well-known machine learning algorithms. \n",
      "  |  https://doi.org/10.1155/2020/3658795  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32300372/  |  \n",
      "------------------------------------------- \n",
      "10.1007/s10439-019-02332-y  |  Robotics, Surgery  |  Robotics  |  Review  |  Review  |   Robots in orthopedic surgery have been developed rapidly for decades and bring significant benefits to the patients and healthcare providers. However, robotics in fracture reduction remains at the infant stage. As essential components of the current robotic system, external fixators were used in fracture reduction, including the unilateral and Ilizarov-like ring fixators. With emerging of the industrial robots and mechanical arms, their sterilized variants were developed as the serial robots, including the traction device and robotic arm, for fracture reduction. Besides, parallel robots (e.g., Gough-Stewart platform) were devised for lower extremity traction and fracture reduction. After combining the advantages of the serial and parallel mechanisms, hybrid robots can fulfill specific clinical requirements (e.g., the joint fracture, including multiple major fragments). Furthermore, with the aid of intra-operative navigation systems, fracture reduction can be performed under real-time guidance. The paper presents a comprehensive overview of the advancement of the robots in fracture reduction and evaluates research challenges and future perspectives, including ergonomic and economic issues, operation time, artificial realities and intelligence, and telesurgery. \n",
      "  |  https://doi.org/10.1007/s10439-019-02332-y  |  \n",
      "------------------------------------------- \n",
      "10.1021/acs.jcim.9b01030  |  Drug Discovery, Treatment  |  Drug Discovery, Treatment, Smart Healthcare  |  Research  |  Research  |   Farnesoid X receptor (FXR) agonists can reverse dysregulated bile acid metabolism, and thus, they are potential therapeutics to prevent and treat nonalcoholic fatty liver disease. The low success rate of FXR agonists' R&amp;D and the side effects of clinical candidates such as obeticholic acid make it urgent to discover new chemotypes. Unfortunately, structure-based virtual screening (SBVS) that can speed up drug discovery has rarely been reported with success for FXR, which was likely hindered by the failure in addressing protein flexibility. To address this issue, we devised human FXR (hFXR)-specific ensemble learning models based on pose filters from 24 agonist-bound hFXR crystal structures and coupled them to traditional SBVS approaches of the FRED docking plus Chemgauss4 scoring function. It turned out that the hFXR-specific pose filter ensemble (PFE) was able to improve ligand enrichment significantly, which rendered 3RUT-based SBVS with its PFE the ideal approach for FXR agonist discovery. By screening of the Specs chemical library and in vitro FXR transactivation bioassay, we identified a new class of FXR agonists with compound XJ034 as the representative, which would have been missed if the PFE was not coupled. Following that, we performed in-depth biological studies which demonstrated that XJ034 resulted in a downtrend of intracellular triglyceride in vitro, significantly decreased the serum/liver TG in high fat diet-induced C57BL/6J obese mice, and more importantly, showed metabolic stabilities in both plasma and liver microsomes. To provide insight into further structure-based lead optimization, we solved the crystal structure of hFXR complexed with compound XJ034, uncovering a unique hydrogen bond between compound XJ034 and residue Y375. The current work highlights the power of our pose filter-based ensemble learning approach in terms of scaffold hopping and provides a promising lead compound for further development. \n",
      "  |  https://dx.doi.org/10.1021/acs.jcim.9b01030  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41467-020-14649-7  |  Other  |  None, Other  |  Research  |  Research  |   Recent studies suggest that attention samples space rhythmically through oscillatory interactions in the frontoparietal network. How these attentional fluctuations coincide with spatial exploration/displacement and exploitation/selection by a dynamic attentional spotlight under top-down control is unclear. Here, we show a direct contribution of prefrontal attention selection mechanisms to a continuous space exploration. Specifically, we provide a direct high spatio-temporal resolution prefrontal population decoding of the covert attentional spotlight. We show that it continuously explores space at a 7-12 Hz rhythm. Sensory encoding and behavioral reports are increased at a specific optimal phase w/ to this rhythm. We propose that this prefrontal neuronal rhythm reflects an alpha-clocked sampling of the visual environment in the absence of eye movements. These attentional explorations are highly flexible, how they spatially unfold depending both on within-trial and across-task contingencies. These results are discussed in the context of exploration-exploitation strategies and prefrontal top-down attentional control. \n",
      "  |  http://dx.doi.org/10.1038/s41467-020-14649-7  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32066740/  |  \n",
      "------------------------------------------- \n",
      "10.15252/emmm.201911622  |  Treatment, Drug Discovery  |  Prognosis, Treatment  |  Research  |  Research  |   Chemotherapy still constitutes the standard of care for the treatment of most neoplastic diseases. Certain chemotherapeutics from the oncological armamentarium are able to trigger pre-mortem stress signals that lead to immunogenic cell death (ICD), thus inducing an antitumor immune response and mediating long-term tumor growth reduction. Here, we used an established model, built on artificial intelligence to identify, among a library of 50,000 compounds, anticancer agents that, based on their molecular descriptors, were predicted to induce ICD. This algorithm led us to the identification of dactinomycin (DACT, best known as actinomycin D), a highly potent cytotoxicant and ICD inducer that mediates immune-dependent anticancer effects in vivo. Since DACT is commonly used as an inhibitor of DNA to RNA transcription, we investigated whether other experimentally established or algorithm-selected, clinically employed ICD inducers would share this characteristic. As a common leitmotif, a panel of pharmacological ICD stimulators inhibited transcription and secondarily translation. These results establish the inhibition of RNA synthesis as an initial event for ICD induction. \n",
      "  |  https://doi.org/10.15252/emmm.201911622  |  \n",
      "------------------------------------------- \n",
      "10.1055/a-1111-2431  |  Epidemiology, Diagnosis, Prognosis, Treatment  |  Diagnosis, Prognosis, Treatment, Epidemiology  |  Review  |  Review  |   This review is intended to present the latest developments in the prevention and treatment of early breast cancer. The risk of breast cancer can be increasingly better characterised with large epidemiological studies on genetic and non-genetic risk factors. Through new analyses, the evidence for high-penetrance genes as well as for low-penetrance genes was able to be improved. New data on denosumab and atezolizumab are available in the neoadjuvant situation as is a pooled appraisal of numerous studies on capecitabine in the curative situation. There is also an update to the overall survival data of pertuzumab in the adjuvant situation with a longer follow-up observation period. Finally, digital medicine is steadily finding its way into science. A recently conducted study on automated breast cancer detection using artificial intelligence establishes the basis for a future review in clinical studies. \n",
      "  |  http://www.thieme-connect.com/DOI/DOI?10.1055/a-1111-2431  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32139917/  |  \n",
      "------------------------------------------- \n",
      "10.1053/j.gastro.2020.02.036  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background &amp; aims:  Narrow-band imaging (NBI) can be used to determine whether colorectal polyps are adenomatous or hyperplastic. We investigated whether an artificial intelligence (AI) system can increase the accuracy of characterizations of polyps by endoscopists of different skill levels. \n",
      "  Methods:  We developed convolutional neural networks (CNNs) for evaluation of diminutive colorectal polyps, based on efficient neural architecture searches via parameter sharing with augmentation using narrow-band images of diminutive (≤5 mm) polyps, collected from October 2015 through October 2017 at the Seoul National University Hospital, Healthcare System Gangnam Center (training set). We trained the CNN using images from 1100 adenomatous polyps and 1050 hyperplastic polyps from 1379 patients. We then tested the system using 300 images of 180 adenomatous polyps and 120 hyperplastic polyps, obtained from January 2018 to May 2019. We compared the accuracy of 22 endoscopists of different skill levels (7 novices, 4 experts, and 11 NBI-trained experts) vs the CNN in evaluation of images (adenomatous vs hyperplastic) from 180 adenomatous and 120 hyperplastic polyps. The endoscopists then evaluated the polyp images with knowledge of the CNN-processed results. We conducted mixed-effect logistic and linear regression analyses to determine the effects of AI assistance on the accuracy of analysis of diminutive colorectal polyps by endoscopists (primary outcome). \n",
      "  Results:  The CNN distinguished adenomatous vs hyperplastic diminutive polyps with 86.7% accuracy, based on histologic analysis as the reference standard. Endoscopists distinguished adenomatous vs hyperplastic diminutive polyps with 82.5% overall accuracy (novices, 73.8% accuracy; experts, 83.8% accuracy; and NBI-trained experts, 87.6% accuracy). With knowledge of the CNN-processed results, the overall accuracy of the endoscopists increased to 88.5% (P&lt;.05). With knowledge of the CNN-processed results, the accuracy of novice endoscopists increased to 85.6% (P&lt;.05). The CNN-processed results significantly reduced endoscopist time of diagnosis (from 3.92 to 3.37 seconds per polyp, P=.042). \n",
      "  Conclusions:  We developed a CNN that significantly increases the accuracy of evaluation of diminutive colorectal polyps (as adenomatous vs hyperplastic) and reduces the time of diagnosis by endoscopists. This AI assistance system significantly increased the accuracy of analysis by novice endoscopists, who achieved near-expert levels of accuracy without extra training. The CNN assistance system can reduce the skill-level dependence of endoscopists and costs. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0016-5085(20)30263-8  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.ajo.2020.04.003  |  Diagnosis  |  Diagnosis, Prognosis  |  Research  |  Research  |    Purpose:  o investigate the association between retinal microstructure and cone- and rod-function in geographic atrophy (GA) secondary to age-related macular degeneration (AMD) using artificial-intelligence-(AI) algorithms. Design; Prospective, observational case series METHODS: Forty-one eyes of 41 patients (75.8±8.4 years; 22 female) from a tertiary referral hospital were included (Directional-Spread-in-Geographic-Atrophy (DSGA) natural history study; <a href=\"http://clinicaltrials.gov/show/NCT02051998\" title=\"See in ClinicalTrials.gov\">NCT02051998</a>). Mesopic, dark-adapted (DA) cyan and red sensitivity were assessed using fundus-controlled perimetry (\"microperimetry\"); retinal microstructure using spectral-domain optical-coherence-tomography (SD-OCT), fundus autofluorescence (FAF) and near-infrared-reflectance (IR) imaging. Layer-thicknesses and -intensities and FAF- and IR-intensities were extracted for each test-point. We evaluated the cross-validated mean absolute error (MAE) for random-forest-based predictions of retinal sensitivity with and without patient-specific training-data and the increase mean-squared error (%IncMSE) as measure of feature-importance. \n",
      "  Results:  Retinal sensitivity was predicted with a MAE of 4.64 dB for mesopic, 4.89 dB for DA cyan and 4.40 dB for DA red testing in absence of patient-specific data. Partial addition of patient-specific sensitivity data to the training sets decreased the MAE to 2.89 dB, 2.86 dB and 2.77 dB. For all three types of testing, the outer nuclear layer-thickness constituted the most important predictive feature (35.0, 42.22 and 53.74 %IncMSE). Spatially-resolved mapping of \"inferred sensitivity\" revealed regions with differential degrees of mesopic and DA cyan sensitivity loss outside of the GA lesions. \n",
      "  Conclusions:  \"Inferred sensitivity\" accurately reflected retinal function in patients with GA. Mapping of \"inferred sensitivity\" could facilitate monitoring of disease progression and serve as \"quasi functional\" surrogate outcome in clinical trials, especially in consideration of retinal regions beyond areas of GA. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0002-9394(20)30170-7  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.cmpb.2019.105059  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background and objective:  With the rapid development of medical imaging and intelligent diagnosis, artificial intelligence methods have become a research hotspot of radiography processing technology in recent years. The low definition of knee magnetic resonance image texture seriously affects the diagnosis of knee osteoarthritis. This paper presents a super-resolution reconstruction method to address this problem. \n",
      "  Methods:  In this paper, we propose an efficient medical image super-resolution (EMISR) method, in which we mainly adopted three hidden layers of super-resolution convolution neural network (SRCNN) and a sub-pixel convolution layer of efficient sub-pixel convolution neural network (ESPCN). The addition of the efficient sub-pixel convolutional layer in the hidden layer and the small network replacement consisting of concatenated convolutions to address low-resolution images but not high-resolution images are important. The EMISR method also uses cascaded small convolution kernels to improve reconstruction speed and deepen the convolution neural network to improve reconstruction quality. \n",
      "  Results:  The proposed method is tested in the public dataset IDI, and the reconstruction quality of the algorithm is higher than that of the sparse coding-based network (SCN) method, the SRCNN method, and the ESPCN method (+ 2.306 dB, + 2.540 dB, + 1.089 dB improved); moreover, the reconstruction speed is faster than its counterparts (+ 4.272 s, + 1.967 s, and + 0.073 s improved). \n",
      "  Conclusion:  The experimental results show that our EMISR framework has improved performance and greatly reduces the number of parameters and training time. Furthermore, the reconstructed image presents more details, and the edges are more complete. Therefore, the EMISR technique provides a more powerful medical analysis in knee osteoarthritis examinations. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)31241-6  |  \n",
      "------------------------------------------- \n",
      "10.1002/hbm.24856  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   Thalamic atrophy is a common feature across all forms of FTD but little is known about specific nuclei involvement. We aimed to investigate in vivo atrophy of the thalamic nuclei across the FTD spectrum. A cohort of 402 FTD patients (age: mean(SD) 64.3(8.2) years; disease duration: 4.8(2.8) years) was compared with 104 age-matched controls (age: 62.5(10.4) years), using an automated segmentation of T1-weighted MRIs to extract volumes of 14 thalamic nuclei. Stratification was performed by clinical diagnosis (180 behavioural variant FTD (bvFTD), 85 semantic variant primary progressive aphasia (svPPA), 114 nonfluent variant PPA (nfvPPA), 15 PPA not otherwise specified (PPA-NOS), and 8 with associated motor neurone disease (FTD-MND), genetic diagnosis (27 MAPT, 28 C9orf72, 18 GRN), and pathological confirmation (37 tauopathy, 38 TDP-43opathy, 4 FUSopathy). The mediodorsal nucleus (MD) was the only nucleus affected in all FTD subgroups (16-33% smaller than controls). The laterodorsal nucleus was also particularly affected in genetic cases (28-38%), TDP-43 type A (47%), tau-CBD (44%), and FTD-MND (53%). The pulvinar was affected only in the C9orf72 group (16%). Both the lateral and medial geniculate nuclei were also affected in the genetic cases (10-20%), particularly the LGN in C9orf72 expansion carriers. Use of individual thalamic nuclei volumes provided higher accuracy in discriminating between FTD groups than the whole thalamic volume. The MD is the only structure affected across all FTD groups. Differential involvement of the thalamic nuclei among FTD forms is seen, with a unique pattern of atrophy in the pulvinar in C9orf72 expansion carriers. \n",
      "  |  https://doi.org/10.1002/hbm.24856  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.scitotenv.2020.137320  |  None  |  Prognosis  |  Research  |  Research  |   Predictive capability of landslide susceptibilities is assumed to be varied with different sampling techniques, such as (a) the landslide scarp centroid, (b) centroid of landslide body, (c) samples of the scrap region representing the scarp polygon, and (d) samples of the landslide body representing the entire landslide body. However, new advancements in statistical and machine learning algorithms continuously being updated the landslide susceptibility paradigm. This paper explores the predictive performance power of different sampling techniques in landslide susceptibility mapping in the wake of increased usage of artificial intelligence. We used logistic regression (LR), neural network (NNET), and deep learning neural network (DNN) model for testing and validation of the models. The tests were applied to the 2018 Hokkaido Earthquake affected areas using a set of 11 predictor variables (seismic, topographic, and hydrological). We found that the prediction rates are inconsequential with the DNN model irrespective of the sampling technique (AUC: 0.904 - 0.919). Whereas, testing with LR (AUC: 0.825 - 0.785) and NNET (AUC: 0.882 - 0.858) produces larger differences in the accuracies between the four datasets. Nonetheless, the highest success rates were obtained for samples within the landslide scarp area. The analogy was then validated with a published landslide inventory from the 2015 Gorkha earthquake. We, therefore, suggest that DNN models as an appropriate technique to increase the predictive performance of landslide susceptibilities if the landslide scarp and body are not characterized properly in an inventory. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0048-9697(20)30830-5  |  \n",
      "------------------------------------------- \n",
      "10.1002/adma.202000497  |  None  |  None, Other  |  Research  |  Research  |   Bioinspired elastomeric fibrillar surfaces have significant potential as reversible dry adhesives, but their adhesion performance is sensitive to the presence of liquids at the contact interface. Like their models in nature, many artificial mimics can effectively repel water, but fail when low-surface-tension liquids are introduced at the contact interface. A bioinspired fibrillar adhesive surface that is liquid-superrepellent even toward ultralow-surface-tension liquids while retaining its adhesive properties is proposed herein. This surface combines the effective adhesion principle of mushroom-shaped fibrillar arrays with liquid repellency based on double re-entrant fibril tip geometry. The adhesion performance of the proposed microfibril structures is retained even when low-surface-tension liquids are added to the contact interface. The extreme liquid repellency enables real-world applications of fibrillar adhesives for surfaces covered with water, oil, and other liquids. Moreover, fully elastomeric liquid-superrepellent surfaces are mechanically not brittle, highly robust against physical contact, and highly deformable and stretchable, which can increase the real-world uses of such antiwetting surfaces. \n",
      "  |  https://doi.org/10.1002/adma.202000497  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41598-020-59541-y  |  Treatment  |  Treatment  |  Research  |  Research  |   Modern society characterized by a 24/7 lifestyle leads to misalignment between environmental cycles and endogenous circadian rhythms. Persisting circadian misalignment leads to deleterious effects on health and healthspan. However, the underlying mechanism remains not fully understood. Here, we subjected adult, wild-type mice to distinct chronic jet-lag paradigms, which showed that long-term circadian misalignment induced significant early mortality. Non-biased RNA sequencing analysis using liver and kidney showed marked activation of gene regulatory pathways associated with the immune system and immune disease in both organs. In accordance, we observed enhanced steatohepatitis with infiltration of inflammatory cells. The investigation of senescence-associated immune cell subsets from the spleens and mesenteric lymph nodes revealed an increase in PD-1<sup>+</sup>CD44<sup>high</sup> CD4 T cells as well as CD95<sup>+</sup>GL7<sup>+</sup> germinal center B cells, indicating that the long-term circadian misalignment exacerbates immune senescence and consequent chronic inflammation. Our results underscore immune homeostasis as a pivotal interventional target against clock-related disorders. \n",
      "  |  http://dx.doi.org/10.1038/s41598-020-59541-y  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32054990/  |  \n",
      "------------------------------------------- \n",
      "10.2174/0929867327666200408115817  |  Other  |  Treatment  |  Review  |  Review  |   Background：Hydrogel has a three-dimensional network structure that is able to absorb large amount of water/liquid and maintain its original structure. Hemicellulose (HC) is the second most abundant polysaccharide after cellulose in plants and a heterogeneous polysaccharide consisting of various saccharide units. The unique physical and chemical properties of hemicellulose make it a promising material for hydrogels. \n",
      "  Methods:  This review first summarizes the three research hotspots on the hemicellulose-based hydrogels: intelligence, biodegradability and biocompatibility. Overviews the progress in the fabrication and applications of hemicellulose hydrogels in drug delivery system and tissue engineering (articular cartilage, cell immobilization, and wound dressing). \n",
      "  Results:  Hemicellulose-based hydrogels have many unique properties, such as stimuli-responsibility, biodegradability and biocompatibility. Interpenetrating networking can endow appropriate mechanical properties to hydrogels. These properties make the hemicellulose-based hydrogels promising materials in biomedical applications such as drug delivery system and tissue engineering (articular cartilage, cell immobilization, and wound dressing). \n",
      "  Conclusion:  Hydrogels have been widely used in biomedicine and tissue engineering areas, such as tissue fillers, drug release agents, enzyme encapsulation, protein electrophoresis, contact lenses, artificial plasma, artificial skin, and tissue engineering scaffold materials. This article reviews the recent progress in the fabrication and applications of hemicellulose-based hydrogels in the biomedical field. \n",
      "  |  http://www.eurekaselect.com/180789/article  |  \n",
      "------------------------------------------- \n",
      "10.1002/mp.13986  |  Treatment  |  Prognosis, Treatment  |  Research  |  Research  |    Purpose:  Beam orientation selection, whether manual or protocol-based, is the current clinical standard in radiation therapy treatment planning, but it is tedious and can yield suboptimal results. Many algorithms have been designed to optimize beam orientation selection because of its impact on treatment plan quality, but these algorithms suffer from slow calculation of the dose influence matrices of all candidate beams. We propose a fast beam orientation selection method, based on deep learning neural networks (DNN), capable of developing a plan comparable to those developed by the state-of-the-art column generation (CG) method. Our model's novelty lies in its supervised learning structure (using CG to teach the network), DNN architecture, and ability to learn from anatomical features to predict dosimetrically suitable beam orientations without using dosimetric information from the candidate beams. This may save hours of computation. \n",
      "  Methods:  A supervised DNN is trained to mimic the CG algorithm, which iteratively chooses beam orientations one-by-one by calculating beam fitness values based on Karush-Kush-Tucker optimality conditions at each iteration. The DNN learns to predict these values. The dataset contains 70 prostate cancer patients - 50 training, 7 validation, and 13 test patients - to develop and test the model. Each patient's data contains 6 contours: PTV, body, bladder, rectum, and left and right femoral heads. Column generation was implemented with a GPU-based Chambolle-Pock algorithm, a first-order primal-dual proximal-class algorithm, to create 6270 plans. The DNN trained over 400 epochs, each with 2500 steps and a batch size of 1, using the Adam optimizer at a learning rate of 1 × 10<sup>-5</sup> and a sixfold cross-validation technique. \n",
      "  Results:  The average and standard deviation of training, validation, and testing loss functions among the six folds were 0.62 ± 0.09%, 1.04 ± 0.06%, and 1.44 ± 0.11%, respectively. Using CG and supervised DNN, we generated two sets of plans for each scenario in the test set. The proposed method took at most 1.5 s to select a set of five beam orientations and 300 s to calculate the dose influence matrices for 5 beams and finally 20 s to solve the fluence map optimization (FMO). However, CG needed around 15 h to calculate the dose influence matrices of all beams and at least 400 s to solve both the beam orientation selection and FMO problems. The differences in the dose coverage of PTV between plans generated by CG and by DNN were 0.2%. The average dose differences received by organs at risk were between 1 and 6 percent: Bladder had the smallest average difference in dose received (0.956 ± 1.184%), then Rectum (2.44 ± 2.11%), Left Femoral Head (6.03 ± 5.86%), and Right Femoral Head (5.885 ± 5.515%). The dose received by Body had an average difference of 0.10 ± 0.1% between the generated treatment plans. \n",
      "  Conclusions:  We developed a fast beam orientation selection method based on a DNN that selects beam orientations in seconds and is therefore suitable for clinical routines. In the training phase of the proposed method, the model learns the suitable beam orientations based on patients' anatomical features and omits time intensive calculations of dose influence matrices for all possible candidate beams. Solving the FMO to get the final treatment plan requires calculating dose influence matrices only for the selected beams. \n",
      "  |  https://doi.org/10.1002/mp.13986  |  \n",
      "------------------------------------------- \n",
      "10.1186/s41199-020-0047-y  |  Prognosis, Treatment  |  Prognosis, Treatment  |  Review  |  Review  |   For many years, head and neck squamous cell carcinoma (HNSCC) has been considered as a single entity. However, in the last decades HNSCC complexity and heterogeneity have been recognized. In parallel, high-throughput <i>omics</i> techniques had allowed picturing a larger spectrum of the behavior and characteristics of molecules in cancer and a large set of omics web-based tools and informative repository databases have been developed. The objective of the present review is to provide an overview on biological, prognostic and predictive molecular signatures in HNSCC. To contextualize the selected data, our literature survey includes a short summary of the main characteristics of omics data repositories and web-tools for data analyses. The timeframe of our analysis was fixed, encompassing papers published between January 2015 and January 2019. From more than 1000 papers evaluated, 61 omics studies were selected: 33 investigating mRNA signatures, 11 and 13 related to miRNA and other non-coding-RNA signatures and 4 analyzing DNA methylation signatures. More than half of identified signatures (36) had a prognostic value but only in 10 studies selection of a specific anatomical sub-site (8 oral cavity, 1 oropharynx and 1 both oral cavity and oropharynx) was performed. Noteworthy, although the sample size included in many studies was limited, about one-half of the retrieved studies reported an external validation on independent dataset(s), strengthening the relevance of the obtained data. Finally, we highlighted the development and exploitation of three gene-expression signatures, whose clinical impact on prognosis/prediction of treatment response could be high. Based on this overview on omics<i>-related</i> literature in HNSCC, we identified some limits and strengths. The major limits are represented by the low number of signatures associated to DNA methylation and to non-coding RNA (miRNA, lncRNA and piRNAs) and the availability of a single dataset with multiple omics on more than 500 HNSCC (i.e. TCGA). The major strengths rely on the integration of multiple datasets through meta-analysis approaches and on the growing integration among <i>omics</i> data obtained on the same cohort of patients. Moreover, new approaches based on artificial intelligence and informatic analyses are expected to be available in the next future. \n",
      "  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31988797/  |  \n",
      "------------------------------------------- \n",
      "10.3171/2020.1.FOCUS19914  |  Diagnosis, Treatment  |  Diagnosis, Treatment  |  Research  |  Research  |    Objective:  The semiology of cingulate gyrus epilepsy is varied and may involve the paracentral area, the adjacent limbic system, and/or the orbitofrontal gyrus. Invasive electroencephalography (iEEG) recording is usually required for patients with deeply located epileptogenic foci. This paper reports on the authors' experiences in the diagnosis and surgical treatment of patients with focal epilepsy originating in the cingulate gyrus. \n",
      "  Methods:  Eighteen patients (median age 24 years, range 5-53 years) with a mean seizure history of 23 years (range 2-32 years) were analyzed retrospectively. The results of presurgical evaluation, surgical strategy, and postoperative pathology are reported, as well as follow-up concerning functional morbidity and seizures (median follow-up 7 years, range 2-12 years). \n",
      "  Results:  Patients with cingulate gyrus epilepsy presented with a variety of semiologies and scalp EEG patterns. Prior to ictal onset, 11 (61%) of the patients presented with aura. Initial ictal symptoms included limb posturing in 12 (67%), vocalization in 5, and hypermotor movement in 4. In most patients (n = 16, 89%), ictal EEG presented as widespread patterns with bilateral hemispheric origin, as well as muscle artifacts obscuring the onset of EEG during the ictal period in 11 patients. Among the 18 patients who underwent resection, the pathology revealed mild malformation of cortical development in 2, focal cortical dysplasia (FCD) Ib in 4, FCD IIa in 4, FCD IIb in 4, astrocytoma in 1, ganglioglioma in 1, and gliosis in 2. The seizure outcome after surgery was satisfactory: Engel class IA in 12 patients, IIB in 3, IIIA in 1, IIIB in 1, and IVB in 1 at the 2-year follow-up. \n",
      "  Conclusions:  In this study, the authors exploited the improved access to the cingulate epileptogenic network made possible by the use of 3D electrodes implanted using stereoelectroencephalography methodology. Under iEEG recording and intraoperative neuromonitoring, epilepsy surgery on lesions in the cingulate gyrus can result in good outcomes in terms of seizure recurrence and the incidence of postoperative permanent deficits. \n",
      "  |  https://thejns.org/doi/10.3171/2020.1.FOCUS19914  |  \n",
      "------------------------------------------- \n",
      "10.1007/s00330-019-06652-4  |  Prognosis, Diagnosis  |  Diagnosis, Prognosis  |  Research  |  Research  |    Purpose:  This study aimed to validate a deep learning model's diagnostic performance in using computed tomography (CT) to diagnose cervical lymph node metastasis (LNM) from thyroid cancer in a large clinical cohort and to evaluate the model's clinical utility for resident training. \n",
      "  Methods:  The performance of eight deep learning models was validated using 3838 axial CT images from 698 consecutive patients with thyroid cancer who underwent preoperative CT imaging between January and August 2018 (3606 and 232 images from benign and malignant lymph nodes, respectively). Six trainees viewed the same patient images (n = 242), and their diagnostic performance and confidence level (5-point scale) were assessed before and after computer-aided diagnosis (CAD) was included. \n",
      "  Results:  The overall area under the receiver operating characteristics (AUROC) of the eight deep learning algorithms was 0.846 (range 0.784-0.884). The best performing model was Xception, with an AUROC of 0.884. The diagnostic accuracy, sensitivity, specificity, positive predictive value, and negative predictive value of Xception were 82.8%, 80.2%, 83.0%, 83.0%, and 80.2%, respectively. After introducing the CAD system, underperforming trainees received more help from artificial intelligence than the higher performing trainees (p = 0.046), and overall confidence levels significantly increased from 3.90 to 4.30 (p &lt; 0.001). \n",
      "  Conclusion:  The deep learning-based CAD system used in this study for CT diagnosis of cervical LNM from thyroid cancer was clinically validated with an AUROC of 0.884. This approach may serve as a training tool to help resident physicians to gain confidence in diagnosis. \n",
      "  Key points:  • A deep learning-based CAD system for CT diagnosis of cervical LNM from thyroid cancer was validated using data from a clinical cohort. The AUROC for the eight tested algorithms ranged from 0.784 to 0.884. • Of the eight models, the Xception algorithm was the best performing model for the external validation dataset with 0.884 AUROC. The accuracy, sensitivity, specificity, positive predictive value, and negative predictive value were 82.8%, 80.2%, 83.0%, 83.0%, and 80.2%, respectively. • The CAD system exhibited potential to improve diagnostic specificity and accuracy in underperforming trainees (3 of 6 trainees, 50.0%). This approach may have clinical utility as a training tool to help trainees to gain confidence in diagnoses. \n",
      "  |  https://dx.doi.org/10.1007/s00330-019-06652-4  |  \n",
      "------------------------------------------- \n",
      "10.1158/1078-0432.CCR-19-1376  |  Diagnosis, Treatment, Drug Discovery  |  Diagnosis, Drug Discovery, Treatment  |  Research  |  Research  |    Purpose:  Non-small cell lung cancer (NSCLC) is the most common cause of cancer-related deaths worldwide. There is an unmet need to develop novel clinically relevant models of NSCLC to accelerate identification of drug targets and our understanding of the disease. \n",
      "  Experimental design:  Thirty surgically resected NSCLC primary patient tissue and 35 previously established patient-derived xenograft (PDX) models were processed for organoid culture establishment. Organoids were histologically and molecularly characterized by cytology and histology, exome sequencing, and RNA-sequencing analysis. Tumorigenicity was assessed through subcutaneous injection of organoids in NOD/SCID mice. Organoids were subjected to drug testing using EGFR, FGFR, and MEK-targeted therapies. \n",
      "  Results:  We have identified cell culture conditions favoring the establishment of short-term and long-term expansion of NSCLC organoids derived from primary lung patient and PDX tumor tissue. The NSCLC organoids recapitulated the histology of the patient and PDX tumor. They also retained tumorigenicity, as evidenced by cytologic features of malignancy, xenograft formation, preservation of mutations, copy number aberrations, and gene expression profiles between the organoid and matched parental tumor tissue by whole-exome and RNA sequencing. NSCLC organoid models also preserved the sensitivity of the matched parental tumor to targeted therapeutics, and could be used to validate or discover biomarker-drug combinations. \n",
      "  Conclusions:  Our panel of NSCLC organoids closely recapitulates the genomics and biology of patient tumors, and is a potential platform for drug testing and biomarker validation. \n",
      "  |  http://clincancerres.aacrjournals.org/cgi/pmidlookup?view=long&pmid=31694835  |  \n",
      "------------------------------------------- \n",
      "10.1186/s12859-020-3430-0  |  Diagnosis, Treatment  |  Diagnosis, Treatment  |  Research  |  Research  |    Background:  Methylated RNA immunoprecipitation sequencing (MeRIP-Seq) is a popular sequencing method for studying RNA modifications and, in particular, for N6-methyladenosine (m6A), the most abundant RNA methylation modification found in various species. The detection of enriched regions is a main challenge of MeRIP-Seq analysis, however current tools either require a long time or do not fully utilize features of RNA sequencing such as strand information which could cause ambiguous calling. On the other hand, with more attention on the treatment experiments of MeRIP-Seq, biologists need intuitive evaluation on the treatment effect from comparison. Therefore, efficient and user-friendly software that can solve these tasks must be developed. \n",
      "  Results:  We developed a software named \"model-based analysis and inference of MeRIP-Seq (MoAIMS)\" to detect enriched regions of MeRIP-Seq and infer signal proportion based on a mixture negative-binomial model. MoAIMS is designed for transcriptome immunoprecipitation sequencing experiments; therefore, it is compatible with different RNA sequencing protocols. MoAIMS offers excellent processing speed and competitive performance when compared with other tools. When MoAIMS is applied to studies of m6A, the detected enriched regions contain known biological features of m6A. Furthermore, signal proportion inferred from MoAIMS for m6A treatment datasets (perturbation of m6A methyltransferases) showed a decreasing trend that is consistent with experimental observations, suggesting that the signal proportion can be used as an intuitive indicator of treatment effect. \n",
      "  Conclusions:  MoAIMS is efficient and easy-to-use software implemented in R. MoAIMS can not only detect enriched regions of MeRIP-Seq efficiently but also provide intuitive evaluation on treatment effect for MeRIP-Seq treatment datasets. \n",
      "  |  https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-3430-0  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32171255/  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.healthplace.2019.102243  |  Epidemiology  |  Epidemiology  |  Research  |  Research  |   Spatial lifecourse epidemiology is an interdisciplinary field that utilizes advanced spatial, location-based, and artificial intelligence technologies to investigate the long-term effects of environmental, behavioural, psychosocial, and biological factors on health-related states and events and the underlying mechanisms. With the growing number of studies reporting findings from this field and the critical need for public health and policy decisions to be based on the strongest science possible, transparency and clarity in reporting in spatial lifecourse epidemiologic studies is essential. A task force supported by the International Initiative on Spatial Lifecourse Epidemiology (ISLE) identified a need for guidance in this area and developed a Spatial Lifecourse Epidemiology Reporting Standards (ISLE-ReSt) Statement. The aim is to provide a checklist of recommendations to improve and make more consistent reporting of spatial lifecourse epidemiologic studies. The STrengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement for cohort studies was identified as an appropriate starting point to provide initial items to consider for inclusion. Reporting standards for spatial data and methods were then integrated to form a single comprehensive checklist of reporting recommendations. The strength of our approach has been our international and multidisciplinary team of content experts and contributors who represent a wide range of relevant scientific conventions, and our adherence to international norms for the development of reporting guidelines. As spatial, location-based, and artificial intelligence technologies used in spatial lifecourse epidemiology continue to evolve at a rapid pace, it will be necessary to revisit and adapt the ISLE-ReSt at least every 2-3 years from its release. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1353-8292(19)30635-5  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41746-019-0205-y  |  Treatment  |  Treatment  |  Research  |  Research  |   Complex health problems require multi-strategy, multi-target interventions. We present a method that uses machine learning techniques to choose optimal interventions from a set of possible interventions within a case study aiming to increase General Practitioner (GP) discussions of physical activity (PA) with their patients. Interventions were developed based on a causal loop diagram with 26 GPs across 13 clinics in Geelong, Australia. GPs prioritised eight from more than 80 potential interventions to increase GP discussion of PA with patients. Following a 2-week baseline, a multi-arm bandit algorithm was used to assign optimal strategies to GP clinics with the target outcome being GP PA discussion rates. The algorithm was updated weekly and the process iterated until the more promising strategies emerged (a duration of seven weeks). The top three performing strategies were continued for 3 weeks to improve the power of the hypothesis test of effectiveness for each strategy compared to baseline. GPs recorded a total of 11,176 conversations about PA. GPs identified 15 factors affecting GP PA discussion rates with patients including GP skills and awareness, fragmentation of care and fear of adverse outcomes. The two most effective strategies were correctly identified within seven weeks of the algorithm-based assignment of strategies. These were clinic reception staff providing PA information to patients at check in and PA screening questionnaires completed in the waiting room. This study demonstrates an efficient way to test and identify optimal strategies from multiple possible solutions. \n",
      "  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31993505/  |  \n",
      "------------------------------------------- \n",
      "10.1002/jmri.27104  |  Other  |  Diagnosis  |  Research  |  Research  |    Grant support:  This project was funded by the Research Council of Norway. \n",
      "  Background:  Oxygen uptake through the gastrointestinal tract after oral administration of oxygenated water in humans is not well studied and is debated in the literature. Due to the paramagnetic properties of oxygen and deoxyhemoglobin, MRI as a technique might be able to detect changes in relaxometry values caused by increased oxygen levels in the blood. \n",
      "  Purpose:  To assess whether oxygen dissolved in water is absorbed from the gastrointestinal tract and transported into the bloodstream after oral administration. \n",
      "  Study type:  A randomized, double-blinded, placebo-controlled crossover trial. \n",
      "  Population/subjects:  Thirty healthy male volunteers age 20-35. \n",
      "  Field strength/sequence:  3T/Modified Look-Locker inversion recovery (MOLLI) T<sub>1</sub> -mapping and multi fast field echo (mFFE) T<sub>2</sub> *-mapping. \n",
      "  Assessment:  Each volunteer was scanned in two separate sessions. T<sub>1</sub> and T<sub>2</sub> * maps were acquired repeatedly covering the hepatic portal vein (HPV) and vena cava inferior (VCI, control vein) before and after intake of oxygenated or control water. Assessments were done by placing a region of interest in the HPV and VCI. \n",
      "  Statistical test:  A mixed linear model was performed to the compare control vs. oxygen group. \n",
      "  Results:  Drinking caused a mean 1.6% 95% CI (1.1-2.0% P &lt; 0.001) increase in T<sub>1</sub> of HPV blood and water oxygenation attributed another 0.70% 95% confidence interval (CI) (0.07-1.3% P = 0.028) increase. Oxygenation did not change T<sub>1</sub> in VCI blood. Mean T<sub>2</sub> * increased 9.6% 95% CI (1.7-17.5% P = 0.017) after ingestion of oxygenated water and 1.2% 95% CI (-4.3-6.8% P = 0.661) after ingestion of control water. The corresponding changes in VCI blood were not significant. \n",
      "  Data conclusion:  Ingestion of water caused changes in T<sub>1</sub> and T<sub>2</sub> * of HPV blood compatible with dilution due to water absorption. The effects were enhanced by oxygen. Assessment of oxygen enrichment of HPV blood was not possible due to the dilution effect. \n",
      "  Level of evidence:  2 TECHNICAL EFFICACY STAGE: 2. \n",
      "  |  https://doi.org/10.1002/jmri.27104  |  \n",
      "------------------------------------------- \n",
      "10.2196/17125  |  Diagnosis, Epidemiology  |  Prognosis, Epidemiology  |  Research  |  Research  |    Background:  Coding of underlying causes of death from death certificates is a process that is nowadays undertaken mostly by humans with potential assistance from expert systems, such as the Iris software. It is, consequently, an expensive process that can, in addition, suffer from geospatial discrepancies, thus severely impairing the comparability of death statistics at the international level. The recent advances in artificial intelligence, specifically the rise of deep learning methods, has enabled computers to make efficient decisions on a number of complex problems that were typically considered out of reach without human assistance; they require a considerable amount of data to learn from, which is typically their main limiting factor. However, the CépiDc (Centre d'épidémiologie sur les causes médicales de Décès) stores an exhaustive database of death certificates at the French national scale, amounting to several millions of training examples available for the machine learning practitioner. \n",
      "  Objective:  This article investigates the application of deep neural network methods to coding underlying causes of death. \n",
      "  Methods:  The investigated dataset was based on data contained from every French death certificate from 2000 to 2015, containing information such as the subject's age and gender, as well as the chain of events leading to his or her death, for a total of around 8 million observations. The task of automatically coding the subject's underlying cause of death was then formulated as a predictive modelling problem. A deep neural network-based model was then designed and fit to the dataset. Its error rate was then assessed on an exterior test dataset and compared to the current state-of-the-art (ie, the Iris software). Statistical significance of the proposed approach's superiority was assessed via bootstrap. \n",
      "  Results:  The proposed approach resulted in a test accuracy of 97.8% (95% CI 97.7-97.9), which constitutes a significant improvement over the current state-of-the-art and its accuracy of 74.5% (95% CI 74.0-75.0) assessed on the same test example. Such an improvement opens up a whole field of new applications, from nosologist-level batch-automated coding to international and temporal harmonization of cause of death statistics. A typical example of such an application is demonstrated by recoding French overdose-related deaths from 2000 to 2010. \n",
      "  Conclusions:  This article shows that deep artificial neural networks are perfectly suited to the analysis of electronic health records and can learn a complex set of medical rules directly from voluminous datasets, without any explicit prior knowledge. Although not entirely free from mistakes, the derived algorithm constitutes a powerful decision-making tool that is able to handle structured medical data with an unprecedented performance. We strongly believe that the methods developed in this article are highly reusable in a variety of settings related to epidemiology, biostatistics, and the medical sciences in general. \n",
      "  |  https://medinform.jmir.org/2020/4/e17125/  |  \n",
      "------------------------------------------- \n",
      "10.1002/mp.14129  |  Diagnosis  |  Diagnosis, Prognosis  |  Research  |  Research  |    Purpose:  Image-based breast lesion detection is a powerful clinical diagnosis technology. In recent years, deep learning architectures have achieved considerable success in medical image analysis however, they always require large-scale samples. In mammography images, breast lesions are inconspicuous, multiscale, and have blurred edges. Moreover, few well-labeled images exist. Because of these factors, the detection accuracy of conventional deep learning methods is low. Therefore, we attempted to improve the accuracy of mammary lesion detection by introducing transfer learning (TL) into a deep learning framework for the few-shot learning task and thus provide a method that will further assist physicians in detecting breast lesions. \n",
      "  Methods:  In this paper, we propose a method called \"few-shot learning with deformable convolution for multiscale lesion detection in mammography,\" named FDMNet. Deformable convolution is introduced for enhancing the network's ability to detect lesions, and the sensitivity of the multiscale feature space is reinforced by using a feature pyramid method. Furthermore, by introducing location information in the predictor, the sensitivity of the model to lesion location is also enhanced. The proposed method, through the TL technique that is applied mines the potentially common knowledge of features in the source domain and transfers it into the target domain to improve the accuracy of breast lesion detection in the few-shot learning task. \n",
      "  Results:  On the publicly available datasets for screening mammography CBIS-DDSM and Mini-MIAS, the proposed method performs better than five widely used detection methods. On the CBIS-DDSM dataset, its comprehensive scores, sensitivity, precision, and the mean dice similarity coefficient are 0.911, 0.949, 0.873, and 0.913, respectively, and on the Mini-MIAS dataset, these values are 0.931, 0.966, 0.882, and 0.941, respectively. \n",
      "  Conclusions:  To achieve the few-shot learning required for medical image analysis, the proposed method uses TL to execute feature knowledge transformation and includes deformable convolution to build a feature pyramid structure, which enhances the learning performance of the network for lesions. The results of comparative numerical experiments show that the proposed method outperforms some state-of-the-art methods. \n",
      "  |  https://doi.org/10.1002/mp.14129  |  \n",
      "------------------------------------------- \n",
      "10.20900/jpbs.20200001  |  Treatment, Smart Healthcare  |  Treatment, Smart Healthcare  |  Research  |  Research  |    Background:  The majority of individuals with Opioid Use Disorder (OUD) do not receive any formal substance use treatment. Due to limited engagement and access to traditional treatment, there is increasing evidence that patients with OUDs turn to online social platforms to access peer support and obtain health-related information about addiction and recovery. Interacting with peers before and during recovery is a key component of many evidence-based addiction recovery programs, and may improve self-efficacy and treatment engagement as well as reduce relapse. Commonly-used online social platforms are limited in utility and scalability as an adjunct to addiction treatment; lack effective content moderation (e.g., misinformed advice, maliciousness or \"trolling\"); and lack common security and ethical safeguards inherent to clinical care. \n",
      "  Methods:  This present study will develop a novel, artificial-intelligence (AI) enabled, mobile treatment delivery method that fulfills the need for a robust, secure, technology-based peer support platform to support patients with OUD. Forty adults receiving outpatient buprenorphine treatment for OUD will be asked to pilot a smartphone-based mobile peer support application, the \"Marigold App\", for a duration of six weeks. The program will use (1) a prospective cohort study to obtain text message content and feasibility metrics, and (2) qualitative interviews to evaluate usability and acceptability of the mobile platform. \n",
      "  Anticipated findings and future directions:  The Marigold mobile platform will allow patients to access a tailored chat support group 24/7 as a complement to different forms of clinical OUD treatment. Marigold can keep groups safe and constructive by augmenting chats with AI tools capable of understanding the emotional sentiment in messages, automatically \"flagging\" critical or clinically relevant content. This project will demonstrate the robustness of these AI tools by adapting them to catch OUD-specific \"flags\" in peer messages while also examining the adoptability of the platform itself within OUD patients. \n",
      "  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32149192/  |  \n",
      "------------------------------------------- \n",
      "10.2196/15963  |  Diagnosis  |  Diagnosis, Prognosis  |  Research  |  Research  |    Background:  Bone marrow aspiration and biopsy remain the gold standard for the diagnosis of hematological diseases despite the development of flow cytometry (FCM) and molecular and gene analyses. However, the interpretation of the results is laborious and operator dependent. Furthermore, the obtained results exhibit inter- and intravariations among specialists. Therefore, it is important to develop a more objective and automated analysis system. Several deep learning models have been developed and applied in medical image analysis but not in the field of hematological histology, especially for bone marrow smear applications. \n",
      "  Objective:  The aim of this study was to develop a deep learning model (BMSNet) for assisting hematologists in the interpretation of bone marrow smears for faster diagnosis and disease monitoring. \n",
      "  Methods:  From January 1, 2016, to December 31, 2018, 122 bone marrow smears were photographed and divided into a development cohort (N=42), a validation cohort (N=70), and a competition cohort (N=10). The development cohort included 17,319 annotated cells from 291 high-resolution photos. In total, 20 photos were taken for each patient in the validation cohort and the competition cohort. This study included eight annotation categories: erythroid, blasts, myeloid, lymphoid, plasma cells, monocyte, megakaryocyte, and unable to identify. BMSNet is a convolutional neural network with the YOLO v3 architecture, which detects and classifies single cells in a single model. Six visiting staff members participated in a human-machine competition, and the results from the FCM were regarded as the ground truth. \n",
      "  Results:  In the development cohort, according to 6-fold cross-validation, the average precision of the bounding box prediction without consideration of the classification is 67.4%. After removing the bounding box prediction error, the precision and recall of BMSNet were similar to those of the hematologists in most categories. In detecting more than 5% of blasts in the validation cohort, the area under the curve (AUC) of BMSNet (0.948) was higher than the AUC of the hematologists (0.929) but lower than the AUC of the pathologists (0.985). In detecting more than 20% of blasts, the AUCs of the hematologists (0.981) and pathologists (0.980) were similar and were higher than the AUC of BMSNet (0.942). Further analysis showed that the performance difference could be attributed to the myelodysplastic syndrome cases. In the competition cohort, the mean value of the correlations between BMSNet and FCM was 0.960, and the mean values of the correlations between the visiting staff and FCM ranged between 0.952 and 0.990. \n",
      "  Conclusions:  Our deep learning model can assist hematologists in interpreting bone marrow smears by facilitating and accelerating the detection of hematopoietic cells. However, a detailed morphological interpretation still requires trained hematologists. \n",
      "  |  https://medinform.jmir.org/2020/4/e15963/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32267237/  |  \n",
      "------------------------------------------- \n",
      "10.1055/a-1035-9088  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   <b>Background and study aims</b> Capsule endoscopy (CE) is the preferred method for small bowel (SB) exploration. With a mean number of 50,000 SB frames per video, SBCE reading is time-consuming and tedious (30 to 60 minutes per video). We describe a large, multicenter database named CAD-CAP (Computer-Assisted Diagnosis for CAPsule Endoscopy, CAD-CAP). This database aims to serve the development of CAD tools for CE reading. <b>Materials and methods</b> Twelve French endoscopy centers were involved. All available third-generation SB-CE videos (Pillcam, Medtronic) were retrospectively selected from these centers and deidentified. Any pathological frame was extracted and included in the database. Manual segmentation of findings within these frames was performed by two pre-med students trained and supervised by an expert reader. All frames were then classified by type and clinical relevance by a panel of three expert readers. An automated extraction process was also developed to create a dataset of normal, proofread, control images from normal, complete, SB-CE videos. <b>Results</b> Four-thousand-one-hundred-and-seventy-four SB-CE were included. Of them, 1,480 videos (35 %) containing at least one pathological finding were selected. Findings from 5,184 frames (with their short video sequences) were extracted and delimited: 718 frames with fresh blood, 3,097 frames with vascular lesions, and 1,369 frames with inflammatory and ulcerative lesions. Twenty-thousand normal frames were extracted from 206 SB-CE normal videos. CAD-CAP has already been used for development of automated tools for angiectasia detection and also for two international challenges on medical computerized analysis. \n",
      "  |  http://www.thieme-connect.com/DOI/DOI?10.1055/a-1035-9088  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32118115/  |  \n",
      "------------------------------------------- \n",
      "10.3389/fonc.2020.00093  |  Diagnosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Review  |  Research  |   <b>Background:</b> Neoadjuvant chemotherapy (NAC) is commonly utilized in preoperative treatment for local breast cancer, and it gives high clinical response rates and can result in pathologic complete response (pCR) in 6-25% of patients. In recent years, dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) has been increasingly used to assess the pathological response of breast cancer to NAC. In present analysis, we assess the diagnostic performance of DCE-MRI in evaluating the pathological response of breast cancer to NAC. <b>Materials and Methods:</b> A systematic search in PubMed, the Cochrane Library, and Web of Science for original studies was performed. The Quality Assessment of Diagnostic Accuracy Studies-2 tool was used to assess the methodological quality of the included studies. Patient, study, and imaging characteristics were extracted, and sufficient data to reconstruct 2 × 2 tables were obtained. Data pooling, heterogeneity testing, forest plot construction, meta-regression analysis and sensitivity analysis were performed using Stata version 12.0 (StataCorp LP, College Station, TX). <b>Results:</b> Eighteen studies (969 patients with breast cancer) were included in the present meta-analysis. The pooled sensitivity and specificity of DCE-MRI were 0.80 (95% confidence interval [CI]: 0.70, 0.88) and 0.84 (95% [CI]: 0.79, 0.88), respectively. Meta-regression analysis found no significant factors affecting heterogeneity. Sensitivity analysis showed that studies that set pathological complete response (pCR) (<i>n</i> = 14) as a responder showed a tendency for higher sensitivity compared with those that set pCR and near pCR together (<i>n</i> = 5) as a responder (0.83 vs. 0.72), and studies (<i>n</i> = 14) that used DCE-MRI to early predict the pathological response of breast cancer had a higher sensitivity (0.83 vs. 0.71) and equivalent specificity (0.80 vs. 0.86) compared to studies (<i>n</i> = 5) that assessed the response after NAC completion. <b>Conclusion:</b> Our results indicated that DCE-MRI could be considered an important auxiliary method for evaluating the pathological response of breast cancer to NAC and used as an effective method for dynamically monitoring the efficacy during NAC. DCE-MRI also performed well in predicting the pCR of breast cancer to NAC. However, due to the heterogeneity of the included studies, caution should be exercised in applying our results. \n",
      "  |  https://doi.org/10.3389/fonc.2020.00093  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32117747/  |  \n",
      "------------------------------------------- \n",
      "10.1001/jamanetworkopen.2020.0265  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Importance:  Mammography screening currently relies on subjective human interpretation. Artificial intelligence (AI) advances could be used to increase mammography screening accuracy by reducing missed cancers and false positives. \n",
      "  Objective:  To evaluate whether AI can overcome human mammography interpretation limitations with a rigorous, unbiased evaluation of machine learning algorithms. \n",
      "  Design, setting, and participants:  In this diagnostic accuracy study conducted between September 2016 and November 2017, an international, crowdsourced challenge was hosted to foster AI algorithm development focused on interpreting screening mammography. More than 1100 participants comprising 126 teams from 44 countries participated. Analysis began November 18, 2016. \n",
      "  Main outcomes and measurements:  Algorithms used images alone (challenge 1) or combined images, previous examinations (if available), and clinical and demographic risk factor data (challenge 2) and output a score that translated to cancer yes/no within 12 months. Algorithm accuracy for breast cancer detection was evaluated using area under the curve and algorithm specificity compared with radiologists' specificity with radiologists' sensitivity set at 85.9% (United States) and 83.9% (Sweden). An ensemble method aggregating top-performing AI algorithms and radiologists' recall assessment was developed and evaluated. \n",
      "  Results:  Overall, 144 231 screening mammograms from 85 580 US women (952 cancer positive ≤12 months from screening) were used for algorithm training and validation. A second independent validation cohort included 166 578 examinations from 68 008 Swedish women (780 cancer positive). The top-performing algorithm achieved an area under the curve of 0.858 (United States) and 0.903 (Sweden) and 66.2% (United States) and 81.2% (Sweden) specificity at the radiologists' sensitivity, lower than community-practice radiologists' specificity of 90.5% (United States) and 98.5% (Sweden). Combining top-performing algorithms and US radiologist assessments resulted in a higher area under the curve of 0.942 and achieved a significantly improved specificity (92.0%) at the same sensitivity. \n",
      "  Conclusions and relevance:  While no single AI algorithm outperformed radiologists, an ensemble of AI algorithms combined with radiologist assessment in a single-reader screening environment improved overall accuracy. This study underscores the potential of using machine learning methods for enhancing mammography screening interpretation. \n",
      "  |  https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2020.0265  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32119094/  |  \n",
      "------------------------------------------- \n",
      "10.1007/s00330-020-06856-z  |  Diagnosis, Prognosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Research  |  Research  |    Objectives:  To develop and evaluate the performance of a deep learning-based system for automatic patellar height measurements using knee radiographs. \n",
      "  Methods:  The deep learning-based algorithm was developed with a data set consisting of 1018 left knee radiographs for the prediction of patellar height parameters, specifically the Insall-Salvati index (ISI), Caton-Deschamps index (CDI), modified Caton-Deschamps index (MCDI), and Keerati index (KI). The performance and generalizability of the algorithm were tested with 200 left knee and 200 right knee radiographs, respectively. The intra-class correlation coefficient (ICC), Pearson correlation coefficient, mean absolute difference (MAD), root mean square (RMS), and Bland-Altman plots for predictions by the system were evaluated in comparison with manual measurements as the reference standard. \n",
      "  Results:  Compared with the reference standard, the deep learning-based algorithm showed high accuracy in predicting the ISI, CDI, and KI (left knee ICC = 0.91-0.95, r = 0.84-0.91, MAD = 0.02-0.05, RMS = 0.02-0.07; right knee ICC = 0.87-0.96, r = 0.78-0.92, MAD = 0.02-0.06, RMS = 0.02-0.10), but not the MCDI (left knee ICC = 0.65, r = 0.50, MAD = 0.14, RMS = 0.18; right knee ICC = 0.62, r = 0.47, MAD = 0.15, RMS = 0.20). The performance of the algorithm met or exceeded that of manual determination of ISI, CDI, and KI by radiologists. \n",
      "  Conclusions:  In its current state, the developed system can predict the ISI, CDI, and KI for both left and right knee radiographs as accurately as radiologists. Training the system further with more data would increase its utility in helping radiologists measure patellar height in clinical practice. \n",
      "  Key points:  • Objective and reliable measurement of patellar height parameters is important for clinical diagnosis and the development of a treatment strategy. • Deep learning can be used to create an automatic patellar height measurement system based on knee radiographs. • The deep learning-based patellar height measurement system achieves comparable performance to radiologists in measuring ISI, CDI, and KI. \n",
      "  |  https://dx.doi.org/10.1007/s00330-020-06856-z  |  \n",
      "------------------------------------------- \n",
      "10.3389/fonc.2020.00235  |  Prognosis, Treatment  |  Prognosis, Treatment  |  Research  |  Research  |   <b>Purpose:</b> The majority of patients with low-grade gliomas (LGGs) experience tumor-related epilepsy during the disease course. Our study aimed to build a radiomic prediction model for LGG-related epilepsy type based on magnetic resonance imaging (MRI) data. <b>Methods:</b> A total of 205 cases with LGG-related epilepsy were enrolled in the retrospective study and divided into training and validation cohorts (1:1) according to their surgery time. Seven hundred thirty-four radiomic features were extracted from T2-weighted imaging, including six location features. Pearson correlation coefficient, univariate area under curve (AUC) analysis, and least absolute shrinkage and selection operator regression were adopted to select the most relevant features for the epilepsy type to build a radiomic signature. Furthermore, a novel radiomic nomogram was developed for clinical application using the radiomic signature and clinical variables from all patients. <b>Results:</b> Four MRI-based features were selected from the 734 radiomic features, including one location feature. Good discriminative performances were achieved in both training (AUC = 0.859, 95% CI = 0.787-0.932) and validation cohorts (AUC = 0.839, 95% CI = 0.761-0.917) for the type of epilepsy. The accuracies were 80.4 and 80.6%, respectively. The radiomic nomogram also allowed for a high degree of discrimination. All models presented favorable calibration curves and decision curve analyses. <b>Conclusion:</b> Our results suggested that the MRI-based radiomic analysis may predict the type of LGG-related epilepsy to enable individualized therapy for patients with LGG-related epilepsy. \n",
      "  |  https://doi.org/10.3389/fonc.2020.00235  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32231995/  |  \n",
      "------------------------------------------- \n",
      "10.1007/s11682-019-00252-y  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |   Vascular cognitive impairment, no dementia (VCIND) refers to cognitive deficits associated with underlying vascular causes that are insufficient to confirm a diagnosis of dementia. The default mode network (DMN) is a large-scale brain network of interacting brain regions involved in attention, working memory and executive function. The role of DMN white matter integrity in cognitive deficits of VCIND patients is unclear. Using diffusion tensor imaging (DTI), this study was carried out to investigate white matter microstructural changes in the DMN in VCIND patients and their contributions to cognitive deficits. Thirty-one patients with subcortical VCIND and twenty-two healthy elderly subjects were recruited. All patients underwent neuropsychological assessments and DTI examination. Voxel-based analyses were performed to extract fractional anisotropy (FA) and mean diffusivity (MD) measures in the DMN. Compared with the healthy elderly subjects, patients diagnosed with subcortical VCIND presented with abnormal white matter integrity in several key hubs of the DMN. The severity of damage in the white matter microstructure in the DMN significantly correlated with cognitive dysfunction. Mediation analyses demonstrated that DTI values could account for attention, executive and language impairments, and partly mediated global cognitive dysfunction in the subcortical VCIND patients. DMN integrity is significantly impaired in subcortical VCIND patients. The disrupted DMN connectivity could explain the attention, language and executive dysfunction, which indicates that the white matter integrity of the DMN may be a neuroimaging marker for VCIND. \n",
      "  |  https://dx.doi.org/10.1007/s11682-019-00252-y  |  \n",
      "------------------------------------------- \n",
      "10.1038/s41586-020-2284-y  |  Epidemiology  |  Prognosis, Epidemiology  |  Research  |  Research  |   Sudden, large-scale, and diffuse human migration can amplify localized outbreaks into widespread epidemics.<sup>1-4</sup> Rapid and accurate tracking of aggregate population flows may therefore be epidemiologically informative. Here, we use mobile-phone-data-based counts of 11,478,484 people egressing or transiting through the prefecture of Wuhan between 1 January and 24 January 2020 as they moved to 296 prefectures throughout China. First, we document the efficacy of quarantine in ceasing movement. Second, we show that the distribution of population outflow from Wuhan accurately predicts the relative frequency and geographic distribution of COVID-19 infections through February 19, 2020, across all of China. Third, we develop a spatio-temporal \"risk source\" model that leverages population flow data (which operationalizes risk emanating from epidemic epicenters) to not only forecast confirmed cases, but also to identify high-transmission-risk locales at an early stage. Fourth, we use this risk source model to statistically derive the geographic spread of COVID-19 and the growth pattern based on the population outflow from Wuhan; the model yields a benchmark trend and an index for assessing COVID-19 community transmission risk over time for different locations. This approach can be used by policy-makers in any nation with available data to make rapid and accurate risk assessments and to plan allocation of limited resources ahead of ongoing outbreaks. \n",
      "  |  https://doi.org/10.1038/s41586-020-2284-y  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.brainres.2020.146693  |  Other  |  Diagnosis  |  Research  |  Research  |   A direct measure of spoken lexical processing based on neuroimaging technology would provide us useful information to understand the neural mechanisms underlying speech or auditory language processing. The neural mechanisms of spoken word segmentation for English as a second language (ESL) learners remain elusive. The present study, using functional near-infrared spectroscopy (fNIRS), addresses this issue by measuring hemodynamic responses in the temporo-parietal junction (TPJ) and the prefrontal cortex (PFC) in a word-spotting task, designed with two task conditions (easy vs. difficult). Thirty participants, divided into a high listening proficiency group (HLG) and a low listening proficiency group (LLG), were tested. Results revealed significantly less TPJ activation in the HLG than in the LLG. Further analyses supported this result by showing that activation in the TPJ was in a negative correlation with listening proficiency. This association appears to be related to the more efficient use of processing resources in a bottom-up fashion for accurate and efficient sensory representations in high proficient language learners. In contrast, cortical activation in the PFC increased with listening proficiency and was stronger in the difficult task condition than in the easy task condition, implying that recruitment of top-down cognitive control functions might play a role in word segmentation. Our results suggest that the combination of the functions mediated via bottom-up sensory input processing (demonstrated in the TPJ activation) and top-down cognitive processing (demonstrated in the PFC activation) are crucial for ESL listeners' spoken word segmentation. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0006-8993(20)30049-4  |  \n",
      "------------------------------------------- \n",
      "10.1186/s12864-020-6542-z  |  Other  |  None, Other  |  Research  |  Research  |    Background:  Read coverage of RNA sequencing data reflects gene expression and RNA processing events. Single-cell RNA sequencing (scRNA-seq) methods, particularly \"full-length\" ones, provide read coverage of many individual cells and have the potential to reveal cellular heterogeneity in RNA transcription and processing. However, visualization tools suited to highlighting cell-to-cell heterogeneity in read coverage are still lacking. \n",
      "  Results:  Here, we have developed Millefy, a tool for visualizing read coverage of scRNA-seq data in genomic contexts. Millefy is designed to show read coverage of all individual cells at once in genomic contexts and to highlight cell-to-cell heterogeneity in read coverage. By visualizing read coverage of all cells as a heat map and dynamically reordering cells based on diffusion maps, Millefy facilitates discovery of \"local\" region-specific, cell-to-cell heterogeneity in read coverage. We applied Millefy to scRNA-seq data sets of mouse embryonic stem cells and triple-negative breast cancers and showed variability of transcribed regions including antisense RNAs, 3 <sup>'</sup> UTR lengths, and enhancer RNA transcription. \n",
      "  Conclusions:  Millefy simplifies the examination of cellular heterogeneity in RNA transcription and processing events using scRNA-seq data. Millefy is available as an R package (https://github.com/yuifu/millefy) and as a Docker image for use with Jupyter Notebook (https://hub.docker.com/r/yuifu/datascience-notebook-millefy). \n",
      "  |  https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-6542-z  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32122302/  |  \n",
      "------------------------------------------- \n",
      "10.1089/ast.2019.2129  |  None  |  Diagnosis, Robotics  |  Research  |  Research  |   One of Saturn's largest moons, Enceladus, possesses a vast extraterrestrial ocean (<i>i.e.,</i> exo-ocean) that is increasingly becoming the hotspot of future research initiatives dedicated to the exploration of putative life. Here, a new bio-exploration concept design for Enceladus' exo-ocean is proposed, focusing on the potential presence of organisms across a wide range of sizes (<i>i.e.,</i> from uni- to multicellular and animal-like), according to state-of-the-art sensor and robotic platform technologies used in terrestrial deep-sea research. In particular, we focus on combined direct and indirect life-detection capabilities, based on optoacoustic imaging and passive acoustics, as well as molecular approaches. Such biologically oriented sampling can be accompanied by concomitant geochemical and oceanographic measurements to provide data relevant to exo-ocean exploration and understanding. Finally, we describe how this multidisciplinary monitoring approach is currently enabled in terrestrial oceans through cabled (fixed) observatories and their related mobile multiparametric platforms (<i>i.e.,</i> Autonomous Underwater and Remotely Operated Vehicles, as well as crawlers, rovers, and biomimetic robots) and how their modified design can be used for exo-ocean exploration. \n",
      "  |  https://www.liebertpub.com/doi/full/10.1089/ast.2019.2129?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.2196/15411  |  Prognosis  |  Prognosis  |  Research  |  Research  |    Background:  Preeclampsia and intrauterine growth restriction are placental dysfunction-related disorders (PDDs) that require a referral decision be made within a certain time period. An appropriate prediction model should be developed for these diseases. However, previous models did not demonstrate robust performances and/or they were developed from datasets with highly imbalanced classes. \n",
      "  Objective:  In this study, we developed a predictive model of PDDs by machine learning that uses features at 24-37 weeks' gestation, including maternal characteristics, uterine artery (UtA) Doppler measures, soluble fms-like tyrosine kinase receptor-1 (sFlt-1), and placental growth factor (PlGF). \n",
      "  Methods:  A public dataset was taken from a prospective cohort study that included pregnant women with PDDs (66/95, 69%) and a control group (29/95, 31%). Preliminary selection of features was based on a statistical analysis using SAS 9.4 (SAS Institute). We used Weka (Waikato Environment for Knowledge Analysis) 3.8.3 (The University of Waikato, Hamilton, NZ) to automatically select the best model using its optimization algorithm. We also manually selected the best of 23 white-box models. Models, including those from recent studies, were also compared by interval estimation of evaluation metrics. We used the Matthew correlation coefficient (MCC) as the main metric. It is not overoptimistic to evaluate the performance of a prediction model developed from a dataset with a class imbalance. Repeated 10-fold cross-validation was applied. \n",
      "  Results:  The classification via regression model was chosen as the best model. Our model had a robust MCC (.93, 95% CI .87-1.00, vs .64, 95% CI .57-.71) and specificity (100%, 95% CI 100-100, vs 90%, 95% CI 90-90) compared to each metric of the best models from recent studies. The sensitivity of this model was not inferior (95%, 95% CI 91-100, vs 100%, 95% CI 92-100). The area under the receiver operating characteristic curve was also competitive (0.970, 95% CI 0.966-0.974, vs 0.987, 95% CI 0.980-0.994). Features in the best model were maternal weight, BMI, pulsatility index of the UtA, sFlt-1, and PlGF. The most important feature was the sFlt-1/PlGF ratio. This model used an M5P algorithm consisting of a decision tree and four linear models with different thresholds. Our study was also better than the best ones among recent studies in terms of the class balance and the size of the case class (66/95, 69%, vs 27/239, 11.3%). \n",
      "  Conclusions:  Our model had a robust predictive performance. It was also developed to deal with the problem of a class imbalance. In the context of clinical management, this model may improve maternal mortality and neonatal morbidity and reduce health care costs. \n",
      "  |  https://doi.org/10.2196/15411  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.drugalcdep.2019.107716  |  Other  |  None, Other  |  Research  |  Research  |    Background:  Data from controlled laboratory experiments in adults indicate that the subjective effects of cannabis vary by administration method (e.g., combustible, vaporized). Whether the subjective effects of cannabis experienced in the natural ecology and among adolescents differ by cannabis administration method is unknown. In this observational study, adolescents' retrospective reports of subjective effects after combustible, edible, and vaporized cannabis use were examined. \n",
      "  Methods:  Students from ten public schools in Los Angeles, CA, USA (M[SD] age = 16.1 [.43] years) who reported past 6-month use of combustible, edible, or vaporized cannabis (N = 584) were surveyed on subjective effects experienced after use (yes/no). They were provided with a 12 item self-report checklist of six positive (e.g., relaxed, energetic) and six negative (e.g., drowsy, lazy) subjective effects. For each method of administration, affirmative responses were summed in positive (range: 0-6) and negative (range: 0-6) effect composite scores. \n",
      "  Results:  Generalized estimating equations adjusted for demographics and recent cannabis use revealed a graded pattern of differences in positive subjective effects across products, with highest scores for combustible (M[SD] = 3.98[1.76]), followed by edible (M[SD] = 3.58 [2.04]) and vaporized (M[SD] = 3.11 [2.21]) cannabis (all pairwise cross-product contrasts p &lt; .01). Mean negative effect score was highest for edible (M[SD] = 2.27 [1.95]), followed by combustible (M[SD] = 1.94 [1.66]), and vaporized (M[SD] = 1.34 [1.73]) cannabis, respectively (all pairwise contrasts p &lt; .02). \n",
      "  Conclusion:  Adolescents' reports of subjective effects varied across cannabis administration methods. Combustible cannabis' more desirable subjective effects profile might be indicative of higher abuse liability. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0376-8716(19)30493-4  |  \n",
      "------------------------------------------- \n",
      "10.3390/s20092489  |  None  |  Diagnosis  |  Research  |  Research  |   Under the conditions of low flow rate and strong noise, the current electromagnetic flowmeter (EMF) cannot satisfy the requirement for measurement or separate the actual flow signal and interference signal accurately. Correlation detection technology can reduce the bandwidth and suppress noise effectively using the periodic transmission of signal and noise randomness. As for the problem that the current anti-interference technology cannot suppress noise effectively, the noise and interference of the electromagnetic flowmeter were analyzed in this paper, and a design of the electromagnetic flowmeter based on differential correlation detection was proposed. Then, in order to verify the feasibility of the electromagnetic flow measurement system based on differential correlation, an experimental platform for the comparison between standard flow and measured flow was established and a verification experiment was carried out under special conditions and with flow calibration measurements. Finally, the data obtained in the experiment were analyzed. The research result showed that an electromagnetic flowmeter based on differential correlation detection satisfies the need for measurement completely. The lower limit of the flow rate of the electromagnetic flowmeter based on the differential correlation principle could reach 0.084 m/s. Under strong external interferences, the electromagnetic flowmeter based on differential correlation had a fluctuation range in output value of only 10 mV. This shows that the electromagnetic flowmeter based on the differential correlation principle has unique advantages in measurements taken under the conditions of strong noise, slurry flow, and low flow rate. \n",
      "  |  http://www.mdpi.com/resolver?pii=s20092489  |  \n",
      "------------------------------------------- \n",
      "10.1002/ece3.6147  |  None  |  Diagnosis  |  Research  |  Research  |   Ecological camera traps are increasingly used by wildlife biologists to unobtrusively monitor an ecosystems animal population. However, manual inspection of the images produced is expensive, laborious, and time-consuming. The success of deep learning systems using camera trap images has been previously explored in preliminary stages. These studies, however, are lacking in their practicality. They are primarily focused on extremely large datasets, often millions of images, and there is little to no focus on performance when tasked with species identification in new locations not seen during training. Our goal was to test the capabilities of deep learning systems trained on camera trap images using modestly sized training data, compare performance when considering unseen background locations, and quantify the gradient of lower bound performance to provide a guideline of data requirements in correspondence to performance expectations. We use a dataset provided by Parks Canada containing 47,279 images collected from 36 unique geographic locations across multiple environments. Images represent 55 animal species and human activity with high-class imbalance. We trained, tested, and compared the capabilities of six deep learning computer vision networks using transfer learning and image augmentation: DenseNet201, Inception-ResNet-V3, InceptionV3, NASNetMobile, MobileNetV2, and Xception. We compare overall performance on \"trained\" locations where DenseNet201 performed best with 95.6% top-1 accuracy showing promise for deep learning methods for smaller scale research efforts. Using trained locations, classifications with &lt;500 images had low and highly variable recall of 0.750 ± 0.329, while classifications with over 1,000 images had a high and stable recall of 0.971 ± 0.0137. Models tasked with classifying species from untrained locations were less accurate, with DenseNet201 performing best with 68.7% top-1 accuracy. Finally, we provide an open repository where ecologists can insert their image data to train and test custom species detection models for their desired ecological domain. \n",
      "  |  https://doi.org/10.1002/ece3.6147  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32274005/  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.cmpb.2019.105162  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background and objective:  In most patients presenting with respiratory symptoms, the findings of chest radiography play a key role in the diagnosis, management, and follow-up of the disease. Consolidation is a common term in radiology, which indicates focally increased lung density. When the alveolar structures become filled with pus, fluid, blood cells or protein subsequent to a pulmonary pathological process, it may result in different types of lung opacity in chest radiograph. This study aims at detecting consolidations in chest x-ray radiographs, with a certain precision, using artificial intelligence and especially Deep Convolutional Neural Networks to assist radiologist for better diagnosis. \n",
      "  Methods:  Medical image datasets usually are relatively small to be used for training a Deep Convolutional Neural Network (DCNN), so transfer learning technique with well-known DCNNs pre-trained with ImageNet dataset are used to improve the accuracy of the models. ImageNet feature space is different from medical images and in the other side, the well-known DCNNs are designed to achieve the best performance on ImageNet. Therefore, they cannot show their best performance on medical images. To overcome this problem, we designed a problem-based architecture which preserves the information of images for detecting consolidation in Pediatric Chest X-ray dataset. We proposed a three-step pre-processing approach to enhance generalization of the models. To demonstrate the correctness of numerical results, an occlusion test is applied to visualize outputs of the model and localize the detected appropriate area. A different dataset as an extra validation is used in order to investigate the generalization of the proposed model. \n",
      "  Results:  The best accuracy to detect consolidation is 94.67% obtained by our problem based architecture for the understudy dataset which outperforms the previous works and the other architectures. \n",
      "  Conclusions:  The designed models can be employed as computer aided diagnosis tools in real practice. We critically discussed the datasets and the previous works based on them and show that without some considerations the results of them may be misleading. We believe, the output of AI should be only interpreted as focal consolidation. The clinical significance of the finding can not be interpreted without integration of clinical data. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)30696-0  |  \n",
      "------------------------------------------- \n",
      "10.1111/den.13688  |  Diagnosis  |  Diagnosis, Prognosis  |  Research  |  Research  |    Objectives:  Detecting early gastric cancer is difficult, and it may even be overlooked by experienced endoscopists. Recently, artificial intelligence based on deep learning through convolutional neural networks (CNNs) has enabled significant advancements in the field of gastroenterology. However, it remains unclear whether a CNN can outperform endoscopists. In this study, we evaluated whether the performance of a CNN in detecting early gastric cancer is better than that of endoscopists. \n",
      "  Methods:  The CNN was constructed using 13,584 endoscopic images from 2,639 lesions of gastric cancer. Subsequently, its diagnostic ability was compared to that of 67 endoscopists using an independent test dataset (2,940 images from 140 cases). \n",
      "  Results:  The average diagnostic time for analyzing 2,940 test endoscopic images by the CNN and endoscopists were 45.5 ± 1.8 s and 173.0 ± 66.0 min, respectively. The sensitivity, specificity, and positive and negative predictive values for the CNN were 58.4%, 87.3%, 26.0%, and 96.5%, respectively. These values for the 67 endoscopists were 31.9%, 97.2%, 46.2%, and 94.9%, respectively. The CNN had a significantly higher sensitivity than the endoscopists (by 26.5%; 95% confidence interval, 14.9-32.5%). \n",
      "  Conclusion:  The CNN detected more early gastric cancer cases in a shorter time than the endoscopists. The CNN needs further training to achieve higher diagnostic accuracy. However, a diagnostic support tool for gastric cancer using a CNN will be realized in the near future. \n",
      "  |  https://doi.org/10.1111/den.13688  |  \n",
      "------------------------------------------- \n",
      "10.3390/s20010293  |  None  |  Treatment, Smart Healthcare  |  Research  |  Research  |   To generate indoor as-built building information models (AB BIMs) automatically and economically is a great technological challenge. Many approaches have been developed to address this problem in recent years, but it is far from being settled, particularly for the point cloud segmentation and the extraction of the relationship among different elements due to the complicated indoor environment. This is even more difficult for the low-quality point cloud generated by low-cost scanning equipment. This paper proposes an automatic as-built BIMs generation framework that transforms the noisy 3D point cloud produced by a low-cost RGB-D sensor (about 708 USD for data collection equipment, 379 USD for the Structure sensor and 329 USD for iPad) to the as-built BIMs, without any manual intervention. The experiment results show that the proposed method has competitive robustness and accuracy, compared to the high-quality Terrestrial Lidar System (TLS), with the element extraction accuracy of 100%, mean dimension reconstruction accuracy of 98.6% and mean area reconstruction accuracy of 93.6%. Also, the proposed framework makes the BIM generation workflows more efficient in both data collection and data processing. In the experiments, the time consumption of data collection for a typical room, with an area of 45-67 m 2 , is reduced to 4-6 min with an RGB-D sensor from 50-60 min with TLS. The processing time to generate BIM models is about half minutes automatically, from around 10 min with a conventional semi-manual method. \n",
      "  |  http://www.mdpi.com/resolver?pii=s20010293  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31948010/  |  \n",
      "------------------------------------------- \n",
      "10.1097/MLR.0000000000001221  |  Treatment  |  Diagnosis, Treatment  |  Research  |  Research  |    Objective:  Experts cautioned that patients affected by the November 2010 withdrawal of the opioid analgesic propoxyphene might receive riskier prescriptions. To explore this, we compared drug receipts and outcomes among propoxyphene users before and aftermarket withdrawal. \n",
      "  Study design:  Using OptumLabs data, we studied 3 populations: commercial, Medicare Advantage (MA) aged (age 65+ y) and MA disabled (age below 65 y) enrollees. The exposed enrollees received propoxyphene in the 3 months before market withdrawal (n=13,622); historical controls (unexposed) received propoxyphene 1 year earlier (n=9971). Regression models estimated daily milligrams morphine equivalent (MME), daily prescription acetaminophen dose, potentially toxic acetaminophen doses, nonopioid prescription analgesics receipt, emergency room visits, and diagnosed falls, motor vehicle accidents, and hip fractures. \n",
      "  Principal findings:  Aged MA enrollees illustrate the experience of all 3 populations examined. Following the market withdrawal, propoxyphene users in the exposed cohort experienced an abrupt decline of 69% in average daily MME, compared with a 14% decline in the unexposed. Opioids were discontinued by 34% of the exposed cohort and 18% of the unexposed. Tramadol and hydrocodone were the most common opioids substituted for propoxyphene. The proportion of each group receiving ≥4 g of prescription acetaminophen per day decreased from 12% to 2% in the exposed group but increased from 6% to 8% among the unexposed. Adverse events were rare and not significantly different in exposed versus unexposed groups. \n",
      "  Conclusions:  After propoxyphene market withdrawal, many individuals experienced abrupt discontinuation of opioids. Policymakers might consider supporting appropriate treatment transitions and monitoring responses following drug withdrawals. \n",
      "  |  http://dx.doi.org/10.1097/MLR.0000000000001221  |  \n",
      "------------------------------------------- \n",
      "10.1111/nyas.14320  |  Other  |  None, Other  |  Review  |  Review  |   Visual perception involves the rapid formation of a coarse image representation at the onset of visual processing, which is iteratively refined by late computational processes. These early versus late time windows approximately map onto feedforward and feedback processes, respectively. State-of-the-art convolutional neural networks, the main engine behind recent machine vision successes, are feedforward architectures. Their successes and limitations provide critical information regarding which visual tasks can be solved by purely feedforward processes and which require feedback mechanisms. We provide an overview of recent work in cognitive neuroscience and machine vision that highlights the possible role of feedback processes for both visual recognition and beyond. We conclude by discussing important open questions for future research. \n",
      "  |  https://doi.org/10.1111/nyas.14320  |  \n",
      "------------------------------------------- \n",
      "PMID:32355515  |  Prognosis, Treatment  |  Prognosis, Treatment  |  Research  |  Research  |   Colorectal cancer (CRC) is one of the most common malignancies, with varying prognoses and a high mortality. There is an urgent need to establish a new prediction model to predict the survival risk of CRC patients. The long non-coding RNAs (lncRNAs) expression profiles and corresponding clinical information of CRC patients were obtained from The Cancer Genome Atlas, TCGA. We identified a total of 1,176 lncRNAs differentially expressed between 480 CRC and 41 normal tissues. In the training test, we combined these differentially expressed lncRNAs with overall survival of CRC patients. Six lncRNAs (AL356270.1, LINC02257, AC020891.2, LINC01485, AC083967.1 and RBAKDN) were finally screened out by using LASSO regression mode to establish a novel prediction model as a prognostic indicator for CRC patients. The area under the curve (AUC) of 3- and 5-year ROC analysis in CRC were 0.6923 and 0.7328 for training set, and were 0.6803 and 0.7035 for testing set, respectively. K-M analysis revealed a significant difference between high risk and low risk in the training set (<i>P</i>-value = 5.0e-05) and testing set (<i>P</i>-value = 0.00052), respectively. Our study shows that the six lncRNAs model can improve the survival prediction mechanism of patients with CRC and provide help for patients through personalized treatment. \n",
      "  |  None  |  \n",
      "------------------------------------------- \n",
      "10.1002/jum.15071  |  Treatment  |  Diagnosis, Treatment  |  Research  |  Research  |    Objectives:  To explore the value of ultrasomics in temporal monitoring of tumor changes in response to gene therapy in hepatocellular carcinoma compared with methods according to the Response Evaluation Criteria in Solid Tumors (RECIST) and modified RECIST (mRECIST). \n",
      "  Methods:  Hepatocellular carcinoma-bearing mice were injected intratumorally with microRNA-122 (miR-122) mimics and an miR-122 negative control in the treatment and control groups, respectively. The injections were performed every 3 days for 5 times (on days 0, 3, 6, 9, and 12). Before each injection and at the experiment ending, 2-dimensional ultrasound imaging was performed for tumor size measurement with RECIST and computing a quantitative imaging analysis with ultrasomics. To analyze the tumor perfusion by mRECIST, perfusion parameters were analyzed offline based on dynamic contrast-enhanced ultrasound image videos using SonoLiver software (TomTec, Unterschleissheim, Germany) on day 13. Tumor miR-122 expression was then analyzed by real-time reverse transcription-polymerase chain reaction experiments. \n",
      "  Results:  Tumors in mice treated with miR-122 mimics demonstrated a mean ± SD 763- ± 60-fold increase in miR-122 levels compared with tumors in the control group. With RECIST, a significant therapeutic response evaluated by tumor size changes was detected after day 9 (days 9, 12, and 13; P &lt; .001). With mRECIST, no parameters showed significant differences (P &gt; .05). Significant different features of the 2-dimensional ultrasound images between the groups were detected by the ultrasomics analysis, and the model could be successfully built. The ultrasomics score values between the groups were statistically significant after day 6 (days 6, 9, 12, and 13; P &lt; .05). \n",
      "  Conclusions:  Ultrasomics revealed significant changes after the second injection of miR-122, showing the potential as an important imaging biomarker for gene therapy. \n",
      "  |  https://doi.org/10.1002/jum.15071  |  \n",
      "------------------------------------------- \n",
      "10.1158/2326-6066.CIR-19-0521  |  Treatment  |  Treatment  |  Research  |  Research  |   CD8<sup>+</sup> T cells can be polarized into several different subsets as defined by the cytokines they produce and the transcription factors that govern their differentiation. Here, we identified the polarizing conditions to induce an IL22-producing CD8<sup>+</sup> Tc22 subset, which is dependent on IL6 and the aryl hydrocarbon receptor transcription factor. Further characterization showed that this subset was highly cytolytic and expressed a distinct cytokine profile and transcriptome relative to other subsets. In addition, polarized Tc22 were able to control tumor growth as well as, if not better than, the traditional IFNγ-producing Tc1 subset. Tc22s were also found to infiltrate the tumors of human patients with ovarian cancer, comprising up to approximately 30% of expanded CD8<sup>+</sup> tumor-infiltrating lymphocytes (TIL). Importantly, IL22 production in these CD8<sup>+</sup> TILs correlated with improved recurrence-free survival. Given the antitumor properties of Tc22 cells, it may be prudent to polarize T cells to the Tc22 lineage when using chimeric antigen receptor (CAR)-T or T-cell receptor (TCR) transduction-based immunotherapies. \n",
      "  |  http://cancerimmunolres.aacrjournals.org/cgi/pmidlookup?view=long&pmid=31964625  |  \n",
      "------------------------------------------- \n",
      "10.4070/kcj.2019.0105  |  Prognosis  |  Prognosis, Smart Healthcare  |  Research  |  Research  |    Background and objectives:  We aim to explore the additional discriminative accuracy of a deep learning (DL) algorithm using repeated-measures data for identifying people at high risk for cardiovascular disease (CVD), compared to Cox hazard regression. \n",
      "  Methods:  Two CVD prediction models were developed from National Health Insurance Service-Health Screening Cohort (NHIS-HEALS): a Cox regression model and a DL model. Performance of each model was assessed in the internal and 2 external validation cohorts in Koreans (National Health Insurance Service-National Sample Cohort; NHIS-NSC) and in Europeans (Rotterdam Study). A total of 412,030 adults in the NHIS-HEALS; 178,875 adults in the NHIS-NSC; and the 4,296 adults in Rotterdam Study were included. \n",
      "  Results:  Mean ages was 52 years (46% women) and there were 25,777 events (6.3%) in NHIS-HEALS during the follow-up. In internal validation, the DL approach demonstrated a C-statistic of 0.896 (95% confidence interval, 0.886-0.907) in men and 0.921 (0.908-0.934) in women and improved reclassification compared with Cox regression (net reclassification index [NRI], 24.8% in men, 29.0% in women). In external validation with NHIS-NSC, DL demonstrated a C-statistic of 0.868 (0.860-0.876) in men and 0.889 (0.876-0.898) in women, and improved reclassification compared with Cox regression (NRI, 24.9% in men, 26.2% in women). In external validation applied to the Rotterdam Study, DL demonstrated a C-statistic of 0.860 (0.824-0.897) in men and 0.867 (0.830-0.903) in women, and improved reclassification compared with Cox regression (NRI, 36.9% in men, 31.8% in women). \n",
      "  Conclusions:  A DL algorithm exhibited greater discriminative accuracy than Cox model approaches. \n",
      "  Trial registration:  ClinicalTrials.gov Identifier: <a href=\"http://clinicaltrials.gov/show/NCT02931500\" title=\"See in ClinicalTrials.gov\">NCT02931500</a>. \n",
      "  |  https://e-kcj.org/DOIx.php?id=10.4070/kcj.2019.0105  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31456363/  |  \n",
      "------------------------------------------- \n",
      "10.1186/s12916-020-01563-4  |  Smart Healthcare, Diagnosis, Treatment  |  Diagnosis, Treatment, Smart Healthcare  |  Research  |  Research  |    Background:  Healthcare represents a paradox. While change is everywhere, performance has flatlined: 60% of care on average is in line with evidence- or consensus-based guidelines, 30% is some form of waste or of low value, and 10% is harm. The 60-30-10 Challenge has persisted for three decades. \n",
      "  Main body:  Current top-down or chain-logic strategies to address this problem, based essentially on linear models of change and relying on policies, hierarchies, and standardisation, have proven insufficient. Instead, we need to marry ideas drawn from complexity science and continuous improvement with proposals for creating a deep learning health system. This dynamic learning model has the potential to assemble relevant information including patients' histories, and clinical, patient, laboratory, and cost data for improved decision-making in real time, or close to real time. If we get it right, the learning health system will contribute to care being more evidence-based and less wasteful and harmful. It will need a purpose-designed digital backbone and infrastructure, apply artificial intelligence to support diagnosis and treatment options, harness genomic and other new data types, and create informed discussions of options between patients, families, and clinicians. While there will be many variants of the model, learning health systems will need to spread, and be encouraged to do so, principally through diffusion of innovation models and local adaptations. \n",
      "  Conclusion:  Deep learning systems can enable us to better exploit expanding health datasets including traditional and newer forms of big and smaller-scale data, e.g. genomics and cost information, and incorporate patient preferences into decision-making. As we envisage it, a deep learning system will support healthcare's desire to continually improve, and make gains on the 60-30-10 dimensions. All modern health systems are awash with data, but it is only recently that we have been able to bring this together, operationalised, and turned into useful information by which to make more intelligent, timely decisions than in the past. \n",
      "  |  None  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.cmpb.2020.105475  |  Diagnosis  |  Diagnosis  |  Research  |  Research  |    Background and objective:  Skin cancer is among the most common cancer types in the white population and consequently computer aided methods for skin lesion classification based on dermoscopic images are of great interest. A promising approach for this uses transfer learning to adapt pre-trained convolutional neural networks (CNNs) for skin lesion diagnosis. Since pre-training commonly occurs with natural images of a fixed image resolution and these training images are usually significantly smaller than dermoscopic images, downsampling or cropping of skin lesion images is required. This however may result in a loss of useful medical information, while the ideal resizing or cropping factor of dermoscopic images for the fine-tuning process remains unknown. \n",
      "  Methods:  We investigate the effect of image size for skin lesion classification based on pre-trained CNNs and transfer learning. Dermoscopic images from the International Skin Imaging Collaboration (ISIC) skin lesion classification challenge datasets are either resized to or cropped at six different sizes ranging from 224 × 224 to 450 × 450. The resulting classification performance of three well established CNNs, namely EfficientNetB0, EfficientNetB1 and SeReNeXt-50 is explored. We also propose and evaluate a multi-scale multi-CNN (MSM-CNN) fusion approach based on a three-level ensemble strategy that utilises the three network architectures trained on cropped dermoscopic images of various scales. \n",
      "  Results:  Our results show that image cropping is a better strategy compared to image resizing delivering superior classification performance at all explored image scales. Moreover, fusing the results of all three fine-tuned networks using cropped images at all six scales in the proposed MSM-CNN approach boosts the classification performance compared to a single network or a single image scale. On the ISIC 2018 skin lesion classification challenge test set, our MSM-CNN algorithm yields a balanced multi-class accuracy of 86.2% making it the currently second ranked algorithm on the live leaderboard. \n",
      "  Conclusions:  We confirm that the image size has an effect on skin lesion classification performance when employing transfer learning of CNNs. We also show that image cropping results in better performance compared to image resizing. Finally, a straightforward ensembling approach that fuses the results from images cropped at six scales and three fine-tuned CNNs is shown to lead to the best classification performance. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0169-2607(19)31146-0  |  \n",
      "------------------------------------------- \n",
      "10.2196/17279  |  Smart Healthcare  |  Treatment, Smart Healthcare  |  Research  |  Research  |    Background:  Interprofessional team training is needed to improve nurse-physician communication skills that are lacking in clinical practice. Using simulations has proven to be an effective learning approach for team training. Yet, it has logistical constraints that call for the exploration of virtual environments in delivering team training. \n",
      "  Objective:  This study aimed to evaluate a team training program using virtual reality vs conventional live simulations on medical and nursing students' communication skill performances and teamwork attitudes. \n",
      "  Methods:  In June 2018, the authors implemented nurse-physician communication team training using communication tools. A randomized controlled trial study was conducted with 120 undergraduate medical and nursing students who were randomly assigned to undertake team training using virtual reality or live simulations. The participants from both groups were tested on their communication performances through team-based simulation assessments. Their teamwork attitudes were evaluated using interprofessional attitude surveys that were administered before, immediately after, and 2 months after the study interventions. \n",
      "  Results:  The team-based simulation assessment revealed no significant differences in the communication performance posttest scores (P=.29) between the virtual and simulation groups. Both groups reported significant increases in the interprofessional attitudes posttest scores from the baseline scores, with no significant differences found between the groups over the 3 time points. \n",
      "  Conclusions:  Our study outcomes did not show an inferiority of team training using virtual reality when compared with live simulations, which supports the potential use of virtual reality to substitute conventional simulations for communication team training. Future studies can leverage the use of artificial intelligence technology in virtual reality to replace costly human-controlled facilitators to achieve better scalability and sustainability of team-based training in interprofessional education. \n",
      "  Trial registration:  ClinicalTrials.gov <a href=\"http://clinicaltrials.gov/show/NCT04330924\" title=\"See in ClinicalTrials.gov\">NCT04330924</a>; https://clinicaltrials.gov/ct2/show/NCT04330924. \n",
      "  |  https://www.jmir.org/2020/4/e17279/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32267235/  |  \n",
      "------------------------------------------- \n",
      "10.1002/1878-0261.12635  |  Prognosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Research  |  Research  |   In breast cancer (BC), the presence of cancer stem cells (CSCs) has been related to relapse, metastasis, and radioresistance. Radiotherapy (RT) is an extended BC treatment, but is not always effective. CSCs have several mechanisms of radioresistance in place, and some miRNAs are involved in the cellular response to ionizing radiation (IR). Here, we studied how IR affects the expression of miRNAs related to stemness in different molecular BC subtypes. Exposition of BC cells to radiation doses of 2, 4, or 6 Gy affected their phenotype, functional characteristics, pluripotency gene expression, and in vivo tumorigenic capacity. This held true for various molecular subtypes of BC cells (classified by ER, PR and HER-2 status), and for BC cells either plated in monolayer, or being in suspension as mammospheres. However, the effect of IR on the expression of eight stemness- and radioresistance-related miRNAs (miR-210, miR-10b, miR-182, miR-142, miR-221, miR-21, miR-93, miR-15b) varied, depending on cell line subpopulation and clinicopathological features of BC patients. Therefore, clinicopathological features and, potentially also, chemotherapy regimen should be both taken into consideration, for determining a potential miRNA signature by liquid biopsy in BC patients treated with RT. Personalized and precision RT dosage regimes could improve the prognosis, treatment, and survival of BC patients. \n",
      "  |  https://doi.org/10.1002/1878-0261.12635  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31930680/  |  \n",
      "------------------------------------------- \n",
      "10.3390/s20092460  |  None  |  None, Other  |  Research  |  Research  |   Leaf area index (LAI) is an important biophysical parameter, which can be effectively applied in the estimation of vegetation growth status. At present, amounts of studies just focused on the LAI estimation of a single plant type, while plant types are usually mixed rather than single distribution. In this study, the suitability of GF-1 data for multi-species LAI estimation was evaluated by using Gaussian process regression (GPR), and a look-up table (LUT) combined with a PROSAIL radiative transfer model. Then, the performance of the LUT and GPR for multi-species LAI estimation was analyzed in term of 15 different band combinations and 10 published vegetation indices (VIs). Lastly, the effect of the different band combinations and published VIs on the accuracy of LAI estimation was discussed. The results indicated that GF-1 data exhibited a good potential for multi-species LAI retrieval. Then, GPR exhibited better performance than that of LUT for multi-species LAI estimation. What is more, modified soil adjusted vegetation index (MSAVI) was selected based on the GPR algorithm for multi-species LAI estimation with a lower root mean squared error (RMSE = 0.6448 m<sup>2</sup>/m<sup>2</sup>) compared to other band combinations and VIs. Then, this study can provide guidance for multi-species LAI estimation. \n",
      "  |  http://www.mdpi.com/resolver?pii=s20092460  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.canrad.2020.01.011  |  Diagnosis, Prognosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Review  |  Review  |    Purpose:  Radiomics are a set of methods used to leverage medical imaging and extract quantitative features that can characterize a patient's phenotype. All modalities can be used with several different software packages. Specific informatics methods can then be used to create meaningful predictive models. In this review, we will explain the major steps of a radiomics analysis pipeline and then present the studies published in the context of radiation therapy. \n",
      "  Methods:  A literature review was performed on Medline using the search engine PubMed. The search strategy included the search terms \"radiotherapy\", \"radiation oncology\" and \"radiomics\". The search was conducted in July 2019 and reference lists of selected articles were hand searched for relevance to this review. \n",
      "  Results:  A typical radiomics workflow always includes five steps: imaging and segmenting, data curation and preparation, feature extraction, exploration and selection and finally modeling. In radiation oncology, radiomics studies have been published to explore different clinical outcome in lung (n=5), head and neck (n=5), esophageal (n=3), rectal (n=3), pancreatic (n=2) cancer and brain metastases (n=2). The quality of these retrospective studies is heterogeneous and their results have not been translated to the clinic. \n",
      "  Conclusion:  Radiomics has a great potential to predict clinical outcome and better personalize treatment. But the field is still young and constantly evolving. Improvement in bias reduction techniques and multicenter studies will hopefully allow more robust and generalizable models. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1278-3218(20)30071-8  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.actbio.2020.02.007  |  Prognosis, Treatment  |  Prognosis, Treatment  |  Research  |  Research  |   Throughout the process of aging, dynamic changes of bone material, micro- and macro-architecture result in a loss of strength and therefore in an increased likelihood of fragility fractures. To date, precise contributions of age-related changes in bone (re)modeling and (de)mineralization dynamics to this fragility increase are not completely understood. Here, we present an image-based deep learning approach to quantitatively describe the effects of short-term aging and adaptive response to cyclic loading applied to proximal mouse tibiae and fibulae. Our approach allowed us to perform an end-to-end age prediction based on μCT imaging to determine the dynamic biological process of aging during a two week period, therefore permitting short-term bone aging analysis with 95% accuracy in predicting time points. In a second application, our deep learning analysis reveals that two weeks of in vivo mechanical loading are associated with an underlying rejuvenating effect of 5 days. Additionally, by quantitatively analyzing the learning process, we could, for the first time, identify the localization of the age-relevant encoded information and demonstrate 89% load-induced similarity of these locations in the loaded tibia with younger control bones. These data therefore suggest that our method enables identifying a general prognostic phenotype of a certain skeletal age as well as a temporal and localized loading-treatment effect on this apparent skeletal age for the studied mouse tibia and fibula. Future translational applications of this method may provide an improved decision-support method for osteoporosis treatment at relatively low cost. STATEMENT OF SIGNIFICANCE: Bone is a highly complex and dynamic structure that undergoes changes during the course of aging as well as in response to external stimuli, such as loading. Automatic assessment of \"age\" and \"state\" of the bone may lead to early prognosis of deceases such as osteoporosis and enables evaluating the effects of certain treatments. Here, we present an artificial intelligence-based method capable of automatically predicting the skeletal age from μCT images with 95% accuracy. Additionally, we utilize it to demonstrate the rejuvenation effects of in-vivo loading treatment on bones. We further, for the first time, break down aging-related local changes in bone by quantitatively analyzing \"what the age assessment model has learned\" and use this information to investigate the structural details of rejuvenation process. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1742-7061(20)30085-4  |  \n",
      "------------------------------------------- \n",
      "10.1016/j.brainres.2020.146700  |  Treatment  |  Treatment  |  Research  |  Research  |   The central nervous system (CNS) has a limited auto-regeneration capacity, which makes it challenging for the development of new therapies. Previous studies from our lab have demonstrated the applicability of human bone marrow mesenchymal stem cells (hBM-MSCs) secretome as a possible therapeutic tool for CNS. Astrocytes, glial cells present in all brain regions, are important players in brain function through their vast influence in extracellular homeostasis, neuro-vascular regulation, synaptic modulation and neurogenesis. Thus, in the present work, we aimed to evaluate the specific impact of MSCs secretome on hippocampal proliferation and astrocyte morphology, in both WT and dnSNARE mice, a transgenic model that presents impaired astrocytic exocytosis and consequently impaired astrocytic function. Results demonstrated increased levels of proliferation for WT when treated with secretome. Additionally, it was possible to observe that dnSNARE animals injected with hBM-MSCs secretome disclosed increased levels of proliferating GFAP stained cells at the SGZ. Morphometrical evaluation found increased process hypertrophy and branching of dnSNARE astrocytes when treated with secretome. These results are closely related with the trophic factors present in the secretome, namely FGF-2, BDNF, GDNF, IGF-1, VEGF, CADH2, PEDF and miR-16. Moreover, the impaired exocytosis of astrocytes may also have implications for the response to the proliferative stimulus, given the established autocrine signaling through this mechanism. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S0006-8993(20)30056-1  |  \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(\"dois_with_abstract_m/extract2020.txt\", 'r', encoding='utf8') as f_in:\n",
    "        \n",
    "        count = 0\n",
    "        papers = f_in.read()\n",
    "        paperlist = papers.split(\"-------------------------------------------\")\n",
    "        del paperlist[-1]\n",
    "        text_out = \"\"\n",
    "        for paper in paperlist:\n",
    "            count+=1\n",
    "            paper_text = \"\"\n",
    "            data = paper.split(\"  |  \")\n",
    "            \n",
    "            \n",
    "            assigned_lit_type = categorise(text.lower(), literature_types)\n",
    "            if assigned_lit_type:\n",
    "                separator =\", \"\n",
    "                data[4] = separator.join(assigned_lit_type)\n",
    "            else:\n",
    "                data[4] = \"Research\"\n",
    "            \n",
    "            assigned_subfields = categorise(text.lower(), subfields)\n",
    "            if assigned_subfields:\n",
    "                separator =\", \"\n",
    "                data[2] = separator.join(assigned_subfields)\n",
    "            else:\n",
    "                data[2] = \"None, Other\"\n",
    "            \n",
    "            i = 0\n",
    "            for field in data:\n",
    "                if(i == len(data) - 1):\n",
    "                    break\n",
    "                paper_text = paper_text + data[i] + \"  |  \"\n",
    "                i+=1\n",
    "            paper_text = paper_text + \"\\n-------------------------------------------\"\n",
    "            text_out = text_out + paper_text\n",
    "        \n",
    "        print(str(count) + \" papers classified\\n\")\n",
    "        f_out = codecs.open(\"dois_with_abstract_a/extract2020.txt\", 'w', encoding='utf8')\n",
    "        print(text_out)\n",
    "        f_out.write(text_out)\n",
    "        f_out.close()\n",
    "        f_in.close()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of the 16 papers about Review\n",
      "Correctly predicted: 14\n",
      "Incorrectly predicted: 2\n",
      " \n",
      "10.1016/j.media.2019.101561  |  Diagnosis  |  Diagnosis, Treatment  |  Review  |  Research  |   Diabetic Retinopathy (DR) is the most common cause of avoidable vision loss, predominantly affecting the working-age population across the globe. Screening for DR, coupled with timely consultation and treatment, is a globally trusted policy to avoid vision loss. However, implementation of DR screening programs is challenging due to the scarcity of medical professionals able to screen a growing global diabetic population at risk for DR. Computer-aided disease diagnosis in retinal image analysis could provide a sustainable approach for such large-scale screening effort. The recent scientific advances in computing capacity and machine learning approaches provide an avenue for biomedical scientists to reach this goal. Aiming to advance the state-of-the-art in automatic DR diagnosis, a grand challenge on \"Diabetic Retinopathy - Segmentation and Grading\" was organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI - 2018). In this paper, we report the set-up and results of this challenge that is primarily based on Indian Diabetic Retinopathy Image Dataset (IDRiD). There were three principal sub-challenges: lesion segmentation, disease severity grading, and localization of retinal landmarks and segmentation. These multiple tasks in this challenge allow to test the generalizability of algorithms, and this is what makes it different from existing ones. It received a positive response from the scientific community with 148 submissions from 495 registrations effectively entered in this challenge. This paper outlines the challenge, its organization, the dataset used, evaluation methods and results of top-performing participating solutions. The top-performing approaches utilized a blend of clinical information, data augmentation, and an ensemble of models. These findings have the potential to enable new developments in retinal image analysis and image-based DR screening in particular. \n",
      "  |  https://linkinghub.elsevier.com/retrieve/pii/S1361-8415(19)30103-3  |  \n",
      "------------------------------------------- \n",
      "10.3389/fonc.2020.00093  |  Diagnosis, Treatment  |  Diagnosis, Prognosis, Treatment  |  Review  |  Research  |   <b>Background:</b> Neoadjuvant chemotherapy (NAC) is commonly utilized in preoperative treatment for local breast cancer, and it gives high clinical response rates and can result in pathologic complete response (pCR) in 6-25% of patients. In recent years, dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) has been increasingly used to assess the pathological response of breast cancer to NAC. In present analysis, we assess the diagnostic performance of DCE-MRI in evaluating the pathological response of breast cancer to NAC. <b>Materials and Methods:</b> A systematic search in PubMed, the Cochrane Library, and Web of Science for original studies was performed. The Quality Assessment of Diagnostic Accuracy Studies-2 tool was used to assess the methodological quality of the included studies. Patient, study, and imaging characteristics were extracted, and sufficient data to reconstruct 2 × 2 tables were obtained. Data pooling, heterogeneity testing, forest plot construction, meta-regression analysis and sensitivity analysis were performed using Stata version 12.0 (StataCorp LP, College Station, TX). <b>Results:</b> Eighteen studies (969 patients with breast cancer) were included in the present meta-analysis. The pooled sensitivity and specificity of DCE-MRI were 0.80 (95% confidence interval [CI]: 0.70, 0.88) and 0.84 (95% [CI]: 0.79, 0.88), respectively. Meta-regression analysis found no significant factors affecting heterogeneity. Sensitivity analysis showed that studies that set pathological complete response (pCR) (<i>n</i> = 14) as a responder showed a tendency for higher sensitivity compared with those that set pCR and near pCR together (<i>n</i> = 5) as a responder (0.83 vs. 0.72), and studies (<i>n</i> = 14) that used DCE-MRI to early predict the pathological response of breast cancer had a higher sensitivity (0.83 vs. 0.71) and equivalent specificity (0.80 vs. 0.86) compared to studies (<i>n</i> = 5) that assessed the response after NAC completion. <b>Conclusion:</b> Our results indicated that DCE-MRI could be considered an important auxiliary method for evaluating the pathological response of breast cancer to NAC and used as an effective method for dynamically monitoring the efficacy during NAC. DCE-MRI also performed well in predicting the pCR of breast cancer to NAC. However, due to the heterogeneity of the included studies, caution should be exercised in applying our results. \n",
      "  |  https://doi.org/10.3389/fonc.2020.00093  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32117747/  |  \n",
      "-------------------------------------------\n",
      "Out of the 17 papers predicted to be about Review\n",
      "Correctly predicted: 14\n",
      "Incorrectly predicted: 3\n",
      " \n",
      "10.1148/radiol.2020201491  |  Diagnosis  |  Diagnosis  |  Research  |  Review  |   Background COVID-19 and pneumonia of other etiology share similar CT characteristics, contributing to the challenges in differentiating them with high accuracy. Purpose To establish and evaluate an artificial intelligence (AI) system in differentiating COVID-19 and other pneumonia on chest CT and assess radiologist performance without and with AI assistance. Methods 521 patients with positive RT-PCR for COVID-19 and abnormal chest CT findings were retrospectively identified from ten hospitals from January 2020 to April 2020. 665 patients with non-COVID-19 pneumonia and definite evidence of pneumonia on chest CT were retrospectively selected from three hospitals between 2017 and 2019. To classify COVID-19 versus other pneumonia for each patient, abnormal CT slices were input into the EfficientNet B4 deep neural network architecture after lung segmentation, followed by two-layer fully-connected neural network to pool slices together. Our final cohort of 1,186 patients (132,583 CT slices) was divided into training, validation and test sets in a 7:2:1 and equal ratio. Independent testing was performed by evaluating model performance on separate hospitals. Studies were blindly reviewed by six radiologists without and then with AI assistance. Results Our final model achieved a test accuracy of 96% (95% CI: 90-98%), sensitivity 95% (95% CI: 83-100%) and specificity of 96% (95% CI: 88-99%) with Receiver Operating Characteristic (ROC) AUC of 0.95 and Precision-Recall (PR) AUC of 0.90. On independent testing, our model achieved an accuracy of 87% (95% CI: 82-90%), sensitivity of 89% (95% CI: 81-94%) and specificity of 86% (95% CI: 80-90%) with ROC AUC of 0.90 and PR AUC of 0.87. Assisted by the models' probabilities, the radiologists achieved a higher average test accuracy (90% vs. 85%, Δ=5, p&lt;0.001), sensitivity (88% vs. 79%, Δ=9, p&lt;0.001) and specificity (91% vs. 88%, Δ=3, p=0.001). Conclusion AI assistance improved radiologists' performance in distinguishing COVID-19 from non-COVID-19 pneumonia on chest CT. \n",
      "  |  http://pubs.rsna.org/doi/10.1148/radiol.2020201491?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub  0pubmed  |  \n",
      "------------------------------------------- \n",
      "10.2196/15022  |  Treatment, Smart Healthcare, Prognosisbiomarker-drug  |  Prognosis, Treatment, Smart Healthcare  |  Research  |  Review  |    Background:  Alternative evidence-based cardiac rehabilitation (CR) delivery models that overcome significant barriers to access and delivery are needed to address persistent low utilization. Models utilizing contemporary digital technologies could significantly improve reach and fidelity as complementary alternatives to traditional center-based programs. \n",
      "  Objective:  The aim of this study is to compare the effects and costs of the innovative Smartphone Cardiac Rehabilitation, Assisted self-Management (SCRAM) intervention with usual care CR. \n",
      "  Methods:  In this investigator-, assessor-, and statistician-blinded parallel 2-arm randomized controlled trial, 220 adults (18+ years) with coronary heart disease are being recruited from 3 hospitals in metropolitan and regional Victoria, Australia. Participants are randomized (1:1) to receive advice to engage with usual care CR or the SCRAM intervention. SCRAM is a 24-week dual-phase intervention that includes 12 weeks of real-time remote exercise supervision and coaching from exercise physiologists, which is followed by 12 weeks of data-driven nonreal-time remote coaching via telephone. Both intervention phases include evidence- and theory-based multifactorial behavior change support delivered via smartphone push notifications. Outcomes assessed at baseline, 12 weeks, and 24 weeks include maximal aerobic exercise capacity (primary outcome at 24 weeks), modifiable cardiovascular risk factors, exercise adherence, secondary prevention self-management behaviors, health-related quality of life, and adverse events. Economic and process evaluations will determine cost-effectiveness and participant perceptions of the treatment arms, respectively. \n",
      "  Results:  The trial was funded in November 2017 and received ethical approval in June 2018. Recruitment began in November 2018. As of September 2019, 54 participants have been randomized into the trial. \n",
      "  Conclusions:  The innovative multiphase SCRAM intervention delivers real-time remote exercise supervision and evidence-based self-management behavioral support to participants, regardless of their geographic proximity to traditional center-based CR facilities. Our trial will provide unique and valuable information about effects of SCRAM on outcomes associated with cardiac and all-cause mortality, as well as acceptability and cost-effectiveness. These findings will be important to inform health care providers about the potential for innovative program delivery models, such as SCRAM, to be implemented at scale, as a complement to existing CR programs. The inclusion of a cohort comprising metropolitan-, regional-, and rural-dwelling participants will help to understand the role of this delivery model across health care contexts with diverse needs. \n",
      "  Trial registration:  Australian New Zealand Clinical Trials Registry (ACTRN): 12618001458224; anzctr.org.au/Trial/Registration/TrialReview.aspx?id=374508. \n",
      "  International registered report identifier (irrid):  DERR1-10.2196/15022. \n",
      "  |  https://www.researchprotocols.org/2020/1/e15022/  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/32012103/  |  \n",
      "------------------------------------------- \n",
      "10.1210/clinem/dgz141  |  Diagnosis  |  Diagnosis  |  Research  |  Review  |    Context:  Urine steroid metabolomics, combining mass spectrometry-based steroid profiling and machine learning, has been described as a novel diagnostic tool for detection of adrenocortical carcinoma (ACC). \n",
      "  Objective, design, setting:  This proof-of-concept study evaluated the performance of urine steroid metabolomics as a tool for postoperative recurrence detection after microscopically complete (R0) resection of ACC. \n",
      "  Patients and methods:  135 patients from 14 clinical centers provided postoperative urine samples, which were analyzed by gas chromatography-mass spectrometry. We assessed the utility of these urine steroid profiles in detecting ACC recurrence, either when interpreted by expert clinicians or when analyzed by random forest, a machine learning-based classifier. Radiological recurrence detection served as the reference standard. \n",
      "  Results:  Imaging detected recurrent disease in 42 of 135 patients; 32 had provided pre- and post-recurrence urine samples. 39 patients remained disease-free for ≥3 years. The urine \"steroid fingerprint\" at recurrence resembled that observed before R0 resection in the majority of cases. Review of longitudinally collected urine steroid profiles by 3 blinded experts detected recurrence by the time of radiological diagnosis in 50% to 72% of cases, improving to 69% to 92%, if a preoperative urine steroid result was available. Recurrence detection by steroid profiling preceded detection by imaging by more than 2 months in 22% to 39% of patients. Specificities varied considerably, ranging from 61% to 97%. The computational classifier detected ACC recurrence with superior accuracy (sensitivity = specificity = 81%). \n",
      "  Conclusion:  Urine steroid metabolomics is a promising tool for postoperative recurrence detection in ACC; availability of a preoperative urine considerably improves the ability to detect ACC recurrence. \n",
      "  |  https://academic.oup.com/jcem/article-lookup/doi/10.1210/clinem/dgz141  |  https://www.ncbi.nlm.nih.gov/pmc/articles/pmid/31665449/  |  \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(\"dois_with_abstract_a/extract2020.txt\", 'r', encoding='utf8') as f_in:\n",
    "        \n",
    "        papers = f_in.read()\n",
    "        paperlist = papers.split(\"-------------------------------------------\")\n",
    "        del paperlist[-1]\n",
    "        false_negatives = \"\"\n",
    "        false_positives = \"\"\n",
    "        subfield = \"Review\"\n",
    "        tp = 0\n",
    "        fn = 0\n",
    "        fp = 0\n",
    "        for paper in paperlist:\n",
    "            data = paper.split(\"  |  \")\n",
    "            \n",
    "            if data[3].__contains__(subfield):\n",
    "                if data[4].__contains__(subfield):\n",
    "                    tp+=1 \n",
    "\n",
    "                else:\n",
    "                    paper_text = \"\"\n",
    "                    fn+=1\n",
    "                    i = 0\n",
    "                    for field in data:\n",
    "                        if(i == len(data) - 1):\n",
    "                            break\n",
    "                        paper_text = paper_text + data[i] + \"  |  \"\n",
    "                        i+=1\n",
    "                    paper_text = paper_text + \"\\n-------------------------------------------\"\n",
    "                    false_negatives = false_negatives + paper_text\n",
    "                    \n",
    "            if data[4].__contains__(subfield):\n",
    "                if not data[3].__contains__(subfield):\n",
    "                    paper_text = \"\"\n",
    "                    fp+=1\n",
    "                    i = 0\n",
    "                    for field in data:\n",
    "                        if(i == len(data) - 1):\n",
    "                            break\n",
    "                        paper_text = paper_text + data[i] + \"  |  \"\n",
    "                        i+=1\n",
    "                    paper_text = paper_text + \"\\n-------------------------------------------\"\n",
    "                    false_positives = false_positives + paper_text\n",
    "                    \n",
    "\n",
    "        print(\"Out of the \" + str(tp + fn) + \" papers about \" + subfield)\n",
    "        print(\"Correctly predicted: \" + str(tp))\n",
    "        print(\"Incorrectly predicted: \" + str(fn))\n",
    "        print(false_negatives)\n",
    "        print(\"Out of the \" + str(tp + fp) + \" papers predicted to be about \" + subfield)\n",
    "        print(\"Correctly predicted: \" + str(tp))\n",
    "        print(\"Incorrectly predicted: \" + str(fp))\n",
    "        print(false_positives)\n",
    "        \n",
    "        f_in.close()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"scopus-eid": "2-s2.0-85063882867", "originalText": "serial JL 278549 291210 291703 31 90 Canadian Association of Radiologists Journal CANADIANASSOCIATIONRADIOLOGISTSJOURNAL 2019-04-05 2019-04-05 2019-04-24 2019-04-24 2019-09-26T22:56:04 1-s2.0-S0846537119300063 S0846-5371(19)30006-3 S0846537119300063 10.1016/j.carj.2019.03.001 S300 S300.2 FULL-TEXT 1-s2.0-S0846537118X00072 2019-09-26T22:05:22.056104Z 0 0 20190501 20190531 2019 2019-04-06T00:49:28.897285Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body acknowledge affil appendices articletitle auth auth authfirstini authfull authkeywords authlast grantsponsor grantsponsorid nonengabst primabst pubtype ref 0846-5371 08465371 UNLIMITED NONE true 70 70 2 2 Volume 70, Issue 2 2 107 118 107 118 201905 May 2019 2019-05-01 2019-05-31 2019 Artificial Intelligence / Intelligence artificielle article rev \u00a9 2019 The Authors. Published by Elsevier Inc. on behalf of Canadian Association of Radiologists. CANADIANASSOCIATIONRADIOLOGISTSWHITEPAPERETHICALLEGALISSUESRELATEDARTIFICIALINTELLIGENCEINRADIOLOGY JAREMKO J Data Value and Ownership Data Privacy Consent Recommendations: Technical Aspects of Implementing Data Privacy Recommendations: Role of Data Custodian: Data Sharing Recommendations: Role of the Radiologist: Liability Recommendations: Unmet Needs and Future Directions Conclusions Acknowledgements Disclosures Supplementary Data References KALIS 2018 B TANG 2018 120 135 A BANKS 2018 15 18 J MORRIS 2018 4 16 M BALLANTYNE 2018 392 396 A WINFIELD 2018 A DOERR 1973 A ROLEWHITEPAPERSINPOLICYMAKINGPROCESSEXPERIENCEGOVERNMENTCANADA PESAPANE 2018 F 2018 AIINUKREADYWILLINGABLE 1992 SUPREMECOURTJUDGMENTS 2007 WHITEPAPERINFORMATIONGOVERNANCEINTEROPERABLEELECTRONICHEALTHRECORDEHR KOSSEIM 2008 5 P 2014 210 TRICOUNCILPOLICYSTATEMENTETHICALCONDUCTFORRESEARCHINVOLVINGHUMANS BROTHERS 2015 43 51 K ORMOND 2014 211 222 K GARBUTT 2011 267 270 G PRICE 2019 37 43 W KHO 2009 b866 M 2016 294 SHAW 2014 1205 D SAUNDERS 2010 84 87 B 1996 191 2014 51345 51354 MCCALLISTER 2010 E GUIDEPROTECTINGCONFIDENTIALITYPERSONALLYIDENTIFIABLEINFORMATION 2018 727 742 NOUMEIR 2007 284 295 R MOORE 2015 727 735 S KOHLI 2018 M ARYANTO 2015 3685 3695 K MONTEIRO 2017 89 E KALAVATHI 2016 365 379 P MARTIN 2018 30 43 A BELL 2014 1699 1708 E SAWATSKY 2010 E INFORMATIONSHARINGAGREEMENTSFORDISCLOSUREEHRDATAWITHINCANADA BESKOW 2010 e13302 L MURPHY 2009 2128 2134 J WILLISON 2009 10 D POWLES 2017 351 367 J DAGOSTINO 2005 G 2015 HEALTHDATAEXECUTIVESUMMARY MOOR 1999 61 65 J SAEINTERNATIONAL LEHMAN 2015 1828 1837 C KOHLI 2018 535 537 A 2018 25598 ALLAIN 2012 1049 J JAREMKOX2019X107 JAREMKOX2019X107X118 JAREMKOX2019X107XJ JAREMKOX2019X107X118XJ Full 2019-03-17T18:55:48Z Author http://creativecommons.org/licenses/by-nc-nd/4.0/ 2020-04-24T00:00:00.000Z 2020-04-24T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license. \u00a9 2019 The Authors. Published by Elsevier Inc. on behalf of Canadian Association of Radiologists. 2019-04-29T19:21:09.994Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp Fraser Health Authority Canadian Association of Radiologists American Association for Women Radiologists http://data.elsevier.com/vocabulary/SciValFunders/100011547 http://sws.geonames.org/6252001/ E.L. E.L. Wiegand Foundation http://data.elsevier.com/vocabulary/SciValFunders/100007315 http://sws.geonames.org/6252001/ MedTEQ and Imagia Cybernetics Canadian Institutes of Health Research Canadian Institutes of Health Research http://data.elsevier.com/vocabulary/SciValFunders/501100000024 http://sws.geonames.org/6251999/ Alberta Health Services Chair Alberta Health Services http://data.elsevier.com/vocabulary/SciValFunders/100007582 http://sws.geonames.org/6251999/ Canadian Association of Radiologists' Artificial Intelligence Working Group FRQ-S VHA J.C. Ontario Health Technologies Fund CAR M.A. Medical Imaging Consultants FRQR-ARQ 34939 Fondation de l'association des Radiologistes du Qu?bec IBM Watson Fonds de recherche du Qu?bec en Sant? (FRQ-S) and Fondation de l'association des Radiologistes du Qu?bec (FARQ) Clinical Research Scholarship Salary Award (FRQR-ARQ #34939) to An Tang. Dr Jaremko receives unrestricted support from Medical Imaging Consultants (Edmonton) and the Alberta Health Services Chair in Diagnostic Imaging.J.L.J. is one of three co-founders of MEDO.ai, a startup company investigating automated ultrasound image analysis. MEDO has no revenue, and did not provide any support for, or control over, this work. M.C. is a shareholder, co-founder, and Chief Operating Officer of 16 Bit Inc, a software company developing AI algorithms for medical image analysis. 16 Bit did not provide any support for, or control over, Dr Cicero's contribution to this work. J.S. has received research funding from the Ontario Health Technologies Fund, VHA Home Health Care, and the Canadian Institutes of Health Research. F.J.R. is the Medical Director of Imagia Cybernetics, and the Chair of the American College of Radiology Appropriateness Criteria. None of the entities noted provided any support for, or control over, Dr Rybicki's contribution to this work. C.H. is employed by the Canadian Association of Radiologists, which receives corporate grants from IBM Watson. E.L. is the President of the Canadian Association of Radiologists, a partial expense remunerated position, and Regional Medical Director/Regional Department Head, Department of Medical Imaging, Fraser Health Authority (FHA), BC, Canada, a contracted position with the FHA. The FHA and CAR did not provide any support for, or control over, Dr Lee's contribution to this work. A.T. is Chair of the Canadian Association of Radiologists' Artificial Intelligence Working Group. Dr Tang has received a research grant co-funded by MedTEQ and Imagia Cybernetics. M.A., A.L., L.H.A.C., M.G., F.L., B.G., C.R., R.B., and J.C. have no declarations of interest. item S0846-5371(19)30006-3 S0846537119300063 1-s2.0-S0846537119300063 10.1016/j.carj.2019.03.001 278549 2019-09-26T22:05:22.056104Z 2019-05-01 2019-05-31 UNLIMITED NONE 1-s2.0-S0846537119300063-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/MAIN/application/pdf/987a694a0580268641dbcd369e33bc1b/main.pdf main.pdf pdf true 834699 MAIN 12 1-s2.0-S0846537119300063-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/PREVIEW/image/png/08ce863ab1c92a3c59236e27ba7ce0e3/main_1.png main_1.png png 68919 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0846537119300063-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr3/THUMBNAIL/image/gif/c1b1050cac9e57caf829477b90b717d3/gr3.sml gr3 gr3.sml sml 11429 122 219 IMAGE-THUMBNAIL 1-s2.0-S0846537119300063-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr1/THUMBNAIL/image/gif/3180b286a5eea02cbb763684711969b0/gr1.sml gr1 gr1.sml sml 13568 164 198 IMAGE-THUMBNAIL 1-s2.0-S0846537119300063-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr2/THUMBNAIL/image/gif/6f60c4fbd290c9703b4d4892788d8825/gr2.sml gr2 gr2.sml sml 24316 124 219 IMAGE-THUMBNAIL 1-s2.0-S0846537119300063-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr3/DOWNSAMPLED/image/jpeg/e32cf2a394b10575b2ca9b7cadcbad12/gr3.jpg gr3 gr3.jpg jpg 27853 187 337 IMAGE-DOWNSAMPLED 1-s2.0-S0846537119300063-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr1/DOWNSAMPLED/image/jpeg/f1759ec8a569e05d8487b79602ef4b53/gr1.jpg gr1 gr1.jpg jpg 69119 497 600 IMAGE-DOWNSAMPLED 1-s2.0-S0846537119300063-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr2/DOWNSAMPLED/image/jpeg/8ec6d3219daa43c05036645bcfe9c9cb/gr2.jpg gr2 gr2.jpg jpg 63265 341 600 IMAGE-DOWNSAMPLED 1-s2.0-S0846537119300063-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr3/HIGHRES/image/jpeg/53a791b2c6f3f93a771f677416ce5eba/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 125970 830 1494 IMAGE-HIGH-RES 1-s2.0-S0846537119300063-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr1/HIGHRES/image/jpeg/19ad712f44271f9432c32b9ee6bf1d59/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 512218 2200 2657 IMAGE-HIGH-RES 1-s2.0-S0846537119300063-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/gr2/HIGHRES/image/jpeg/e26d9c576377b526a831d4ee08258bb8/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 420726 1508 2657 IMAGE-HIGH-RES 1-s2.0-S0846537119300063-mmc1.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0846537119300063/mmc1/MAIN/application/pdf/3371d0f61fe03883000dbbf30d1ec83c/mmc1.pdf mmc1 mmc1.pdf pdf false 23437 APPLICATION CARJ 679 S0846-5371(19)30006-3 10.1016/j.carj.2019.03.001 The Authors Figure 1 (A) Assuming proper respect of confidentiality and minimal risk associated with data sharing in scenarios where explicit consent is impractical, the balance between ethical principles may shift in the era of machine learning in radiology. (B) It is anticipated that the previous emphasis on fundamental rights of individuals may shift toward civic responsibility for public good. This figure is available in colour online at http://carjonline.org/. Figure 2 Example of recognizable personal data hidden within magnetic resonance imaging images. (A) Raw data from an axial fluid-attenuated inversion recovery image. (B) Coronal 3-dimensional reconstruction from this data using a skin threshold, showing the subject's face. This figure is available in colour online at http://carjonline.org/. Figure 3 Shifting paradigm: secondary use of electronic medical records in the machine learning paradigm can provide new insights in health care and potential commercial value. This figure is available in colour online at http://carjonline.org/. Table 1 Key learning points 1 In Canada, our public health care system provides the opportunity to develop AI decision support tools using population-wide training data, a key advantage that allows the opportunity for Canada to be a world leader in harnessing the power of AI to improve health care for its citizens. 2 Canadian jurisprudence reveals that the health care provider that produced a medical record owned the physical record itself and the patient has a right of access to it. 3 In the electronic era, the ownership of medical records and the secondary use of de-identified medical data is a complex issue that will likely depend on the type of use. 4 Respect of data privacy requires balancing of principles of beneficence and justice (to improve medical care for others via secondary use of an individual's data) versus autonomy (as regards the concept of free and ongoing informed consent) 5 Historically, institutional review boards have granted waivers of consent when gaining explicit consent is impractical, risk associated with data sharing is minimal, and data custodian is trusted. 6 To facilitate development of AI applications in health care, a transition from \u201cinformed consent\u201d for specific data uses, to \u201cbroad consent,\u201d \u201copt-out consent,\u201d and/or \u201cpresumed consent\u201d to more general data uses is required. 7 Tools and policies are required to facilitate and standardize anonymization of medical images. 8 Public education campaigns should inform the public of the benefits that sharing of fully anonymized personal health data can provide. 9 Guidelines will be required prior to the deployment of AI assistive tools in hospital departments to minimize the potential harm and liability for malpractice in case of medical error involving AI. 10 Advances using big data and AI cause a shift in the value of data. AI = artificial intelligence. Table 2 Exceptions to obligation for consent IRBs can waive consent for secondary use research when: 1. Gaining consent is impractical. 2. Requiring consent would impair the scientific validity of the study. 3. The research addresses important health questions that pose minimal harm to participants. IRB = institutional review board. Table 3 CAR levels of autonomy for AI systems applied to radiology CAR level Name Description Liability 0 No automation Interpretation/intervention is done solely by the radiologist. Radiologist/Clinician 1 Physician assistance Interpretation/intervention is done primarily by the radiologist with AI providing secondary oversight (ie, existing CAD software for mammography and lung nodules, worklist prioritization). Radiologist/Clinician 2 Partial automation Interpretation/intervention is done primarily by the AI with radiologist providing secondary oversight (ie, bone age prediction, chest x-ray pathology detection and report pre-population). Radiologist/Clinician 3 Conditional automation Interpretation/intervention is done solely by the AI for a specific indication with the expectation that radiologist will intervene if the results are positive or indeterminate (ie, automated triaging of normal cases where radiologist is expected to intervene if positive but not if negative). AI/Radiologist/Clinician 4 High automation Interpretation/intervention is done solely by the AI for a specific indication without the expectation that radiologist will intervene. AI is able to arrive at a differential diagnosis and recommend management autonomously (ie, AI analyzes thyroid ultrasound and recommends and/or performs biopsy for a nodule). AI 5 Full automation Interpretation/intervention is done solely by the AI for all indications expected of radiologists. AI is able to arrive at a differential diagnosis and recommend management autonomously (ie, chest x-ray requisition states \u201cr/o pneumonia,\u201d AI reports bone tumor with differential diagnosis and recommendations for further imaging/consultation). AI AI = artificial intelligence; CAD = computer-aided detection; CAR = Canadian Association of Radiologists. Artificial Intelligence / Intelligence artificielle Canadian Association of Radiologists White Paper on Ethical and Legal Issues Related to Artificial Intelligence in Radiology Jacob L. Jaremko MD, PhD, FRCPC a Marleine Azar MSc b Rebecca Bromwich PhD, LLM, LLB c Andrea Lum MD, FRCPC d Li Hsia Alicia Cheong MDCM e Martin Gibert PhD f Fran\u00e7ois Laviolette PhD g Bruce Gray MD, FRCPC h Caroline Reinhold MD, MSc, FRCPC i Mark Cicero MD, BESc, FRCPC j Jaron Chong MD, MHI, FRCPC i James Shaw PhD k Frank J. Rybicki MD, PhD l m Casey Hurrell PhD n Emil Lee MD, FRCPC n o p An Tang MD, MSc, FRCPC q \u2217 an.tang@umontreal.ca for the Canadian Association of Radiologists (CAR) Artificial Intelligence Working Group a Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Alberta, Canada Department of Radiology and Diagnostic Imaging University of Alberta Edmonton Alberta Canada b Department of Medicine, Universit\u00e9 de Montr\u00e9al, Montr\u00e9al, Quebec, Canada Department of Medicine Universit\u00e9 de Montr\u00e9al Montr\u00e9al Quebec Canada c Department of Law and Legal Studies, Carleton University, Ottawa, Canada Department of Law and Legal Studies Carleton University Ottawa Canada d Department of Medical Imaging, Western University, London, Ontario, Canada Department of Medical Imaging Western University London Ontario Canada e Department of Medical Imaging, University of Toronto, Toronto, Ontario, Canada Department of Medical Imaging University of Toronto Toronto Ontario Canada f Centre de recherche en \u00e9thique, Universit\u00e9 de Montr\u00e9al, Montr\u00e9al, Quebec, Canada Centre de recherche en \u00e9thique Universit\u00e9 de Montr\u00e9al Montr\u00e9al Quebec Canada g Department of Computer Science, Universit\u00e9 Laval, Qu\u00e9bec, Quebec, Canada Department of Computer Science Universit\u00e9 Laval Qu\u00e9bec Quebec Canada h Department of Medical Imaging, St Michael's Hospital, University of Toronto, Toronto, Ontario, Canada Department of Medical Imaging St Michael's Hospital University of Toronto Toronto Ontario Canada i Department of Radiology, McGill University Health Center, Montreal, Quebec, Canada Department of Radiology McGill University Health Center Montreal Quebec Canada j 16 Bit Inc, Toronto, Ontario, Canada 16 Bit Inc Toronto Ontario Canada k Institute for Health System Solutions and Virtual Care, Women's College Hospital, Toronto, Ontario, Canada Institute for Health System Solutions and Virtual Care Women's College Hospital Toronto Ontario Canada l Department of Radiology, The University of Ottawa Faculty of Medicine and The Ottawa Hospital Research Institute, Ottawa, Ontario, Canada Department of Radiology The University of Ottawa Faculty of Medicine and The Ottawa Hospital Research Institute Ottawa Ontario Canada m Imagia Cybernetics, Montreal, Quebec, Canada Imagia Cybernetics Montreal Quebec Canada n Canadian Association of Radiologists, Ottawa, Ontario, Canada Canadian Association of Radiologists Ottawa Ontario Canada o Department of Radiology, Valley Medical Imaging, Langley, British Columbia, Canada Department of Radiology Valley Medical Imaging Langley British Columbia Canada p Department of Medical Imaging, Fraser Health Authority, British Columbia, Canada Department of Medical Imaging Fraser Health Authority British Columbia Canada q Department of Radiology, Radio-oncology, and Nuclear Medicine, Universit\u00e9 de Montr\u00e9al, Montr\u00e9al, Quebec, Canada Department of Radiology, Radio-oncology, and Nuclear Medicine Universit\u00e9 de Montr\u00e9al Montr\u00e9al Quebec Canada \u2217 Address for correspondence: An Tang, MD, MSc, FRCPC, 1051, rue Sanguinet, Montreal, Quebec H2X 0C1, Canada. 1051, rue Sanguinet Montreal Quebec H2X 0C1 Canada Abstract Artificial intelligence (AI) software that analyzes medical images is becoming increasingly prevalent. Unlike earlier generations of AI software, which relied on expert knowledge to identify imaging features, machine learning approaches automatically learn to recognize these features. However, the promise of accurate personalized medicine can only be fulfilled with access to large quantities of medical data from patients. This data could be used for purposes such as predicting disease, diagnosis, treatment optimization, and prognostication. Radiology is positioned to lead development and implementation of AI algorithms and to manage the associated ethical and legal challenges. This white paper from the Canadian Association of Radiologists provides a framework for study of the legal and ethical issues related to AI in medical imaging, related to patient data (privacy, confidentiality, ownership, and sharing); algorithms (levels of autonomy, liability, and jurisprudence); practice (best practices and current legal framework); and finally, opportunities in AI from the perspective of a universal health care system. R\u00e9sum\u00e9 Les logiciels d\u2019intelligence artificielle (IA) analysant les images m\u00e9dicales sont de plus en plus pr\u00e9valents. Contrairement aux g\u00e9n\u00e9rations pr\u00e9c\u00e9dentes de logiciels d\u2019IA qui reposaient sur un savoir d\u2019expert pour identifier les caract\u00e9ristiques d\u2019une image, les approches d\u2019apprentissage machine permettent aux syst\u00e8mes d\u2019apprendre \u00e0 reconna\u00eetre ces caract\u00e9ristiques. Toutefois, la promesse d\u2019une m\u00e9decine personnalis\u00e9e pr\u00e9cise ne peut \u00eatre remplie qu\u2019avec un acc\u00e8s \u00e0 de tr\u00e8s grandes quantit\u00e9s de donn\u00e9es m\u00e9dicales de patients. Ces donn\u00e9es pourraient servir \u00e0 pr\u00e9dire les maladies, \u00e0 les diagnostiquer, \u00e0 optimiser les traitements et \u00e0 \u00e9tablir un pronostic. La radiologie se trouve en position de chef de file pour le d\u00e9veloppement et la mise en \u0153uvre des algorithmes d\u2019IA, ainsi que pour la gestion des d\u00e9fis \u00e9thiques et l\u00e9gaux qui leur sont associ\u00e9s. Ce livre blanc de l\u2019Association canadienne des radiologistes (CAR) propose un cadre d\u2019\u00e9tude pour les probl\u00e8mes l\u00e9gaux et \u00e9thiques en rapport avec l\u2019utilisation de l\u2019IA dans l\u2019imagerie m\u00e9dicale pour les donn\u00e9es des patients (vie priv\u00e9e, confidentialit\u00e9, propri\u00e9t\u00e9 et partage), les algorithmes (degr\u00e9s d\u2019autonomie, responsabilit\u00e9 et jurisprudence), la pratique m\u00e9dicale (meilleures pratiques et cadre r\u00e9glementaire actuel) et les opportunit\u00e9s offertes par l\u2019IA du point de vue d\u2019un syst\u00e8me de soins de sant\u00e9 universel. Key Words Artificial intelligence Machine learning Ethics Legal Radiology Imaging Artificial intelligence (AI) and machine learning (ML) are increasingly omnipresent in modern life and becoming integrated into health care. Radiology studies are large data sets in which megabytes of image data are typically distilled into a short text-based data set (ie, the radiologist's report) highlighting clinically relevant information (pathology or other findings termed biomarkers). AI and ML applications are highly suited to aid in this process of synthesizing key elements from raw data. Potential benefits include improved diagnostic accuracy, enhanced efficiency, new biomarker discovery, optimized post-treatment diagnosis of complications, and potentially less costly health care. Automated radiologic image diagnosis is forecast to save USD $3 billion annually in the United States \u201cby giving radiologists more time to focus on reviews that require greater interpretation or judgment\u201d [1]. To achieve these benefits, as observed in the Canadian Association of Radiologists' (CAR) white paper on artificial intelligence in radiology, \u201cAI hinges on researchers gaining access to large sets of health data from thousands of patients\u201d [2]. Use of bulk training data allows prediction of diagnoses, prognoses, and treatment response for future patients. This shifts the relationship between patients, health care providers, and medical data [3]. Crucially, a patient's individual data now has a new use, as part of \u201cbig data\u201d [4]. Historically, a patient's medical data was consulted only occasionally and solely in care of that patient, at initial consultation and follow-up, then archived and often deleted over time due to the cost of storage. With the advent of AI, ML, and personalized medicine, medical data is consulted for a new purpose: in bulk to inform the care of other patients. This secondary use of patient data imposes legal and ethical challenges related to the data, its use, and the implications of AI in radiology [2]. Data mining projects using AI to create models that can detect, diagnose, predict, and prognosticate disease processes can be seen as altruistic, on the assumption that the data sharing [5] leads to a powerful benefit to society. Tempering the incentive to share patient data for AI training is the potential threat of patient privacy and confidentiality breaches. The collection, storage, and use of bulk medical data present additional challenges related to social acceptability and public perception, legislative obstacles, information technology barriers, and the risk of breaches in data security [6]. A white paper is a \u201creport or guide that informs readers concisely about a complex issue and presents the issuing body's philosophy on the matter. It is meant to help readers understand an issue, solve a problem, or make a decision\u201d [7,8]. This white paper summarizes key ethical and legal issues pertaining to the implementation of AI and ML in radiology, primarily focusing on imaging data, although the issues raised are also pertinent to non-imaging data in electronic medical records. Issues arising from non-imaging use of AI in radiology departments, such as in optimizing workflow, are a related topic outside the scope of this paper. Although ethical principles are universal, legal and regulatory environments differ worldwide [9]. Here, we focus on a Canadian perspective. We provide a conceptual framework for further discussion and make recommendations regarding integration of AI in radiology (Table 1 ). Definitions are summarized in Supplemental Table S1 and abbreviations in Supplemental Table S2. Data Value and Ownership Access to health data has increasing commercial value, as seen with IBM's 2015 acquisition of Merge Healthcare (USD $1 billion) that could access 5\u20136 million patients' records [10]. In Canada, we are close to having a \u201csingle payer\u201d government-funded health care system. While this could, in theory, allow access to population-wide data, the health care system remains fragmented, managed at the provincial or regional level. Access to this rich data set has great potential to enable improved health care for individual Canadians and across the Canadian population, as well as immense potential commercial value. The issue of who owns this personal health data is characterized by a complex tension between health care provider proprietary interests, patient privacy, copyright issues, and AI developer intellectual property, and an overarching public interest in open access to data that can improve medical care. In Canada this is complicated by the constitutional division of powers, under which copyright law is in federal jurisdiction, governed by the Copyright Act R.S.C. 1985, c. C-42, while health care is in the jurisdiction of provinces and territories. To the question, \u201cwho owns patient medical data in Canada,\u201d the answer is nuanced and depends on how and by whom the data is being used. Canada's current legal treatment of the ownership and privacy of electronic health records mixes clarity and confusion. In the era of paper medical records, the seminal case McInerney v. MacDonald, [11] 2 S.C.R. 138, set forth clear law: the health care provider that produced a medical record owned the physical record itself and the patient had a right of access to it. This is confirmed in some provinces by legislation, for example in Ontario's Public Hospitals Act R.S.O. 1990, c. P.40. Health care providers are \u201cinformation custodians\u201d of the patients' private health data under provincial privacy laws (eg, Personal Health Information Protection Act, 2004, S.O. 2004, c 3, Sch. A) and under the 2007 Canadian Medical Association guidelines [12]. This \u201ccustodianship\u201d reflects the reality that patients have privacy interests in their medical records that are protected through provincial/territorial legislation, as well as, increasingly, through tort law. In a growing number of cases, patients are having success in launching civil actions for \u201cintrusion upon seclusion\u201d where their rights to privacy over their electronic medical records are violated (For recent discussion, see eg Oliveira v. Aviva Canada Inc. et al, 2017 ONSC 6161). Today in Canada, how electronic records and their contents are to be dealt with legally is a pressing question that is not yet clearly answered [13]. The issue of data ownership now extends not just to proprietary interests in paper records but also to copyrights over individual and aggregate data collected in databases, as well as the databases themselves. There are many stakeholders, including individual patients, public sector entities (federal and provincial governments, institutional health care providers), academic entities (researchers and universities), and private sector parties (tech corporations and legal professionals). In this area with relatively little Canadian legal precedent, an analogy might be made to ownership of land. Unlike in the United States, in most of Canada, a homeowner \u201cowns\u201d the land surface but generally not the minerals underlying their land [14] and is restricted in how they can use their land by zoning ordinances and utility rights of way. Perhaps the patient \u201cowns\u201d their identifiable medical data just as a landowner has surface rights, but the \u201cmining rights\u201d to access this data in de-identified form for purposes, such as improving health care, may be deemed to \u201cbelong\u201d to other parties, such as the health care provider or government. In land, the meaning of \u201cownership\u201d is complex and depends on the type of use it will be put to, and this is likely also true in medical data. These complex issues remain to be explored in case law as AI in health care evolves. Data Privacy The Constitution Act of Canada defines privacy as one of our fundamental human rights [15]. Privacy refers to an individual's right to be free from intrusion or interference by others [16]. This right includes exercising control over information pertaining to oneself and consent for others to use that information [16]. A breach of privacy refers to the loss of, unauthorized access to, or disclosure of, personal information [17]. Personal information in radiology comprises mainly images, analogous to photos taken by various \u201ccameras\u201d (x-ray, ultrasound, computed tomography [CT], etc). This data is highly personal and sensitive. Radiology image data is particularly sensitive. Images of a person may capture something of their essence, more than words, perhaps in some ways like data contained in an individual's own genome (which can show what gene-related conditions that individual has or risks developing). The advent of inexpensive whole-genome sequencing has led in the past 5 years to extensive consideration of issues, such as consent to secondary use of data (ie, for purposes other than an individual patient's own medical care) [18,19]. Although medical image data is not as tightly linked to prognosis as genome data, some of the ethical issues raised are broadly similar and can inform our deliberations. Widespread data use for AI training raises obvious concerns about data privacy, balancing on the one hand beneficence and justice (improving medical care for others via secondary use of an individual's data) versus autonomy, particularly regarding the concept of free and ongoing informed consent (Figure 1 A). Privacy concerns at the level of individual patients include: how will patients know to what extent their data is undergoing secondary use; which portions of their data are involved; who can access their data; to what extent anonymization of data is effective and complete; whether that data could potentially be used in a way that harms them; can their data be altered; is their data being used for financial benefit of others; and will a change in data privacy policies in the near or distant future affect the care they receive. Harm from data privacy breaches can be consequential, where a patient demonstrably suffered (eg, from discrimination, humiliation, or increased cost of insurance), or the harm can be deontological, where even if that particular patient did not suffer a negative consequence, the privacy breach still violates the duty owed by health care providers to the patient [20,21]. Concerns regarding data privacy at a societal level include: how mandatory consent may adversely affect data quality because of selection bias [22]; risks of data breaches; and how to ensure AI development leads to widespread societal benefit rather than outcomes many would not welcome, such as commoditization of personal data (data as a product). Consent In the setting of AI imaging analysis, a patient giving traditional consent for their data to be used may reasonably wish for information to know exactly in which models their data will be used and to whom it will be traded or transmitted, and limits on processing so that they can define how their data can and cannot be used, or even erase their data from trained models in future. Unfortunately, these wishes are challenging or even impossible to fully grant for secondary use of imaging data. Given that this secondary use is relatively new, patients will generally not have been consented for these purposes when they were imaged, leading to the current dilemma of how to handle the issue of patient consent. Historically, consent waivers have enabled researchers to access medical data for specific projects without explicit individual consent (Table 2 ). This waiver is typically granted by Institutional Review Boards for 2 reasons; (1) it is impractical to retrospectively obtain consent from tens or hundreds of thousands of patients, which are the sample sizes required to achieve best results in AI; and (2) the expected societal benefits of the research outweigh the perceived relatively low risk to human subjects (ie, that of a privacy breach) when appropriate protocols and data-handling measures are in place. One pathway to broader implementation of AI would be a shift from explicit consent to a new paradigm in which health care providers had more widespread default access to medical data that could be applied to AI algorithms. Beyond the potential for individual privacy breach, a risk to this expanded access is that AI may lead to broad changes in health care, and what is considered an acceptable initial risk-to-reward ratio might not be desirable after a period of time where algorithms have impacted patient care. In the European Union, the General Data Protection Regulation deals with this by allowing patients to give a general \u201cconsent to certain areas of scientific research, when in keeping with recognized ethical standards\u201d [23]. This type of consent has been termed \u201cbroad consent\u201d [13] in which although the exact users of the data and exact projects are not known, the data custodian and the general parameters of possible data use are identified and agreed to. A granular \u201copt-out\u201d consent system allowing certain items to be excluded is an option [24], although in many cases, this would be extremely cumbersome or logistically unmanageable to implement. \u201cPresumed consent,\u201d in which consent is assumed by default in settings where it would generally be considered morally wrong not to consent, is increasingly applied to posthumous organ donation [25] and could be considered for appropriately safeguarded use of health care data in AI. Consistent consent policy for AI is needed, at institutional, provincial and national levels. This will maximize the potential for collaborative innovation across borders and simplify the role of stakeholders including industry. In Canada, the consent process is informed by the Tri-Council Policy Statement: Ethical Conduct for Research Involving Humans [16]. A 2014 amendment to this statement reads: \u201cconsent is not required for research that relies exclusively on secondary use of non-identifiable information.\u201d This crucial change indicates that in Canada, in the opinion of the 3 main national research agencies\u2014Canadian Institutes of Health Research, National Sciences and Engineering Research Council, and Social Sciences and Humanities Research Council\u2014consent is not required for sharing anonymized data. Similarly, in the European Union General Data Protection Regulation, personal data can be processed without informed consent when a task is \u201cin the public interest\u201d [23], Article 6. This is a monumental shift in consent policy, which places increasing responsibilities on the data custodians. CAR needs to lead advocacy to ensure that this position held by Canada's largest research agencies also makes its way to other institutions and agencies and to the general public. The optimal definition and format of a \u201cbroad consent\u201d requires further research and consultation. Waiver of explicit individual consent requires a guarantee of anonymity, minimal risk associated with data sharing, impracticality of explicit consent, and crucially a trusted data custodian (Figure 1B). Canadian provincial health acts vary in specific language, but in general, require removal of any data that readily identifies an individual or can be reasonably expected to be combined with other data to identify an individual [13]. The US Health Insurance Portability and Accountability Act (1996) [26] considers data to be de-identified when 18 specific data elements are absent, or if a knowledgeable expert considers there to be a \u201cvery small risk\u201d of re-identification. Implicit in well-protected patient privacy is \u201cdata protection by design and default\u201d [23], ie, a system where institutions and individual health care workers are structurally encouraged to work together to ensure confidentiality and security of patient data. For AI to be implemented successfully beyond individual projects, there needs to be a strong guarantee of data security and of complete anonymization of all data processed for secondary use in AI. There also needs to be a better understanding of the risks versus benefits of sharing health information. Standardized implicit consent for appropriate secondary use of all publicly-funded health care data is crucial to enable innovation and development in AI. Government health care policies must prioritize an individual's data privacy rights and optimize security of personal health care data over commoditization of valuable clinical data. Furthermore, there must also be public confidence that advances in AI will be implemented throughout the health care system. The authors of this paper, representing the CAR, believe that the benefits of AI can outweigh risks when institutional protocols and technical considerations are appropriately implemented to safeguard or remove the individually identifiable components of medical imaging data. The CAR AI Working Group makes these recommendations. Recommendations: 1. CAR to advocate for public education programs to increase public awareness of the benefits of sharing fully anonymized personal health data, and harm reduction strategies. 2. CAR to advocate for general adoption of revised forms of consent (such as \u201cbroad consent\u201d) for appropriately safeguarded secondary use of data for AI in Canadian health care. 3. CAR to develop a framework to guide approaches to data security, anonymization, and secondary use of radiology data. Technical Aspects of Implementing Data Privacy The blanket approvals from institutions such as the Canadian Tri-Council and the European Union [16,23] for secondary use of non-identifiable patient data in AI presume that the data is, in fact, fully anonymized. While images of different people can appear similar, genomic data is unique to an individual. Accordingly, the National Institutes of Health policy (for the United States) that allowed de-identified genomic data for secondary research was retracted so that since January 2015, informed consent must again be specifically given to perform unrestricted secondary research using a patient's genetic material [27]. This is due to concerns that data can be easily re-identified from clues within the data set itself, or by combining multiple data sets [21]. In radiology data, re-identification can often be performed from inadequately processed Digital Imaging and Communications in Medicine (DICOM) image headers. De-identification refers to removal or obscuration of personally identifying information, while anonymization refers to data that can never be re-identified, and pseudonymization refers to replacing personal identifiers with artificial identifiers [28]. Even this anonymized data remains \u201cpersonal data\u201d under European law [23,29]. Achieving true de-identification is often more challenging than expected. Radiology databases are built using DICOM files, which contain images and also meta-data within \u201cheader\u201d fields such as \u201c.studydate = 20140507,\u201d \u201c.modality = MR,\u201d and \u201c.PatientName = John Smith.\u201d Anonymization requires manipulation of these file headers [30] to selectively remove or codify all identifiers. Unfortunately, each radiologic equipment manufacturer also adds their own proprietary DICOM header fields, which may contain identifying data in unexpected or un-documented locations [31]. Many picture archiving and communication systems and commercial and open-source DICOM viewer software packages offer DICOM header removal as a core feature [32,33]. One popular tool for anonymizing and transferring images is the American College of Radiology Triad package (https://triadhelp.acr.org/). Anonymization tools typically remove or replace the standard DICOM header fields but may leave proprietary fields intact, preserving personal health information [34]. Alternatively, an \u201cadditive\u201d approach can be taken wherein a new DICOM file is constructed including image data and only a limited set of DICOM headers. The anonymization effectiveness of common software tools has been evaluated [35], but this requires reassessment with each software update. Anonymization can be (laboriously) tested by having a \u201cwhite-hat\u201d hacker attempt to find patient identifiers in sample DICOM headers. Ideally, to facilitate anonymization equipment manufacturers would not include individually identifiable information in any private or non-standard DICOM headers. CAR, along with other societies, can advocate for this change, both with manufacturers and with the custodians of the DICOM standard, the US National Electrical Manufacturers Association [36]. Anonymization can also be incomplete due to factors inherent to the imaging itself. In ultrasound or fluoroscopy, many scanners display the patient name and identification as text burned directly into the image bitmap (eg, at the top of the image). This can be obscured by image masking algorithms [35], some of which now use AI techniques [37]. For new imaging, it is often possible to have the required individually identifying data limited to a more easily removable portion of the scan, eg, only on the first image of an ultrasound or fluoroscopic study. Radiographs may also, at times, inadvertently include bracelets that allow reidentification of patients. This can be avoided through specific technologist training, or digitally masked before images are released to the picture archiving and communication system. Head/neck magnetic resonance imaging or CT scans can often be re-windowed in 3-D using a threshold calibrated to the skin surface, generating a strikingly recognizable 3-D image of the patient's face (Figure 2 ) or other body parts. This image could be fed into an AI face-recognition algorithm [34]. Pre-processing with so-called \u201cskull stripping\u201d algorithms can help prevent this [38]. Data privacy also involves minimizing risks during the process of data transfer. Data sharing is needed between AI stakeholders, such as between a health care institution with patient data and an AI team or company performing analysis. Each method of data transfer has inherent security risks, eg, internet data interception or loss or theft of disks being physically transferred. Innovative solutions are possible where rather than bringing the data to the app, the app can be brought to the data. For example, Developer A may have an AI app they wish to try on a data set but does not want Hospital B to have access to the app code. On the other hand, Hospital B does not wish to share the data with the developer but wishes to see the results. The code from Developer A can be put into a secured container (managed by software such as Docker [39]) and allowed to run on data from Hospital B. A and B only receive the output from the code. A never sees the data, and B never sees the code, but both receive the output. This type of data sharing model is common outside health care and has potential security advantages, but is itself vulnerable to hacking and misuse [40]. This kind of model becomes impractical for very large datasets and model architectures requiring expensive hardware or the use of cloud computing. Data privacy also requires safe storage and appropriate deletion. The principle traditionally governing data storage has been that it should be kept for no longer than is necessary for the purposes for which it was collected [21]. If data is to be stored for secondary use and is increasingly valuable as longer-term outcomes become available, a new paradigm needs to be developed. Recommendations: 1. CAR recommends that, since DICOM de-identification/anonymization is uniquely crucial to maintaining privacy in medical imaging, a key component of any AI image analysis must be a clear protocol demonstrating how DICOM data is ensured to be truly de-identified and non-reidentifiable. 2. CAR also recommends that for any AI analysis that requires data transfer between stakeholders, a protocol be developed specifically demonstrating the security of this transfer. 3. CAR should consider advocating to radiologists that addition of patient-identifying data to medical images that already meet DICOM standards should be standardized and easily removable in case of future anonymization. 4. CAR should consider providing links to reputable DICOM anonymization software tools. Role of Data Custodian: Data Sharing Especially when consent has not been explicitly granted for a specific project, the data custodian (such as a hospital, regional health authority, or even a radiology partnership) plays a vital gatekeeper role in determining which AI projects are ethically appropriate to perform. Authorization is usually granted by a hospital or university research ethics board, per an approved research protocol and/or data transfer agreement, could include a commercial entity with responsibility shared between parties. The legally recognized data custodian varies by institution and may be a hospital corporation with a public board of governors, or a private radiology partnership. Data custodians balance risks and benefits of data sharing by focusing on core questions: what data is being shared, who this data is being shared with, why the data is being shared, and finally, how this data is being shared. The ethical and social acceptability of usage are tied to these considerations. The social acceptability of sharing medical data strongly depends on what data is being shared. Certain forms of data, such as the image of one's face, psychiatric medical records, or vulnerable population status (eg, human immunodeficiency virus status) are considered especially sensitive [41]. Other medical data can be surprisingly sensitive in certain settings, for example, a shoulder radiograph may not seem particularly private but could be sensitive if it shows pre-existing osteoarthritis that could lead to the patient being denied insurance coverage. First, it is important to identify who data is being shared with. Researcher-to-researcher sharing commonly involves a data sharing agreement between their institutions specifying the terms under which disclosed data may be used, responsibilities in the event of data breach, permitted secondary uses (eg, commercialization), and terms of expiry [42]. Where there is disclosure to any third-party including, but not limited to a for-profit AI company, prospective explicit a priori consent has traditionally been required, such as with surgical pathology biobanks [43,44]. As discussed above, emerging alternatives such as \u201cbroad consent,\u201d \u201copt-out consent,\u201d or \u201cpresumed consent\u201d require further evaluation. The reasons why data is shared also affect acceptability of sharing. Academic non-commercial data usage may be less controversial, with extensive precedents set [45], but there is considerable concern among the Canadian Heads of Academic Radiology regarding the ability to develop and implement academic-based algorithms that use data from within a specific medical center. Regardless of the clinical scenario and the methodology, the data custodian must decide whether and in what circumstances to grant data access to scientists, physicians, and commercial entities. It is important to recognize that many problems could arise. Although new AI routines can benefit a wide spectrum of patients, there is potential for abuse. One theoretical concern is that a company with access to hospital data in turn develops an AI routine to detect a disease without a specific, defined contractual obligation and societal commitment regarding the use and commercialization of software. If such assurances, contracts, and details were not in place, there would be no check on the natural tendency of a company to market and sell the routine in the interests of its shareholders rather than those of society as a whole. For example, if a company sells AI software at a high price only accessible to a small segment of the population, some might feel this violates the principle of justice. With increasing needs to build larger models trained on more data, the technical demands of AI endeavors are influencing how data is being shared. These demands grow beyond the scope of a single hospital, clinic or radiology department to requiring specialized resources in the form of large scale graphics processing unit clusters or the use of cloud computing, the need to move data \u201coff-site\u201d becomes a necessity. In practice, as more and more of this data in fact lives \u201coff-site\u201d the notion of \u201con-site\u201d and \u201coff-site\u201d becomes a more abstract construct implying ownership of the hardware on which the analysis is performed and, inherently, a level of supervision. While data custodians need to be mindful of this practice and ensure adequate safeguards are in place in both scenarios, whether potential benefits outweigh the added risks that an initiative requiring \u201coff-site\u201d analysis brings is in the hands of the Institutional Review Boards. Data commoditization also plays a role in how much money the data is transferred for. If data is a commodity, how much is it worth? Providing data to third parties is crucial to innovation in AI. To what extent should a data custodian be able to charge for granting a third-party access to de-identified patient data? In Canada, data custodians often represent publicly funded institutions, and many of the costs to acquire, store, and maintain these records are fixed costs required for the provision of publicly-funded health care. Should the custodian be limited to recovery of costs directly related to anonymization and transfer of data, either via institutional overhead fees or on a per-record basis? How should direct costs be calculated? These will differ for dealing with medical imaging data such as large DICOM files versus other text-based clinical data. Charges exceeding direct costs provide a profit for the data custodian, which some would consider desirable, resulting in a third-party contribution that could support other aspects of health care provided by the custodian but that others would consider undesirable because high costs of data will tend to hinder innovation by stifling data access. Ideally, CAR will in the future be able to provide specific guidance on this issue to assist all stakeholders. Relations with commercial entities risk a lack of transparency that can lead to suspicion and public backlash, as with the recent Google DeepMind/National Health Service collaboration in the United Kingdom. With the simple stated intent of developing a clinical app to identify acute kidney injury, millions of complete identifiable health records were transferred to DeepMind without patient consent, with minimal consultation of regulatory bodies, and without clear safeguards in place [46]. This was particularly controversial given that Google's core business model involves monetizing personal data. The custodian (National Health Service) was felt by many to have placed inadequate constraints on the commercial entity, jeopardizing the privacy of millions of patients and risking data misuse. This highlights the increasingly pivotal role of the data custodian in health care AI. The notion of intellectual property ownership rights with respect to work derived from health records is presently ambiguous. Legal analysis of previous examples have identified a complex intersection between copyright, database rights, contract laws, and personal and human rights protection [47], with greater support for data sharing when it successfully advocates for patient care improvement and innovation. Framed appropriately, the inherent asymmetries in risks to permitting regulated access to information can be balanced to maximize safe research and innovation [48]. Recommendations: 1. CAR to assist radiology data custodians by developing clear guidelines for the custodian role and preparing sample templates of data sharing agreements for common AI-related scenarios. 2. CAR to educate stakeholders on the increasing importance of the data custodian role in the absence of explicit consent. 3. CAR to work to set budgetary guidelines and formulae for departments when granting data-access to third parties. Role of the Radiologist: Liability Whether it is ethically appropriate to use AI depends on whether the AI will, in fact, contribute positively to individual patients and/or society. The philosopher of computer ethics JH Moor suggests that policy should be guided by the principle of \u201cjust consequentialism,\u201d balancing considerations of justice (fairness, impartiality) with the expected positive consequences (reducing harm, increasing happiness) [49]. This is more nuanced than simply applying to AI the old, now-discarded motto of Google, \u201cDon't be evil.\u201d Just as AI in vehicles ranges from a gentle reminder that a human driver is drifting into another lane to AI completely controlling a car, AI in radiology functions at different levels of autonomy, from assisting with triage to providing a second opinion to replacing human expertise [2]. We propose a more granular classification system for levels of autonomy for AI systems applied to radiology (Table 3 ) based on the existing SAE International classification system for autonomous vehicles [50]. It is important to note that each modality and body system represents a separate \u201cuse case\u201d that could be considered its own AI system. For example, level 3 autonomy for mammography may arrive before level 2 autonomy for CT head analysis. It can be argued that level 5 autonomy may never come to fruition for many use cases due to both technical and legislative considerations. In case of malpractice arising where AI was involved, it is currently unclear to what extent each involved party bears responsibility: the patient's physician, the institution at which AI was applied, the broader health care system, and/or the AI technology developer. Fear of liability can have a chilling effect; for example, discouraging data sharing out of fear that this will be used against the institution providing the data. At higher levels of AI autonomy, liability for medical errors becomes more ambiguous. The AI software may be simply non-helpful, like current computer-aided detection (CAD) software in mammography, which is ubiquitous and costly but does not necessarily improve diagnostic accuracy [51,52]. Worse, AI may be harmful. The US Food and Drug Administration states that diagnostic medical devices can be harmful in 5 ways [53]: increasing false-positive results (leading to unnecessary additional procedures), increasing false-negative results (failing to diagnose disease), being applied to inappropriate populations; being misused by human users; and malfunctioning by providing incorrect output. AI software is viewed by regulatory bodies such as Health Canada and the Food and Drug Administration as a medical device [9]. In order to receive approval to market a device, an intended use statement must be submitted by the device manufacturer. If given approval for the intended use, the regulatory body may also place additional controls on the device to ensure safety. An example of the use case for iCAD's Second Look Digital mammography CAD system is the following [54]: \u201cThe MammoReader is a computer system intended to identify and mark regions of interest on standard mammographic views to bring them to the attention of the radiologist after the initial reading has been completed. Thus, the system assists the radiologist in minimizing observational oversights by identifying areas on the original mammogram that may warrant a second review.\u201d Based on this, relatively benign, intended-use statement, it is hard to conceive of any situation where the \u201cAI\u201d would be considered liable in the event of misdiagnosis. Indeed, liability with these level 1 systems continues to rest with the user (radiologist or other clinician). However, as higher levels of autonomy are intended, liability will begin to shift to the AI system and hence to the manufacturer and regulatory body. If the device is intended to autonomously diagnose a certain disease and the system is used as intended by the physician or institution, how could they be accused of malpractice? Consider a malfunctioned CT scanner exposing patients to more radiation than intended. If the institution could prove it was using the device as intended and performed appropriate maintenance, the most likely culprit for damages would be the manufacturer of the CT scanner. By this same token, damages arising from misdiagnosis by a level 4 AI system would be expected to fall on the device manufacturer. If AI interacts directly with the patient (level 5), a duty of care is formed, but if AI at the more common lower levels of autonomy only supplies a consultative opinion, eg, assists the user (radiologist or other clinician) in detecting nodules on a CT scan, it likely does not have a duty of care to the patient, which is still assumed by the clinician [55]. The institution implementing AI could potentially be held liable for AI-related medical error in several ways. It could be held responsible for malpractice under \u201cvicarious liability\u201d in the following circumstances: (1) if the AI system is deemed equivalent to an employee, or as a \u201clearned intermediary,\u201d or (2) if the AI system is deemed a technological device that the institution has a duty to deploy appropriately. The AI technology manufacturer/developer could theoretically be held liable under \u201cproducts liability,\u201d though this type of liability is notoriously difficult to demonstrate for computer software [55]. It is clear that the physician and institution are responsible to implement proper controls and use AI medical devices as intended. For example, specific controls for iCAD's Second Look Digital system state that the software should not be used to overturn a radiologist's decision to call back a patient if they felt a mammogram was suspicious before using the CAD [56]. All of this remains un-tested; to date there have been no medico-legal cases at the Canadian Medical Protective Association related to AI-assisted decision-making. Regardless of the ultimate distribution of liability in these cases, AI ought to be implemented with systemic mitigation measures in place to reduce each of the 5 risks to health from AI, providing reasonable assurance of safety and effectiveness: detailed description of algorithms, study protocols and appropriate datasets, performance testing, labelling, user training, warnings, limitations, and precautions. Recommendations: 1. CAR to work together with other stakeholders such as provincial Ministries of Health and the Canadian Medical Protection Association to develop guidelines for appropriate deployment of AI assistive tools in hospital departments and radiology groups, seeking to minimize potential harm and institutional liability for malpractice in case of medical error involving AI. 2. Radiologists using AI should be aware of its limitations, use AI appropriately within algorithms of care, and not allow AI to replace human expert judgment. Unmet Needs and Future Directions Advances using \u201cbig data\u201d such as AI and genomics have resulted in a paradigm shift in data valuation and usage (Figure 3 ). Older patient data has been considered to be of declining value over time as it became less relevant to that patient's current care. These data now appear to have increasing value over time, especially when linked with longer-term longitudinal follow-up, which continuously improves the robustness and validity of the clinical outcomes to be compared with the patient's original data at clinical presentation. For these reasons, and particularly when a commercialization component emerges, the role of the data custodian is becoming increasingly important. In Canada, our public health care system has the opportunity to develop AI decision support tools using population-wide training data, a key advantage that could enable Canada to be a world leader in harnessing the power of AI to improve health care. In a universal health care system, positive effects of AI are more likely to be applied broadly than in a more fragmented user-pay system, in line with Moore's principle of just consequentiality [49]. This ensures minorities are appropriately included in data sets, limiting potential bias [29]. Data sharing can be seen as a form of altruism, but this requires placing great trust in the data custodians to ensure that data is fully anonymized and is used only for appropriate purposes benefiting the public. Algorithms must be designed to function safely and as transparently as possible, minimizing a \u201cblack-box\u201d approach. At the same time, efforts must be directed at goals maximizing health of individual patients and/or the entire population, not toward less defensible goals, such as excessive benefit to one group of patients or maximizing corporate profit [34]. Conclusions Sharing medical data for research purposes is a complex issue balancing individual privacy rights versus potential collective societal benefits. This is particularly important for radiology AI data analysis, which uniquely requires large quantities of sensitive image data for algorithm training. A paradigm shift\u2014from a patient's right to near-absolute data privacy, to the sharing of anonymized data becoming regarded as one of the duties or responsibilities of a citizen\u2014is underway. This requires a move from \u201cinformed consent\u201d for traditional research projects, toward other forms of consent (\u201cbroad consent,\u201d \u201copt-out' consent,\u201d \u201cpresumed consent\u201d) for AI data analyses. Robust anonymization is crucial to AI data analyses. Best practices for anonymization in radiology can include modifications to the DICOM standard, working with manufacturers to avoid placing identifiable data in proprietary fields within DICOM files, optimizing hospital protocols to minimize data risks, encouraging researchers to use validated protocols of de-identification, and investigating safer means of data sharing such as containerization and blockchain. Institutions (such as a hospital, health care system, or private practice group) implementing AI increasingly must act as a benevolent and enlightened data custodian. They serve as the patient's proxy to make decisions that balance positive consequences for a particular group with justice for all groups and privacy for the individual. Especially since liability for malpractice may rest increasingly on the institution implementing AI, a radiology department or group adopting AI must pay careful attention to the algorithms integrating AI into their health care environment. As we have discussed, AI in radiology is a powerful tool with tremendous potential for individual and societal benefit and also for harm. In a world where data is increasingly valuable and the role of the data custodian is increasingly important, implementation of AI in radiology requires thoughtful planning and frequent re-evaluation. Acknowledgements Fonds de recherche du Qu\u00e9bec en Sant\u00e9 (FRQ-S) and Fondation de l'association des Radiologistes du Qu\u00e9bec (FARQ) Clinical Research Scholarship Salary Award (FRQR-ARQ #34939) to An Tang. Dr Jaremko receives unrestricted support from Medical Imaging Consultants (Edmonton) and the Alberta Health Services Chair in Diagnostic Imaging. Disclosures J.L.J. is one of three co-founders of MEDO.ai, a startup company investigating automated ultrasound image analysis. MEDO has no revenue, and did not provide any support for, or control over, this work. M.C. is a shareholder, co-founder, and Chief Operating Officer of 16 Bit Inc, a software company developing AI algorithms for medical image analysis. 16 Bit did not provide any support for, or control over, Dr Cicero's contribution to this work. J.S. has received research funding from the Ontario Health Technologies Fund, VHA Home Health Care, and the Canadian Institutes of Health Research. F.J.R. is the Medical Director of Imagia Cybernetics, and the Chair of the American College of Radiology Appropriateness Criteria. None of the entities noted provided any support for, or control over, Dr Rybicki's contribution to this work. C.H. is employed by the Canadian Association of Radiologists, which receives corporate grants from IBM Watson. E.L. is the President of the Canadian Association of Radiologists, a partial expense remunerated position, and Regional Medical Director/Regional Department Head, Department of Medical Imaging, Fraser Health Authority (FHA), BC, Canada, a contracted position with the FHA. The FHA and CAR did not provide any support for, or control over, Dr Lee's contribution to this work. A.T. is Chair of the Canadian Association of Radiologists' Artificial Intelligence Working Group. Dr Tang has received a research grant co-funded by MedTEQ and Imagia Cybernetics. M.A., A.L., L.H.A.C., M.G., F.L., B.G., C.R., R.B., and J.C. have no declarations of interest. Supplementary Data Supplemental Tables S1 and S2 Supplementary Data Supplementary data related to this article can be found at https://doi.org/10.1016/j.carj.2019.03.001. References [1] B. Kalis M. Collier R. Fu 10 promising AI applications in health care Harvard Business Review 2018 Available at: https://hbr.org/2018/05/10-promising-ai-applications-in-health-care. Accessed January 14, 2019 [2] A. Tang R. Tam A. Cadrin-Chenevert Canadian Association of Radiologists white paper on artificial intelligence in radiology Can Assoc Radiol J 69 2018 120 135 [3] J. Banks The human touch: practical and ethical implications of putting AI and robotics to work for patients IEEE Pulse 9 2018 15 18 [4] M.A. Morris B. Saboury B. Burkett J. Gao E.L. Siegel Reinventing radiology: Big data and the future of medical imaging J Thorac Imaging 33 2018 4 16 [5] A. Ballantyne G.O. Schaefer Consent and the ethical duty to participate in health data research J Med Ethics 44 2018 392 396 [6] A.F.T. Winfield M. Jirotka Ethical governance is essential to building trust in robotics and artificial intelligence systems Philos Trans A Math Phys Eng Sci 376 2018 [7] Wikipedia White Paper Available at: https://en.wikipedia.org/wiki/White_paper#cite_note-Doerr2-7 [8] A.D. Doerr The role of white papers in the policy-making process: the experience of the government of Canada 1973 Carleton University [9] F. Pesapane C. Volont\u00e9 M. Codari F. Sardanelli Artificial intelligence as a medical device in radiology: ethical and regulatory issues in Europe and the United States Insights Imaging 1\u20139 2018 [10] House of Lords Select Committee AI in the UK: Ready, Willing and Able? 36 2018 House of Lords [11] Supreme Court Judgments 1992 McInerney v. MacDonald Available at: https://scc-csc.lexum.com/scc-csc/scc-csc/en/item/884/index.do. Accessed January 14, 2019 [12] Canada Health Infoway Inc White Paper on Information Governance of the Interoperable Electronic Health Record (EHR) 2007 Available at: https://www.infoway-inforoute.ca/en/component/edocman/resources/toolkits/change-management/national-framework/governance-and-leadership/further-reading/691-white-paper-on-governance-of-the-interoperable-electronic-health-record. Accessed January 14, 2019 [13] P. Kosseim M. Brady Policy by procrastination: secondary use of electronic health records for health research purposes McGill JL & Health 2 2008 5 [14] Ministry of Service Alberta. An Introduction to Alberta Land Titles. Available at: https://www.servicealberta.gov.ab.ca/pdf/lt/Land_Titles_Introduction.pdf. Accessed January 14, 2019 [15] Constitution Act of Canada, 1982 Available at: https://laws-lois.justice.gc.ca/eng/Const/Const_index.html [16] Canadian Institutes of Health Research Tri-council policy statement. Ethical conduct for research involving humans 2014 Government of Canada Ottawa 210 [17] Office of the Privacy Commissioner of Canada. Privacy Breaches Available at: https://www.priv.gc.ca/en/privacy-topics/privacy-breaches/ [18] K.B. Brothers M.A. Rothstein Ethical, legal and social implications of incorporating personalized medicine into healthcare Per Med 12 2015 43 51 [19] K.E. Ormond M.K. Cho Translating personalized medicine using new genetic technologies in clinical practice: the ethical issues Per Med 11 2014 211 222 [20] G. Garbutt P. Davies Should the practice of medicine be a deontological or utilitarian enterprise? J Med Ethics 37 2011 267 270 [21] W.N. Price 2nd I.G. Cohen Privacy in the age of medical big data Nat Med 25 2019 37 43 [22] M.E. Kho M. Duffett D.J. Willison D.J. Cook M.C. Brouwers Written informed consent and selection bias in observational studies using medical records: systematic review BMJ 338 2009 b866 [23] General Data Protection Regulation Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46 Official Journal of the European Union 59 2016 294 [24] D. Shaw Care, data, consent, and confidentiality Lancet 383 2014 1205 [25] B. Saunders Normative consent and opt-out organ donation J Med Ethics 36 2010 84 87 [26] Accountability Act. Health insurance portability and accountability act of 1996 Public Law 104 1996 191 [27] National Institutes of Health Final NIH Genomic Data Sharing Policy Federal Register 79 2014 51345 51354 [28] E. McCallister Guide to Protecting the Confidentiality of Personally Identifiable Information 2010 Diane Publishing Darby, PA [29] Artificial intelligence and medical imaging 2018: French Radiology Community white paper Diagn Interv Imaging 99 2018 727 742 [30] R. Noumeir A. Lemay J.M. Lina Pseudonymization of radiology data for research purposes J Digit Imaging 20 2007 284 295 [31] S.M. Moore D.R. Maffitt K.E. Smith De-identification of medical images with retention of scientific research value RadioGraphics 35 2015 727 735 [32] Horos Available at: https://horosproject.org [33] DicomCleaner\u2122 Available at: https://www.dclunie.com/pixelmed/software/webstart/DicomCleanerUsage.html [34] M. Kohli R. Geis Ethics, artificial intelligence, and radiology J Am Coll Radiol 2018 [35] K.Y. Aryanto M. Oudkerk P.M. van Ooijen Free DICOM de-identification tools in clinical research: functioning and safety of patient privacy Eur Radiol 25 2015 3685 3695 [36] Digital Imaging and Communications in Medicine (DICOM) Available at: https://www.dicomstandard.org/ [37] E. Monteiro C. Costa J.L. Oliveira A de-identification pipeline for ultrasound medical images in DICOM format J Med Syst 41 2017 89 [38] P. Kalavathi V.B. Prasath Methods on skull stripping of MRI head scan images-a Review J Digit Imaging 29 2016 365 379 [39] Docker Available at: https://www.docker.com/ [40] A. Martin S. Raponi T. Combe R. Di Pietro Docker ecosystem\u2013vulnerability analysis Comput Comm 122 2018 30 43 [41] E.A. Bell L. Ohno-Machado M.A. Grando Sharing my health data: a survey of data sharing preferences of healthy individuals AMIA Annu Symp Proc 2014 2014 1699 1708 [42] E. Sawatsky Information Sharing Agreements for Disclosure of EHR Data within Canada 2010 Pan Canadian Health Information (HIP) Group Available at: http://www.ehealthinformation.ca/wp-content/uploads/2014/08/isa.pdf. Accessed January 14, 2019 [43] L.M. Beskow J.Y. Friedman N.C. Hardy L. Lin K.P. Weinfurt Developing a simplified consent form for biobanking PLoS One 5 2010 e13302 [44] J. Murphy J. Scott D. Kaufman G. Geller L. LeRoy K. Hudson Public perspectives on informed consent for biobanking Am J Pub Health 99 2009 2128 2134 [45] D.J. Willison V. Steeves C. Charles Consent for use of personal information for health research: do people with potentially stigmatizing health conditions and the general public differ in their opinions? BMC Med Ethics 10 2009 10 [46] J. Powles H. Hodson Google DeepMind and healthcare in an age of algorithms Health Technol 7 2017 351 367 [47] G.V.D. D\u2019Agostino C. Hinds M. Jirotka Ownership of intellectual property rights in medical data in collaborative computing environments All Papers 2005 Paper 103 Available at: http://digitalcommons.osgoode.yorku.ca/all_papers/103. Accessed January 14, 2019 [48] Council of Canadian Academies Health Data Executive Summary 2015 Government of Canada Ottawa [49] J.H. Moor Just consequentialism and computing Ethics and Information Technology 1 1999 61 65 [50] SAE International Automated Driving Available at: https://web.archive.org/web/20161120142825/http:/www.sae.org/misc/pdfs/automated_driving.pdf [51] C.D. Lehman R.D. Wellman D.S. Buist Diagnostic accuracy of digital screening mammography with and without computer-aided detection JAMA Intern Med 175 2015 1828 1837 [52] A. Kohli S. Jha Why CAD failed in mammography J Am Coll Radiol 15 3 Pt B 2018 535 537 [53] Radiology Devices Fed Regist 83 2018 25598 [54] Summary of safety and effectiveness data Available at: https://www.accessdata.fda.gov/cdrh_docs/pdf/P010038B.pdf [55] J.S. Allain From Jeopardy! to jaundice: the medical liability implications of Dr. Watson and other artificial intelligence systems La L Rev 73 2012 1049 [56] FDA Premarket Approval of iCAD\u2019s Second Look Digital System Available at: https://www.accessdata.fda.gov/scrIpts/cdrh/cfdocs/cfpma/pma.cfm?id=P010038", "scopus-id": "85063882867", "pubmed-id": "30962048", "coredata": {"eid": "1-s2.0-S0846537119300063", "dc:description": "Abstract Artificial intelligence (AI) software that analyzes medical images is becoming increasingly prevalent. Unlike earlier generations of AI software, which relied on expert knowledge to identify imaging features, machine learning approaches automatically learn to recognize these features. However, the promise of accurate personalized medicine can only be fulfilled with access to large quantities of medical data from patients. This data could be used for purposes such as predicting disease, diagnosis, treatment optimization, and prognostication. Radiology is positioned to lead development and implementation of AI algorithms and to manage the associated ethical and legal challenges. This white paper from the Canadian Association of Radiologists provides a framework for study of the legal and ethical issues related to AI in medical imaging, related to patient data (privacy, confidentiality, ownership, and sharing); algorithms (levels of autonomy, liability, and jurisprudence); practice (best practices and current legal framework); and finally, opportunities in AI from the perspective of a universal health care system.", "openArchiveArticle": "false", "prism:coverDate": "2019-05-31", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0846537119300063", "dc:creator": [{"@_fa": "true", "$": "Jaremko, Jacob L."}, {"@_fa": "true", "$": "Azar, Marleine"}, {"@_fa": "true", "$": "Bromwich, Rebecca"}, {"@_fa": "true", "$": "Lum, Andrea"}, {"@_fa": "true", "$": "Alicia Cheong, Li Hsia"}, {"@_fa": "true", "$": "Gibert, Martin"}, {"@_fa": "true", "$": "Laviolette, Fran\u00e7ois"}, {"@_fa": "true", "$": "Gray, Bruce"}, {"@_fa": "true", "$": "Reinhold, Caroline"}, {"@_fa": "true", "$": "Cicero, Mark"}, {"@_fa": "true", "$": "Chong, Jaron"}, {"@_fa": "true", "$": "Shaw, James"}, {"@_fa": "true", "$": "Rybicki, Frank J."}, {"@_fa": "true", "$": "Hurrell, Casey"}, {"@_fa": "true", "$": "Lee, Emil"}, {"@_fa": "true", "$": "Tang, An"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0846537119300063"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0846537119300063"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0846-5371(19)30006-3", "prism:volume": "70", "prism:publisher": "The Authors. Published by Elsevier Inc. on behalf of Canadian Association of Radiologists.", "dc:title": "Canadian Association of Radiologists White Paper on Ethical and Legal Issues Related to Artificial Intelligence in Radiology", "prism:copyright": "\u00a9 2019 The Authors. Published by Elsevier Inc. on behalf of Canadian Association of Radiologists.", "openaccess": "1", "prism:issn": "08465371", "prism:issueIdentifier": "2", "dcterms:subject": [{"@_fa": "true", "$": "Artificial intelligence"}, {"@_fa": "true", "$": "Machine learning"}, {"@_fa": "true", "$": "Ethics"}, {"@_fa": "true", "$": "Legal"}, {"@_fa": "true", "$": "Radiology"}, {"@_fa": "true", "$": "Imaging"}], "openaccessArticle": "true", "prism:publicationName": "Canadian Association of Radiologists Journal", "prism:number": "2", "openaccessSponsorType": "Author", "prism:pageRange": "107-118", "prism:endingPage": "118", "pubType": "Artificial Intelligence / Intelligence artificielle", "prism:coverDisplayDate": "May 2019", "prism:doi": "10.1016/j.carj.2019.03.001", "prism:startingPage": "107", "dc:identifier": "doi:10.1016/j.carj.2019.03.001", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "122", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "11429", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "198", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "13568", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "124", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "24316", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "187", "@width": "337", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "27853", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "497", "@width": "600", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "69119", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "341", "@width": "600", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "63265", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "830", "@width": "1494", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "125970", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2200", "@width": "2657", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "512218", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1508", "@width": "2657", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "420726", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0846537119300063-mmc1.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "APPLICATION", "@size": "23437", "@ref": "mmc1", "@mimetype": "application/pdf"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85063882867"}}
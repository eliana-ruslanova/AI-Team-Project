{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608009002895", "dc:identifier": "doi:10.1016/j.neunet.2009.11.004", "eid": "1-s2.0-S0893608009002895", "prism:doi": "10.1016/j.neunet.2009.11.004", "pii": "S0893-6080(09)00289-5", "dc:title": "A fast algorithm for AR parameter estimation using a novel noise-constrained least-squares method ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "23", "prism:issueIdentifier": "3", "prism:startingPage": "396", "prism:endingPage": "405", "prism:pageRange": "396-405", "prism:number": "3", "dc:format": "application/json", "prism:coverDate": "2010-04-30", "prism:coverDisplayDate": "April 2010", "prism:copyright": "Copyright \u00a9 2009 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Xia, Youshen"}, {"@_fa": "true", "$": "Kamel, Mohamed S."}, {"@_fa": "true", "$": "Leung, Henry"}], "dc:description": "\n               Abstract\n               \n                  In this paper, a novel noise-constrained least-squares (NCLS) method for online autoregressive (AR) parameter estimation is developed under blind Gaussian noise environments, and a discrete-time learning algorithm with a fixed step length is proposed. It is shown that the proposed learning algorithm converges globally to an AR optimal estimate. Compared with conventional second-order and high-order statistical algorithms, the proposed learning algorithm can obtain a robust estimate which has a smaller mean-square error than the conventional least-squares estimate. Compared with the learning algorithm based on the generalized least absolute deviation method, instead of minimizing a non-smooth linear \n                        \n                           \n                              L\n                           \n                           \n                              1\n                           \n                        \n                      function, the proposed learning algorithm minimizes a quadratic convex function and thus is suitable for online parameter estimation. Simulation results confirm that the proposed learning algorithm can obtain more accurate estimates with a fast convergence speed.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Autoregressive parameter estimation"}, {"@_fa": "true", "$": "Noise-constrained least-squares method"}, {"@_fa": "true", "$": "Fast learning algorithm"}, {"@_fa": "true", "$": "Fixed step length"}, {"@_fa": "true", "$": "Robust estimate"}, {"@_fa": "true", "$": "Mean-square error"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608009002895", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608009002895", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "76849091485", "scopus-eid": "2-s2.0-76849091485", "pubmed-id": "20005072", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/76849091485", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20091117", "$": "2009-11-17"}}}}}
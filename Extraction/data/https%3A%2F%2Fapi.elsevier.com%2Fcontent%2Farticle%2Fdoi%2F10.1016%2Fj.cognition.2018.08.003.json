{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0010027718302087", "dc:identifier": "doi:10.1016/j.cognition.2018.08.003", "eid": "1-s2.0-S0010027718302087", "prism:doi": "10.1016/j.cognition.2018.08.003", "pii": "S0010-0277(18)30208-7", "dc:title": "People are averse to machines making moral decisions ", "prism:publicationName": "Cognition", "prism:aggregationType": "Journal", "pubType": "\n               Original Articles\n            ", "prism:issn": "00100277", "prism:volume": "181", "prism:startingPage": "21", "prism:endingPage": "34", "prism:pageRange": "21-34", "dc:format": "application/json", "prism:coverDate": "2018-12-31", "prism:coverDisplayDate": "December 2018", "prism:copyright": "\u00a9 2018 Elsevier B.V. All rights reserved.", "prism:publisher": "Elsevier B.V.", "dc:creator": [{"@_fa": "true", "$": "Bigman, Yochanan E."}, {"@_fa": "true", "$": "Gray, Kurt"}], "dc:description": "\n               Abstract\n               \n                  Do people want autonomous machines making moral decisions? Nine studies suggest that that the answer is \u2018no\u2019\u2014in part because machines lack a complete mind. Studies 1\u20136 find that people are averse to machines making morally-relevant driving, legal, medical, and military decisions, and that this aversion is mediated by the perception that machines can neither fully think nor feel. Studies 5\u20136 find that this aversion exists even when moral decisions have positive outcomes. Studies 7\u20139 briefly investigate three potential routes to increasing the acceptability of machine moral decision-making: limiting the machine to an advisory role (Study 7), increasing machines\u2019 perceived experience (Study 8), and increasing machines\u2019 perceived expertise (Study 9). Although some of these routes show promise, the aversion to machine moral decision-making is difficult to eliminate. This aversion may prove challenging for the integration of autonomous technology in moral domains including medicine, the law, the military, and self-driving vehicles.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Mind perception"}, {"@_fa": "true", "$": "Morality"}, {"@_fa": "true", "$": "Moral agency"}, {"@_fa": "true", "$": "Autonomous machines"}, {"@_fa": "true", "$": "Skynet"}, {"@_fa": "true", "$": "Robots"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0010027718302087", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0010027718302087", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "85051401081", "scopus-eid": "2-s2.0-85051401081", "pubmed-id": "30107256", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/85051401081", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20180811", "$": "2018-08-11"}}}}}
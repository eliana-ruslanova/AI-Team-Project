{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608011001493", "dc:identifier": "doi:10.1016/j.neunet.2011.05.007", "eid": "1-s2.0-S0893608011001493", "prism:doi": "10.1016/j.neunet.2011.05.007", "pii": "S0893-6080(11)00149-3", "dc:title": "Snap\u2013drift neural network for self-organisation and sequence learning ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2011 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "24", "prism:issueIdentifier": "8", "prism:startingPage": "897", "prism:endingPage": "905", "prism:pageRange": "897-905", "prism:number": "8", "dc:format": "application/json", "prism:coverDate": "2011-10-31", "prism:coverDisplayDate": "October 2011", "prism:copyright": "Copyright \u00a9 2011 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "Artificial Neural Networks: Selected Papers from ICANN 2010", "dc:creator": [{"@_fa": "true", "$": "Palmer-Brown, Dominic"}, {"@_fa": "true", "$": "Jayne, Chrisina"}], "dc:description": "\n               Abstract\n               \n                  This paper presents two novel neural networks based on snap\u2013drift in the context of self-organisation and sequence learning. The snap\u2013drift neural network employs modal learning that is a combination of two modes; fuzzy AND learning (snap), and Learning Vector Quantisation (drift). We present the snap\u2013drift self-organising map (SDSOM) and the recurrent snap\u2013drift neural network (RSDNN). The SDSOM uses the standard SOM architecture, where a layer of input nodes connects to the self-organising map layer and the weight update consists of either snap (min of input and weight) or drift (LVQ, as in SOM). The RSDNN uses a simple recurrent network (SRN) architecture, with the hidden layer values copied back to the input layer. A form of reinforcement learning is deployed in which the mode is swapped between the snap and drift when performance drops, and in which adaptation is probabilistic, whereby the probability of a neuron being adapted is reduced as performance increases. The algorithms are evaluated on several well known data sets, and it is found that these exhibit effective learning that is faster than alternative neural network methods.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Modal learning"}, {"@_fa": "true", "$": "Snap\u2013drift algorithm"}, {"@_fa": "true", "$": "Self-organising map"}, {"@_fa": "true", "$": "Recurrent neural network"}, {"@_fa": "true", "$": "Unsupervised learning"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608011001493", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608011001493", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "80051798771", "scopus-eid": "2-s2.0-80051798771", "pubmed-id": "21723705", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/80051798771", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20110606", "$": "2011-06-06"}}}}}
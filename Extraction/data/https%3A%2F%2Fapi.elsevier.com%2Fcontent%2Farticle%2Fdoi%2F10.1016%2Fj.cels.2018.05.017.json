{"scopus-eid": "2-s2.0-85048928895", "originalText": "serial JL 312390 291210 291849 291850 291856 31 Cell Systems CELLSYSTEMS 2018-06-20 2018-06-20 2018-08-22 2018-08-22 2018-09-07T04:52:58 1-s2.0-S2405471218302357 S2405-4712(18)30235-7 S2405471218302357 10.1016/j.cels.2018.05.017 S300 S300.2 FULL-TEXT 1-s2.0-S2405471217X00069 2019-08-22T01:39:05.923791Z 0 0 20180822 2018 2018-06-20T15:31:26.355295Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor grantsponsorid highlightsabst misctext primabst pubtype ref specialabst teaserabst 2405-4712 24054712 true 7 7 2 2 Volume 7, Issue 2 6 185 191.e4 185 191.e4 20180822 22 August 2018 2018-08-22 2018 Focus on Recomb article sco \u00a9 2018 Published by Elsevier Inc. GENERALIZABLESCALABLEVISUALIZATIONSINGLECELLDATAUSINGNEURALNETWORKS CHO H Introduction Results Increasing Redundancy in Single-Cell Datasets Overview of net-SNE net-SNE Learns High-Quality Visualizations of Single Cells net-SNE Accurately Maps New Cells net-SNE Accelerates Visualization of Millions of Cells Discussion STAR\u2605Methods Key Resources Table Contact for Reagent and Resource Sharing Method Details Review of t-Stochastic Neighbor Embedding Our Method: Neural t-SNE Accelerating net-SNE via Stochastic Optimization Training net-SNE with Reference Visualization Benchmark Datasets Data and Software Availability Acknowledgments Supplemental Information References AMIR 2013 545 E AMODIO 2017 M ANCHANG 2016 1264 1279 B BIASE 2014 1787 1796 F BOUSQUET 2008 161 168 O ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS21 TRADEOFFSLARGESCALELEARNING BUETTNER 2015 155 160 F DENG 2014 193 196 Q DZWINEL 2015 572 581 W GAWAD 2016 175 188 C GOOLAM 2016 61 74 M GRUN 2015 251 255 D HAGHVERDI 2017 L HARTIGAN 1979 100 108 J HUTCHISON 2017 L JACKSON 2005 J AUSERSGUIDEPRINCIPALCOMPONENTS JAITIN 2014 776 779 D KIKUCHITAURA 2006 427 A KISELEV 2017 483 486 V KLEIN 2015 1187 1201 A KOLODZIEJCZYK 2015 471 485 A LECUN 2015 436 444 Y LOH 2012 627 630 P MAATEN 2008 2579 2605 L MOON 2017 K PALMER 2012 R71 N PATEL 2014 1396 1401 A PEDREGOSA 2011 2825 2830 F PIERSON 2015 241 E POLLEN 2014 1053 1058 A QIU 2017 979 982 X RAND 1971 846 850 W REGEV 2017 A SAMET 1984 187 260 H SIMMONS 2015 715 728 S STUBBINGTON 2017 58 63 M SVENSSON 2018 599 604 V TING 2014 1905 1918 D TREUTLEIN 2014 371 375 B TUNG 2017 39921 P USOSKIN 2015 145 153 D VANDERMAATEN 2014 3221 3245 L VANDERMAATEN 2009 26 L WANG 2017 414 416 B WANG 2014 155 160 Y YOON 2011 714 717 H YU 2015 130 140 Y ZEISEL 2015 1138 1142 A ZHENG 2017 14049 G CHOX2018X185 CHOX2018X185X191.e4 CHOX2018X185XH CHOX2018X185X191.e4XH Full 2019-08-22T01:12:31Z OA-Window Author http://www.elsevier.com/open-access/userlicense/1.0/ 2019-08-22T00:00:00.000Z 2019-08-22T00:00:00.000Z \u00a9 2018 Published by Elsevier Inc. This article is made available under the Elsevier license. item S2405-4712(18)30235-7 S2405471218302357 1-s2.0-S2405471218302357 10.1016/j.cels.2018.05.017 312390 2019-04-08T19:37:42.200206Z 2018-08-22 1-s2.0-S2405471218302357-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/MAIN/application/pdf/85c249470490d226d36fc026fd9943f6/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/MAIN/application/pdf/85c249470490d226d36fc026fd9943f6/main.pdf main.pdf pdf true 2514393 MAIN 12 1-s2.0-S2405471218302357-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/PREVIEW/image/png/28e8e456a8d2c260b0ac9a8ac914e996/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/PREVIEW/image/png/28e8e456a8d2c260b0ac9a8ac914e996/main_1.png main_1.png png 38602 849 656 IMAGE-WEB-PDF 1 1-s2.0-S2405471218302357-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr3/THUMBNAIL/image/gif/dca0f9f188c611f16a065daa50b3ef26/gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr3/THUMBNAIL/image/gif/dca0f9f188c611f16a065daa50b3ef26/gr3.sml gr3 gr3.sml sml 14586 96 219 IMAGE-THUMBNAIL 1-s2.0-S2405471218302357-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr1/THUMBNAIL/image/gif/7531b442ddabfb515f7e7d5e3ac28520/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr1/THUMBNAIL/image/gif/7531b442ddabfb515f7e7d5e3ac28520/gr1.sml gr1 gr1.sml sml 13467 76 219 IMAGE-THUMBNAIL 1-s2.0-S2405471218302357-fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/fx1/THUMBNAIL/image/gif/b3c51f7c7f16d2d839de521dafcd801c/fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/fx1/THUMBNAIL/image/gif/b3c51f7c7f16d2d839de521dafcd801c/fx1.sml fx1 true fx1.sml sml 21670 164 164 IMAGE-THUMBNAIL 1-s2.0-S2405471218302357-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr4/THUMBNAIL/image/gif/684881c5499b367cfb59e51f53996dbf/gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr4/THUMBNAIL/image/gif/684881c5499b367cfb59e51f53996dbf/gr4.sml gr4 gr4.sml sml 21769 110 219 IMAGE-THUMBNAIL 1-s2.0-S2405471218302357-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr2/THUMBNAIL/image/gif/2f530610c717f2f38e226a6bf57c6eaa/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr2/THUMBNAIL/image/gif/2f530610c717f2f38e226a6bf57c6eaa/gr2.sml gr2 gr2.sml sml 14592 81 219 IMAGE-THUMBNAIL 1-s2.0-S2405471218302357-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr3/DOWNSAMPLED/image/jpeg/708dcbaf479364aca189c89a09bd7070/gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr3/DOWNSAMPLED/image/jpeg/708dcbaf479364aca189c89a09bd7070/gr3.jpg gr3 gr3.jpg jpg 80535 286 655 IMAGE-DOWNSAMPLED 1-s2.0-S2405471218302357-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr1/DOWNSAMPLED/image/jpeg/390da31509c7474c93152807b0582197/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr1/DOWNSAMPLED/image/jpeg/390da31509c7474c93152807b0582197/gr1.jpg gr1 gr1.jpg jpg 76996 229 655 IMAGE-DOWNSAMPLED 1-s2.0-S2405471218302357-fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/fx1/DOWNSAMPLED/image/jpeg/ce2402d0cf6ee7effe049583e8e1d3c3/fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/fx1/DOWNSAMPLED/image/jpeg/ce2402d0cf6ee7effe049583e8e1d3c3/fx1.jpg fx1 true fx1.jpg jpg 57695 375 375 IMAGE-DOWNSAMPLED 1-s2.0-S2405471218302357-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr4/DOWNSAMPLED/image/jpeg/8ce4fe758e33f6033cffa7da972d93b4/gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr4/DOWNSAMPLED/image/jpeg/8ce4fe758e33f6033cffa7da972d93b4/gr4.jpg gr4 gr4.jpg jpg 120175 330 655 IMAGE-DOWNSAMPLED 1-s2.0-S2405471218302357-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr2/DOWNSAMPLED/image/jpeg/87903d911e545b9dd8a1fa412f095864/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr2/DOWNSAMPLED/image/jpeg/87903d911e545b9dd8a1fa412f095864/gr2.jpg gr2 gr2.jpg jpg 80298 242 655 IMAGE-DOWNSAMPLED 1-s2.0-S2405471218302357-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr3/HIGHRES/image/jpeg/12a0342aafb6321cc670d09826172bdd/gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr3/HIGHRES/image/jpeg/12a0342aafb6321cc670d09826172bdd/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 621552 1267 2902 IMAGE-HIGH-RES 1-s2.0-S2405471218302357-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr1/HIGHRES/image/jpeg/93547bf9f0b3b9343b4968b1389b042d/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr1/HIGHRES/image/jpeg/93547bf9f0b3b9343b4968b1389b042d/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 384476 1013 2900 IMAGE-HIGH-RES 1-s2.0-S2405471218302357-fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/fx1/HIGHRES/image/jpeg/67436db1dd8970c7a49a11cc3fd32b9c/fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/fx1/HIGHRES/image/jpeg/67436db1dd8970c7a49a11cc3fd32b9c/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 161089 996 996 IMAGE-HIGH-RES 1-s2.0-S2405471218302357-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr4/HIGHRES/image/jpeg/be45aaf5725d02d4e0852b7c1064faf8/gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr4/HIGHRES/image/jpeg/be45aaf5725d02d4e0852b7c1064faf8/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 1141994 1463 2900 IMAGE-HIGH-RES 1-s2.0-S2405471218302357-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/gr2/HIGHRES/image/jpeg/79dd8de7bc5e31de36c14c520631771b/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/gr2/HIGHRES/image/jpeg/79dd8de7bc5e31de36c14c520631771b/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 590535 1073 2900 IMAGE-HIGH-RES 1-s2.0-S2405471218302357-mmc2.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/mmc2/MAIN/application/pdf/27c125365e0504f167739e66a96c9013/mmc2.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/mmc2/MAIN/application/pdf/27c125365e0504f167739e66a96c9013/mmc2.pdf mmc2 mmc2.pdf pdf false 4020019 APPLICATION 1-s2.0-S2405471218302357-mmc1.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/mmc1/MAIN/application/pdf/413e6f749d56da485d435bceb08ffed8/mmc1.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/mmc1/MAIN/application/pdf/413e6f749d56da485d435bceb08ffed8/mmc1.pdf mmc1 mmc1.pdf pdf false 1509239 APPLICATION 1-s2.0-S2405471218302357-si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/45e9a5b0afb49168329720b7cd624474/si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/45e9a5b0afb49168329720b7cd624474/si16.gif si16 si16.gif gif 1615 39 287 ALTIMG 1-s2.0-S2405471218302357-si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/0de2c3b21db206ceeb791d33c07ecc18/si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/0de2c3b21db206ceeb791d33c07ecc18/si17.gif si17 si17.gif gif 337 15 80 ALTIMG 1-s2.0-S2405471218302357-si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/75d16a4510e8564b81b150f105fd629c/si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/75d16a4510e8564b81b150f105fd629c/si24.gif si24 si24.gif gif 147 14 11 ALTIMG 1-s2.0-S2405471218302357-si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/b0346b68c8a8d499530ffeb2c39336b2/si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/b0346b68c8a8d499530ffeb2c39336b2/si21.gif si21 si21.gif gif 171 15 15 ALTIMG 1-s2.0-S2405471218302357-si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/8c2f974caea57d7b3fc04967d5a288b1/si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/8c2f974caea57d7b3fc04967d5a288b1/si19.gif si19 si19.gif gif 2061 39 424 ALTIMG 1-s2.0-S2405471218302357-si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/f5f595d2c7c9a3892c2b75293b5748cf/si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/f5f595d2c7c9a3892c2b75293b5748cf/si9.gif si9 si9.gif gif 333 15 67 ALTIMG 1-s2.0-S2405471218302357-si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/085231101beee3760b73c8eb77c7cc66/si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/085231101beee3760b73c8eb77c7cc66/si18.gif si18 si18.gif gif 1783 41 309 ALTIMG 1-s2.0-S2405471218302357-si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/a677ddaec53dfd908f0add73fac7d88d/si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/a677ddaec53dfd908f0add73fac7d88d/si2.gif si2 si2.gif gif 147 11 13 ALTIMG 1-s2.0-S2405471218302357-si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/b57e3c15e6a829f19c38911cc2fbba96/si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/b57e3c15e6a829f19c38911cc2fbba96/si10.gif si10 si10.gif gif 206 14 32 ALTIMG 1-s2.0-S2405471218302357-si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/b36e08d17529364dbac1cd2f56e46535/si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/b36e08d17529364dbac1cd2f56e46535/si11.gif si11 si11.gif gif 265 14 45 ALTIMG 1-s2.0-S2405471218302357-si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/db5dcd8ee2d05d8efe872c8fea15a781/si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/db5dcd8ee2d05d8efe872c8fea15a781/si14.gif si14 si14.gif gif 148 11 11 ALTIMG 1-s2.0-S2405471218302357-si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/436a6927e2bebc4dac67084f582c5cab/si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/436a6927e2bebc4dac67084f582c5cab/si6.gif si6 si6.gif gif 1304 39 297 ALTIMG 1-s2.0-S2405471218302357-si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/aca2b9bf51ce280097126788486653e5/si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/aca2b9bf51ce280097126788486653e5/si15.gif si15 si15.gif gif 210 11 28 ALTIMG 1-s2.0-S2405471218302357-si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/ffe11a97634d4dcfaaae5dc30e1a6ed1/si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/ffe11a97634d4dcfaaae5dc30e1a6ed1/si3.gif si3 si3.gif gif 326 14 79 ALTIMG 1-s2.0-S2405471218302357-si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/04191fc48b0d37486029d957ace9ec6e/si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/04191fc48b0d37486029d957ace9ec6e/si5.gif si5 si5.gif gif 2087 57 338 ALTIMG 1-s2.0-S2405471218302357-si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/471622865e1127d622caba8aad5bf6b6/si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/471622865e1127d622caba8aad5bf6b6/si8.gif si8 si8.gif gif 1443 38 302 ALTIMG 1-s2.0-S2405471218302357-si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/920ea057abd1c79a74e782f12db6e116/si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/920ea057abd1c79a74e782f12db6e116/si25.gif si25 si25.gif gif 147 12 10 ALTIMG 1-s2.0-S2405471218302357-si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/a9219e9046520ba0c797e0a096259c31/si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/a9219e9046520ba0c797e0a096259c31/si23.gif si23 si23.gif gif 335 15 80 ALTIMG 1-s2.0-S2405471218302357-si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/072a353128d385c2156234b030c3c3d3/si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/072a353128d385c2156234b030c3c3d3/si7.gif si7 si7.gif gif 175 13 18 ALTIMG 1-s2.0-S2405471218302357-si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/85ebec5446a39674de26aaecd2aa0b57/si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/85ebec5446a39674de26aaecd2aa0b57/si1.gif si1 si1.gif gif 330 17 82 ALTIMG 1-s2.0-S2405471218302357-si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/b40ae4330c909e94780c8e4fe1cd46d8/si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/b40ae4330c909e94780c8e4fe1cd46d8/si4.gif si4 si4.gif gif 1111 34 248 ALTIMG 1-s2.0-S2405471218302357-si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/8f019a2ca9c695f48c7cb6256edc25c1/si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/8f019a2ca9c695f48c7cb6256edc25c1/si22.gif si22 si22.gif gif 494 15 101 ALTIMG 1-s2.0-S2405471218302357-si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/83954a9677e84ea7c8903975cf79866a/si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/83954a9677e84ea7c8903975cf79866a/si20.gif si20 si20.gif gif 858 39 151 ALTIMG 1-s2.0-S2405471218302357-si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/0e7b42d11b9d53d21d280a5c33bc603f/si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/0e7b42d11b9d53d21d280a5c33bc603f/si12.gif si12 si12.gif gif 1470 65 258 ALTIMG 1-s2.0-S2405471218302357-si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405471218302357/STRIPIN/image/gif/e52118fe7999f3e86be3bd257d5ba78b/si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S2405471218302357/STRIPIN/image/gif/e52118fe7999f3e86be3bd257d5ba78b/si13.gif si13 si13.gif gif 416 15 88 ALTIMG 1-s2.0-S2405471218302357-am.pdf am am.pdf pdf 25611007 AAM-PDF https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10JFKM2TBFV/MAIN/application/pdf/ebcecc216e4e9b7e23183b5eb6398c4f/am.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/egi:10JFKM2TBFV/MAIN/application/pdf/ebcecc216e4e9b7e23183b5eb6398c4f/am.pdf CELS 464 S2405-4712(18)30235-7 10.1016/j.cels.2018.05.017 Figure 1 The Increasing Scale and Redundancy of Single-Cell RNA-Seq Datasets (A) The exponential increase in the number of single cells sequenced by individual studies (adapted from Svensson et al., 2018). Note that the y axis scales exponentially. (B) Retrospective analysis of redundancy in the Brain1m dataset (STAR Methods) with 2,000 initial cells and repeated doubling of the data size. For each batch added, we computed the distribution of the cells' minimum Euclidean distance to cells already observed based on their gene expression. Each curve corresponds to a particular distance threshold for deeming the new cell redundant. The thresholds are chosen as the deciles of the overall distribution of minimum Euclidean distances. Figure 2 net-SNE Recapitulates t-SNE Mapping on 13 Benchmark Datasets with Known Subtypes (A) Comparison of net-SNE and t-SNE visualizations on four largest benchmark datasets with known clusters. Colors indicate known cell types provided by the original work. net-SNE visualizations of the Klein and Zeisel datasets are reflected over a diagonal axis for comparison. Figures for the remaining datasets are provided in Figure S1. (B) Quality of each visualization is quantified by the adjusted Rand index between the known labels and the output of k-means clustering based on the embedding. Each dot represents one of the 13 datasets analyzed. Results based on agglomerative clustering instead of k-means are provided in Figure S2, also showing a high concordance between net-SNE and t-SNE. Figure 3 net-SNE Generalizes to Unseen Cells (A) Each column represents a cross-validation experiment whereby the visualization is performed only on a subset of data (shown in gray), where all cells corresponding to one of the four known cell types in the Klein dataset were held out. Held-out cells were later added to the visualization (shown in color). We compared net-SNE with a naive extension of t-SNE whereby each new cell is placed at the average position of the five nearest neighbors in the initial dataset. Unlike t-SNE, net-SNE is able to identify the newly added cells as a separate cluster. Also, in the setting where the new cells belong to subtypes already represented in the initial dataset, net-SNE accurately assigns the new cells to the respective clusters (Figure S4B). (B) To further test net-SNE's generalizability, we obtained scRNA-seq datasets from 10x Genomics for six representative blood cell subtypes (shown in subfigures), each purified via fluorescence-activated cell sorting. We visualized each of the purified cell populations (in red) over a pre-trained net-SNE embedding of the PBMC68k dataset (shown in gray), which is from a whole blood sample encompassing all of the purified cell types. Despite coming from a different sequencing experiment with different sample preparation, many of the purified cell types were mapped by net-SNE to well-defined clusters in the visualization, demonstrating its potential for knowledge transfer across different datasets. Figure 4 net-SNE Enables Fast Visualization of Mega-Scale Datasets The Brain1m dataset with 1.3 million cells is visualized using a novel bootstrap approach enabled by net-SNE, whereby the embedding learned on a subset of 100 K cells (A) was used to initialize training on the whole dataset. Our initial generalization to the full data instantly obtained (in minutes) a visualization (B) of higher quality, as measured by the KL divergence objective score minimized by both methods (STAR Methods), than that of t-SNE with default parameters achieved after 13 hr (D). While the t-SNE embedding provided in the original dataset by 10x Genomics (E) achieves a better objective, net-SNE outperforms this embedding with less than an hour of further training (C). Top row shows the heatmap for each embedding using a linear color map, where the highest value represented is chosen for each plot to achieve the best clarity. Bottom row shows contour plots of the same data. Lower objective score corresponds to better agreement between the gene-expression landscape and the visualization. \u2217The visualization by 10x Genomics can be closely reproduced by increasing the number of iterations for t-SNE, and based on our experiments t-SNE required 1.5 days to achieve a solution with a comparable score. Report Generalizable and Scalable Visualization of Single-Cell Data Using Neural Networks Hyunghoon Cho 1 Bonnie Berger 1 2 4 \u2217 bab@mit.edu Jian Peng 3 \u2217\u2217 jianpeng@illinois.edu 1 Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA 02139, USA Computer Science and Artificial Intelligence Laboratory MIT Cambridge MA 02139 USA 2 Department of Mathematics, MIT, Cambridge, MA 02139, USA Department of Mathematics MIT Cambridge MA 02139 USA 3 Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, USA Department of Computer Science University of Illinois at Urbana-Champaign Urbana IL 61801 USA \u2217 Corresponding author \u2217\u2217 Corresponding author 4 Lead Contact Published: June 20, 2018 Summary Visualization algorithms are fundamental tools for interpreting single-cell data. However, standard methods, such as t-stochastic neighbor embedding (t-SNE), are not scalable to datasets with millions of cells and the resulting visualizations cannot be generalized to analyze new datasets. Here we introduce net-SNE, a generalizable visualization approach that trains a neural network to learn a mapping function from high-dimensional single-cell gene-expression profiles to a low-dimensional visualization. We benchmark net-SNE on 13 different datasets, and show that it achieves visualization quality and clustering accuracy comparable with t-SNE. Additionally we show that the mapping function learned by net-SNE can accurately position entire new subtypes of cells from previously unseen datasets and can also be used to reduce the runtime of visualizing 1.3 million cells by 36-fold (from 1.5 days to an hour). Our work provides a framework for bootstrapping single-cell analysis from existing datasets. Graphical Abstract Highlights \u2022 We train a neural network to visualize single-cell RNA-sequencing datasets \u2022 Our method can map new cells onto existing visualizations to allow knowledge transfer \u2022 Our method efficiently visualizes millions of cells via a bootstrap procedure Researchers are applying single-cell RNA sequencing to increasingly large numbers of cells in diverse tissues and organisms. We introduce a data visualization tool, named net-SNE, which trains a neural network to embed single cells in 2D or 3D. Unlike previous approaches, our method allows new cells to be mapped onto existing visualizations, facilitating knowledge transfer across different datasets. Our method also vastly reduces the runtime of visualizing large datasets containing millions of cells. Keywords data visualization single-cell RNA sequencing neural network Introduction Complex biological systems arise from functionally diverse, heterogeneous populations of cells. Single-cell RNA sequencing (scRNA-seq) (Gawad et al., 2016), which profiles transcriptomes of individual cells rather than bulk samples, has been a key tool in dissecting the intercellular variation in a wide range of domains, including cancer biology (Wang et al., 2014), immunology (Stubbington et al., 2017), and metagenomics (Yoon et al., 2011). scRNA-seq also enables the de novo identification of cell types with distinct expression patterns (Gr\u00fcn et al., 2015; Jaitin et al., 2014). A standard analysis for scRNA-seq data is to visualize single-cell gene-expression patterns of samples in a low-dimensional (2D or 3D) space via methods such as t-stochastic neighbor embedding (t-SNE) (Maaten and Hinton, 2008) or, in earlier studies, principal component analysis (Jackson, 2005), whereby each cell is represented as a dot and cells with similar expression profiles are located close to each other. Such visualization reveals the salient structure of the data in a form that is easy for researchers to grasp and further manipulate. For instance, researchers can quickly identify distinct subpopulations of cells through visual inspection of the image, or use the image as a common lens through which different aspects of the cells are compared. The latter is typically achieved by overlaying additional data on top of the visualization, such as known labels of the cells or the expression levels of a gene of interest (Zheng et al., 2017). While many of these approaches have initially been explored for visualizing bulk RNA-seq (Palmer et al., 2012; Simmons et al., 2015), methods that take into account the idiosyncrasies of scRNA-seq (e.g., dropout events where nonzero expression levels are missed as zero) have also been proposed (Pierson and Yau, 2015; Wang et al., 2017). Recently, more advanced approaches that visualize the cells while capturing important global structures such as cellular hierarchy or trajectory have been proposed (Anchang et al., 2016; Hutchison et al., 2017; Moon et al., 2017; Qiu et al., 2017), which constitute a valuable complementary approach to general-purpose methods such as t-SNE. Comprehensively characterizing the landscape of single cells requires a large number of cells to be sequenced. Fortunately, advances in automatic cell isolation and multiplex sequencing have led to an exponential growth in the number of cells sequenced for individual studies (Svensson et al., 2018) (Figure 1 A). For example, 10x Genomics recently made publicly available a dataset containing the expression profiles of 1.3 million brain cells from mice (https://support.10xgenomics.com/single-cell-gene-expression/datasets). However, the emergence of such mega-scale datasets poses new computational challenges before they can be widely adopted. Many of the existing computational methods for analyzing scRNA-seq data require prohibitive runtimes or computational resources; in particular, the state-of-the-art implementation of t-SNE (Van Der Maaten, 2014) requires 1.5 days to run on 1.3 million cells based on our estimates. Here, we introduce neural t-SNE (net-SNE), a scalable and generalizable method for visualizing single cells for scRNA-seq analysis. Taking inspiration from compressive genomics (Loh et al., 2012), we exploit the intuition that when a large number of cells are sequenced, a significant portion of the cells are redundant (i.e., highly similar to other cells). Taking advantage of the expressive power of neural networks (NNs), which has been demonstrated in numerous applications (LeCun et al., 2015), net-SNE trains an NN to learn a high-quality mapping function that takes an expression profile as input and outputs a low-dimensional embedding in 2D or 3D for visualization. Unlike t-SNE, the mapping function learned by net-SNE can be used to map previously unseen cells that were not included in the input data. This capability allows for novel workflows for single-cell studies, whereby newly observed cells are visualized in the context of existing datasets to gain additional insights. To demonstrate visualization quality as well as scalability, we show that net-SNE learns visualizations that are similar to those of t-SNE on 14 scRNA-seq datasets of various cell types and data sizes up to 1.3 million cells. Next we focused on generalizability, demonstrating that net-SNE newly achieves the ability to map previously unseen cells; in particular, we show that net-SNE not only can identify subtypes of cells that were not included in the initial data but can also be used to bootstrap the visualization from a subset of data to achieve significantly better scalability to mega-scale datasets. Given the inherent redundancy in biological data (Yu et al., 2015), we expect our techniques for neural data visualization to accelerate and enhance other high-dimensional biological data analyses beyond visualization. Results Increasing Redundancy in Single-Cell Datasets We first set out to empirically assess the extent to which additional sequencing of single cells from the same biological source capture unforeseen expression patterns. Starting with 2,000 randomly chosen cells from the 10x Genomics scRNA-seq dataset with 1.3 million mouse neurons (STAR Methods), we repeatedly doubled the data size up to a million cells by sampling the remaining cells (without replacement) and measured how redundant the newly added cells are compared with the ones already observed (Figure 1B). As the scale of data grows, sequencing more cells exhibits a clear diminishing return in terms of capturing cells with unique expression patterns. For example, the majority of cells (53%) in the final half of the data can be considered redundant according to a certain distance threshold, which deems only 10% of the cells redundant in the initial batch. Nevertheless, a considerable fraction of the newly observed cells remains unique even at the scale of a million cells. For instance, 10% of the cells in the final half are as unique as the top 30% of the initial batch, which suggests that the push toward a higher cell count is indeed valuable for gaining access to relatively unexplored regions of the gene-expression landscape, albeit with decreasing effectiveness. These results imply that, as researchers collectively accumulate scRNA-seq data for a particular biological system (e.g., tissue, organism, or microbial population) to the scale of millions of cells, a significant portion of newly sequenced cells will fall into the space already visited by existing data, where useful insights may be available from previous analyses. This observation motivates our development of net-SNE, which allows new data to be mapped onto an existing visualization to accelerate such knowledge transfer across different studies or experiments. Overview of net-SNE net-SNE achieves generalizability by training a feedforward neural network (LeCun et al., 2015) to learn a parameterized embedding function that takes a cell's expression profile as input and outputs the coordinates in a low-dimensional space for visualization (STAR Methods). Given the wide success of t-SNE in single-cell biology (Amir et al., 2013), we aim to emulate the behavior of t-SNE while newly achieving the ability to map new cells, by training our neural network to optimize the same objective function as t-SNE. This objective function intuitively captures how faithfully the local structure among the input vectors (i.e., single-cell gene-expression profiles) is represented in the visualization. Although our parametric approach to t-SNE has been theoretically considered (Van Der Maaten, 2009), its application to real-world, large-scale datasets has been considerably limited due to the difficulties in successfully training a neural network to perform a complex task such as t-SNE. Our work employs new optimization techniques to improve the scalability of neural network training for t-SNE (STAR Methods) and newly demonstrates the effectiveness of this approach for single-cell analysis. net-SNE Learns High-Quality Visualizations of Single Cells To evaluate the ability of net-SNE to accurately model the visualization of single-cell datasets, we tested it on 13 existing scRNA-seq datasets of varying sizes with known clusters (STAR Methods). We found that for all of the datasets net-SNE is able to learn an embedding that closely matches the output of t-SNE (Figures 2A and S1). To systematically evaluate the quality of embeddings produced by net-SNE, we assessed the agreement between the known subtypes and clusters that are computationally identified based on the low-dimensional embeddings. The level of agreement was quantified by the adjusted Rand index (Rand, 1971), following previous work (Kiselev et al., 2017). We obtained the clusters by applying the standard k-means clustering algorithm (Hartigan and Wong, 1979) to the embeddings, where the known number of clusters was provided to the algorithm. As shown in Figure 2B, net-SNE achieves clustering accuracy that is comparable with t-SNE for all 13 datasets, which agrees with the visual concordance of the two methods. An analogous analysis we performed, based on agglomerative clustering instead of k-means, leads to similar concordance between net-SNE and t-SNE (Figure S2). Notably, we obtained all of these results using a relatively simple neural network with only two layers of nonlinearities with 50 units in each layer (Figure S1B). In additional experiments, not only did we observe that the net-SNE results are reasonably stable across a wide range of network architectures, we also found that the size of our network can be reduced to as low as 10 units per layer without significantly sacrificing the quality of visualizations (Figure S4), even for the PBMC68k dataset containing tens of thousands of cells. This finding suggests that the relationship between gene-expression profiles and the clustering pattern of cells may be simple enough to admit a concise characterization for various cell populations. net-SNE Accurately Maps New Cells To demonstrate the potential of net-SNE for translational analyses across different datasets, we performed a cross-validation experiment whereby an entire cluster of cells was removed from a dataset and placed onto the visualization after the fact. While the original t-SNE does not support the visualization of new data points, we considered as baseline a naive extension of t-SNE whereby the embedding of a new cell is determined as the average position (in the low-dimensional space) of the cell's nearest neighbors in the initial data according to expression measurements (t-SNE + k-NN). An alternative extension of t-SNE whereby the new cells are randomly initialized and optimized while fixing the positions of the initial cells similarly lacks the scalability to mega-scale datasets as the original t-SNE and thus was not considered in our analysis. Figure 3 shows our cross-validation results from the Klein dataset (Klein et al., 2015), which contains four known clusters, each of which was held out in four separate experiments. Remarkably, in three out of the four cases, the embedding learned by net-SNE accurately positioned the held-out cells as a distinct cluster, despite the fact that the training data did not contain any of the cells from this cluster. In contrast, our nearest neighbor-extension of t-SNE (t-SNE + k-NN) overlaid most of the new cells onto existing clusters and ended up incorrectly outputting an obfuscated map. Although visualizing the entire dataset from scratch tends to result in better-quality scores than both of these approaches (Figure S4A), we note that the initial generalization obtained by either approach can be further optimized if desired. The setting of this cross-validation analysis may arise in practice in cases where a rare subpopulation of cells was omitted from the initial dataset (e.g., due to small data size). Our results suggest that, while the naive nearest neighbor-based projection of newly observed cells (including the rare subtype) will likely render the new subtype invisible, net-SNE is still able to identify the new cluster, given that its gene expression is sufficiently distinct from that of existing cells. In an alternative setting where the new cells are from a subtype that is already represented in the initial dataset, net-SNE is still able to accurately assign the new cells to the correct cluster (Figure S4B). To further demonstrate the utility of net-SNE's generalization performance beyond cross-validation, we obtained six scRNA-seq datasets of different purified blood cell subtypes from 10x Genomics (STAR Methods). We projected each dataset onto a pre-trained, net-SNE visualization of the PBMC68k dataset of a whole blood sample, which includes all six subtypes. Despite the differences in sample preparation and the possibility of batch effects (Tung et al., 2017), net-SNE accurately positions the purified cell populations onto existing clusters, immediately providing a useful characterization for a number of clusters in the PBMC68k dataset (Figure 3B). Notably, net-SNE projected most of the purified CD34-positive cells onto a distinct region that contained only a small number of cells in the initial dataset. This observation is consistent with the low basal levels of CD34-positive cells in blood (Kikuchi-Taura et al., 2006) and further illustrates net-SNE's ability to capture previously unseen subtypes of cells. net-SNE Accelerates Visualization of Millions of Cells After validating net-SNE's ability to map new cells, we then asked whether this ability can be exploited to achieve fast visualization of mega-scale datasets. Drawing from the intuition that datasets of this scale can be accurately represented by a smaller subset of cells due to high redundancy, we first trained net-SNE on a subset of 100,000 cells from the Brain1m dataset containing 1.3 million cells and later applied the learned embedding function to the entire dataset. This fast approach took around only 20 min overall and resulted in a higher-quality map than the output of t-SNE with the default parameter settings, which took 13 hr to finish. Note that we use the Kullback-Leibler (KL) divergence objective score\u2014the quantity minimized by both t-SNE and net-SNE\u2014as the metric of quality (inversely related), which is more objective than a visual assessment. If a researcher already has access to a pre-trained mapping based on an existing dataset, the reduction in runtime achieved by net-SNE is likely to be even more drastic (e.g., days for t-SNE to a few minutes). It is worth noting that the original dataset provided by 10x Genomics also included a t-SNE embedding, which appeared higher in quality than the t-SNE output we obtained using the default setting (Figure 4 E). While the objective score we computed based on the published embedding was superior to net-SNE's initial generalization, 45 min of further optimization of net-SNE was sufficient to outperform this score (Figure 4C). After observing that we can achieve a visualization similar to the one provided by 10x Genomics by increasing the number of iterations for t-SNE (thus increasing runtime), we performed an experiment whereby we ran t-SNE until it reached an objective score matching the provided embedding. This resulted in a runtime estimate of 1.5 days for the published visualization, which is substantially longer than that required by net-SNE to achieve a superior quality (i.e., 20 min of pre-training and 45 min of further optimization). Notably, if the visualization by net-SNE was performed based on a well-characterized dataset, the map obtained by net-SNE would have the additional benefit of allowing researchers to immediately transfer insights from the existing dataset. The visual difference between the net-SNE and t-SNE outputs in this experiment can be partially attributed to the fact that there are likely many locally optimal solutions to the same optimization problem solved by both methods. Although the clusters may appear more clearly separated in the t-SNE output, the fact that our visualization actually achieves a better objective score suggests the possibility of the abrupt boundaries in t-SNE being an artifact that is not warranted by the underlying data. Since net-SNE restricts the space of possible visualizations to those that can be modeled as a continuous function of gene expression as specified by our relatively simple neural network, it has a tendency to obtain a \u201csmoother\u201d visualization, which could potentially be a more accurate representation of the gene-expression landscape. Note that we obtained our results on the Brain1m dataset using a two-layer neural network with 50 hidden units per layer, as in our aforementioned analyses. Discussion As we enter the age of mega-scale single-cell analysis, new computational methods that take advantage of the growing redundancy in the scRNA-seq data are needed. To this end we have presented net-SNE, a visualization method that uses a neural network to learn a parametric embedding function that emulates t-SNE's visualization while newly achieving the ability to map previously unseen cells. We have demonstrated that net-SNE not only learns high-quality maps such as t-SNE, but also gracefully generalizes to unseen cells\u2014even when a whole subpopulation is missing from the initial dataset or when the new data come from a different sequencing experiment. Indeed, net-SNE's ability to generalize allows researchers to exploit redundancy across different datasets by projecting the cells in one dataset onto another to facilitate transfer of knowledge. In addition, we have shown that using a pre-trained embedding from a subsampled (or an existing) dataset is an effective way for performing fast visualization of mega-scale scRNA-seq datasets. Our approach achieves significantly better scalability than t-SNE, which is on the verge of being impractical for datasets with more than a million cells. Although a number of recent studies introduced new techniques for improving the scalability of data visualization tools (Dzwinel and Wcis\u0142o, 2015; Tang et al., 2016), they do not address the lack of generalizability that net-SNE overcomes. A number of recently proposed techniques for single-cell analysis can be used in conjunction with net-SNE to potentially further enhance its visualization quality; for instance, methods that account for dropout events (Wang et al., 2017) or batch effects (Haghverdi et al., 2017) can be employed to improve the input similarity matrix before applying net-SNE. Notably, Amodio et al. (2017), concurrently with this work, introduced an autoencoder-based approach for jointly performing batch effect correction and visualization, which finds a parametric embedding like net-SNE. Because they optimize a different objective function, however, the behavior of their embedding is fundamentally different from that of t-SNE (and thus net-SNE). The fact that net-SNE obtains a visualization whereby the coordinates are directly modeled by the neural network as a function of gene expression opens up new directions for further research. In particular, one can investigate the parameters of the NNs trained by net-SNE for insights into what types of expression patterns are being utilized for t-SNE-like visualizations. Furthermore, while the characterization of conspicuous clusters in t-SNE output has typically been done by summarizing the expression of cells that belong to the cluster of interest, net-SNE enables a more direct and potentially more effective approach that analyzes the behavior of the embedding function. A recently proposed idea of building a reference map of all human cell types based on high-throughput single-cell experiments (called the Human Cell Atlas [Regev et al., 2017]) is closely related to our vision. While embedding all cell types in a space with as few as two or three dimensions is unlikely to be successful given the complexity of the problem, we believe that insights from net-SNE and its future extensions may lead to an effective approach for learning compact vector space representations of all human cells that can be readily plugged into new and existing computational methods to further advance our understanding of biology. STAR\u2605Methods Key Resources Table REAGENT or RESOURCE SOURCE IDENTIFIER Deposited Data Benchmark scRNA-seq data (Biase) Biase et al., 2014 GEO: GSE57249 Benchmark scRNA-seq data (Treutlein) Treutlein et al., 2014 Supplementary Data 3 Benchmark scRNA-seq data (Goolam) Goolam et al., 2016 ArrayExpress: E-MTAB-3321 Benchmark scRNA-seq data (Ting) Ting et al., 2014 GEO: GSE51372 Benchmark scRNA-seq data (Buettner) Buettner et al., 2015 ArrayExpress: E-MTAB-2805 Benchmark scRNA-seq data (Deng) Deng et al., 2014 GEO: GSE45719 Benchmark scRNA-seq data (Pollen) Pollen et al., 2014 SRA: SRP041736 Benchmark scRNA-seq data (Patel) Patel et al., 2014 GEO: GSE57872 Benchmark scRNA-seq data (Usoskin) Usoskin et al., 2015 GEO: GSE59739 Benchmark scRNA-seq data (Kolodziejczyk) Kolodziejczyk et al., 2015 ArrayExpress: E-MTAB-2600 Benchmark scRNA-seq data (Klein) Klein et al., 2015 GEO: GSE65525 Benchmark scRNA-seq data (Zeisel) Zeisel et al., 2015 GEO: GSE60361 Benchmark scRNA-seq data (PBMC68k) Zheng et al., 2017 https://support.10xgenomics.com/single-cell-gene-expression/datasets Benchmark scRNA-seq data (Brain1m) 10x Genomics https://support.10xgenomics.com/single-cell-gene-expression/datasets Benchmark scRNA-seq data (FACS-purified blood cells) Zheng et al., 2017 https://support.10xgenomics.com/single-cell-gene-expression/datasets Software and Algorithms Barnes-Hut t-SNE Van Der Maaten, 2014 https://github.com/lvdmaaten/bhtsne Scikit-learn (k-means and agglomerative clustering) Pedregosa et al., 2011 http://scikit-learn.org/stable/; RRID:SCR_002577 Other Software package for net-SNE This paper http://netsne.csail.mit.edu Contact for Reagent and Resource Sharing Bonnie Berger, bab@mit.edu, Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA. Method Details Review of t-Stochastic Neighbor Embedding Let x 1 , \u2026 , x n \u2208 R d represent the (normalized) expression profiles for each of the n cells in a scRNA-seq dataset that we wish to visualize in R s , where d is typically on the order of tens of thousands (number of human genes) and s is two or three. More precisely, we want to learn the low-dimensional embedding of the cells y 1 , \u2026 , y n \u2208 R s that capture the low-dimensional structure represented by the original input vectors x 1,\u2026, x n . A widely-used approach called t-stochastic neighbor embedding (t-SNE) (Maaten and Hinton, 2008) relates the notion of quality of an embedding y 1,\u2026, y n (inversely) to the Kullback-Leibler (KL) divergence between the two probability distributions P and Q defined over all pairs of cells, which reflect how the cells are laid out in the input and output (embedding) spaces, respectively. The probability assigned to a particular pair (i, j) in each distribution represents how close the two associated vectors are---i.e., ( x i , x j ) for P and ( y i , y j ) for Q . Intuitively, maximizing the agreement between P and Q corresponds to finding a good embedding that faithfully represents the structure in the original data. Formally, t-SNE solves the following optimization problem minimize y 1 , \u2026 , y n KL ( P \u2225 Q ) = \u2211 i \u2260 j p i j log p i j q i j , where p i j = p i | j + p i | j 2 with p i | j = exp { \u2212 \u2016 x i \u2212 x j \u2016 2 2 / ( 2 \u03c3 j 2 ) } \u2211 i \u2032 \u2260 j exp { \u2212 \u2016 x i \u2032 \u2212 x j \u2016 2 2 / ( 2 \u03c3 j 2 ) } , and q i j = q \u02dc i j Z with q \u02dc i j = ( 1 + \u2016 y i \u2212 y j \u2016 2 2 ) \u2212 1 and Z = \u2211 i \u2260 j q \u02dc i j . Note p ij and q ij denote the (i, j) element of matrices P and Q , respectively. In addition, \u03c3 j is a parameter that is tuned for each j to ensure p i | j achieves a predefined value of information-theoretic entropy. t-SNE solves the above optimization problem via gradient descent on the embedding vectors y 1,\u2026, y n with random initialization. As derived in the original paper (Maaten and Hinton, 2008), the gradient of the objective with respect to each y i is given as \u03b4 KL ( P \u2225 Q ) \u03b4 y i = \u2211 j \u2260 i p i j q \u02dc i j ( y i \u2212 y j ) \u2212 1 Z \u2211 j \u2260 i q \u02dc i j 2 ( y i \u2212 y j ) . Computing this gradient for every cell i would require O(n 2) computation, which is prohibitive for large n. In the state-of-the-art implementation of t-SNE (Van Der Maaten, 2014), this expression is approximated in two ways for computational efficiency. First, P is approximated with a sparse matrix based on k-nearest neighbors for each cell, which greatly speeds up the computation of the first term since most summands are zero. Second, an efficient data structure (space-partitioning trees (Samet, 1984)) is built over y 1,\u2026, y n so that the second summation can be coarsely approximated by grouping terms corresponding to nearby y i 's together. Even with these optimizations, applying t-SNE to datasets with millions of cells requires days of computation as shown in our results. Our Method: Neural t-SNE We introduce neural t-SNE (net-SNE), which models each embedding vector y i as the output of a parameterized embedding function evaluated at the corresponding input vector x i . Importantly, our approach is generalizable\u2014i.e., it induces the embedding of any point in the input space, not just the observed data points as in t-SNE. We use standard feedforward neural networks (NNs) (LeCun et al., 2015) to represent the embedding function, drawing from the intuition that NNs have sufficient expressive capacity to find high-quality maps similar to those typically uncovered by t-SNE. The precise form of the parameterized mapping of net-SNE is as follows. Let \u2113 be the number of hidden layers in the NN and u be the number of units in each layer (same for every layer). Furthermore, let W ( t ) \u2208 R u \u00d7 u ( R u \u00d7 d for t = 1) be the weight matrix and b ( t ) \u2208 R u be the intercept associated with layers t = 1,\u2026,\u2113. An additional weight matrix W (\u2113+1) is associated with the final output layer. Given a data point x i , the forward pass through the NN to compute the embedding y i can be recursively described as h i ( 0 ) = x i , h i ( t ) = f ( W ( t ) h i ( t \u2212 1 ) + b ( t ) ) , for t = 1 , \u2026 , \u2113 , y i = W ( \u2113 + 1 ) h i ( \u2113 ) . Note that f denotes an element-wise nonlinear activation function (e.g., sigmoid or rectifier). In the following, we compactly represent the above NN-based embedding function as y i = NN ( x i ; \u0398 ) , where \u0398 refers to the network parameters W (1),\u2026, W (\u2113+1) and b (1),\u2026, b (\u2113). All of our experimental results are obtained uniformly based on a simple architecture with \u2113 = 2, u = 50, and rectifier activation, as illustrated in Figure S1B. Given a NN that defines an embedding for every point in the input space, net-SNE optimizes the same KL divergence objective as t-SNE over the observed data points, via gradient descent. To see how the gradients are computed in net-SNE, first note that for a particular network parameter \u03b8 \u2208 \u0398 , we have \u03b4 KL ( P \u2225 Q ) \u03b4 \u03b8 = \u2211 i = 1 n ( \u03b4 KL ( P \u2225 Q ) \u03b4 y i ) T \u03b4 NN ( x i ; \u0398 ) \u03b4 \u03b8 by the chain rule and using y i = NN ( x i ; \u0398 ) . Notice the first term in each product is identical to the t-SNE gradient and can be computed in the same manner. The second term can be computed via standard backpropagation algorithm (LeCun et al., 2015). Intuitively, here we keep most of the computation in t-SNE intact, but add an additional step to each iteration, where, after computing the gradients for y 1,\u2026, y n as in t-SNE, we propagate them backward through the NN to update the network weights accordingly. Consequently, net-SNE is compatible with any computational optimization for t-SNE. In particular, our implementation of net-SNE incorporates the state-of-the-art version of t-SNE based on the Barnes-Hut approximation (Van Der Maaten, 2014) to the gradients with respect to y 1,\u2026, y n , which achieves substantially faster runtime than vanilla t-SNE. Although our method was independently developed, we note that a theoretical approach of training a parametric embedding (e.g., a neural network) for t-SNE via the chain rule has been previously described in an earlier work (Van Der Maaten, 2009). However, given the difficulty in successfully training a neural network to find good solutions to the t-SNE objective on large-scale datasets, practical adoption of this approach has been limited. In our work, we introduce additional techniques described in the following sections to improve the effectiveness of neural network-based visualization, while also demonstrating its utility for single cell analysis on a wide range of benchmark datasets. Accelerating net-SNE via Stochastic Optimization To fully exploit the generalizability of net-SNE, we improve upon the above procedure with techniques from stochastic optimization. First, note that the gradient for \u03b8 \u2208 \u0398 given in the previous section is a summation over all data points, and thus can be approximated with a randomly chosen subset B \u2282 { 1 , \u2026 , n } (\u201cmini-batch\u201d) as \u03b4 KL ( P \u2225 Q ) \u03b4 \u03b8 \u2248 n | B | \u2211 i \u2208 B ( \u03b4 K L ( P \u2225 Q ) \u03b4 y i ) T \u03b4 NN ( x i ; \u0398 ) \u03b4 \u03b8 . Similarly, the gradient with respect to y i for i \u2208 B can be approximated as \u03b4 KL ( P \u2225 Q ) \u03b4 y i \u2248 n \u2212 1 | B | \u2212 1 \u2211 j \u2208 B \u2227 j \u2260 i p i j q \u02dc i j ( y i \u2212 y j ) \u2212 n \u2212 1 | B \u2212 1 | \u22c5 1 Z \u02c6 \u2211 j \u2208 B \u2227 j \u2260 i q \u02dc i j 2 ( y i \u2212 y j ) using the approximate normalization factor Z \u02c6 = n | B | \u22c5 n \u2212 1 | B | \u2212 1 \u2211 i , j \u2208 B \u2227 i \u2260 j q \u02c6 i j . With small | B | and precomputed P (which typically constitutes a small fraction of the runtime of t-SNE), this approach greatly reduces the required computation in each gradient step and improves the rate of convergence to a good visualization, as we demonstrate in our experiments. Our observation is in line with well-known results in the field of optimization (Bousquet and Bottou, 2008) showing superior runtimes of stochastic gradient descent (SGD) methods compared to their exact counterparts that process the entire dataset for every iteration. Notably, although only a small subset of cells are considered for each iteration, each of our gradient updates to \u0398 affects all cells in the data (due to its generalizability). In contrast, applying a similar mini-batch SGD procedure to t-SNE results in an ineffective method, as only the positions of the cells in a given mini-batch are updated while the remaining cells are fixed. This reduces to a coordinate descent-like procedure, which we found to be very slow in terms of learning speed, likely due to the tight coupling of parameters being optimized. Although net-SNE shares the model parameters across all cells and thus is less prone to this issue, we did notice difficulties in optimization with mini-batches that are too small. We found setting | B | to be around 10% of the dataset to be a reasonable compromise that leads to good performance. In addition, sampling strategy for B has a considerable effect on the quality of approximation for the gradients. Specifically, given a sparse approximation of P , the first summation in our equation for \u03b4 KL ( P \u2225 Q ) / \u03b4 y i has only a few nonzero summands. If B is uniformly sampled, then only a few indices will contribute to the sum, leading to high variance in the estimate. We address this problem by introducing additional structure into B . In particular, we first sample a smaller set of seed cells S \u2282 { 1 , \u2026 , n } uniformly at random and then sample a fixed number of cells from each of their \u201cneighbors\u201d (where p ij > 0). After these local samples are used to facilitate the approximation of t-SNE gradients for the seed cells, these gradients are backpropagated through the neural network to update the embedding parameters of net-SNE. Given that our estimated normalization factor Z \u02c6 appears in the denominator of the approximate t-SNE gradient, our gradient estimate based on Z \u02c6 is thus biased. To control the amount of error introduced, we impose a minimum threshold (10%) on the fraction of total samples used to approximate Z \u02c6 . If the set of seed cells is too small, additional samples are drawn to ensure Z \u02c6 is of sufficient quality. Training net-SNE with Reference Visualization Even with our stochastic optimization techniques, training a neural network to optimize the t-SNE objective is a challenging task, especially for large-scale datasets with complex patterns. We thus introduce another technique, where a pre-trained t-SNE embedding is used to provide more direct feedback to the neural network instead of relying on the gradients of the highly complex t-SNE objective. More precisely, mean-squared error between the net-SNE embedding and an existing t-SNE map is used as the loss function to optimize the network in order to obtain a good initial solution, which can be further optimized if needed. Although this does require t-SNE to be performed before applying net-SNE, the initial t-SNE map need not be fully optimized, as further SGD iterations in net-SNE can fine-tune the solution. Note that all of our datasets other than PBMC68k and Brain1m are small enough that we were able to train net-SNE in batch mode without the stochastic optimization and the use of a reference visualization. On the other hand, our results on PBMC68k and the 100k subset of Brain1m were obtained by training net-SNE to match a t-SNE reference using mini-batch SGD with a batch size of 10%. We did not further fine-tune net-SNE after training on the reference visualization, as the resulting visualization quality was sufficiently high. After generalizing the 100k cell visualization to the full Brain1m dataset, further training of net-SNE was performed without a t-SNE map (since t-SNE becomes impractical at this scale); instead, we used our stochastic optimization with a batch size of 10%. Although our generalization based on a smaller subset is the primary factor in achieving fast runtime for the Brain1m visualization, our stochastic optimization techniques also lead to significant runtime reductions. For instance, with a batch size of 10%, the average runtime of each iteration of net-SNE is reduced by around a factor of 10 as a result of our techniques. Benchmark Datasets For our main experiments, we used 13 published scRNA-seq datasets of varying sizes with known cluster labels for the cells, which allowed us to directly assess the quality of the visualization produced by net-SNE. The list of datasets, sorted in increasing order of size: (Biase et al., 2014) (n = 49, k = 3), (Treutlein et al., 2014) (n = 80, k = 5), (Goolam et al., 2016) (n = 124, k = 5), (Ting et al., 2014) (n = 149, k = 7), (Buettner et al., 2015) (n = 182, k = 3), (Deng et al., 2014) (n = 268, k = 10), (Pollen et al., 2014) (n = 301, k = 11), (Patel et al., 2014) (n = 430, k = 5), (Usoskin et al., 2015) (n = 622, k = 4), (Kolodziejczyk et al., 2015) (n = 704, k = 3), (Klein et al., 2015) (n = 2,717, k = 4), (Zeisel et al., 2015) (n = 3,005, k = 9), and PBMC68k (Zheng et al., 2017) (n = 68,560, k = 10). Note that n denotes the number of cells and k denotes the number of clusters defined by the original publications. We additionally used a mega-scale dataset Brain1m (n = 1,283,543), downloaded from the 10x Genomics website (https://support.10xgenomics.com/single-cell-gene-expression/datasets), to assess the generalizability and scalability of net-SNE. However, this dataset does not have any known labels, and thus we resorted to using the objective score optimized by both net-SNE and t-SNE as the quality metric for comparison. For demonstrating the generalization of net-SNE across different datasets, we used the datasets of six blood cell subtypes (CD4+, CD8+, CD14+, CD19+, CD34+, and CD56+) experimentally purified via fluorescence activated cell sorting (FACS), which are provided by 10x Genomics and described in Zheng et al. (2017). These datasets were downloaded from the same URL as the Brain1m dataset given above. Our benchmark datasets measured gene expression via a number of different metrics, including read, fragment, transcript, or unique molecule (UMI) counts that are either normalized or unnormalized for gene length (Table S1). We kept the metric chosen by the original publication for each dataset with the goal of demonstrating the performance of net-SNE in a variety of settings. Unless already performed by the original publication, we applied the standard log(1 + x) transformation to each element x of the cell-gene expression matrix before visualizing the data. Data and Software Availability A C++ implementation of net-SNE with example data and scripts are available at: http://netsne.csail.mit.edu and https://github.com/hhcho/netsne. The accession numbers for all scRNA-seq datasets analyzed in this paper are provided in Key Resources Table. Preprocessed gene-expression matrices are available from the authors upon request. Acknowledgments H.C. and B.B. are partially supported by the US NIH grant R01GM081871 (to B.B.). H.C. is also partially supported by the Kwanjeong Educational Foundation. J.P. is supported by the Sloan Research Fellowship and the US National Science Foundation Career Award 1652815. We thank Serafim Batzoglou and Bo Wang for providing the preprocessed data for Pollen and Kolodziejczyk datasets. Editor's note: An early version of this paper was submitted to and peer reviewed at the 2018 Annual International Conference on Research in Computational Molecular Biology (RECOMB). The manuscript was revised and then independently further reviewed at Cell Systems. Author Contributions Conceptualization, H.C., B.B., and J.P.; Data Curation, H.C. and J.P.; Investigation, H.C., B.B., and J.P.; Methodology, H.C., B.B., and J.P.; Resources, B.B.; Software, H.C.; Validation, H.C.; Visualization, H.C.; Writing \u2013 Original Draft, H.C.; Writing \u2013 Review & Editing, H.C., B.B., and J.P.; Funding Acquisition, B.B.; Supervision, B.B. and J.P. Declaration of Interests The authors declare no conflicting interests. Supplemental Information Supplemental Information includes four figures and one table and can be found with this article online at https://doi.org/10.1016/j.cels.2018.05.017. Supplemental Information Document S1. Figures S1\u2013S4 and Table S1 Document S2. Article plus Supplemental Information References Amir et al., 2013 el-A.D. Amir K.L. Davis M.D. Tadmor E.F. Simonds J.H. Levine S.C. Bendall D.K. Shenfeld S. Krishnaswamy G.P. Nolan D. Pe'er viSNE enables visualization of high dimensional single-cell data and reveals phenotypic heterogeneity of leukemia Nat. Biotechnol. 31 2013 545 Amodio et al., 2017 M. Amodio K. Srinivasan D. van Dijk H. Moshen K. Yim R. Muhle K.R. Moon S. Kaech R. Sowell R. Montgomery Exploring single-cell data with deep multitasking neural networks bioRxiv 2017 10.1101/237065 Anchang et al., 2016 B. Anchang T.D.P. Hart S.C. Bendall P. Qiu Z. Bjornson M. Linderman G.P. Nolan S.K. Plevritis Visualization and cellular hierarchy inference of single-cell data using SPADE Nat. Protoc. 11 2016 1264 1279 Biase et al., 2014 F.H. Biase X. Cao S. Zhong Cell fate inclination within 2-cell and 4-cell mouse embryos revealed by single-cell RNA sequencing Genome Res. 24 2014 1787 1796 Bousquet and Bottou, 2008 O. Bousquet L. Bottou The tradeoffs of large scale learning D. Koller D. Schuurmans Y. Bengio L. Bottou Advances in Neural Information Processing Systems 21 2008 NIPS 161 168 Buettner et al., 2015 F. Buettner K.N. Natarajan F.P. Casale V. Proserpio A. Scialdone F.J. Theis S.A. Teichmann J.C. Marioni O. Stegle Computational analysis of cell-to-cell heterogeneity in single-cell RNA-sequencing data reveals hidden subpopulations of cells Nat. Biotechnol. 33 2015 155 160 Deng et al., 2014 Q. Deng D. Ramsk\u00f6ld B. Reinius R. Sandberg Single-cell RNA-seq reveals dynamic, random monoallelic gene expression in mammalian cells Science 343 2014 193 196 Dzwinel and Wcis\u0142o, 2015 W. Dzwinel R. Wcis\u0142o Very fast interactive visualization of large sets of high-dimensional data Procedia Comput. Sci. 51 2015 572 581 Gawad et al., 2016 C. Gawad W. Koh S.R. Quake Single-cell genome sequencing: current state of the science Nat. Rev. Genet. 17 2016 175 188 Goolam et al., 2016 M. Goolam A. Scialdone S.J. Graham I.C. Macaulay A. Jedrusik A. Hupalowska T. Voet J.C. Marioni M. Zernicka-Goetz Heterogeneity in Oct4 and Sox2 targets biases cell fate in 4-cell mouse embryos Cell 165 2016 61 74 Gr\u00fcn et al., 2015 D. Gr\u00fcn A. Lyubimova L. Kester K. Wiebrands O. Basak N. Sasaki H. Clevers A. van Oudenaarden Single-cell messenger RNA sequencing reveals rare intestinal cell types Nature 525 2015 251 255 Haghverdi et al., 2017 L. Haghverdi A.T.L. Lun M.D. Morgan J.C. Marioni Correcting batch effects in single-cell RNA sequencing data by matching mutual nearest neighbours bioRxiv 2017 10.1101/165118 Hartigan and Wong, 1979 J.A. Hartigan M.A. Wong Algorithm AS 136: a k-means clustering algorithm J. R. Stat. Soc. Ser. C Appl. Stat. 28 1979 100 108 Hutchison et al., 2017 L.A.D. Hutchison B. Berger I. Kohane C. elegans exhibits coordinated oscillation in gene expression during development bioRxiv 2017 10.1101/114074 Jackson, 2005 J.E. Jackson A User's Guide to Principal Components 2005 John Wiley & Sons Jaitin et al., 2014 D.A. Jaitin E. Kenigsberg H. Keren-Shaul N. Elefant F. Paul I. Zaretsky A. Mildner N. Cohen S. Jung A. Tanay Massively parallel single-cell RNA-seq for marker-free decomposition of tissues into cell types Science 343 2014 776 779 Kikuchi-Taura et al., 2006 A. Kikuchi-Taura T. Soma T. Matsuyama D.M. Stern A. Taguchi A new protocol for quantifying CD34+ cells in peripheral blood of patients with cardiovascular disease Tex. Heart Inst. J. 33 2006 427 Kiselev et al., 2017 V.Y. Kiselev K. Kirschner M.T. Schaub T. Andrews A. Yiu T. Chandra K.N. Natarajan W. Reik M. Barahona A.R. Green SC3: consensus clustering of single-cell RNA-seq data Nat. Methods 14 2017 483 486 Klein et al., 2015 A.M. Klein L. Mazutis I. Akartuna N. Tallapragada A. Veres V. Li L. Peshkin D.A. Weitz M.W. Kirschner Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells Cell 161 2015 1187 1201 Kolodziejczyk et al., 2015 A.A. Kolodziejczyk J.K. Kim J.C. Tsang T. Ilicic J. Henriksson K.N. Natarajan A.C. Tuck X. Gao M. B\u00fchler P. Liu Single cell RNA-sequencing of pluripotent states unlocks modular transcriptional variation Cell Stem Cell 17 2015 471 485 LeCun et al., 2015 Y. LeCun Y. Bengio G. Hinton Deep learning Nature 521 2015 436 444 Loh et al., 2012 P.-R. Loh M. Baym B. Berger Compressive genomics Nat. Biotechnol. 30 2012 627 630 Maaten and Hinton, 2008 L.V.D. Maaten G. Hinton Visualizing data using t-SNE J. Mach. Learn. Res. 9 2008 2579 2605 Moon et al., 2017 K.R. Moon D. van Dijk Z. Wang D. Burkhardt W. Chen A. van den Elzen M.J. Hirn R.R. Coifman N.B. Ivanova G. Wolf S. Krishnaswamy Visualizing transitions and structure for high dimensional data exploration bioRxiv 2017 10.1101/120378 Palmer et al., 2012 N.P. Palmer P.R. Schmid B. Berger I.S. Kohane A gene expression profile of stem cell pluripotentiality and differentiation is conserved across diverse solid and hematopoietic cancers Genome Biol. 13 2012 R71 Patel et al., 2014 A.P. Patel I. Tirosh J.J. Trombetta A.K. Shalek S.M. Gillespie H. Wakimoto D.P. Cahill B.V. Nahed W.T. Curry R.L. Martuza Single-cell RNA-seq highlights intratumoral heterogeneity in primary glioblastoma Science 344 2014 1396 1401 Pedregosa et al., 2011 F. Pedregosa G. Varoquaux A. Gramfort V. Michel B. Thirion O. Grisel M. Blondel P. Prettenhofer R. Weiss V. Dubourg Scikit-learn: machine learning in Python J. Mach. Learn. Res. 12 2011 2825 2830 Pierson and Yau, 2015 E. Pierson C. Yau ZIFA: dimensionality reduction for zero-inflated single-cell gene expression analysis Genome Biol. 16 2015 241 Pollen et al., 2014 A.A. Pollen T.J. Nowakowski J. Shuga X. Wang A.A. Leyrat J.H. Lui N. Li L. Szpankowski B. Fowler P. Chen Low-coverage single-cell mRNA sequencing reveals cellular heterogeneity and activated signaling pathways in developing cerebral cortex Nat. Biotechnol. 32 2014 1053 1058 Qiu et al., 2017 X. Qiu Q. Mao Y. Tang L. Wang R. Chawla H.A. Pliner C. Trapnell Reversed graph embedding resolves complex single-cell trajectories Nat. Methods 14 2017 979 982 Rand, 1971 W.M. Rand Objective criteria for the evaluation of clustering methods J. Am. Stat. Assoc. 66 1971 846 850 Regev et al., 2017 A. Regev S. Teichmann E.S. Lander I. Amit C. Benoist E. Birney B. Bodenmiller P. Campbell P. Carninci M. Clatworthy The human cell atlas Elife 6 2017 10.7554/eLife.27041 Samet, 1984 H. Samet The quadtree and related hierarchical data structures ACM Comput. Surv. 16 1984 187 260 Simmons et al., 2015 S. Simmons J. Peng J. Bienkowska B. Berger Discovering what dimensionality reduction really tells us about RNA-seq data J. Comput. Biol. 22 2015 715 728 Stubbington et al., 2017 M.J. Stubbington O. Rozenblatt-Rosen A. Regev S.A. Teichmann Single-cell transcriptomics to explore the immune system in health and disease Science 358 2017 58 63 Svensson et al., 2018 V. Svensson R. Vento-Tormo S.A. Teichmann Exponential scaling of single-cell RNA-seq in the past decade Nat. Protoc. 13 2018 599 604 Tang et al., 2016 Tang, J., Liu, J., Zhang, M., and Mei, Q. (2016). Visualizing large-scale and high-dimensional data. Proceedings of the 25th International Conference on World Wide Web 287\u2013297. https://doi.org/10.1145/2872427.2883041. Ting et al., 2014 D.T. Ting B.S. Wittner M. Ligorio N.V. Jordan A.M. Shah D.T. Miyamoto N. Aceto F. Bersani B.W. Brannigan K. Xega Single-cell RNA sequencing identifies extracellular matrix gene expression by pancreatic circulating tumor cells Cell Rep. 8 2014 1905 1918 Treutlein et al., 2014 B. Treutlein D.G. Brownfield A.R. Wu N.F. Neff G.L. Mantalas F.H. Espinoza T.J. Desai M.A. Krasnow S.R. Quake Reconstructing lineage hierarchies of the distal lung epithelium using single-cell RNA-seq Nature 509 2014 371 375 Tung et al., 2017 P.-Y. Tung J.D. Blischak C.J. Hsiao D.A. Knowles J.E. Burnett J.K. Pritchard Y. Gilad Batch effects and the effective design of single-cell gene expression studies Sci. Rep. 7 2017 39921 Usoskin et al., 2015 D. Usoskin A. Furlan S. Islam H. Abdo P. L\u00f6nnerberg D. Lou J. Hjerling-Leffler J. Haeggstr\u00f6m O. Kharchenko P.V. Kharchenko Unbiased classification of sensory neuron types by large-scale single-cell RNA sequencing Nat. Neurosci. 18 2015 145 153 Van Der Maaten, 2014 L. Van Der Maaten Accelerating t-SNE using tree-based algorithms J. Mach. Learn. Res. 15 2014 3221 3245 Van Der Maaten, 2009 L. Van Der Maaten Learning a parametric embedding by preserving local structure RBM 500 2009 26 Wang et al., 2017 B. Wang J. Zhu E. Pierson D. Ramazzotti S. Batzoglou Visualization and analysis of single-cell RNA-seq data by kernel-based similarity learning Nat. Methods 14 2017 414 416 Wang et al., 2014 Y. Wang J. Waters M.L. Leung A. Unruh W. Roh X. Shi K. Chen P. Scheet S. Vattathil H. Liang Clonal evolution in breast cancer revealed by single nucleus genome sequencing Nature 512 2014 155 160 Yoon et al., 2011 H.S. Yoon D.C. Price R. Stepanauskas V.D. Rajah M.E. Sieracki W.H. Wilson E.C. Yang S. Duffy D. Bhattacharya Single-cell genomics reveals organismal interactions in uncultivated marine protists Science 332 2011 714 717 Yu et al., 2015 Y.W. Yu N.M. Daniels D.C. Danko B. Berger Entropy-scaling search of massive biological data Cell Syst. 1 2015 130 140 Zeisel et al., 2015 A. Zeisel A.B. Mu\u00f1oz-Manchado S. Codeluppi P. L\u00f6nnerberg G. La Manno A. Jur\u00e9us S. Marques H. Munguba L. He C. Betsholtz Cell types in the mouse cortex and hippocampus revealed by single-cell RNA-seq Science 347 2015 1138 1142 Zheng et al., 2017 G.X. Zheng J.M. Terry P. Belgrader P. Ryvkin Z.W. Bent R. Wilson S.B. Ziraldo T.D. Wheeler G.P. McDermott J. Zhu Massively parallel digital transcriptional profiling of single cells Nat. Commun. 8 2017 14049", "scopus-id": "85048928895", "pubmed-id": "29936184", "coredata": {"eid": "1-s2.0-S2405471218302357", "dc:description": "Summary Visualization algorithms are fundamental tools for interpreting single-cell data. However, standard methods, such as t-stochastic neighbor embedding (t-SNE), are not scalable to datasets with millions of cells and the resulting visualizations cannot be generalized to analyze new datasets. Here we introduce net-SNE, a generalizable visualization approach that trains a neural network to learn a mapping function from high-dimensional single-cell gene-expression profiles to a low-dimensional visualization. We benchmark net-SNE on 13 different datasets, and show that it achieves visualization quality and clustering accuracy comparable with t-SNE. Additionally we show that the mapping function learned by net-SNE can accurately position entire new subtypes of cells from previously unseen datasets and can also be used to reduce the runtime of visualizing 1.3 million cells by 36-fold (from 1.5 days to an hour). Our work provides a framework for bootstrapping single-cell analysis from existing datasets.", "openArchiveArticle": "true", "prism:coverDate": "2018-08-22", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S2405471218302357", "dc:creator": [{"@_fa": "true", "$": "Cho, Hyunghoon"}, {"@_fa": "true", "$": "Berger, Bonnie"}, {"@_fa": "true", "$": "Peng, Jian"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S2405471218302357"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S2405471218302357"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S2405-4712(18)30235-7", "prism:volume": "7", "prism:publisher": "Published by Elsevier Inc.", "dc:title": "Generalizable and Scalable Visualization of Single-Cell Data Using Neural Networks", "prism:copyright": "\u00a9 2018 Published by Elsevier Inc.", "openaccess": "1", "prism:issn": "24054712", "prism:issueIdentifier": "2", "dcterms:subject": [{"@_fa": "true", "$": "data visualization"}, {"@_fa": "true", "$": "single-cell RNA sequencing"}, {"@_fa": "true", "$": "neural network"}], "openaccessArticle": "true", "prism:publicationName": "Cell Systems", "prism:number": "2", "openaccessSponsorType": "Author", "prism:pageRange": "185-191.e4", "prism:endingPage": "191.e4", "pubType": "Report", "prism:coverDisplayDate": "22 August 2018", "prism:doi": "10.1016/j.cels.2018.05.017", "prism:startingPage": "185", "dc:identifier": "doi:10.1016/j.cels.2018.05.017", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "96", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "14586", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "76", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "13467", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "164", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "21670", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "110", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "21769", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "81", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "14592", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "286", "@width": "655", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "80535", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "229", "@width": "655", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "76996", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "375", "@width": "375", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "57695", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "330", "@width": "655", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "120175", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "242", "@width": "655", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "80298", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1267", "@width": "2902", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "621552", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1013", "@width": "2900", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "384476", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "996", "@width": "996", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "161089", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1463", "@width": "2900", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1141994", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1073", "@width": "2900", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "590535", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-mmc2.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "APPLICATION", "@size": "4020019", "@ref": "mmc2", "@mimetype": "application/pdf"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-mmc1.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "APPLICATION", "@size": "1509239", "@ref": "mmc1", "@mimetype": "application/pdf"}, {"@category": "thumbnail", "@height": "39", "@width": "287", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1615", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "80", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "337", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si24.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "147", "@ref": "si24", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "171", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "424", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2061", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "67", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "333", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "41", "@width": "309", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1783", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "147", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "32", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "206", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "45", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "265", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "148", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "297", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1304", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "28", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "210", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "79", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "326", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "57", "@width": "338", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2087", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "38", "@width": "302", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1443", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si25.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "147", "@ref": "si25", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "80", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si23.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "335", "@ref": "si23", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "175", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "82", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "330", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "34", "@width": "248", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1111", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "101", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si22.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "494", "@ref": "si22", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "151", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "858", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "65", "@width": "258", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1470", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "88", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "416", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405471218302357-am.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "AAM-PDF", "@size": "25611007", "@ref": "am", "@mimetype": "application/pdf"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85048928895"}}
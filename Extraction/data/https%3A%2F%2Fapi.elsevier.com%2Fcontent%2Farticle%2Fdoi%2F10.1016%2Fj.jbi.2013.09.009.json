{"scopus-eid": "2-s2.0-84895450146", "originalText": "serial JL 272371 291210 291682 291870 291901 31 90 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2013-09-26 2013-09-26 2014-10-03T20:16:27 1-s2.0-S1532046413001500 S1532-0464(13)00150-0 S1532046413001500 10.1016/j.jbi.2013.09.009 S300 S300.3 FULL-TEXT 1-s2.0-S1532046413X00085 2015-05-15T06:30:58.629321-04:00 0 0 20140201 20140228 2014 2013-09-26T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes highlightsabst primabst ref specialabst 1532-0464 15320464 UNLIMITED EPSRC true 47 47 C Volume 47 11 83 90 83 90 201402 February 2014 2014-02-01 2014-02-28 2014 Original Research article fla Copyright \u00a9 2013 The Authors. Published by Elsevier Inc. DETERMININGDIFFICULTYWORDSENSEDISAMBIGUATION MCINNES B 1 Introduction 2 Resources and background 2.1 Resources 2.1.1 Unified Medical Language System 2.1.2 MEDLINE 2.1.3 UMLSonMedline 2.1.4 Medical Subject Headings (MeSH) 2.2 Measures of similarity and relatedness 2.2.1 Similarity measures 2.2.2 Relatedness measures 3 Estimating WSD difficulty 3.1 Previous approaches 3.2 Pairwise similarity 3.3 Implementation 3.4 Example 4 Evaluation 4.1 Word sense disambiguation 4.1.1 Supervised method 4.1.2 Unsupervised method 4.2 Data 4.2.1 Abbreviation dataset 4.2.2 NLM-WSD dataset 4.2.3 MSH-WSD dataset 5 Results and discussion 5.1 WSD performance and corpus statistics 5.2 Results for previous approaches 5.3 Results for similarity and relatedness measures 5.3.1 Results by data set 6 Conclusion and future work Acknowledgment References LIU 2004 320 331 H HUMPHREY 2006 96 113 S STEVENSON 2008 S7 M AGIRRE 2010 2889 2896 E PLAZA 2011 355 L WEEBER 2001 548 557 M SWANSON 1988 526 557 D ARTSTEIN 2008 555 596 R JIMENYEPES 2011 223 A HUMPHREYS 1998 1 11 L IDE 2007 253 263 N NELSON 2002 369 378 S RADA 1989 17 30 R CAVIEDES 2004 77 85 J COVER 1991 T ELEMENTSINFORMATIONTHEORY KILGARRIFF 2000 15 48 A PALMER 2007 137 M STEVENSON 2008 11 M LIU 2001 249 261 H MCINNESX2014X83 MCINNESX2014X83X90 MCINNESX2014X83XB MCINNESX2014X83X90XB Full 2013-09-25T14:17:50Z FundingBody Engineering and Physical Sciences Research Council http://creativecommons.org/licenses/by/3.0/ item S1532-0464(13)00150-0 S1532046413001500 1-s2.0-S1532046413001500 10.1016/j.jbi.2013.09.009 272371 2014-10-05T01:53:47.535418-04:00 2014-02-01 2014-02-28 UNLIMITED EPSRC 1-s2.0-S1532046413001500-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/MAIN/application/pdf/ef90edb511e7b69046b4fc7aa717afee/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/MAIN/application/pdf/ef90edb511e7b69046b4fc7aa717afee/main.pdf main.pdf pdf true 623844 MAIN 8 1-s2.0-S1532046413001500-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/PREVIEW/image/png/8425e5e8285be06240ce3593ab65b5c9/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/PREVIEW/image/png/8425e5e8285be06240ce3593ab65b5c9/main_1.png main_1.png png 60201 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046413001500-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/46ffa4cbf52361139cf32cd6b13a0c48/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/46ffa4cbf52361139cf32cd6b13a0c48/si9.gif si9 si9.gif gif 1837 30 339 ALTIMG 1-s2.0-S1532046413001500-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/1b9266db7655b9d48c7af600ff5fd83d/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/1b9266db7655b9d48c7af600ff5fd83d/si8.gif si8 si8.gif gif 2298 77 312 ALTIMG 1-s2.0-S1532046413001500-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/bd247d447fbe942665d57d1fec7215a1/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/bd247d447fbe942665d57d1fec7215a1/si7.gif si7 si7.gif gif 1044 24 176 ALTIMG 1-s2.0-S1532046413001500-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/28007fdf671b46082292823c17922e4c/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/28007fdf671b46082292823c17922e4c/si6.gif si6 si6.gif gif 1568 48 250 ALTIMG 1-s2.0-S1532046413001500-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/70bd2dc1becfe37f4e3e8ff74b02afae/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/70bd2dc1becfe37f4e3e8ff74b02afae/si5.gif si5 si5.gif gif 1792 42 371 ALTIMG 1-s2.0-S1532046413001500-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/d6757f1eeb4140a8352c944afee630da/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/d6757f1eeb4140a8352c944afee630da/si4.gif si4 si4.gif gif 1637 43 241 ALTIMG 1-s2.0-S1532046413001500-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/930414ec97a3b8ea4b1f1433d7788820/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/930414ec97a3b8ea4b1f1433d7788820/si3.gif si3 si3.gif gif 1656 19 383 ALTIMG 1-s2.0-S1532046413001500-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/a101d844ef7819862f229a07eb43e1ef/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/a101d844ef7819862f229a07eb43e1ef/si2.gif si2 si2.gif gif 2077 43 291 ALTIMG 1-s2.0-S1532046413001500-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/df4c8f958d0ea8d9f263db933bd092db/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/df4c8f958d0ea8d9f263db933bd092db/si10.gif si10 si10.gif gif 7513 254 542 ALTIMG 1-s2.0-S1532046413001500-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/STRIPIN/image/gif/b58fe3971177cdd99b26c740b5684b62/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/STRIPIN/image/gif/b58fe3971177cdd99b26c740b5684b62/si1.gif si1 si1.gif gif 1492 42 261 ALTIMG 1-s2.0-S1532046413001500-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/gr1/HIGHRES/image/jpeg/ede0b7d3e33909288ffcd7085d848528/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/gr1/HIGHRES/image/jpeg/ede0b7d3e33909288ffcd7085d848528/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 266450 1481 1683 IMAGE-HIGH-RES 1-s2.0-S1532046413001500-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/fx1/HIGHRES/image/jpeg/7ea56348a585c6c904a9658fa7acd9cf/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/fx1/HIGHRES/image/jpeg/7ea56348a585c6c904a9658fa7acd9cf/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 136204 663 2213 IMAGE-HIGH-RES 1-s2.0-S1532046413001500-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/gr1/DOWNSAMPLED/image/jpeg/7a3ec0b78b7b28cf2a3154034193a5dc/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/gr1/DOWNSAMPLED/image/jpeg/7a3ec0b78b7b28cf2a3154034193a5dc/gr1.jpg gr1 gr1.jpg jpg 30695 334 380 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001500-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/fx1/DOWNSAMPLED/image/jpeg/ec0c7484c94a23582a0960f69d777ead/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/fx1/DOWNSAMPLED/image/jpeg/ec0c7484c94a23582a0960f69d777ead/fx1.jpg fx1 true fx1.jpg jpg 23914 150 500 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001500-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/gr1/THUMBNAIL/image/gif/8e1a702512697e2ea1822fcb077a884e/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/gr1/THUMBNAIL/image/gif/8e1a702512697e2ea1822fcb077a884e/gr1.sml gr1 gr1.sml sml 6650 164 186 IMAGE-THUMBNAIL 1-s2.0-S1532046413001500-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001500/fx1/THUMBNAIL/image/gif/a1827f88f18ae65a95366c2375db4922/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001500/fx1/THUMBNAIL/image/gif/a1827f88f18ae65a95366c2375db4922/fx1.sml fx1 true fx1.sml sml 3453 66 219 IMAGE-THUMBNAIL YJBIN 2064 S1532-0464(13)00150-0 10.1016/j.jbi.2013.09.009 The Authors Fig. 1 Relationship between three senses of the term cold in the UMLS (2009AB version). Parent/child relations in the MeSH hierarchy are shown (e.g. C1256751 \u2018Topical descriptor\u2019 is parent of C0012674 \u2018Diseases\u2019 and C2930671 \u2018Phenomena and Process\u2019). Table 1 Definitions of the possible senses of cold. Term UMLS CUI Example UMLS Definitions Temperature, Cold C009264 An absence of warmth or heat or a temperature notably below an accustomed norm; Having less heat energy than the object against which it is compared; the absence of heat Common Colds C009443 A catarrhal disorder of the upper respiratory tract, which may be viral or a mixed infection. It generally involves a runny nose, nasal congestion, and sneezing COLD C0024117 A chronic, irreversible obstruction of air flow from the lungs. A disease of chronic diffuse irreversible air-flow obstruction Table 2 Corpus statistics and overall disambiguation accuracies of WSD systems. Dataset WSD Corpus statistics Unsupervised Supervised # Senses MFS Entropy NLM-WSD 0.52 0.91 2.3 0.78 0.45 Abbrev 0.91 0.98 2.6 0.70 0.82 MSH-WSD 0.78 0.97 2.1 0.54 1.00 Combined 0.75 0.96 2.10 0.67 0.89 Table 3 Correlations with WSD accuracy. Dataset Measure WSD Unsupervised Supervised NLM-WSD # Senses \u22120.30 \u22120.17 MFS 0.15 0.89 Entropy \u22120.17 \u22120.88 Abbr # Senses \u22120.46 \u22120.14 MFS 0.18 \u22120.57 Entropy \u22120.33 0.32 MSH-WSD # Senses \u22120.05 \u22120.06 MFS 0.11 0.14 Entropy 0.11 0.17 Combined # Senses \u22120.11 \u22120.11 MFS \u22120.05 0.03 Entropy 0.03 \u22120.09 Table 4 Spearman\u2019s rank correlation results over the combined set. Category Measure Unsupervised Supervised Mean Max Mean Max Path-based path \u22120.16 \u22120.19 \u22120.21 \u22120.24 wup \u22120.09 \u22120.11 \u22120.05 \u22120.07 IC-based res \u22120.10 \u22120.12 \u22120.17 \u22120.18 jcn \u22120.18 \u22120.19 \u22120.27 \u22120.27 lin \u22120.15 \u22120.16 \u22120.23 \u22120.23 Relatedness a-lesk \u22120.33 \u22120.33 \u22120.48 \u22120.49 vector \u22120.06 \u22120.09 \u22120.18 \u22120.23 Table 5 Significance of spearman\u2019s rank correlations over the combined set for max similarity. Measure path wup res jcn lin a-lesk vector path 0.03 0.26 0.33 0.47 0.0006 0.47 wup 0.18 0.10 0.28 0.03 0.0000 0.03 res 0.20 0.48 0.14 0.29 0.0000 0.56 jcn 0.47 0.20 0.22 0.30 0.0023 0.30 lin 0.34 0.31 0.33 0.38 0.0004 0.50 lesk 0.05 0.005 0.006 0.04 0.02 0.0006 vector 0.13 0.41 0.38 0.14 0.23 0.003 Table 6 Top 5 least and most difficult terms to disambiguate using lesk with the mean similarity. Least Difficult Most Difficult Term Score Term Score cardiac pacemaker 0.0004 aa 1.9448 cda 0.0004 fat 1.9713 extraction 0.0005 secretion 1.9910 determination 0.0007 radiation 2.2477 surgery 0.0007 fluid 2.8214 Table 7 Breakdown of spearman\u2019s rank correlation results on the datasets. Dataset Measure Unsupervised Supervised Mean Max Mean Max NLM-WSD path \u22120.25 \u22120.40 \u22120.06 \u22120.14 wup \u22120.03 \u22120.21 \u22120.28 \u22120.35 res \u22120.12 \u22120.13 \u22120.32 \u22120.30 jcn 0.03 \u22120.04 \u22120.07 \u22120.10 lin \u22120.10 \u22120.10 \u22120.31 \u22120.26 lesk \u22120.30 \u22120.29 \u22120.44 \u22120.42 vector 0.002 \u22120.07 \u22120.22 \u22120.38 Abbrev path 0.23 0.15 \u22120.13 0.01 wup 0.29 \u22120.09 0.15 0.18 res 0.23 0.07 \u22120.18 \u22120.27 jcn \u22120.11 \u22120.05 \u22120.19 \u22120.01 lin 0.16 0.04 \u22120.13 \u22120.24 lesk \u22120.23 \u22120.15 \u22120.39 \u22120.27 vector \u22120.05 \u22120.35 \u22120.07 0.02 MSH-WSD path \u22120.22 \u22120.22 \u22120.32 \u22120.31 wup 0.01 0.002 0.10 0.10 res \u22120.17 \u22120.18 \u22120.20 \u22120.21 jcn \u22120.25 \u22120.25 \u22120.35 \u22120.35 lin \u22120.19 \u22120.20 \u22120.25 \u22120.25 lesk \u22120.41 \u22120.42 \u22120.57 \u22120.57 vector \u22120.03 \u22120.06 \u22120.20 \u22120.21 Table 8 Breakdown of Spearman\u2019s Rank Correlation on MSH-WSD using lesk. Unsupervised Supervised MSH-WSD Mean Max Mean Max Abbreviations \u22120.26 \u22120.30 \u22120.32 \u22120.35 Terms 0.02 0.01 \u22120.30 \u22120.31 Terms/abbreviations \u22120.94 \u22120.92 \u22120.48 \u22120.52 Determining the difficulty of Word Sense Disambiguation Bridget T. McInnes a \u204e btmcinnes@gmail.com Mark Stevenson b m.stevenson@dcs.shef.ac.uk a Minnesota Supercomputing Institute, University of Minnesota, 117 Pleasant St SE, Minneapolis, MN 55455, USA Minnesota Supercomputing Institute University of Minnesota 117 Pleasant St SE Minneapolis MN 55455 USA b Natural Language Processing Group, Department of Computer Science, University of Sheffield, Regent Court, 211 Portobello, Sheffield S1 4DP, United Kingdom Natural Language Processing Group Department of Computer Science University of Sheffield Regent Court 211 Portobello Sheffield S1 4DP United Kingdom \u204e Corresponding author. Graphical abstract Highlights \u2022 We explore estimating WSD performance on a range of ambiguous biomedical terms. \u2022 We evaluate the difficulty predictions against the output of two WSD systems. \u2022 Supervised methods are the best predictors but limited by labeled training data. \u2022 Unsupervised methods all perform well and can be applied more widely. \u2022 Best performance was obtained using the relatedness measure proposed by Lesk. Abstract Automatic processing of biomedical documents is made difficult by the fact that many of the terms they contain are ambiguous. Word Sense Disambiguation (WSD) systems attempt to resolve these ambiguities and identify the correct meaning. However, the published literature on WSD systems for biomedical documents report considerable differences in performance for different terms. The development of WSD systems is often expensive with respect to acquiring the necessary training data. It would therefore be useful to be able to predict in advance which terms WSD systems are likely to perform well or badly on. This paper explores various methods for estimating the performance of WSD systems on a wide range of ambiguous biomedical terms (including ambiguous words/phrases and abbreviations). The methods include both supervised and unsupervised approaches. The supervised approaches make use of information from labeled training data while the unsupervised ones rely on the UMLS Metathesaurus. The approaches are evaluated by comparing their predictions about how difficult disambiguation will be for ambiguous terms against the output of two WSD systems. We find the supervised methods are the best predictors of WSD difficulty, but are limited by their dependence on labeled training data. The unsupervised methods all perform well in some situations and can be applied more widely. Keywords Natural Language Processing NLP Word Sense Disambiguation WSD Ambiguity Biomedical documents 1 Introduction Word Sense Disambiguation (WSD) is the task of automatically identifying the appropriate sense of an ambiguous word based on the context in which the word is used. For example, the term cold could refer to the temperature or the common cold, depending on how the word is used in the sentence. Automatically identifying the intended sense of ambiguous words improves the performance of biomedical and clinical applications such as medical coding and indexing; applications that are becoming essential tasks due to the growing amount of information available to researchers. A wide range of approaches have been applied to the problem of WSD in biomedical and clinical documents [1\u20137]. Accurate WSD can improve the performance of biomedical text processing applications, such as summarization [8], but inaccurate WSD has been shown to reduce an application\u2019s overall performance [9]. The disambiguation of individual terms is important since some of those terms are more important than others when determining whether there is any overall improvement of the system [8]. The importance of WSD is likely to depend on the application and research question. For example, Weeber et al. [10] found that it was necessary to resolve the ambiguity in the abbreviation \u201cMG\u201d (which can mean \u201cmagnesium\u201d or \u201cmilligram\u201d) in order to replicate the connection between migraine and magnesium identified by Swanson [11]. It is now possible to perform very accurate disambiguation for some types of ambiguity, such as abbreviations [12]. However, there is considerable difference in the performance of WSD systems for different ambiguities. For example, Humphrey et al. [3] report that the performance of their unsupervised WSD approach varies between 100% (for terms such as culture and determination) and 6% (for fluid). Consequently, it is important to determine the accuracy of a WSD system for the ambiguities of interest to get an idea of whether it will be useful for the overall application, and if so, which terms should be disambiguated. Historically, supervised machine learning approaches have been shown to disambiguate terms with a higher degree of accuracy than unsupervised methods. The disadvantage to supervised methods is that they require manually annotated training data for each term that needs to be disambiguated. However, manual annotation is an expensive, difficult and time-consuming process which is not practical to apply on a large scale [13]. To avoid this problem, techniques for automatically labeling terms with senses have been developed [12,14] but these can only be applied to limited types of ambiguous terms, such as abbreviations and terms which occur with different MeSH codes. Therefore, it would be useful to be able to predict the difficulty of a particular term in order to determine whether applying WSD would be of benefit to the overall system. This paper explores approaches to estimating the difficulty of performing WSD on ambiguities found in biomedical documents. By difficulty we mean the WSD performance that can be obtained for the ambiguity since, in practise, performance is the most important factor in determining whether applying WSD to a particular ambiguity is likely to be useful. Ambiguities for which low WSD performance is obtained are considered to be difficult to disambiguate while those for which the performance is high are considered to be easy to disambiguate. Some of the methods applied in this paper are supervised since they are based on information derived from a corpus containing examples of the ambiguous term labeled with the correct sense. Other methods do not require this resource and only require information about the number of possible senses for each ambiguous term which is normally obtained from a knowledge source, such as the UMLS Metathesaurus (see Section 2.1.1). Section 2 provides background information on relevant resources and techniques for computing similarity or relatedness in the biomedical domain. Section 3 describes a range of methods for estimating WSD difficulty, including ones that have been used previously and an unsupervised method based on the similarity/relatedness measures described in Section 2. Experiments to evaluate these are described in Section 4 and their results in Section 5. Finally, conclusions are presented in Section 6. 2 Resources and background 2.1 Resources This section presents the resources that are used in the experiments described later in the paper. In particular, they are used by the similarity and relatedness measures described in Sections 2.2.1 and 2.2.2. 2.1.1 Unified Medical Language System The Unified Medical Language System (UMLS) is a repository that stores a number of distinct biomedical and clinical resources. One such resource, used in this work, is the Metathesaurus [15]. The Metathesaurus contains biomedical and clinical concepts from over 100 disparate terminology sources that have been semi-automatically integrated into a single resource containing a wide range of biomedical and clinical information. For example, it contains the Systematized Nomenclature of Medicine\u2013Clinical Terms (SNOMED CT), which is a comprehensive clinical terminology created for the electronic exchange of clinical health information, the Foundational Model of Anatomy (FMA), which is an ontology of anatomical concepts created specifically for biomedical and clinical research, and MedlinePlus Health Topics, which is a terminology source containing health related concepts created specifically for consumers of health services. The concepts in these sources can overlap. For example, the concept Cold Temperature exists in both SNOMED CT and MeSH. The Metathesaurus assigns the synonymous concepts from the various sources Concept Unique Identifiers (CUIs). Thus both the Cold Temperature concepts in SNOMED CT and MeSH are assigned the same CUI (C0009264). This allows multiple sources in the Metathesaurus to be treated as a single resource. Some sources in the Metathesaurus contain additional information such as a concept\u2019s synonyms, its definition, 1 Not all concepts in the UMLS have a definition. 1 and its related concepts. The Metathesaurus contains a number of relations. The two main hierarchical relations are: the parent/child (PAR/CHD) and broader/narrower (RB/RN) relations. A parent/child relation is a hierarchical relation between two concepts that has been explicitly defined in one of the sources. For example, the concept Cold Temperature has an is-a relation with the concept Freezing in MeSH. This relation is carried forward to the CUI level creating a parent/child relations between the CUIs C0009264 [Cold Temperature] and C0016701 [Freezing] in the Metathesaurus. A broader/narrower relation is a hierarchical relation that does not explicitly come from a source but is created by the UMLS editors. For this work, we use the parent/child relations. 2.1.2 MEDLINE MEDLINE 2 http://www.ncbi.nlm.nih.gov/pubmed/. 2 is a bibliographic database that currently contains over 22 million citations to journal articles in the biomedical domain and is maintained by the National Library of Medicine (NLM). The 2009 MEDLINE Baseline Repository 3 http://mbr.nlm.nih.gov/. 3 encompasses approximately 5200 journals starting from 1948 and contains 17,764,826 citations; consisting of 2,490,567 unique unigrams (single words) and 39,225,736 unique bigrams (two-word sequences). The majority of the publications are scholarly journals but a small number of other sources such as newspapers and magazines are included. 2.1.3 UMLSonMedline UMLSonMedline, created by NLM, consists of concepts from the 2009AB UMLS and the number of times they occurred in a snapshot of MEDLINE taken on 12/01/2009. The frequency counts were obtained by using the Essie Search Engine [16] which queried MEDLINE with normalized strings from the 2009AB MRCONSO table in the UMLS. The frequency of a CUI was obtained by aggregating the frequency counts of the terms associated with the CUI to provide a rough estimate of its frequency. 2.1.4 Medical Subject Headings (MeSH) The Medical Subject Headings (MeSH) Thesaurus ([17]) is the NLM\u2019s controlled vocabulary thesaurus consisting of biomedical and health related terms/concepts created for the purpose of indexing articles from MEDLINE. Each MEDLINE citation is associated with a set of manually annotated MeSH terms that describe the content of the article. The MeSH terms are organized in a hierarchical structure in order to permit searching at various levels of specificity. The 2013 version contains 26,853 terms organized into 11 different hierarchies. 4 http://www.nlm.nih.gov/pubs/factsheets/mesh.html. 4 2.2 Measures of similarity and relatedness This section described measures of similarity and relatedness between biomedical concepts that have been previously explored in the literature. 2.2.1 Similarity measures Existing semantic similarity measures can be categorized into two groups: path-based and information content (IC)-based. Path-based measures use information about the number of nodes between concepts in a hierarchy, whereas IC-based measures incorporate the probability of the concept occurring in a corpus of text. Path-based Similarity Measures Rada et al. [18] introduce the conceptual distance measure which is the length of the shortest path between two concepts (c1 and c2) in MeSH using RB/RN relations from the UMLS. Caviedes and Cimino [19] later adapted this measure using the PAR/CHD relations in the UMLS. Our first measure, path, is a modification of Caviedes and Cimino\u2019s approach. Similarity is defined as the reciprocal of the length of the shortest path between the two concepts in the UMLS hierarchy. This is shown in Eq. (1), where path_length(c 1,c 2) is the number of nodes in the shortest path between c 1 and c 2. (1) sim path ( c 1 , c 2 ) = 1 path _ length ( c 1 , c 2 ) Wu and Palmer [20] extend this measure by incorporating the depth of the Least Common Subsumer (LCS). The LCS of a pair of concepts is the lowest concept in the hierarchy which subsumes that pair. In this measure, the similarity is twice the depth of the two concepts LCS divided by the product of the depths of the individual concepts as defined in Eq. (2), where depth is the number of nodes between c and the root node in the hierarchy. (2) sim wup ( c 1 , c 2 ) = 2 * depth ( lcs ( c 1 , c 2 ) ) depth ( c 1 ) + depth ( c 2 ) IC-based Similarity Measures Information content (IC) is formally defined as the negative log of the probability of a concept [21]. The probability of a concept, c, is obtained by summing the number of times it or one of its descendants is seen in a corpus. The concepts descendants are obtained from some concept hierarchy, such as one of those contained in the UMLS Metathesaurus. Very general concepts have high probabilities since their descendants are mentioned frequently and this leads to them having low IC values. Conversely, specific concepts have low probabilities and high IC values. Resnik [22] modified IC for use as a similarity measure. He defined the similarity of two concepts to be the IC of their LCS, see Eq. (3). (3) sim res ( c 1 , c 2 ) = IC ( lcs ( c 1 , c 2 ) ) = - log ( P ( lcs ( c 1 , c 2 ) ) ) Jiang and Conrath [23] and Lin [24] extended Resnik\u2019s IC-based measure by incorporating the IC of the individual concepts. Lin defined the similarity between two concepts by taking the quotient between twice the IC of the concepts\u2019 LCS and the sum of the IC of the two concepts as shown in Eq. (4). This is similar to the measure proposed by Wu and Palmer; differing in the use of IC rather than the depth of the concepts. (4) sim lin ( c 1 , c 2 ) = 2 * IC ( lcs ( c 1 , c 2 ) ) IC ( c 1 ) + IC ( c 2 ) Jiang and Conrath defined the distance between two concepts to be the sum of the IC of the two concepts minus twice the IC of the concepts\u2019 LCS. This measure is often modified to return a similarity score by taking the reciprocal of the distance as shown in Eq. (5). (5) sim jcn ( c 1 , c 2 ) = 1 IC ( c 1 ) + IC ( c 2 ) - 2 \u2217 IC ( lcs ( c 1 , c 2 ) ) 2.2.2 Relatedness measures Lesk [25] introduces a measure that determines the relatedness between two concepts by counting the number of shared terms in their definitions. An overlap is the longest sequence of one or more consecutive words that occur in both definitions. When implementing this measure in WordNet, Banerjee and Pedersen [26] found that the definitions were short, and did not contain enough overlaps to distinguish between multiple concepts. They extended this measure by including the definition of related concepts in WordNet. Patwardhan and Pedersen [27] extend the measure proposed by Lesk using second-order co-occurrence vectors. In this method, a vector is created for each word in the concepts definition containing words that co-occur with it in a corpus. These word vectors are average to create a single co-occurrence vector for the concept. The similarity between the concepts is calculated by taking the cosine between the concepts second-order vectors. 3 Estimating WSD difficulty 3.1 Previous approaches There has been little previous work on estimating the difficulty of WSD. Kilgarriff and Rosenzweig [28] analysed the difficulty of disambiguating terms used in the first SemEval WSD evaluation exercise [29] and found the entropy of the sense distribution to work well. This is calculated as follows: (6) Entropy ( S ) = - \u2211 i = 1 N Pr ( s i ) log 2 Pr ( s i ) where S ={s 1, s 2 \u2026 s N } is the set of possible senses for some ambiguous term and Pr (s i ) the probability of sense S i obtained from a labeled corpus. In domain-independent WSD the Most Frequent Sense (MFS) is commonly used to indicate the difficulty of a particular term [30,31]. MFS is simply the sense that is found most frequently in a training corpus and is computed as follows: (7) MFS ( S ) = arg max i P ( s i ) MFS is often used as a simple baseline for supervised WSD systems [32]. Like entropy, MFS also requires labeled training data. Both of these approaches are based on the distribution of senses in text and the assumption behind them is that this information is a useful predictor of the difficulty of disambiguating that term. For example, consider an ambiguity where one of the senses is much more likely to appear than the others. The ambiguity will probably be easy to disambiguate, since always assigning the most probable sense will lead to reasonable WSD performance. Stevenson and Guo [33] applied entropy and MFS to analyse the difficulty of automatically generating labeled WSD training data. However they did not explore whether they could be used to determine the difficulty of WSD for particular terms. Stevenson and Guo [33] also made use of additional measures. One was the number of possible senses for the ambiguous term. The advantages of this measure is that it is very simple to compute and does not require any labeled training data. The intuition behind this approach is that ambiguities with a large number of possible senses will be difficult to disambiguate, simply because of the number of senses to choose from. 3.2 Pairwise similarity Stevenson and Guo [33] also describe an approach that relies on computing the average pairwise similarity between the possible senses of ambiguous terms (see Section 2.2.1). Like counting the number of possible senses, this approach also has the advantage of not requiring any labeled training data. The assumption behind this approach is that if the possible meanings of an ambiguous term are similar then that term will be more difficult to disambiguate than one where the meanings are clearly distinct. This is motivated by previous work on manual annotation of word senses which have shown that humans often struggle to distinguish between closely related meanings [13,34]. We extend this approach by considering the maximum similarity between senses in addition to the average. Two metrics were applied: mean similarity and maximum similarity. For the mean similarity, the degree of similarity between the concepts of each of the ambiguous word\u2019s possible senses is computed and combined by taking the mean of the similarities. This is calculated as follows: (8) mean _ similarity ( S ) = \u2211 { s i , s j } \u220a ( S 2 ) sim ( s i , s j ) S 2 where S is the set of senses and sim(s i , s j ) is the similarity between two of these senses as determined by one of the measures described in Section 2.2. The maximum similarity measure is computed in a similar way. However, instead of taking the mean of the pairwise similarities the maximum is chosen: (9) max _ similarity ( S ) = argmax { s i , s j } \u220a S 2 sim ( s i , s j ) 3.3 Implementation The 2009AB version of the Metathesaurus was used for the experiments described in Section 4. The pairwise similarity approaches described in Section 3.2 are implemented using the UMLS::Similarity package [35], a freely available open source Perl package. 5 http://search.cpan.org/dist/UMLS-Similarity/. 5 Path information is obtained using the parent/child relations throughout the entire UMLS. The probabilities required by the IC-based measures are generated using the UMLSonMedline dataset. For the relatedness measures, the definition information is obtained from the concept definitions, as well as the definitions of its parent, child, narrower and broader relations, and its associated terms. 3.4 Example In this section, we step through an example using the ambiguous term cold. In the UMLS, the possible senses for cold include Temperature, Cold [C0009264], the Common Colds [C0009443], or Chronic Obstructive Airways Disease [C0024117]; also referred to as the acronym COLD (Chronic Obstructive Lung Disease). Table 1 shows some of the UMLS Definitions for each of the above senses and Fig. 1 shows the CUIs and paths between each of the senses. The mean similarity for cold is calculated by first summing the similarity scores of each combination of senses and dividing it by its number of combinations. An example, using the path measure (see Section 2.2.1), is as follows: (10) mean similarity = \u2211 x , y \u220a S 2 sim ( x , y ) S 2 = sim ( C 0009264 , C 0009443 ) + sim ( C 0009264 , C 0024117 ) + sim ( C 0009443 , C 0024117 ) 3 2 = 0.1111 + 0.1111 + 0.25 3 2 = 0.4111 3 2 = 0.1574 4 Evaluation We evaluated the approaches by determining how well they predict the accuracy of a WSD system on a set of ambiguous terms. Two WSD systems were used in our experiments: one supervised [36] (see Section 4.1.1) and one unsupervised [37] (see Section 4.1.2). The accuracy of each approach was determined by ranking the terms using the approach and then comparing this with another ranking based on the accuracy of the WSD system. We compared the rankings using Spearman\u2019s Rank Correlation (\u03c1). Spearman measures the statistical dependence between two variables to assesses how well the relationship between the rankings of the variables can be described using a monotonic function. Spearman\u2019s Rank Correlation was used rather than Pearson\u2019s because Pearson\u2019s assumes that the relationship between the data is linear. We used Fisher\u2019s r-to-z transformation to calculate the significance between the correlation results. 4.1 Word sense disambiguation 4.1.1 Supervised method The supervised WSD system developed by Stevenson et al. [36] combines linguistic and biomedical specific features in a Vector Space Model ([38]). A binary feature vector is created for each possible sense of the ambiguous term and the ambiguous term itself. A range of features are used including local collocations, salient bigrams, unigrams and MeSH terms. Local collocations are bigrams or trigrams containing the ambiguous term constructed from lemmas, word forms or part of speech tags. Salient bigrams are those bigrams with a high log likelihood score. Unigrams are lemmas of all content words in the sentence containing the ambiguous term. MeSH terms are indexing terms that had been manually assigned to each abstract for the purpose of indexing (see Section 2). The sense of an ambiguous term is determined by computing the cosine between the vector representing the ambiguous term each of the vectors representing the senses. The sense whose vector has the smallest angle between it and the ambiguous term\u2019s vector is chosen as its most likely sense. 4.1.2 Unsupervised method We also used the unsupervised WSD system developed by McInnes et al. [37]. In their method, a second-order co-occurrence vector is created for each possible sense of the ambiguous term and the ambiguous term itself. The appropriate sense of the term is then determined by computing the cosine between the vector representing the ambiguous term and each of the vectors representing the sense. The sense whose vector has the smallest angle between it and the ambiguous term\u2019s vector is chosen as the most likely sense. The vector for a specific sense is created by first obtaining a textual description of the possible sense. This consists of its definition, the definition of its parent/children and narrow/broader relations and the terms associated with the sense from the UMLS. Second, a word by word co-occurrence matrix is created where the rows represent the content words in the description and the columns represent words that co-occur with the words in the description found in MEDLINE abstracts. Lastly, each word in the sense\u2019s description is replaced by its corresponding vector, as given in the co-occurrence matrix. The average of these vectors constitutes the second order co-occurrence vector used to represent the sense. The second-order co-occurrence vector for the ambiguous term is created in a similar fashion by using the words surrounding the ambiguous term in the instance as its textual description. 4.2 Data Evaluation was carried out using three data sets that include a range of ambiguous terms and abbreviations found in biomedical documents. 4.2.1 Abbreviation dataset The \u201cAbbrev\u201d dataset 6 http://nlp.shef.ac.uk/BioWSD/downloads/corpora. 6 [39] contains examples of 300 ambiguous abbreviations found in MEDLINE that were initially presented by Liu et al. [40]. The data set was automatically re-created by identifying the abbreviations and long-forms in MEDLINE abstracts and replacing the long-form in the abstract with its abbreviation [39]. The abbreviations long-forms were manually mapped to concepts in the UMLS. 4.2.2 NLM-WSD dataset The National Library of Medicine\u2019s Word Sense Disambiguation (NLM-WSD) dataset 7 The NLM-WSD and MSH-WSD (Section 4.2.3) datasets are available from http://wsd.nlm.nih.gov. 7 contains 50 frequently occurring ambiguous words from the 1998 MEDLINE baseline [41]. Each ambiguous word in the NLM-WSD dataset contains 100 ambiguous instances randomly selected from the 1998 abstracts totaling to 5000 instances. The instances were manually disambiguated by 11 evaluators who assigned the ambiguous word to a concept in the UMLS (CUI) or assigned the concept as \u201cNone\u201d if none of the possible concepts described the term. 4.2.3 MSH-WSD dataset The National Library of Medicine\u2019s MSH Word Sense Disambiguation (MSH-WSD) dataset 8 Available from http://wsd.nlm.nih.gov. 8 contains 203 ambiguous terms and abbreviations from the 2010 MEDLINE baseline [14]. Each target word contains approximately 187 instances, has 2.08 possible senses and has a 54.5% majority sense. Out of 203 target words, 106 are terms, 88 are abbreviations, and 9 have possible senses that are both abbreviations and terms. For example, the target word cold has the abbreviation Chronic Obstructive Airway Disease as a possible sense, as well as the term Cold Temperature. The total number of instances is 37,888. 5 Results and discussion 5.1 WSD performance and corpus statistics Table 2 shows the disambiguation accuracy of the WSD systems for each of the datasets (Abbrev, NLM-WSD and MSH-WSD) and their combination (Combine). The results show that overall the supervised system obtains higher disambiguation accuracies than the unsupervised one, which is consistent with previous results, for example [4\u20137]. They also show that the accuracy on the Abbrev dataset is higher than the MSH-WSD or NLM-WSD datasets. We believe this is because the Abbrev dataset contains only abbreviations, which have a more coarse grained distinction between their senses. We also see this between the MSH-WSD and NLM-WSD datasets. NLM-WSD primarily contains terms where, as mentioned above, MSH-WSD contains a mix of terms and abbreviations. This explains why the WSD systems obtain a higher disambiguation accuracy on the MSH-WSD dataset than the NLM-WSD dataset. Table 2 also shows statistics for all three corpora, the average number of senses per ambiguous term (# Senses), the average MFS and the average entropy. There is not much variation in the average number of senses, with the number varying between 2.1 for MSH-WSD and 2.6 for NLM-WSD. The NLM-WSD dataset has the highest MFS and lowest entropy of the three corpora while the opposite is true for MSH-WSD. The differences in these statistics are due to the way in which these datasets were constructed. The NLM-WSD and Abbrev dataset use the sense distributions that are found in corpora which are often highly skewed. For example, all of the instances containing the term association in the NLM-WSD dataset are annotated with the same sense. However, the MSH-WSD dataset was created by selecting roughly the same number of examples of each possible sense. Consequently information about the sense distribution is less useful for MSH-WSD than it is for the other datasets. 5.2 Results for previous approaches Table 3 shows the Spearman\u2019s Rank Correlations obtained when the WSD difficulty measures presented in Section 3.1 were compared against the WSD systems. Overall these measures are better at predicting the accuracy of supervised WSD systems than unsupervised ones. For the NLM-WSD dataset there are high correlations between the accuracy of supervised WSD and two statistics (MFS and entropy). However, this is not surprising since both of these measures make use of information about the distribution of senses in labeled data, and this is the same data that is used to train the WSD system. Correlations using these measures are lower for the other two corpora, which have more balanced sense distributions. Although the number of senses is not a good indicator of supervised WSD accuracy, it is better than the other measures at predicting unsupervised WSD accuracy on the NLM-WSD and Abbrev datasets. The MFS and entropy measures are not effective at predicting unsupervised WSD accuracy, presumably because the unsupervised WSD approaches do not make use of labeled training data. This analysis suggests that measures such as MFS and entropy are strong indicators of WSD accuracy under some conditions, namely when the WSD system is supervised and the distribution of senses is skewed. However, both of these measures rely on labeled training data. Consequently they are not useful for predicting the accuracy of supervised WSD systems since the labeled data they require could simply be used to train a WSD model and the accuracy computed directly. 5.3 Results for similarity and relatedness measures The pairwise measures (Section 3.2) were evaluated using the measures of similarity and relatedness described in Section 2.2. Table 4 shows the Spearman\u2019s Rank Correlation results of the mean (Mean) and maximum (Max) similarity metrics compared to the accuracies from the supervised and unsupervised WSD systems for the combined data set. A positive correlation signifies that as the values of one variable increase, the values of the second variable also increase; a negative correlation signifies that as the values of one variable are increasing the other is decreasing. Our hypothesis is that the higher the similarity score the harder it is to disambiguate the ambiguous word. If this is true, we expect that terms with a high similarity score would have a lower disambiguation accuracy. Therefore, if the accuracies and the similarity scores of the ambiguous words in the datasets were correlated exactly we would see a correlation of \u22121.0 (exact negative correlation). Table 5 shows the p-values obtained from comparing the max-similarity results using the Fisher r\u2013z transform. Comparison between the measures using the supervised correlation results are in the upper triangle of the matrix and the unsupervised correlation results are in the lower triangle. (The p-values obtained using the mean-similarity are similar.) All p-values lower than 0.05 are considered to be significant and are printed in bold font. The results show that the relatedness measure lesk obtains a statistically significantly higher negative correlation than the other measures (p \u2a7d0.05). The lesk measure quantifies the similarity between the possible senses of a target word based on the overlap between the terms in their definitions. The results indicate that this is a better indicator of how difficult the senses are to distinguish between than the path information obtained from a taxonomy. The results using the IC-based measures (res,jcn and lin) and the path measure (path) are comparable; there is no statistical difference between the scores (p \u2a7e0.26). The path measure quantifies the degree of similarity between two concepts using the shortest path information. The IC-based measures extend this, by incorporating the probability of a concept occurring in a corpus. These results indicate extra information about the probability of a concept is not useful for determining the degree of WSD difficulty. Table 6 shows the top five least and most difficult terms to disambiguate and their scores using the Lin with the Mean Similarity Metric. For example, the term cardiac pacemaker has a similar score of 0.0004 indicating that the similarity between its possible concepts is low making it easier to distinguish between the senses. This is contrary to aa which has a similarity score of 1.9448 indicating that the similarity between its possible senses are high making it more difficult to distinguish between them. The path-based measure, wup, quantifies the degree of similarity based on the depth of the concepts in the hierarchy. The depth signifies the specificity of a concept; the deeper the concept the more specific it is. The results using wup show the correlation to the disambiguation accuracies are random, indicating that using the specificity of the possible senses of a word does not indicate the degree of difficulty to disambiguate it. The relatedness measure (vector) quantifies the relatedness between the possible senses by looking at the context that surrounds the terms that surround the ambiguous word. Results indicate that this second order information is too broad to determine the difficulty of disambiguating between the senses of a target word. The results also show that using the maximum similarity metrics obtains a higher or equal negative correlation than using the mean. Overall, the difference in the results is not significant (p \u2a7e0.05) and either the maximum or mean of the individual similarity scores can be used to quantify the degree of disambiguation difficulty. 5.3.1 Results by data set Table 7 shows the break down of the correlation scores on the NLM-WSD, Abbrev and MSH-WSD datasets individually. The strongest negative correlation is produced by the lesk measure in the majority of cases. For example, using lesk with the mean similarity measure results in a correlation of \u22120.57 for MSH-WSD and \u22120.44 for NLM-WSD. The picture is more mixed for the Abbrev data set where several of the correlation co-efficients are close to 0. This suggests that the measures are more useful for determining the WSD difficulty of terms than abbreviations. Further analysis of how well the methods perform on terms and abbreviations was carried out on the MSH-WSD dataset. This dataset contains 203 target words where 106 are terms, 88 are abbreviations, and 9 have possible senses that are terms and abbreviations. Table 8 show the correlation results for each type of ambiguity in this data set. The supervised results show that there is little difference in the correlation results for abbreviations and terms. This indicates that it is able to determine the difficulty of disambiguating a target word regardless if it is a term or an abbreviation. The unsupervised results show that it was unable to determine the difficulty of the terms in this dataset which is contrary to what was seen in the Abbrev results from Table 7. We believe the results from MSH-WSD may provide a more accurate indication on how well the unsupervised method works for two main reasons. The first is that the number of ambiguous abbreviations in the Abbrev dataset is low (16 abbreviations) compared with the MSH-WSD dataset (88 abbreviations). The second is that the disambiguation accuracies of abbreviations in the Abbrev dataset is smaller than those in the MSH-WSD dataset. The accuracies range from 0.96\u20131.00 in the Abbrev dataset to 0.89\u20131.00 in the MSH-WSD dataset. 6 Conclusion and future work The accuracy of WSD systems for biomedical documents varies enormously across ambiguous terms. It would be useful to be able to predict the difficulty of a particular term for WSD systems in order to determine whether applying WSD would be useful. In this paper, we explore a range of approaches to estimating WSD difficulty. Some of these are based on information extracted from sense-labeled corpora while others make use of information from knowledge sources. Evaluation was carried out by comparing the predictions made by these measures with the actual accuracy of two different WSD systems on three data sets. Results show that the supervised methods are good predictors of WSD difficulty in some cases, but that their results are not consistent across different data sets. These methods also require labeled training data, limiting their usefulness. The unsupervised approaches do not have this limitation and can be applied to a wider range of ambiguities. Our experiments showed that these approaches were also good predictors of WSD difficulty. The best performance was obtained using the relatedness measure proposed by Lesk [25] and aggregating the scores using the mean similarity metric. This method obtained a statistically significantly higher negative correlation than the other measures when compared to both the supervised and unsupervised WSD systems (p \u2a7d0.05). The performance of this measure was also reasonably consistent across different data sets and types of ambiguity (terms and abbreviations). The methods explored in this paper are useful tools for estimating the performance of a WSD system that can be computed without the need for labeled data. In the future, we plan to explore other relatedness measures that use contextual information about the senses rather than (or in conjunction with) their placement within a taxonomy. We would also like to explore semantic groups of the terms to determine if some types are easier to disambiguate than others. Acknowledgment Stevenson is grateful to the UK Engineering and Physical Sciences Research Council for supporting this work (Grant EP/J008427/1). References [1] H. Liu V. Teller C. Friedman A multi-aspect comparison study of supervised word sense disambiguation J Am Med Infor Assoc 11 4 2004 320 331 [2] Joshi M, Pedersen T, Maclin R, A comparative study of support vector machines applied to the word sense disambiguation problem for the medical domain. In: Proceedings of the second Indian Conference on Artificial Intelligence (IICAI-05). Pune, India; 2005. p. 3449\u201368. [3] S. Humphrey W. Rogers H. Kilicoglu D. Demner-Fushman T. Rindflesch Word sense disambiguation by selecting the best semantic type based on journal descriptor indexing: preliminary experiment J Am Soc Infor Sci Technol 57 5 2006 96 113 [4] McInnes B, Pedersen T, Carlis J. Using UMLS Concept Unique Identifiers (CUIs) for word sense disambiguation in the biomedical domain. In: Proceedings of the annual symposium of the american medical informatics association. Chicago, IL; 2007. p. 533\u201337. [5] M. Stevenson Y. Guo R. Gaizauskas D. Martinez Disambiguation of biomedical text using diverse sources of information BMC Bioinformatics 9 Suppl. 11 2008 S7 <http://www.biomedcentral.com/1471-2105/9/S11/S7> [6] E. Agirre A. Sora M. Stevenson Graph-based word sense disambiguation of biomedical documents Bioinformatics 26 2 2010 2889 2896 [7] Jimeno-Yates A, Aronson A. Knolwedge-based biomedical word sense disambiguation: comparison of approaches. BMC Bioinformatics 11(569). [8] L. Plaza A. Jimeno-Yepes A. Diaz A. Aronson Studying the correlation between different word sense disambiguation methods and summarization effectiveness in biomedical texts BMC Bioinformatics 12 1 2011 355 10.1186/1471-2105-12-355 <http://www.biomedcentral.com/1471-2105/12/355> [9] Sanderson M. Word sense disambiguation and information retrieval. In: Proceedings of the 17th ACM SIGIR conference. Dublin, Ireland; 1994. p. 142\u201351. [10] M. Weeber H. Klein L. Berg R. Vos Using concepts in literature-based discovery JASIST 57 7 2001 548 557 [11] D. Swanson Migraine and magnesium \u2013 11 neglected connections Perspect Biol Med 31 4 1988 526 557 [12] Stevenson M, Guo Y, Alamri A, Gaizauskas R. Disambiguation of biomedical abbreviations. In: Proceedings of the BioNLP 2009 workshop, association for computational linguistics. Boulder, Colorado; 2009. p. 71\u20139. <http://www.aclweb.org/anthology/W/W09/W09-1309>. [13] R. Artstein M. Poesio Inter-coder agreement for computational linguistics Comput Linguist 34 4 2008 555 596 [14] A. Jimen-Yepes B. McInnes A. Aronson Exploiting MeSH indexing in MEDLINE to generate a data set for word sense disambiguation BMC Bioinformatics 12 1 2011 223 [15] L. Humphreys D. Lindberg H. Schoolman G. Barnett The unified medical language system: an informatics research collaboration J Am Med Infor Assoc 1 5 1998 1 11 [16] N. Ide R. Loane D. Demner-Fushman Essie: a concept-based search engine for structured biomedical text J Am Med Infor Assoc 14 3 2007 253 263 [17] S. Nelson T. Powell B. Humphreys The unified medical language system (UMLS) project Encyclopedia Lib Infor Sci 2002 369 378 [18] R. Rada H. Mili E. Bicknell M. Blettner Development and application of a metric on semantic nets IEEE Trans Syst Man Cyber 19 1 1989 17 30 [19] J. Caviedes J. Cimino Towards the development of a conceptual distance metric for the UMLS J Biomed Infor 37 2 2004 77 85 [20] Wu Z, Palmer M. Verbs semantics and lexical selection. In: Proceedings of the 32nd meeting of association of computational linguistics. Las Cruces, NM; 1994. p. 133\u201338. [21] T. Cover J. Thomas Elements of information theory 1991 Wiley New York [22] Resnik P. Using information content to evaluate semantic similarity in a taxonomy. In: Proceedings of the 14th international joint conference on artificial intelligence. Montreal, Canada; 1995. p. 448\u201353. [23] Jiang J, Conrath D. Semantic similarity based on corpus statistics and lexical taxonomy. In: Proceedings on international conference on research in computational linguistics. Tapei, Taiwan; 1997. p. 19\u201333. [24] Lin D. An information-theoretic definition of similarity. In: Intl Conf ML Proc. San Francisco, CA; 1998. p. 296\u2013304. <citeseer.ist.psu.edu/95071.html>. [25] Lesk M. Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone. In: Proceedings of the 5th annual international conference on systems documentation. Toronto, Canada; 1986. p. 24\u20136. [26] Banerjee S, Pedersen T. Extended gloss overlaps as a measure of semantic relatedness. In: Proceedings of the eighteenth international joint conference on artificial intelligence. Acapulco, Mexico; 2003. p. 805\u201310. [27] Patwardhan S, Pedersen T. Using WordNet-based context vectors to estimate the semantic relatedness of concepts. In: Proceedings of the EACL 2006 workshop making sense of sense \u2013 bringing computational linguistics and psycholinguistics together. Trento, Italy; 2006. p. 1\u20138. [28] A. Kilgarriff J. Rosenzweig Framework and results for English SENSEVAL Comput Humanities 34 1-2 2000 15 48 [29] Kilgariff A, Palmer M, editors. Proceedings of the Pilot SensEval, association for computational linguistics. Hermonceux Castle, Sussex, UK; 1998. <http://www.aclweb.org/anthology/S98-1>. [30] McCarthy D, Koeling R, Weeds J, Carroll J. Finding predominant word senses in untagged text. In: Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL\u201904), main volume. Barcelona, Spain; 2004. p. 279\u201386. doi:10.3115/1218955.1218991. <http://www.aclweb.org/anthology/P04-1036>. [31] Jin P, McCarthy D, Koeling R, Carroll J. Estimating and exploiting the entropy of sense distributions. In: Proceedings of human language technologies: the 2009 annual conference of the North American chapter of the association for computational linguistics, companion volume: short papers. Association for Computational Linguistics, Boulder, Colorado; 2009. p. 233\u201336. <http://www.aclweb.org/anthology/N/N09/N09-2059>. [32] Agirre E, Edmonds PG, editors. Word sense disambiguation: algorithms and applications. Springer; 2006. [33] Stevenson M, Guo Y. The effect of ambiguity on the automated acquisition of wsd examples. In: Human language technologies: the 2010 annual conference of the North American chapter of the association for computational linguistics. Association for Computational Linguistics, Los Angeles, California; 2010. p. 353\u201356. <http://www.aclweb.org/anthology/N10-1053>. [34] M. Palmer H.T. Dang C. Fellbaum Making fine-grained and coarse-grained sense distinctions, both manually and automatically Nat Language Eng 13 2 2007 137 [35] McInnes B, Pedersen T, Pakhomov S. UMLS-interface and UMLS-similarity: open source software for measuring paths and semantic similarity. In: Proceedings of the American Medical Informatics Association (AMIA) symposium. San Fransico, CA; 2009. [36] M. Stevenson Y. Guo R. Gaizauskas D. Martinez Disambiguation of biomedical text using diverse sources of information BMC Bioinformatics 9 Suppl. 11 2008 11 [37] McInnes B, Pedersen T, Liu Y, Pakhomov S, Melton G. Using second-order vectors in a knowledge-based method for acronym disambiguation. In: Proceedings of the conference on computational natural language learning. Portland, OR; 2011. [38] Agirre E, Martinez D. The basque country university system: english and basque tasks. In: Proceedings of the 3rd ACL workshop on the evaluation of systems for the semantic analysis of text (SENSEVAL-3) at the annual meeting of the association of computational linguistics. Barcelona, Spain; 2004. p. 44\u20138. [39] Stevenson M, Guo Y, Al Amri A, Gaizauskas R. Disambiguation of biomedical abbreviations. In: Proceedings of the ACL BioNLP workshop; 2009. p. 71\u20139. [40] H. Liu Y. Lussier C. Friedman Disambiguating ambiguous biomedical terms in biomedical narrative text: an unsupervised method J Biomed Infor 34 4 2001 249 261 [41] Weeber M, Mork J, Aronson A. Developing a test collection for biomedical word sense disambiguation. In: Proceedings of AMIA Symposium. Washington, DC; 2001. p. 746\u201350.", "scopus-id": "84895450146", "pubmed-id": "24076369", "coredata": {"eid": "1-s2.0-S1532046413001500", "dc:description": "Abstract Automatic processing of biomedical documents is made difficult by the fact that many of the terms they contain are ambiguous. Word Sense Disambiguation (WSD) systems attempt to resolve these ambiguities and identify the correct meaning. However, the published literature on WSD systems for biomedical documents report considerable differences in performance for different terms. The development of WSD systems is often expensive with respect to acquiring the necessary training data. It would therefore be useful to be able to predict in advance which terms WSD systems are likely to perform well or badly on. This paper explores various methods for estimating the performance of WSD systems on a wide range of ambiguous biomedical terms (including ambiguous words/phrases and abbreviations). The methods include both supervised and unsupervised approaches. The supervised approaches make use of information from labeled training data while the unsupervised ones rely on the UMLS Metathesaurus. The approaches are evaluated by comparing their predictions about how difficult disambiguation will be for ambiguous terms against the output of two WSD systems. We find the supervised methods are the best predictors of WSD difficulty, but are limited by their dependence on labeled training data. The unsupervised methods all perform well in some situations and can be applied more widely.", "openArchiveArticle": "false", "prism:coverDate": "2014-02-28", "openaccessUserLicense": "http://creativecommons.org/licenses/by/3.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046413001500", "dc:creator": [{"@_fa": "true", "$": "McInnes, Bridget T."}, {"@_fa": "true", "$": "Stevenson, Mark"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046413001500"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046413001500"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(13)00150-0", "prism:volume": "47", "prism:publisher": "The Authors. Published by Elsevier Inc.", "dc:title": "Determining the difficulty of Word Sense Disambiguation", "prism:copyright": "Copyright \u00a9 2013 The Authors. Published by Elsevier Inc.", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Natural Language Processing"}, {"@_fa": "true", "$": "NLP"}, {"@_fa": "true", "$": "Word Sense Disambiguation"}, {"@_fa": "true", "$": "WSD"}, {"@_fa": "true", "$": "Ambiguity"}, {"@_fa": "true", "$": "Biomedical documents"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "FundingBody", "prism:pageRange": "83-90", "prism:endingPage": "90", "prism:coverDisplayDate": "February 2014", "prism:doi": "10.1016/j.jbi.2013.09.009", "prism:startingPage": "83", "dc:identifier": "doi:10.1016/j.jbi.2013.09.009", "openaccessSponsorName": "Engineering and Physical Sciences Research Council"}, "objects": {"object": [{"@category": "thumbnail", "@height": "30", "@width": "339", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1837", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "77", "@width": "312", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2298", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "24", "@width": "176", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1044", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "48", "@width": "250", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1568", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "42", "@width": "371", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1792", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "43", "@width": "241", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1637", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "383", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1656", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "43", "@width": "291", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2077", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "254", "@width": "542", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "7513", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "42", "@width": "261", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1492", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "1481", "@width": "1683", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "266450", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "663", "@width": "2213", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "136204", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "334", "@width": "380", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "30695", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "150", "@width": "500", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "23914", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "186", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6650", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "66", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001500-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3453", "@ref": "fx1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84895450146"}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608014000525", "dc:identifier": "doi:10.1016/j.neunet.2014.02.011", "eid": "1-s2.0-S0893608014000525", "prism:doi": "10.1016/j.neunet.2014.02.011", "pii": "S0893-6080(14)00052-5", "dc:title": "Learning invariant object recognition from temporal correlation in a hierarchical network ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "54", "prism:startingPage": "70", "prism:endingPage": "84", "prism:pageRange": "70-84", "dc:format": "application/json", "prism:coverDate": "2014-06-30", "prism:coverDisplayDate": "June 2014", "prism:copyright": "Copyright \u00a9 2014 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Lessmann, Markus"}, {"@_fa": "true", "$": "W\u00fcrtz, Rolf P."}], "dc:description": "\n               Abstract\n               \n                  Invariant object recognition, which means the recognition of object categories independent of conditions like viewing angle, scale and illumination, is a task of great interest that humans can fulfill much better than artificial systems. During the last years several basic principles were derived from neurophysiological observations and careful consideration: (1) Developing invariance to possible transformations of the object by learning temporal sequences of visual features that occur during the respective alterations. (2) Learning in a hierarchical structure, so basic level (visual) knowledge can be reused for different kinds of objects. (3) Using feedback to compare predicted input with the current one for choosing an interpretation in the case of ambiguous signals. In this paper we propose a network which implements all of these concepts in a computationally efficient manner which gives very good results on standard object datasets. By dynamically switching off weakly active neurons and pruning weights computation is sped up and thus handling of large databases with several thousands of images and a number of categories in a similar order becomes possible. The involved parameters allow flexible adaptation to the information content of training data and allow tuning to different databases relatively easily. Precondition for successful learning is that training images are presented in an order assuring that images of the same object under similar viewing conditions follow each other. Through an implementation with sparse data structures the system has moderate memory demands and still yields very good recognition rates.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Invariant object recognition"}, {"@_fa": "true", "$": "Learning of temporal sequences"}, {"@_fa": "true", "$": "Hierarchical network"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608014000525", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608014000525", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84896496084", "scopus-eid": "2-s2.0-84896496084", "pubmed-id": "24657573", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84896496084", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20140312", "$": "2014-03-12"}}}}}
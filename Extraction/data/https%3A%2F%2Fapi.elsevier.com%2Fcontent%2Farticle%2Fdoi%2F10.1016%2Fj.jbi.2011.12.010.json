{"scopus-eid": "2-s2.0-84861839384", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2012-01-05 2012-01-05 2015-05-18T20:53:18 1-s2.0-S1532046411002243 S1532-0464(11)00224-3 S1532046411002243 10.1016/j.jbi.2011.12.010 S300 S300.3 FULL-TEXT 1-s2.0-S1532046412X00042 2015-05-18T17:05:41.01962-04:00 0 0 20120601 20120630 2012 2012-01-05T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast otherkwds primabst ref specialabst 1532-0464 15320464 false 45 45 3 3 Volume 45, Issue 3 10 460 470 460 470 201206 June 2012 2012-06-01 2012-06-30 2012 Original Research article fla Copyright \u00a9 2012 Elsevier Inc. All rights reserved. AMETHODFORDETERMININGNUMBERDOCUMENTSNEEDEDFORAGOLDSTANDARDCORPUS JUCKETT D 1 Introduction 2 Methods 2.1 Corpora 2.2 Tools 2.3 Method outline 2.4 Method details 2.4.1 Creating a representative working corpus 2.4.2 Selecting a comparison corpus 2.4.3 Token extraction 2.4.4 Token capture probability 3 Results 3.1 Creation of the working corpus 3.2 Word content comparison 3.3 Capture probabilities versus word length 3.4 Gold standard sample 4 Discussion and conclusions Acknowledgments References NADKARNI 2011 544 551 P CHAPMAN 2011 540 543 W XIAO 2010 R HANDBOOKNATURALLANGUAGEPROCESSING CORPUSCREATION UZUNER 2011 552 557 O SAVOVA 2010 507 513 G UZUNER 2010 514 518 O COROMINASMURTRA 2010 1 9 B THOMPSON 1992 S SAMPLING CHANG 2010 241 264 H JUCKETTX2012X460 JUCKETTX2012X460X470 JUCKETTX2012X460XD JUCKETTX2012X460X470XD Full 2013-07-17T11:42:39Z ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window item S1532-0464(11)00224-3 S1532046411002243 1-s2.0-S1532046411002243 10.1016/j.jbi.2011.12.010 272371 2015-05-18T17:05:41.01962-04:00 2012-06-01 2012-06-30 1-s2.0-S1532046411002243-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/MAIN/application/pdf/ce96088f9076957ff511718fdc863ee2/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/MAIN/application/pdf/ce96088f9076957ff511718fdc863ee2/main.pdf main.pdf pdf true 975313 MAIN 11 1-s2.0-S1532046411002243-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/PREVIEW/image/png/e3d4b7777746bc3117beb962f61ab449/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/PREVIEW/image/png/e3d4b7777746bc3117beb962f61ab449/main_1.png main_1.png png 84091 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046411002243-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/STRIPIN/image/gif/5696b47e26134cd9fe4efe9fec497c72/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/STRIPIN/image/gif/5696b47e26134cd9fe4efe9fec497c72/si7.gif si7 si7.gif gif 976 52 115 ALTIMG 1-s2.0-S1532046411002243-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/STRIPIN/image/gif/9eb559f4665739f6601ab3dc409a04c2/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/STRIPIN/image/gif/9eb559f4665739f6601ab3dc409a04c2/si6.gif si6 si6.gif gif 1215 45 240 ALTIMG 1-s2.0-S1532046411002243-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/STRIPIN/image/gif/b6c58c677c54c77beffd954125389831/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/STRIPIN/image/gif/b6c58c677c54c77beffd954125389831/si5.gif si5 si5.gif gif 863 45 158 ALTIMG 1-s2.0-S1532046411002243-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/STRIPIN/image/gif/a15b5e0fb04844fe4fe011e01ee292b1/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/STRIPIN/image/gif/a15b5e0fb04844fe4fe011e01ee292b1/si4.gif si4 si4.gif gif 417 42 54 ALTIMG 1-s2.0-S1532046411002243-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/STRIPIN/image/gif/9fd45fcacde749dcc771ea3cc1b1fd86/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/STRIPIN/image/gif/9fd45fcacde749dcc771ea3cc1b1fd86/si3.gif si3 si3.gif gif 580 20 141 ALTIMG 1-s2.0-S1532046411002243-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/STRIPIN/image/gif/3ef18e82f98dcae643b8127d90e329a4/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/STRIPIN/image/gif/3ef18e82f98dcae643b8127d90e329a4/si2.gif si2 si2.gif gif 461 20 82 ALTIMG 1-s2.0-S1532046411002243-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/STRIPIN/image/gif/6f048799e084cf9dfe2f5b565775aea6/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/STRIPIN/image/gif/6f048799e084cf9dfe2f5b565775aea6/si1.gif si1 si1.gif gif 618 39 98 ALTIMG 1-s2.0-S1532046411002243-gr8_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr8/HIGHRES/image/jpeg/8ee19cee9827d82a0416426437787797/gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr8/HIGHRES/image/jpeg/8ee19cee9827d82a0416426437787797/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 199345 1517 2260 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr7/HIGHRES/image/jpeg/699a6354d67ceaba7b86156cef0f5591/gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr7/HIGHRES/image/jpeg/699a6354d67ceaba7b86156cef0f5591/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 597508 2980 2968 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr4/HIGHRES/image/jpeg/b6eca44b1f37aa722e890fe4c7c0fdea/gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr4/HIGHRES/image/jpeg/b6eca44b1f37aa722e890fe4c7c0fdea/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 305544 1778 2414 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr3/HIGHRES/image/jpeg/11acb8a3ecc506dde905c1d38531583e/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr3/HIGHRES/image/jpeg/11acb8a3ecc506dde905c1d38531583e/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 344372 2813 2311 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr1/HIGHRES/image/jpeg/e7151141fad5bff45a175d071b1b455a/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr1/HIGHRES/image/jpeg/e7151141fad5bff45a175d071b1b455a/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 324462 4251 1948 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/fx1/HIGHRES/image/jpeg/cbbbe38846ebcfa44cac523502c8e2a9/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/fx1/HIGHRES/image/jpeg/cbbbe38846ebcfa44cac523502c8e2a9/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 146300 886 1451 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr6_lrg.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr6/HIGHRES/image/gif/cc49627eef237a13407666f057800d5d/gr6_lrg.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr6/HIGHRES/image/gif/cc49627eef237a13407666f057800d5d/gr6_lrg.gif gr6 gr6_lrg.gif gif 37274 2310 3166 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr5_lrg.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr5/HIGHRES/image/gif/b0dfcc5c4f8ebc688c8ca484f21b5990/gr5_lrg.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr5/HIGHRES/image/gif/b0dfcc5c4f8ebc688c8ca484f21b5990/gr5_lrg.gif gr5 gr5_lrg.gif gif 122516 5654 3820 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr2_lrg.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr2/HIGHRES/image/gif/5a8de715ecbc1a95fb2b6e99b3e3d967/gr2_lrg.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr2/HIGHRES/image/gif/5a8de715ecbc1a95fb2b6e99b3e3d967/gr2_lrg.gif gr2 gr2_lrg.gif gif 178353 5818 5237 IMAGE-HIGH-RES 1-s2.0-S1532046411002243-gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr8/DOWNSAMPLED/image/jpeg/0d6a4dc42763067f35a56c29cb84d05d/gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr8/DOWNSAMPLED/image/jpeg/0d6a4dc42763067f35a56c29cb84d05d/gr8.jpg gr8 gr8.jpg jpg 30777 342 510 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr7/DOWNSAMPLED/image/jpeg/b3fbb95120197deb71ec0e09285147e9/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr7/DOWNSAMPLED/image/jpeg/b3fbb95120197deb71ec0e09285147e9/gr7.jpg gr7 gr7.jpg jpg 86317 687 684 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr4/DOWNSAMPLED/image/jpeg/fecce9585e2d4e2eef4f9e91efe5cb4c/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr4/DOWNSAMPLED/image/jpeg/fecce9585e2d4e2eef4f9e91efe5cb4c/gr4.jpg gr4 gr4.jpg jpg 49846 401 545 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr3/DOWNSAMPLED/image/jpeg/e1590514b5404c393091986d4766a85c/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr3/DOWNSAMPLED/image/jpeg/e1590514b5404c393091986d4766a85c/gr3.jpg gr3 gr3.jpg jpg 62601 644 529 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr1/DOWNSAMPLED/image/jpeg/982ba2247d1e0511a27bbaced4bde62b/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr1/DOWNSAMPLED/image/jpeg/982ba2247d1e0511a27bbaced4bde62b/gr1.jpg gr1 gr1.jpg jpg 56051 980 449 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/fx1/DOWNSAMPLED/image/jpeg/b7489100b72701c1cc251e3498a2a839/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/fx1/DOWNSAMPLED/image/jpeg/b7489100b72701c1cc251e3498a2a839/fx1.jpg fx1 true fx1.jpg jpg 25315 200 327 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr6/DOWNSAMPLED/image/gif/5a9f5314fd7f30a52e6b06fa1142704a/gr6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr6/DOWNSAMPLED/image/gif/5a9f5314fd7f30a52e6b06fa1142704a/gr6.gif gr6 gr6.gif gif 3924 260 357 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr5/DOWNSAMPLED/image/gif/7e7ebee6acd76b3cc9861950efbb2565/gr5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr5/DOWNSAMPLED/image/gif/7e7ebee6acd76b3cc9861950efbb2565/gr5.gif gr5 gr5.gif gif 10685 531 359 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr2/DOWNSAMPLED/image/gif/6916360c226a8d7549d1634ed50607df/gr2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr2/DOWNSAMPLED/image/gif/6916360c226a8d7549d1634ed50607df/gr2.gif gr2 gr2.gif gif 15714 548 493 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411002243-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr6/THUMBNAIL/image/gif/dce36e6c6b5f0751fd74376f3abb4090/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr6/THUMBNAIL/image/gif/dce36e6c6b5f0751fd74376f3abb4090/gr6.sml gr6 gr6.sml sml 1983 160 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr5/THUMBNAIL/image/gif/f57e972e9664af59ceb21385b46fe274/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr5/THUMBNAIL/image/gif/f57e972e9664af59ceb21385b46fe274/gr5.sml gr5 gr5.sml sml 2066 163 110 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr2/THUMBNAIL/image/gif/f95b90017f301181c950d26defe5acd5/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr2/THUMBNAIL/image/gif/f95b90017f301181c950d26defe5acd5/gr2.sml gr2 gr2.sml sml 2654 163 147 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr8/THUMBNAIL/image/gif/eb2029f23af485b3cd42314b79672302/gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr8/THUMBNAIL/image/gif/eb2029f23af485b3cd42314b79672302/gr8.sml gr8 gr8.sml sml 3080 147 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr7/THUMBNAIL/image/gif/ece0ef57be06e5d1879b9ebdb7938fbd/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr7/THUMBNAIL/image/gif/ece0ef57be06e5d1879b9ebdb7938fbd/gr7.sml gr7 gr7.sml sml 4387 164 163 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr4/THUMBNAIL/image/gif/06ad8e4bf2daf1eeffbc27db18983154/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr4/THUMBNAIL/image/gif/06ad8e4bf2daf1eeffbc27db18983154/gr4.sml gr4 gr4.sml sml 5454 161 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr3/THUMBNAIL/image/gif/880990cf3dcb5f41b2efa3355be95d11/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr3/THUMBNAIL/image/gif/880990cf3dcb5f41b2efa3355be95d11/gr3.sml gr3 gr3.sml sml 3768 163 134 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/gr1/THUMBNAIL/image/gif/1a423ab24af4fb39dfef4c10fd8083f7/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/gr1/THUMBNAIL/image/gif/1a423ab24af4fb39dfef4c10fd8083f7/gr1.sml gr1 gr1.sml sml 2080 164 75 IMAGE-THUMBNAIL 1-s2.0-S1532046411002243-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411002243/fx1/THUMBNAIL/image/gif/2b8f5371eb0fe2bd8c8e87ac45545f06/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411002243/fx1/THUMBNAIL/image/gif/2b8f5371eb0fe2bd8c8e87ac45545f06/fx1.sml fx1 true fx1.sml sml 6645 134 219 IMAGE-THUMBNAIL YJBIN 1870 S1532-0464(11)00224-3 10.1016/j.jbi.2011.12.010 Elsevier Inc. Fig. 1 Patient coding data used for constructing representative samples from the MPC dictations corpus. (A) The distribution of ICD-9-CM codes per patient in the total 2010 dictations corpus. (B) The distribution of CPT procedure codes per patient in the total corpus (gray bars) and in the optimal working corpus, sample #15 (black bars). The correlation between the distributions was 0.99. (C) The distribution of the CPT drug codes patient in the total corpus (gray bars) and in the optimal working corpus, sample #15 (black bars). The correlation between the distributions was 0.99. In panels (B and C), the distributions of the total corpus were scaled to areas of 10,000 for comparison purposes. Fig. 2 Zipf\u2019s law plots of the word frequencies for each corpus examined in the study, with values for the slope of the linear portions of the plots shown in each panel. Fig. 3 Word length distributions for the 1000 most common words in each corpus. Fig. 4 Distributions of unique words in the MPC dictation working corpus as compared to each of four other corpora and as plotted versus word length. Corpora are indicated within the panels of the figure. Values near zero denote few unique words, while values near 1.0 denote that the MPC dictations contain mostly unique words for that word length. Fig. 5 Word count and capture probabilities for MPC dictations. (A) Word count versus word length for the MPC dictations working corpus, with and without subtraction of words found in the Gutenberg Project corpus of English literature. (B) Capture probability calculations (Eq. (5)) for word lengths spanning lengths 9\u201320 characters within the MPC working corpus, for various values of \u03bb, as determined by the n values of 50, 250, and 1000. Fig. 6 Integrated capture probability values for various sample sizes, based on the word content of the MPC working corpus with subtraction of words contained in the Gutenberg Project corpus of English literature. Fig. 7 Comparison of various patient variables between the MPC total corpus and the sample of 500 dictations. (A) Distribution of the count of CPT procedure codes per patient (Corr=0.99). (B) Distribution of the count of CPT drug codes per patient (Corr=0.98). (C) Age distribution of patients (Corr=0.98). (D) The distribution of the number of dictations per patient (Corr=0.99). (E) The distribution of the dictation lengths (Corr=0.95). (F) The distribution of the PAM score values (1\u20134) as a fraction of the total corpus or the sample (Corr=0.99). Fig. 8 Ratios of the most common ICD-9-CM patient codings between the number in the total corpus and the number in a sample of 500 (upper) and the percentage contribution of each ICD-9-CM category to all codings in the total MPC corpus (lower). Table 1 Partial listing of mean deviations between CPT sample distributions and the distributions for the total corpus, ordered by rank. Rank (top 8 of 100) CPT proc. codes CPT drug codes Sample # Combined rank b Sample # Mdev (%) a Sample # Mdev (%) a 1 34 3.44 65 5.12 15 7.81 2 38 3.50 45 5.28 65 11.0 3 68 3.73 87 5.38 38 11.2 4 58 3.75 25 5.48 25 22.4 5 33 3.81 15 5.61 1 26.8 6 15 3.81 64 5.73 42 27.9 7 42 3.82 31 5.83 39 29.7 8 6 3.84 51 5.90 4 31.1 a Mdev : Weighted mean of fractional deviations between the number of CPT codes per patient in a sample and the total corpus, weighting by the distribution entries for the total corpus. b Square root of the sum of squared ranks for the CPT procedure and drug samples. Table 2 Parameter values for corpora distributions. (See supplemental figures.). Zipf\u2019s law plot Distribution characteristics for unique word count versus word size Slope Mean St. dev. Gutenberg 1.077 5.15 0.94 Dictations 1.009 6.38 1.39 Discharge 0.929 6.02 1.48 Pain Abs 0.872 6.90 1.46 Nuc Phys 0.892 6.70 1.47 A method for determining the number of documents needed for a gold standard corpus David Juckett Juckett@msu.edu Clinical & Translational Sciences Institute, Michigan State University, East Lansing, MI 48824, United States Graphical abstract Highlights \u25ba Annotated documents are necessary for NLP machine learning, modeling and testing. \u25ba We create a method to determine a required sample size for the annotation set. \u25ba The probability of word capture from a corpus provides the basis for the method. \u25ba Dictation letters from a pain management medical practice are used as an example. \u25ba We also demonstrate steps for creating a representative sample of dictations. Abstract The unstructured narratives in medicine have been increasingly targeted for content extraction using the techniques of natural language processing (NLP). In most cases, these efforts are facilitated by creating a manually annotated set of narratives containing the ground truth; commonly referred to as a gold standard corpus. This corpus is used for modeling, fine-tuning, and testing NLP software as well as providing the basis for training in machine learning. Determining the number of annotated documents (size) for this corpus is important, but rarely described; rather, the factors of cost and time appear to dominate decision-making about corpus size. In this report, a method is outlined to determine gold standard size based on the capture probabilities for the unique words within a target corpus. To demonstrate this method, a corpus of dictation letters from the Michigan Pain Consultant (MPC) clinics for pain management are described and analyzed. A well-formed working corpus of 10,000 dictations was first constructed to provide a representative subset of the total, with no more than one dictation letter per patient. Each dictation was divided into words and common words were removed. The Poisson function was used to determine probabilities of word capture within samples taken from the working corpus, and then integrated over word length to give a single capture probability as a function of sample size. For these MPC dictations, a sample size of 500 documents is predicted to give a capture probability of approximately 0.95. Continuing the demonstration of sample selection, a provisional gold standard corpus of 500 documents was selected and examined for its similarity to the MPC structured coding and demographic data available for each patient. It is shown that a representative sample, of justifiable size, can be selected for use as a gold standard. Keywords Natural language processing Gold standard corpus Sampling Capture probability Abbreviations NLP natural language processing MPC Michigan Pain Consultants i2b2 Informatics for Integrating Biology and the Bedside CoNLL Conference on Computational Natural Language Learning cTAKES Clinical Text Analysis and Knowledge Extraction System CLEF Clinical E-Science Framework NLTK Natural Language Tool Kit PAM Patient Assessment Matrix CPT Current Protocol Terminology ICD-9-CM International Classification of Diseases 9 Clinical Medicine 1 Introduction Natural language processing (NLP) of medical clinical notes and narratives has been the subject of substantial attention in the biomedical informatics community. Several different NLP tasks have been reported, spanning a broad range of targets [1,2]. To support these studies, modeling, supervised machine learning, and testing typically occur at various stages of the analyses. These tasks are facilitated by utilizing a corpus (gold standard) containing annotations that adequately represent the concepts contained in the domain under analysis [3]. Often, the size of the gold standard corpus appears to be determined by ad hoc procedures that are constrained by financial and personnel resources rather than by statistical sampling procedures. In many reports, the number of documents in the gold standard corpus is simply stated without rationale. For example, the 2010 Informatics for Integrating Biology and the Bedside (i2b2) challenge simply stated that 394 training documents and 477 test documents are provided for participants [4]. In the Conference on Computational Natural Language Learning (CoNLL) 2010 Shared Task, nine journal articles and 1273 abstracts from biomedical research were chosen, but without stating the reason [5]. The Clinical Text Analysis and Knowledge Extraction System (cTAKES) demonstration paper used 273 clinical notes for parts-of-speech (POS) and shallow parsing and 160 notes for named entity recognition [6]. In a paper describing the Clinical E-Science Framework (CLEF), the authors use 77 clinical oncology narratives to explore the extraction of clinical relationships implementing a machine learning system [7]. They concluded that this corpus was too small, but they did not address how big it should be. In these examples, it was not made clear what performance was anticipated and whether the size of the gold standard corpus was appropriate to approach that level of performance. Since creating gold standards is expensive, it is important to know if they have the power to address particular NLP tasks. Corpora that are too small cannot generate reliable conclusions, while those that are too big can represent a waste of resources. The purpose of this report is to describe a general method to determine the adequate sample size for a gold standard by using the capture probability for words or concepts from the full corpus under study. The method is applied to an actual corpus of dictations from a set of secondary care medical clinics located in Western Lower Michigan. An NLP project has been undertaken with Michigan Pain Consultants (MPC) to extract concepts from their clinical dictations. The intention is to create a data warehouse linking narrative contents with patient-reported outcomes and psychosocial variables, coded diagnoses and treatments, and other administrative variables. The purpose of the data warehouse is to facilitate research into pain management and support clinical decision making among practicing physicians. Pain is a very personal physiological experience that cannot be readily measured by blood tests, imaging, or electrophysiological means. Practitioners depend heavily on their patient interactions to determine the best course of intervention. The documentation for their assessments, recommendations, and treatments is largely confined to natural language clinical notes which are formalized as letters dictated for transmittal to payers and the referring physician. The dictations contain a wealth of information because they provide the perspectives of trained professionals in pain management. However, they are not generally available for either analysis or research. It is anticipated that cataloging this information and making it available electronically will enhance the practice of pain management. This effort can be greatly facilitated by utilizing the tools of NLP. From an NLP perspective, physician dictation letters have the advantage that they represent coherent narratives with well-structured grammatical form. They tend to follow a canonical form comprising; patient complaint, patient history, physician observation, diagnoses, treatment, prescriptions, and follow-up recommendations. They also contain an important component related to the physician\u2019s evaluation of patient stress burden and psychological well-being, which supplements the documentation of physiological co-morbidities in the patient\u2019s record. While these evaluations are generally presented in well-structured sentences, the dictations also contain medical terminology, abbreviations, acronyms, numbers, units, references to specific times, multiple references to drugs, doses, and schedules, plus substantial quantities of negation, uncertainty, and co-reference. Therefore, while the dictations are simple narratives in nature, the medically-related features make them different from the general narratives often used to train NLP software components. Thus, a suitably sized gold standard corpus will be needed for this project. This report proposes a solution to gold standard size calculation. The method determines the capture probabilities for words that appear within the dictations but not in a comparison corpus derived from English literature. An additional stringency is also introduced that limits the analysis to words above a pre-defined character length. This is predicated upon the assumption that words of sufficient length represent concepts unto themselves, thus allowing the capture probability to provide a surrogate for concept extraction. This study does not address the capture of concepts that are described by phrases of simple words (e.g., \u201cstraight leg lift test\u201d), but the method is generalizable to pre-defined phrases, as well as general n-grams. For presentation purposes, the method is also combined with a procedure to select a subset of the total corpus that contains no more than one dictation letter per patient. This subset is referred to as working corpus because it is selected in such a manner that it is representative of the total corpus across the clinical variables and population strata available within the MPC structured data. In this report, these methods are demonstrated on the MPC project but are applicable to other NLP projects. In Section 2, information on the corpora, calculation methodologies, and structured data for stratification are presented. In Section 3, the construction of a working corpus is presented, followed by the comparison of word content among corpora, the calculation of capture probabilities, and the construction of a gold standard corpus. In Section 4, the results are discussed with a focus on how to generalize the procedure. 2 Methods 2.1 Corpora Five corpora were used in this study. The de-identified dictation letters from the Michigan Pain Consultants were compared to corpora constructed from: (a) English language literature from the Gutenberg Project [8]; (b) abstracts from the field of pain medicine; (c) abstracts from the field of nuclear physics; and, (d) de-identified discharge notes from Partners Healthcare, used in the i2b2 challenge for medication extraction [9]. The Clinical and Translational Sciences Institute (CTSI) of Michigan State University has a Business Associates agreement with MPC and houses copies of their dictation letters on a secure, isolated workstation in accordance with HIPAA regulations. For this analysis, the letters from MPC were de-identified of all personally identifiable information (PII), clinic names and addresses, phone numbers, dates, and phrases common to all letters (e.g., \u201cDictated but not read\u201d). Due to the common format among dictation letters and the limited amount of PII contained within them, regular expressions were sufficient to identify and extract PII. This was implemented in a Perl script running on the isolated workstation housing the PII-containing dictations. The entries chosen from the Gutenberg Project are: The Adventures of Sherlock Holmes, by Arthor C. Doyle; The Adventures of Tom Sawyer, by Samuel Clemens; Ulysses, by James Joyce; Leaves of Grass, by Walter Whitman; Siddhartha, by Hermann Hesse, War and Peace, by Leo Tolstoy, War of the Worlds, by H.G. Wells; Moby Dick, by Herman Melville; and, The Wisdom of the Father, by G.K. Chesterton. This collection provided an arbitrary cross-section of classic literature from the English language. Abstracts for the fields of pain medicine (2008\u20132010) and nuclear physics (2000\u20132011) were obtained from ISI\u2019s Web of Science (http://apps.webofknowledge.com) using the search phrases \u201cpain AND medicine\u201d, \u201cpain AND (treatment OR management)\u201d for the former, and \u201c\u2019nuclear physics\u2019\u201d for the latter. This yielded 3755 pain abstracts and 1875 nuclear physics abstracts. In both sets, author names, affiliations, journal names, paper titles and other ancillary information were removed. Only the entries listed as keywords and the abstract bodies were retained. Hospital discharge notes were used in several i2b2 challenges for NLP extraction of various medical conditions. Older sets have been made available to researchers that did not partake in the challenge. For this corpus, 695 unannotated discharge notes, comprising the learning set from the medication information challenge [9] were used unaltered. 2.2 Tools Several software tools were used for text processing and for the various analyses. The Natural Language Tool Kit (NLTK) of Bird et al. [10] was used extensively together with specialty scripts written by the author in the Python language. These were used in combination with Perl scripts for tokenization, document sampling, and general text processing. MS Excel and MathCad were chosen for numerical analyses and figure creation. None of the procedures described in this paper depend on any particular software tool for implementation. 2.3 Method outline Estimates for the acceptable size of a gold standard corpus are derived from the probabilities of capturing target words from a working corpus (see below) during random sampling. Target words are a user-defined subset chosen to enhance the capture of concepts from the corpus. An aggregate probability is defined as the weighted sum over all probabilities, where the relative frequencies of the target words in the working corpus constitute the weights. To enhance specificity in the example test case, the calculation of the aggregate probability is confined to the set of large words contained in the corpus. This is based on the conjecture that longer words are more likely to represent well-defined concepts (e.g., hypercholesterolemia, spondyloarthropathy, intercostobrachial, hospitalizations, lymphadenopathy, plantarflexion, antidepressant, trachelectomy, fibromyalgia). Longer tokens unique to a given domain, therefore, are considered a surrogate for concepts unique to that domain. While small words can be assembled into phrases that have unique meaning in a field, they are otherwise so common they can increase the capture probability without representing unique information content. The following steps provide an overview of the procedures to determine the number of documents needed for a gold standard corpus: \u2022 Pre-select a working corpus from clinical text documents such that it meets the needs of the study and suitably represents the population of interest. \u2022 Select a comparative corpus containing appropriate common word usage. \u2022 Convert the clinical text and the comparative corpus text into word tokens. \u2022 Subtract the set of comparison text tokens from the set of clinical text tokens creating a remainder set. \u2022 Compute frequencies of token occurrences in the remainder set. \u2022 Calculate the capture probabilities for each unique token as a function of various choices for gold standard corpus size. \u2022 Integrate (weighted sum) the probabilities into one value for each corpus size. \u2022 Select a corpus size depending on an acceptable capture probability. While these steps provide a general strategy, additional steps are included in this paper for demonstration purposes. Capture probabilities are calculated for subsets defined by token length and a cut-off, as described above, is introduced to eliminate small token sizes. While both of these procedures can be eliminated for other uses of this methodology, they should be explored to determine if word length is important in a particular usage. 2.4 Method details 2.4.1 Creating a representative working corpus The creation of a working corpus allows restrictions to be placed on the document collection to achieve a desired spectrum of document length, authorship, content, target population, or other feature of interest. In the case of the MPC dictations, a working corpus was randomly selected from the total corpus of dictations in such a manner that it contained no more than one dictation per patient, while still representing the various characteristics of the patient population seen by this pain management practice. Since patients with multiple visits are typically seen for the same condition, greater content variability is obtained by making this restriction. The creation of a representative sample can most readily be obtained by sampling randomly within population strata that have meaning to the medical conditions in question. Therefore, structured data (e.g., International Classification of Diseases-9-Clinical Medicine (ICD-9-CM) codes, Current Protocol Terminology (CPT) codes, age) was used to stratify the population to enhance the likelihood of capturing a representative sampling of disease types, treatments, physiological and psychological conditions, and demographics of the patients. 2.4.2 Selecting a comparison corpus The use of a comparison corpus allows the removal of words commonly used in most narratives, regardless of the domain of interest. The choice of the comparison corpus depends on the priorities of the investigators and the characteristics of the domain under study. In this study, the characteristics of word length distribution and Zipf\u2019s law [11] were compared among several corpora to generate a rationale for choosing a comparison corpus. 2.4.3 Token extraction The underlying premise that a capture probability can be calculated and used for determining the size of a gold standard corpus begins with a definition of a token. Definition A token is considered any contiguous sequence of alphanumeric characters, beginning with a letter and occurring between spaces, slashes, brackets, braces, parentheses, quotation marks, and punctuation marks. Regular expressions were used to identify and replace the demarcation characters, listed above, with spaces. The contiguous sequences of characters between spaces were then considered tokens. Tokens beginning with anything other than a letter of alphabet were excluded. Upon random visual inspection, most of the remaining tokens were words with meaning as defined by their presence in WordNet (http://wordnet.princeton.edu/) or UMLS (http://www.nlm.nih.gov/research/umls/). Spelling errors were rare in the MPC dictations because of the high quality transcription service used and all other corpora were well edited, published documents. There was no attempt to remove the small number of tokens without meaning since they occurred with low frequency, resulting in low weights in the capture probability calculation. Furthermore, such tokens could represent acronyms with meaning within a given field of science or literature. Note that throughout this report, \u2018token\u2019 and \u2018word\u2019 will be used interchangeably. 2.4.4 Token capture probability The calculation of a capture probability begins by determining the probability that a given word appears in a sample corpus drawn from a larger corpus of documents, where the word is known to exist in one or more documents of the larger corpus. The normalized sum of probabilities over all the different words of interest is defined as the capture probability. As a heuristic example, consider the following thought experiment in which a total corpus consists of 1000 documents and a word of interest appears one or more times in only 100 of these documents. We can ask how many documents we need to retrieve from the total corpus to guarantee, with some level of probability, that at least one document contains the word of interest. The average number of documents containing the word of interest is 100/1000, or 0.1, but this does not mean that drawing ten documents at random will guarantee that one document contains the word. In fact, as predicted by the Poisson probability distribution, only approximately 63% of the random draws of ten documents will contain the word of interest. To reach a 0.95 probability that a sample will contain the word of interest requires a sample size of 30 documents. We can generalize this heuristic example to produce a calculation methodology for capture probabilities for all the words of interest in a corpus. Those probabilities can be summed by weighting each word according to the frequency that the word occurs. This generates an aggregate probability for word capture. Consider a corpus with a total number of N documents from which a randomly selected sample of size n is drawn. Given a mean number \u03bb, representing the expected occurrence of a specific token, the probability that a sample will have x instances of this token is given by the Poisson probability density function: (1) p ( x ) = e - \u03bb \u03bb x x ! , where 0< x < T and where T is the total count of this token in the corpus. The probability that a sample will not contain the token is obtained by setting the value of x to zero: (2) p ( 0 ) = e - \u03bb , and therefore, the probability that it will contain one or more occurrences is given by: (3) p ( x > 0 ) = 1 - e - \u03bb . The mean number, \u03bbi , for token i is given by: (4) \u03bb i = f i N n , where, fi is the frequency of a token i in the total corpus. To facilitate the examples in this study, it is necessary to create summations at the granularity of word length. For mj unique tokens of length j in the corpus, the aggregate probability of capturing these tokens in a sample of size, n, is given by: (5) P j = \u2211 i = 1 m j a i , j ( 1 - e - \u03bb i ) , where, ai,j is the fraction of occurrences for token, i, having token size, j, within the corpus, such that the normalization relationship: (6) \u2211 i = 1 m j a i , j = 1 , for each value of j is valid for each word length. The aggregate capture probability is obtained by summing over all token sizes and is given by: (7) P = \u2211 j = w 1 W 2 b j P j \u2211 j = W 1 W 2 b j , Where, w 1 and w 2 represent the smallest and largest token sizes chosen for study, respectively, and bj represents the overall frequency of tokens of size, j. 3 Results 3.1 Creation of the working corpus The decision to use a representative working corpus, rather than the total corpus for the calculation of capture probabilities, was motivated by a desire to harmonize the working corpus with the final form that would be used in the gold standard corpus. In particular, the decision was made that the gold standard corpus would contain no more than one dictation per patient and would be highly representative of the total corpus across the various structured data available for the patient population. To facilitate this, it was desirable to construct the working corpus with the same properties. To achieve a representative working corpus, the coded patient characteristics were used as the selection criteria. Each MPC patient record contains entries for all associated ICD-9-CM codes, CPT procedure codes, CPT drug codes, age, and gender. In addition to these quantities, MPC has initiated the use of a patient scoring tool to create a staging scheme for patients. This yields a qualitative indicator of anatomical pathology and psychosocial health on a two dimensional scale, referred to as the Patient Assessment Matrix (PAM). Finally, the length of the dictations is a data characteristic that can be combined with the coding data and PAM scores to help determine if the gold standard corpus is a representative sample of all documents. The number of ICD-9-CM codes per patient (Fig. 1 A) exhibits the largest range and granularity in the MPC database; therefore it was chosen to be matched ad hoc to the total patient population using stratified random sampling, without replacement [12,13]. One hundred samples were created and then individually examined for their degree of match to other patient characteristics, specifically, the CPT codes and the gender ratio. For the year 2010, approximately 76,000 dictations are on file, representing interactions with approximately 19,000 patients. Each of the 100 random samples drawn for this demonstration contained 10,000 dictations, with no more than one per patient. To create the samples, the total population was stratified into groups according to number of ICD codes per patient. Within each stratum, patients were randomly drawn such that the resulting sample yielded the same distribution of ICD codes per patient as the total and contained the desired sample size (10,000). If a selected patient had more than one dictation on file, a dictation was selected at random. Optimization to the CPT procedure and drug code distribution characteristics was achieved by minimizing the mean deviation (square root of the mean square differences) between the sample and total population distributions for each characteristic separately. The top few cases with the lowest mean deviation values are shown in Table 1 along with the top samples with the smallest overall combined rank. Sample #15 out of 100 random samples exhibited a simultaneous minimum in deviations to the procedure and drug CPT-per-patient distributions. The distributions for sample #15 and the total corpus are shown in Fig. 1B and C. The gender ratio is the other variable that is desirable to match between the working corpus and the total corpus. This is motivated by the larger number of females seeking pain management interventions. The working corpus must represent this ratio because critical explanatory information may be contained in the dictations related to this gender difference. The female:male gender ratio for the total corpus (2010 patients) is [0.629:0.371] and the ratio for sample #15 is [0.637:0.363]. To determine whether these two sets of values can be considered as originating from the same distribution, the binomial function can be used. It describes the probability distribution for samples of size nq drawn with a success probability of q from a total population of size, N. Let nq be the number of females resulting from a random draw with expectation fraction of q for females (and (1\u2212q) for males). For N =10,000, the nq , associated with sample #15 lies within the 95% confidence interval around the mean value generated by the q for the total corpus. The combination of this result with the CPT distribution concordances is sufficient to trigger the acceptance of sample #15 as a representative sample for the total population. 3.2 Word content comparison Four corpora (see Section 2.1) were compared to the MPC dictation working corpus (Fig. 2 A\u2013E) to determine their similarities and differences using log\u2013log plots of word frequencies versus word rank (Zipf\u2019s law [e.g., [11,14]]). These plots allow a cursory overview of word usage in a given corpus by showing the relationships between usage and rank. The slopes of these plots give an indication of the diversity of word usage. Steeper slopes indicate less diversity and a higher usage of a smaller number of words. The linear regions of these plots have the slopes shown in Table 2 . The slopes of the corpora from the log\u2013log plots show that the Gutenberg Project corpus has the highest slope, the MPC dictation working corpus has an intermediate slope, and the abstracts and discharge notes have the lowest slopes. The facile conclusion from the Zipf plot is that a higher slope leads to a lower frequency of words with higher numerical rank (less common words) than those of corpora with lower slopes. The interpretation of this is that the Gutenberg Project corpus has the narrowest spectrum of word usage, while the abstracts and discharge notes corpora have the broadest spectrum, and the MPC dictations are in between these two cases. When the 1000 most-frequent words are isolated from each corpus and plotted by word lengths (see Fig. 3 A\u2013E) the Gutenberg Project literature corpus differs from the all the other corpora by having fewer large words and a narrower distribution width (see Table 2). The final comparison was to examine the similarity of word content between the MPC dictations in the working corpus and each of the other corpora. Since word content varies between corpora of dissimilar contents, it is desirable to capture the words that are unique to a given corpus. To determine uniqueness, all words in the MPC working corpus were tested for their presence in the comparison corpora. If a word from the MPC working corpus appeared even once in a comparison corpus, it was not counted. If it did not appear in the comparison corpus, then it was weighted by its frequency in the working corpus, such that a value of zero indicated that all dictation words of a given word length appeared in the comparison corpus, and similarly, a value of 1.0 indicated that none of the dictation words of a given size appeared in the comparison corpus. This method created the greatest stringency for determining uniqueness of dictation word usage. The results are shown in Fig. 4 , revealing that the MPC working corpus was most similar to the abstracts from the pain literature, as expected, and most dissimilar to the Gutenberg Project literature corpus and the abstracts from the nuclear physics literature. The discharge notes were similar, but they are not as strongly similar as the pain literature. In all cases, the region of greatest uniqueness was for the larger words. This provided a rationale to compute the capture probability over the region of large word length in the working corpus. These comparisons reveal that the literature corpus provides a source of common English words, which occur in high frequency and are skewed to smaller word lengths. Therefore this corpus was chosen for use as a way to subtract common words from the MPC study corpus. 3.3 Capture probabilities versus word length The word count by word length is shown in Fig. 5 A for words of length 2\u201320 for the MPC working corpus with and without subtraction of words appearing in the Gutenberg Project corpus. For some of the smaller word lengths, over 90% of the words were removed from the working corpus. This diminished to zero removal for words of length 14 characters and greater. Capture probabilities were calculated using Eq. (5) for each word length spanning sizes 9\u201320 that did not occur in the Gutenberg Project corpus. These probabilities are shown in Fig. 5B for various sample sizes over this span of word lengths. Capture probabilities decrease with increasing word length because the total number of instances of a given word diminishes rapidly with word length, impacting the integrated probability of Eq. (5). Therefore it is important to integrate probabilities over a broad range of word lengths to encompass both the rare words and the more common words of intermediate length. Integrating over all word lengths in the chosen range yields a single probability for word capture (Eq. (7)) for a given choice of gold standard sample size. These probabilities are shown in Fig. 6 for various choices of sample size. If a 95% capture probability is desired, then approximately 500 documents must be randomly selected and used for annotation. If other capture probabilities are acceptable, then other sizes can be justified. 3.4 Gold standard sample The selection of a provisional gold standard corpus followed the same procedure used for the working corpus. In this case, the demonstration target is a sample of 500 documents. A set of 100 random selections of 500 were drawn from the total corpus, using the ICD-9-CM stratification, as described in Sections 2.4.1, and 3.1. Comparisons of each of these 100 samples to CPT procedure and drug code distributions were used to select possible samples. Sample #73 optimized the concordance to the CPT code distributions. The comparison of this sample to the CPT distributions, age distribution, number of dictations per patient, dictation lengths, and the MPC PAM scores are shown in the panels of Fig. 7 . The correlation factors for each panel are given in the figure legend. The female:male ratio was [0.61:0.39], which was well inside the 95% confidence interval for a sample of size, 500. To further verify the quality of this sample, the ratio of the most common individual ICD-9-CM codes between the sample and total corpus is shown in Fig. 8 . The set constitutes approximately 90% of the ICD-9-CM code types assigned to patients in the MPC practice. This demonstrates that the sampling procedure does not selectively choose one health condition over another. Therefore, with high correlations for all examined variables, it is concluded that this provisional sample could be deemed suitable for a gold standard corpus. 4 Discussion and conclusions This report demonstrates a method for calculating the size of a gold standard corpus, which is dependent on choices for capture probabilities, comparison corpora, and word length selection. Assumptions regarding what constitutes a word have also been made, but could be altered by removing text strings that are not found in dictionaries or proprietary lexicons, or by allowing specific word phrases, or by expanding to word n-grams. The demonstration also incorporates selection criteria for creating a representative sample in a use case of medical dictations from a secondary care specialists practice. Other implementations of this methodology could utilize a different comparison corpus, an alternate range for word length acceptance, or a different definition of a word. The capture probability is predicated on the presence of one or more occurrences of a word in a sample drawn from the working corpus. It is clear that capturing a word only once or a small number of times in a gold standard corpus would not be sufficient for machine learning. Rare words, while potentially generating a high probability in Eq. (3), have low ai,j values (Eq. (5)) and contribute only a small fraction of the integrated probability. In many cases, these words will not be the ultimate target for the uses of the gold standard corpus. However, the contributions of such words to the integrated probability provide an unbiased estimate of word sampling success and should be retained to ensure completeness. If it is known what number of word instances are required in a sample, then the probability cutoff in Eq. (3) can be altered, at the risk of introducing some selection bias. In many cases, as in the i2b2 and CoNLL challenges, the targets for annotation and machine detection are classes of concepts. A class, such as a therapeutic drug, has a large number of members represented by many words and phrases. In this case, it is desirable for most documents in a sample corpus to contain a member of the class, but not necessarily the same exact word. If a single class is the only target under consideration, then a simple random draw may be sufficient for the sample provided there is an independent, comprehensive dictionary for determining class members. In such cases, the calculation of sample size depends on the training efficiency of a chosen software tool rather than a capture probability. This was demonstrated for classifiers trained to the i2b2 smoking challenge data [15]. In more complex tasks, where multiple concepts must be identified, capture probabilities will be important but these can also be modified by the training efficiencies for machine learning algorithms by adding a weighting term to Eq. (7); but this is beyond the scope of this report. There are other modifications that can be introduced into this capture probability method depending on the needs of a project. For example, synonyms for a word can be considered to constitute a class and the capture probability for classes can then be substituted for the probabilities of individual words. In an attempt to capture complex concepts, n-grams can be first determined and their capture rate calculated. One could also generalize this by converting sentences or paragraphs into bag-of-words classes and calculate a similarity metric between the sentences or paragraphs in a sample with those from the total corpus. In the example of this report, the word content used for the capture probability calculation was that of the MPC dictations with the common words of the Gutenberg Project literature corpus removed. If there is no removal of common words (not shown), then the probability profile of Fig. 6 would shift up by approximately 2%. While a seemingly small change, the impact on sample size is dramatic because of the low slope of the probability curve in the region near a probability value of 0.95. In fact, the 2% shift would reduce the predicted size of a gold standard corpus by nearly one-half for a capture probability of 0.95. This result occurs because the probability becomes weighted by common words not unique to the study corpus. In such a case, the gold standard corpus would not be of sufficient size to capture those words and associated concepts that are unique to the study corpus. Therefore, subtraction of common words is desirable and the choice of the comparison corpus should be made with consideration of word content and word distribution, as shown in the examples of Figs. 2 and 3. The word lengths used in the calculation of the capture probability were chosen arbitrarily to range between 9 and 22 characters. This was not based on a stringent selection criterion, but was selected to minimize the smaller words that occur more often than the larger words. It is also anticipated that polysemy is rarer in the larger words that are unique to a given domain. As shown in Fig. 5A, this lower cutoff of 9 is near the breakpoint in the distribution and, thus, limits the capture probability calculation to the larger words. Other lower bounds could be used, but they were not examined in this demonstration. When selecting the capture probability for a gold standard, a decision must be made on how it will be subdivided for training and testing. The demonstration project within this report does not make any allowance for this. For example, if one chose a 0.95 capture probability, yielding a need for 500 documents, but used half for training and half for testing, then each subset would have capture probability of approximately 0.90 (see Fig. 6). In the construction of a representative gold standard corpus, this report used ancillary structured data from the clinical practice administration files to guide the selection of the sample, combining stratified random sampling and correlation criteria. To obtain a representative sample for a gold standard, it is incumbent on a researcher to examine as many variables as possible between the sample corpus and the total corpus to justify the final product. In conclusion, the creation of a gold standard corpus for use in NLP modeling, testing, and machine learning is expensive, time-consuming, and requires specialized personnel. Maximizing this investment and securing valid analyses is facilitated by using justifiable sampling techniques on a corpus whose size is estimated from the probability of capturing the content desired. Acknowledgments Thanks to Fred Davis, Mark Gostine, and Chris Cubbage of Michigan Pain Consultants for their engagement and cooperation in this project. Further thanks to Philip Reed, Jason Paluszak, Jon Babbage, Joe Bonner, Eric Ederer, and Patrick Thompson of the Clinical & Translational Sciences Institute of Michigan State University for their valuable input and logistic support. This study was supported by funds from the Office of the Vice President for Research and Graduate Studies, and the Clinical & Translations Sciences Institute of Michigan State University. References [1] P.M. Nadkarni L. Ohno-Machado W.W. Chapman Natural language processing: an introduction Journal of the American Medical Informatics Association 18 2011 544 551 [2] W.W. Chapman P.M. Nadkarni L. Hirschman L.W. D\u2019Avolio G.K. Savova O. Uzuner Overcoming barriers to NLP for clinical text: the role of shared tasks and the need for additional creative solutions J Am Med Inform Assoc 18 2011 540 543 [3] R. Xiao Corpus creation N. Indurkhya F.J. Damerau Handbook of natural language processing 2010 CRC Press Boca Raton, FL [4] O. Uzuner B.R. South S. Shen S.L. Duvall 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text J Am Med Inform Assoc 18 2011 552 557 [5] Farkas R, Vincze V, M\u00f3ra G, Csirik J, and Szarvas G. The CoNLL-2010 shared task: learning to detect hedges and their scope in natural language text. In: Proceedings of the fourteenth conference on computational natural language learning (CoNLL-2010): Shared Task; 2010. p. 1\u201312. [6] G.K. Savova J.J. Masanz P.V. Ogren J. Zheng S. Sohn K.C. Kipper-Schuler Mayo clinical text analysis and knowledge extraction system (cTAKES): architecture, component evaluation and applications J Am Med Inform Assoc 17 2010 507 513 [7] Roberts A, Gaizauskas R, Hepple M, Guo Y. Mining clinical relationships from patient narratives. BMC Bioinform 2008;9(11):S3. [8] Project Gutenberg. http://www.gutenberg.org. [accessed 09.29.10]. [9] O. Uzuner I. Solti E. Cadag Extracting medication information from clinical text J Am Med Inform Assoc 17 2010 514 518 [10] Bird S, Klein E, Loper E. Natural language processing with python \u2013 analyzing text with the natural language toolkit. O\u2019Reilly Media; 2009. [11] B. Corominas-Murtra R. Sol\u00e9 Universality of Zipf\u2019s law Phys Rev E 82 2010 1 9 [12] Lohr SL. Sampling: design and analysis, Pacific Grove, CA: Duxbury Press; 1999. [13] S.K. Thompson Sampling 1992 Wiley-Interscience Publication New York, NY [14] H.M. Chang Constructing n-gram rules for natural language models through exploring the limitation of the Zipf\u2013Mandelbrot law Computing 91 2010 241 264 [15] Sordo M, Zeng Q. On sample size and classification accuracy: a performance comparison. In: Oliveira JL, editor. Biological and medical data analysis: lecture notes in bioinformatics. vol. 3745; 2005. p. 193\u2013201.", "scopus-id": "84861839384", "pubmed-id": "22245601", "coredata": {"eid": "1-s2.0-S1532046411002243", "dc:description": "Abstract The unstructured narratives in medicine have been increasingly targeted for content extraction using the techniques of natural language processing (NLP). In most cases, these efforts are facilitated by creating a manually annotated set of narratives containing the ground truth; commonly referred to as a gold standard corpus. This corpus is used for modeling, fine-tuning, and testing NLP software as well as providing the basis for training in machine learning. Determining the number of annotated documents (size) for this corpus is important, but rarely described; rather, the factors of cost and time appear to dominate decision-making about corpus size. In this report, a method is outlined to determine gold standard size based on the capture probabilities for the unique words within a target corpus. To demonstrate this method, a corpus of dictation letters from the Michigan Pain Consultant (MPC) clinics for pain management are described and analyzed. A well-formed working corpus of 10,000 dictations was first constructed to provide a representative subset of the total, with no more than one dictation letter per patient. Each dictation was divided into words and common words were removed. The Poisson function was used to determine probabilities of word capture within samples taken from the working corpus, and then integrated over word length to give a single capture probability as a function of sample size. For these MPC dictations, a sample size of 500 documents is predicted to give a capture probability of approximately 0.95. Continuing the demonstration of sample selection, a provisional gold standard corpus of 500 documents was selected and examined for its similarity to the MPC structured coding and demographic data available for each patient. It is shown that a representative sample, of justifiable size, can be selected for use as a gold standard.", "openArchiveArticle": "true", "prism:coverDate": "2012-06-30", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046411002243", "dc:creator": {"@_fa": "true", "$": "Juckett, David"}, "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046411002243"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046411002243"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(11)00224-3", "prism:volume": "45", "prism:publisher": "Elsevier Inc.", "dc:title": "A method for determining the number of documents needed for a gold standard corpus", "prism:copyright": "Copyright \u00a9 2012 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "3", "dcterms:subject": [{"@_fa": "true", "$": "Natural language processing"}, {"@_fa": "true", "$": "Gold standard corpus"}, {"@_fa": "true", "$": "Sampling"}, {"@_fa": "true", "$": "Capture probability"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "3", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "460-470", "prism:endingPage": "470", "prism:coverDisplayDate": "June 2012", "prism:doi": "10.1016/j.jbi.2011.12.010", "prism:startingPage": "460", "dc:identifier": "doi:10.1016/j.jbi.2011.12.010", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "52", "@width": "115", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "976", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "45", "@width": "240", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1215", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "45", "@width": "158", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "863", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "42", "@width": "54", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "417", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "141", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "580", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "82", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "461", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "98", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "618", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "1517", "@width": "2260", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr8_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "199345", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2980", "@width": "2968", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr7_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "597508", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1778", "@width": "2414", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "305544", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2813", "@width": "2311", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "344372", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "4251", "@width": "1948", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "324462", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "886", "@width": "1451", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "146300", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2310", "@width": "3166", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr6_lrg.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-HIGH-RES", "@size": "37274", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "high", "@height": "5654", "@width": "3820", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr5_lrg.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-HIGH-RES", "@size": "122516", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "high", "@height": "5818", "@width": "5237", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr2_lrg.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-HIGH-RES", "@size": "178353", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "342", "@width": "510", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "30777", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "687", "@width": "684", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "86317", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "401", "@width": "545", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "49846", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "644", "@width": "529", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62601", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "980", "@width": "449", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "56051", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "200", "@width": "327", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25315", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "260", "@width": "357", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "3924", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "531", "@width": "359", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "10685", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "548", "@width": "493", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "15714", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "160", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "1983", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "110", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2066", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "147", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2654", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "147", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3080", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "163", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4387", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "161", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5454", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "134", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3768", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "75", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2080", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "134", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411002243-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6645", "@ref": "fx1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84861839384"}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S089360801300035X", "dc:identifier": "doi:10.1016/j.neunet.2013.01.020", "eid": "1-s2.0-S089360801300035X", "prism:doi": "10.1016/j.neunet.2013.01.020", "pii": "S0893-6080(13)00035-X", "dc:title": "Learning in compressed space ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "42", "prism:startingPage": "83", "prism:endingPage": "93", "prism:pageRange": "83-93", "dc:format": "application/json", "prism:coverDate": "2013-06-30", "prism:coverDisplayDate": "June 2013", "prism:copyright": "Copyright \u00a9 2013 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Fabisch, Alexander"}, {"@_fa": "true", "$": "Kassahun, Yohannes"}, {"@_fa": "true", "$": "W\u00f6hrle, Hendrik"}, {"@_fa": "true", "$": "Kirchner, Frank"}], "dc:description": "\n               Abstract\n               \n                  We examine two methods which are used to deal with complex machine learning problems: compressed sensing and model compression. We discuss both methods in the context of feed-forward artificial neural networks and develop the backpropagation method in compressed parameter space. We further show that compressing the weights of a layer of a multilayer perceptron is equivalent to compressing the input of the layer. Based on this theoretical framework, we will use orthogonal functions and especially random projections for compression and perform experiments in supervised and reinforcement learning to demonstrate that the presented methods reduce training time significantly.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Model compression"}, {"@_fa": "true", "$": "Compressed sensing"}, {"@_fa": "true", "$": "Artificial neural networks"}, {"@_fa": "true", "$": "Supervised learning"}, {"@_fa": "true", "$": "Reinforcement learning"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S089360801300035X", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S089360801300035X", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84874412836", "scopus-eid": "2-s2.0-84874412836", "pubmed-id": "23501172", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84874412836", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20130207", "$": "2013-02-07"}}}}}
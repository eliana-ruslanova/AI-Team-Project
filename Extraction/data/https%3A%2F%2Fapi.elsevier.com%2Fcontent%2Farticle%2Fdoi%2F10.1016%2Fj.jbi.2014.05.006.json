{"scopus-eid": "2-s2.0-84919846083", "originalText": "serial JL 272371 291210 291682 291870 291901 31 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2014-05-21 2014-05-21 2014-12-22T20:46:19 1-s2.0-S1532046414001233 S1532-0464(14)00123-3 S1532046414001233 10.1016/j.jbi.2014.05.006 S300 S300.2 FULL-TEXT 1-s2.0-S1532046414X00067 2015-11-30T19:05:36.786505-05:00 0 0 20141201 20141231 2014 2014-05-21T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantsponsor highlightsabst primabst ref specialabst 1532-0464 15320464 true 52 52 C Volume 52 7 55 64 55 64 201412 December 2014 2014-12-01 2014-12-31 2014 Special Section: Methods in Clinical Research Informatics Dr. Philip R.O. Payne Dr. Peter J. Embi Special Section: Methods in Clinical Research Informatics Original Research article fla Copyright \u00a9 2014 Elsevier Inc. All rights reserved. TRANSFERLEARNINGBASEDCLINICALCONCEPTEXTRACTIONDATAMULTIPLESOURCES LV X 1 Introduction 2 Background 3 Task definition 4 Methods 4.1 Framework 4.2 TrAdaBoost 4.3 TrAdaBoost in clinical concept extraction 4.4 TrAdaBoost with Bagging 4.5 The overall system 5 Experiments 5.1 Data sets 5.2 Comparison methods 5.3 Results and analysis 6 Conclusion and future work Acknowledgments References SIMPSON 2012 465 517 M MININGTEXTDATA BIOMEDICALTEXTMININGASURVEYRECENTPROGRESS UZUNER 2011 552 556 O DEMNERFUSHMAN 2009 760 772 D FRIEDMAN 1994 161 174 C FRIEDMAN 2004 392 402 C HERSH 1995 743 747 W ZHOU 2006 1145 1149 X PRICAI2006TRENDSINARTIFICIALINTELLIGENCE MAXMATCHERBIOLOGICALCONCEPTEXTRACTIONUSINGAPPROXIMATEDICTIONARYLOOKUP TURCHIN 2006 691 695 A JOACHIMS 1999 T MAKINGLARGESCALESUPPORTVECTORMACHINELEARNINGPRACTICALADVANCESINKERNELMETHODS LAFFERTY 2001 282 289 J PROCEEDINGSEIGHTEENTHINTERNATIONALCONFERENCEMACHINELEARNING CONDITIONALRANDOMFIELDSPROBABILISTICMODELSFORSEGMENTINGLABELINGSEQUENCEDATA DEBRUIJN 2011 557 562 B ROBERTS 2011 568 573 K XU 2012 824 832 Y CHEN 2012 265 272 Y ZHANG 2013 1088 1098 S TORII 2011 580 587 M SINNOJIALIN 2010 1345 1359 P CARUANA 1997 41 75 R GANCHEV 2011 S17 S23 P LEE 2012 155 166 G FREUND 1997 119 139 Y BREIMAN 1996 123 140 L TSURUOKA 2005 382 392 Y ADVANCESININFORMATICS DEVELOPINGAROBUSTPARTOFSPEECHTAGGERFORBIOMEDICALTEXT LVX2014X55 LVX2014X55X64 LVX2014X55XX LVX2014X55X64XX Full 2015-12-01T00:01:08Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(14)00123-3 S1532046414001233 1-s2.0-S1532046414001233 10.1016/j.jbi.2014.05.006 272371 2014-12-22T20:39:04.913195-05:00 2014-12-01 2014-12-31 1-s2.0-S1532046414001233-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/MAIN/application/pdf/b251ecf332487c24d73af518f0853298/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/MAIN/application/pdf/b251ecf332487c24d73af518f0853298/main.pdf main.pdf pdf true 1799235 MAIN 10 1-s2.0-S1532046414001233-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/PREVIEW/image/png/936f85fb74e55c52c2c79f1a450fa92b/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/PREVIEW/image/png/936f85fb74e55c52c2c79f1a450fa92b/main_1.png main_1.png png 58731 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046414001233-si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/23e8ebd26962008ff30c6827710ea1da/si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/23e8ebd26962008ff30c6827710ea1da/si42.gif si42 si42.gif gif 932 22 184 ALTIMG 1-s2.0-S1532046414001233-si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/7e4a80bb1277a129a3d8c1be0a846781/si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/7e4a80bb1277a129a3d8c1be0a846781/si41.gif si41 si41.gif gif 727 18 165 ALTIMG 1-s2.0-S1532046414001233-si40.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/c2a19efe7faa2d1a279a6395c16d08f7/si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/c2a19efe7faa2d1a279a6395c16d08f7/si40.gif si40 si40.gif gif 953 19 199 ALTIMG 1-s2.0-S1532046414001233-si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/24e9f60eb75a465b3b3828707e7e661e/si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/24e9f60eb75a465b3b3828707e7e661e/si39.gif si39 si39.gif gif 991 19 219 ALTIMG 1-s2.0-S1532046414001233-si27.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/6bd387bdc85eab85d389e976a6c2dc5f/si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/6bd387bdc85eab85d389e976a6c2dc5f/si27.gif si27 si27.gif gif 1535 42 231 ALTIMG 1-s2.0-S1532046414001233-si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si9 si9.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si8 si8.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si7 si7.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si67.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/e91483d1fe5f3af08253e46d939bcbf9/si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/e91483d1fe5f3af08253e46d939bcbf9/si44.gif si67 si67.gif gif 424 18 48 ALTIMG 1-s2.0-S1532046414001233-si66.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/25a5d53130a92a309d7e35cd9731c595/si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/25a5d53130a92a309d7e35cd9731c595/si43.gif si66 si66.gif gif 433 20 46 ALTIMG 1-s2.0-S1532046414001233-si65.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si65 si65.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si64.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif si64 si64.gif gif 647 20 98 ALTIMG 1-s2.0-S1532046414001233-si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si63 si63.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si62.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif si62 si62.gif gif 647 20 98 ALTIMG 1-s2.0-S1532046414001233-si61.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si61 si61.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si60 si60.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si6 si6.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si59.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si59 si59.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si58.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si58 si58.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si57.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/f93d00e405785a15181aaa542f2100fe/si57.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/f93d00e405785a15181aaa542f2100fe/si57.gif si57 si57.gif gif 446 19 52 ALTIMG 1-s2.0-S1532046414001233-si56.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2df01880bbcfd8913d0a8e7954390145/si56.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2df01880bbcfd8913d0a8e7954390145/si56.gif si56 si56.gif gif 473 20 52 ALTIMG 1-s2.0-S1532046414001233-si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/1bfc5296c3d0acfcca644684eb46395e/si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/1bfc5296c3d0acfcca644684eb46395e/si55.gif si55 si55.gif gif 465 18 54 ALTIMG 1-s2.0-S1532046414001233-si54.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si54 si54.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si53.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si53 si53.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si52.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si52 si52.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si51.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si51 si51.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si50.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/e91483d1fe5f3af08253e46d939bcbf9/si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/e91483d1fe5f3af08253e46d939bcbf9/si44.gif si50 si50.gif gif 424 18 48 ALTIMG 1-s2.0-S1532046414001233-si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/149015ef788cfacd20cd29cda7775456/si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/149015ef788cfacd20cd29cda7775456/si5.gif si5 si5.gif gif 733 20 98 ALTIMG 1-s2.0-S1532046414001233-si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/25a5d53130a92a309d7e35cd9731c595/si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/25a5d53130a92a309d7e35cd9731c595/si43.gif si49 si49.gif gif 433 20 46 ALTIMG 1-s2.0-S1532046414001233-si48.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si48 si48.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si47 si47.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si46 si46.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si45.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si45 si45.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si44.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/e91483d1fe5f3af08253e46d939bcbf9/si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/e91483d1fe5f3af08253e46d939bcbf9/si44.gif si44 si44.gif gif 424 18 48 ALTIMG 1-s2.0-S1532046414001233-si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/25a5d53130a92a309d7e35cd9731c595/si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/25a5d53130a92a309d7e35cd9731c595/si43.gif si43 si43.gif gif 433 20 46 ALTIMG 1-s2.0-S1532046414001233-si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/8c7be1f6cd3612ce3c98b19e637666b7/si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/8c7be1f6cd3612ce3c98b19e637666b7/si4.gif si4 si4.gif gif 733 20 102 ALTIMG 1-s2.0-S1532046414001233-si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si38 si38.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si37 si37.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/5c2f887d6792dcbb5996e06479409de1/si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/5c2f887d6792dcbb5996e06479409de1/si36.gif si36 si36.gif gif 751 20 120 ALTIMG 1-s2.0-S1532046414001233-si35.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si35 si35.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si34 si34.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si33 si33.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si32 si32.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si31 si31.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si30.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si30 si30.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/71497f3d8f780a9f6929c7ceeb6241a1/si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/71497f3d8f780a9f6929c7ceeb6241a1/si3.gif si3 si3.gif gif 397 19 42 ALTIMG 1-s2.0-S1532046414001233-si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si29 si29.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si28 si28.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si26.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif si26 si26.gif gif 647 20 98 ALTIMG 1-s2.0-S1532046414001233-si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si25 si25.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si24 si24.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/ec05b51d4f13bc44a6f449454b73b41f/si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/ec05b51d4f13bc44a6f449454b73b41f/si23.gif si23 si23.gif gif 261 20 24 ALTIMG 1-s2.0-S1532046414001233-si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si22 si22.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si21 si21.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si20 si20.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/da6a3f50ca240051727d0095f88d2a6a/si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/da6a3f50ca240051727d0095f88d2a6a/si2.gif si2 si2.gif gif 387 19 40 ALTIMG 1-s2.0-S1532046414001233-si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/3f7a96ff3adfe161d08c60a3f4057e75/si19.gif si19 si19.gif gif 647 20 98 ALTIMG 1-s2.0-S1532046414001233-si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/62789ac5922d025803d8de94c551b8dd/si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/62789ac5922d025803d8de94c551b8dd/si18.gif si18 si18.gif gif 503 19 111 ALTIMG 1-s2.0-S1532046414001233-si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/29aff8e36933610feee532cbc0e3c7d8/si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/29aff8e36933610feee532cbc0e3c7d8/si17.gif si17 si17.gif gif 411 17 80 ALTIMG 1-s2.0-S1532046414001233-si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/abb7198f9a83aa2c610f91282510f2f2/si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/abb7198f9a83aa2c610f91282510f2f2/si16.gif si16 si16.gif gif 542 20 109 ALTIMG 1-s2.0-S1532046414001233-si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/06e3ecb079ffe80e155978e5d818823b/si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/06e3ecb079ffe80e155978e5d818823b/si15.gif si15 si15.gif gif 623 19 149 ALTIMG 1-s2.0-S1532046414001233-si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si14 si14.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/2d0cf37236e868829cd683d09a907bee/si48.gif si13 si13.gif gif 383 19 40 ALTIMG 1-s2.0-S1532046414001233-si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/80a4fb66217eb2d7ed3db39a6597be11/si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/80a4fb66217eb2d7ed3db39a6597be11/si12.gif si12 si12.gif gif 857 21 131 ALTIMG 1-s2.0-S1532046414001233-si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/9b562e22090a5962c85af08b2dd07b6c/si34.gif si11 si11.gif gif 401 20 40 ALTIMG 1-s2.0-S1532046414001233-si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/485625a6a5d2b1a5391c2049e2799959/si33.gif si10 si10.gif gif 393 18 41 ALTIMG 1-s2.0-S1532046414001233-si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/STRIPIN/image/gif/6ea2f907213c2a5065f02863312cef0e/si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/STRIPIN/image/gif/6ea2f907213c2a5065f02863312cef0e/si1.gif si1 si1.gif gif 1154 17 276 ALTIMG 1-s2.0-S1532046414001233-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr1/HIGHRES/image/jpeg/d8289de24305584d659afbd1ca76fa05/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr1/HIGHRES/image/jpeg/d8289de24305584d659afbd1ca76fa05/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 209050 1074 2365 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/fx1/HIGHRES/image/jpeg/7673d85d151f4d4822d67e11c87beb27/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/fx1/HIGHRES/image/jpeg/7673d85d151f4d4822d67e11c87beb27/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 380675 822 2213 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr9_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr9/HIGHRES/image/jpeg/a03e7e5682c76f5b7981f9c7f5f7daa9/gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr9/HIGHRES/image/jpeg/a03e7e5682c76f5b7981f9c7f5f7daa9/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 180535 1200 1602 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr8_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr8/HIGHRES/image/jpeg/a0721b7f04627beccd7361240426c99b/gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr8/HIGHRES/image/jpeg/a0721b7f04627beccd7361240426c99b/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 183216 1204 1604 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr7/HIGHRES/image/jpeg/c758f2e24816f36c19f5a0f1d1acf5d2/gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr7/HIGHRES/image/jpeg/c758f2e24816f36c19f5a0f1d1acf5d2/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 600602 994 2676 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr6/HIGHRES/image/jpeg/8c43e94dd87c5e5d4c251a5c5fa5a835/gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr6/HIGHRES/image/jpeg/8c43e94dd87c5e5d4c251a5c5fa5a835/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 232003 881 1281 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr5/HIGHRES/image/jpeg/5f977fc0b70cc0e422c339ac386f0089/gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr5/HIGHRES/image/jpeg/5f977fc0b70cc0e422c339ac386f0089/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 244934 1554 2068 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr4/HIGHRES/image/jpeg/fb02e5be34f83ae6926652dbfc0bae3d/gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr4/HIGHRES/image/jpeg/fb02e5be34f83ae6926652dbfc0bae3d/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 393602 1474 1379 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr3/HIGHRES/image/jpeg/9f031a5e2712b10459d5a2f20a037806/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr3/HIGHRES/image/jpeg/9f031a5e2712b10459d5a2f20a037806/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 214404 926 1436 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr2/HIGHRES/image/jpeg/d3ed269448f94c8b5b3a275ba5d8390a/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr2/HIGHRES/image/jpeg/d3ed269448f94c8b5b3a275ba5d8390a/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 287027 1624 1521 IMAGE-HIGH-RES 1-s2.0-S1532046414001233-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr1/DOWNSAMPLED/image/jpeg/8338c2823a830132957d475a405c2b5b/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr1/DOWNSAMPLED/image/jpeg/8338c2823a830132957d475a405c2b5b/gr1.jpg gr1 gr1.jpg jpg 25987 243 534 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/fx1/DOWNSAMPLED/image/jpeg/c5b8db4bde696d5f998574ce900f8eab/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/fx1/DOWNSAMPLED/image/jpeg/c5b8db4bde696d5f998574ce900f8eab/fx1.jpg fx1 true fx1.jpg jpg 39800 186 500 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr9/DOWNSAMPLED/image/jpeg/4bf208bef5bd658a34a7e7593c773518/gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr9/DOWNSAMPLED/image/jpeg/4bf208bef5bd658a34a7e7593c773518/gr9.jpg gr9 gr9.jpg jpg 22312 271 362 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr8/DOWNSAMPLED/image/jpeg/977aa3ba16a1fe0480beb2b346d49da2/gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr8/DOWNSAMPLED/image/jpeg/977aa3ba16a1fe0480beb2b346d49da2/gr8.jpg gr8 gr8.jpg jpg 22242 272 362 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr7/DOWNSAMPLED/image/jpeg/a39448b268bfa7ac7115b3424c24b9e6/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr7/DOWNSAMPLED/image/jpeg/a39448b268bfa7ac7115b3424c24b9e6/gr7.jpg gr7 gr7.jpg jpg 47354 224 604 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr6/DOWNSAMPLED/image/jpeg/91023f64e2e38642de1ec12ac6b125bb/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr6/DOWNSAMPLED/image/jpeg/91023f64e2e38642de1ec12ac6b125bb/gr6.jpg gr6 gr6.jpg jpg 25583 199 289 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr5/DOWNSAMPLED/image/jpeg/3bde1ad814f224f1056c521235d164b0/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr5/DOWNSAMPLED/image/jpeg/3bde1ad814f224f1056c521235d164b0/gr5.jpg gr5 gr5.jpg jpg 29669 351 467 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr4/DOWNSAMPLED/image/jpeg/ba62faa8927e1aaf2c99c1e044824909/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr4/DOWNSAMPLED/image/jpeg/ba62faa8927e1aaf2c99c1e044824909/gr4.jpg gr4 gr4.jpg jpg 45004 332 311 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr3/DOWNSAMPLED/image/jpeg/49ed6f4ed52bcc67f870cb5dbc8dd616/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr3/DOWNSAMPLED/image/jpeg/49ed6f4ed52bcc67f870cb5dbc8dd616/gr3.jpg gr3 gr3.jpg jpg 20540 209 324 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr2/DOWNSAMPLED/image/jpeg/60feba1795729083f6491989d05b49f2/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr2/DOWNSAMPLED/image/jpeg/60feba1795729083f6491989d05b49f2/gr2.jpg gr2 gr2.jpg jpg 30972 366 343 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414001233-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr1/THUMBNAIL/image/gif/1dd3576617ee35323a168f911a94f652/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr1/THUMBNAIL/image/gif/1dd3576617ee35323a168f911a94f652/gr1.sml gr1 gr1.sml sml 4588 99 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/fx1/THUMBNAIL/image/gif/e2ff14ee6fc9bc67e3c334910e41a934/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/fx1/THUMBNAIL/image/gif/e2ff14ee6fc9bc67e3c334910e41a934/fx1.sml fx1 true fx1.sml sml 7453 81 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr9/THUMBNAIL/image/gif/6dea577530268255a4a83670f073e74c/gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr9/THUMBNAIL/image/gif/6dea577530268255a4a83670f073e74c/gr9.sml gr9 gr9.sml sml 5543 164 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr8/THUMBNAIL/image/gif/4c2593e9c9930f887a613ec26899f061/gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr8/THUMBNAIL/image/gif/4c2593e9c9930f887a613ec26899f061/gr8.sml gr8 gr8.sml sml 5558 164 218 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr7/THUMBNAIL/image/gif/aa69a54dba62f1563f2653db1234c649/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr7/THUMBNAIL/image/gif/aa69a54dba62f1563f2653db1234c649/gr7.sml gr7 gr7.sml sml 7709 81 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr6/THUMBNAIL/image/gif/274e6e14f74357dc22a2584929626d62/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr6/THUMBNAIL/image/gif/274e6e14f74357dc22a2584929626d62/gr6.sml gr6 gr6.sml sml 8323 151 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr5/THUMBNAIL/image/gif/ac1a0dd366560aca656b02807de82120/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr5/THUMBNAIL/image/gif/ac1a0dd366560aca656b02807de82120/gr5.sml gr5 gr5.sml sml 7981 164 218 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr4/THUMBNAIL/image/gif/c556ee3440da49cd6cb7184cbe3f17ec/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr4/THUMBNAIL/image/gif/c556ee3440da49cd6cb7184cbe3f17ec/gr4.sml gr4 gr4.sml sml 7307 164 153 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr3/THUMBNAIL/image/gif/ee92951de37f5b33e007104aa7a43aa9/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr3/THUMBNAIL/image/gif/ee92951de37f5b33e007104aa7a43aa9/gr3.sml gr3 gr3.sml sml 10423 141 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414001233-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414001233/gr2/THUMBNAIL/image/gif/974bfb507df323de5620b666d7f862bd/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414001233/gr2/THUMBNAIL/image/gif/974bfb507df323de5620b666d7f862bd/gr2.sml gr2 gr2.sml sml 6037 163 153 IMAGE-THUMBNAIL YJBIN 2177 S1532-0464(14)00123-3 10.1016/j.jbi.2014.05.006 Elsevier Inc. Fig. 1 Difference between traditional machine learning and transfer learning. Fig. 2 Framework of transfer learning-based clinical concept extraction. Fig. 3 The mechanism of TrAdaBoost. Fig. 4 Algorithm of concept extraction based on TrAdaBoost. Fig. 5 The mechanism of TrAdaBoost with Bagging. Fig. 6 Algorithm of TrAdaBoost with Bagging. Fig. 7 Flow diagram of the overall system. Fig. 8 The F-score curves on BETH vs. PARTNERS for four methods. Fig. 9 The F-score curves on BETHBIO vs. PARTNERS for four methods. Table 1 An example of clinical concept extraction. the patient will use chlorhexidine soap bath once daily O O O O B_Tr I_Tr I_Tr O O Table 2 Features in our work. Category Features Word features the word itself the word shape the POS 4-character-prefix-and-suffix contain with digit begin with digit contain with uppercase letter begin with a uppercase letter Context features two previous tokens two next tokens two previous tokens\u2019 4-character-prefix-and-suffix two next tokens\u2019 4-character-prefix-and-suffix Sentence features end with colon sentence\u2019s tense Section features heading subsection heading Table 3 The three data sets in our experiments. Set name Document type Documents Tokens Problems Tests Treatments BETH Discharge summaries 73 88,722 4187 3036 3073 PARTNERS Discharge summaries 97 60,819 2886 1572 1771 BETHBIO Discharge summaries & Biomedical literatures 216 118,325 4631 3036 3296 BETHBIO is a combination of BETH and BIOLITERATURE. The number of the documents in BETHBIO is 73 (from BETH) plus 143 (from BIOLITERATURE); the rest can be performed in the same manner. Because there are no correspondent \u201ctest\u201d labels in BIOLITERATURE, the number of \u201ctests\u201d is identical between BETH and BETHBIO. Table 4 The data sets for transfer learning experiments. T train source T train target T test target # T train source # T train target # T test target KL BETH PARTNERS (80%) PARTNERS (20%) 88,722 48659 12160 0.36 BETHBIO PARTNERS (80%) PARTNERS (20%) 118,325 48659 12160 0.79 Table 5 Description of the four methods. Methods Training data Test data NoTr(S) T train source T test target NoTr(T) T train target T test target NoTr(S\u222aT) T train source \u222a T train target T test target Our method T train source \u222a T train target T test target Table 6 Performance of the four systems on BETH vs. PARTNERS and BETHBIO vs. PARTNERS when the ratio between | T train target | and | T train source | is set to be 0.02. Method Problem Treatment Test Total PCI(\u00b1) RCI(\u00b1) FCI(\u00b1) PCI(\u00b1) RCI(\u00b1) FCI(\u00b1) PCI(\u00b1) RCI(\u00b1) FCI(\u00b1) PCI(\u00b1) RCI(\u00b1) FCI(\u00b1) a. Results of BETH vs. PARTNERS (KL=0.36) NoTr(T) 0.418 0.255 0.316 0.442 0.230 0.303 0.235 0.209 0.221 0.374 0.237 0.290 0.012 0.011 0.008 0.015 0.012 0.009 0.014 0.015 0.010 0.008 0.007 0.005 NoTr(S) 0.625 0.642 0.633 0.686 0.652 0.669 0.566 0.715 0.631 0.630 0.643 0.636 0.013 0.013 0.009 0.015 0.013 0.010 0.018 0.016 0.012 0.009 0.008 0.006 NoTr(S\u222aT) 0.611 0.664 0.636 0.671 0.622 0.646 0.574 0.669 0.618 0.621 0.653 0.637 0.014 0.012 0.009 0.014 0.014 0.010 0.019 0.017 0.013 0.009 0.008 0.006 Our method 0.648 0.676 0.662 0.701 0.652 0.676 0.562 0.723 0.632 0.644 0.676 0.660 0.014 0.012 0.009 0.014 0.014 0.010 0.019 0.017 0.013 0.009 0.008 0.006 b. Results of BETHBIO vs. PARTNERS (KL=0.79) NoTr(T) 0.394 0.397 0.395 0.333 0.193 0.244 0.488 0.362 0.415 0.395 0.273 0.323 0.013 0.013 0.009 0.014 0.011 0.009 0.017 0.017 0.012 0.008 0.008 0.006 NoTr(S) 0.600 0.668 0.632 0.629 0.607 0.618 0.542 0.690 0.607 0.589 0.641 0.614 0.015 0.012 0.010 0.016 0.014 0.011 0.017 0.017 0.012 0.009 0.008 0.006 NoTr(S\u222aT) 0.598 0.605 0.601 0.638 0.605 0.621 0.584 0.658 0.619 0.604 0.618 0.611 0.015 0.013 0.010 0.014 0.014 0.010 0.019 0.017 0.013 0.009 0.008 0.006 Our method 0.642 0.678 0.659 0.673 0.642 0.657 0.603 0.714 0.653 0.658 0.652 0.655 0.013 0.012 0.009 0.013 0.014 0.010 0.016 0.016 0.012 0.008 0.008 0.006 P, R, F are the three performance metrics standing for precisions, recalls and F-score, which are defined in Section 5.2; CI(\u00b1) is confidence interval for P, R, and F. Bold values mean that our system outperforms the baseline systems. Transfer learning based clinical concept extraction on data from multiple sources Xinbo Lv Yi Guan \u204e guanyi@hit.edu.cn Benyang Deng School of Computer Science and Technology, Harbin Institution of Technology, Harbin, Heilongjiang 150001, China School of Computer Science and Technology Harbin Institution of Technology Harbin Heilongjiang 150001 China \u204e Corresponding author. Address: Mailbox 321, West Da-zhi Street 92, Harbin, Heilongjiang 150001, China. Graphical abstract Highlights \u2022 Using data drawn from different distribution to train concept extraction model. \u2022 An instance based transfer learning method TrAdaBoost is applied in our work. \u2022 We combine TrAdaBoost with Bagging to prevent the negative transfer problem. \u2022 Only a tiny amount of data in target domain is required to build a model. Abstract Machine learning methods usually assume that training data and test data are drawn from the same distribution. However, this assumption often cannot be satisfied in the task of clinical concept extraction. The main aim of this paper was to use training data from one institution to build a concept extraction model for data from another institution with a different distribution. An instance-based transfer learning method, TrAdaBoost, was applied in this work. To prevent the occurrence of a negative transfer phenomenon with TrAdaBoost, we integrated it with Bagging, which provides a \u201csofter\u201d weights update mechanism with only a tiny amount of training data from the target domain. Two data sets named BETH and PARTNERS from the 2010 i2b2/VA challenge as well as BETHBIO, a data set we constructed ourselves, were employed to show the effectiveness of our work\u2019s transfer ability. Our method outperforms the baseline model by 2.3% and 4.4% when the baseline model is trained by training data that are combined from the source domain and the target domain in two experiments of BETH vs. PARTNERS and BETHBIO vs. PARTNERS, respectively. Additionally, confidence intervals for the performance metrics suggest that our method\u2019s results have statistical significance. Moreover, we explore the applicability of our method for further experiments. With our method, only a tiny amount of labeled data from the target domain is required to build a concept extraction model that produces better performance. Keywords Clinical concept extraction Transfer learning TrAdaBoost Bagging Machine learning 1 Introduction Clinical documents are valuable resources in which abundant personalized health information, such as symptoms, medicines and tests, is recorded by physicians in natural language. As a subtask of automatic acquisition of knowledge from these unstructured clinical texts, concept extraction aims to identify words and phrases that stand for clinical concepts from the narrative texts in clinical documents. This is the key component of text processing systems for understanding the content of clinical documents. Only when clinical concepts are correctly identified can other more complex tasks, such as concept relation extraction, assertion classification, co-reference, health information retrieval and health information recommendation, be performed effectively. In the biomedical literature domain, research similar to concept extraction has been conducted in named entity recognition tasks such as gene name recognition [1]. However, research on clinical concept extraction for clinical documents appears to be rather sparse. One important reason for the lag of clinical concept extraction is the lack of shared annotated clinical documents due to patient privacy and confidentiality requirements. Fortunately, efforts to construct de-identified clinical documents are finally allowing studies on clinical concept extraction. For example, the 2010 Informatics for Integrating Biology and the Bedside (i2b2)/Veteran\u2019s Affairs (VA) challenge [2] provided a total of 394 training documents, 477 test documents, and 877 un-annotated documents for all three tasks. However, annotated clinical documents are always scarce and are created by a number of different institutions; the 2010 i2b2/VA challenge\u2019s data consist of four sets from three institutions. Such small-scale data sets limit the performance of a statistical machine learning model. One solution to this problem is to increase the training data sets by gathering data from multiple sources. Nevertheless, different vocabularies and writing styles of multiple sources make the combined data sets heterogeneous, to which the statistical machine learning model is sensitive. Specifically, the marginal probability distributions of words in clinical texts from different institutions are not equal, which violates the traditional machine learning\u2019s basic assumption: the training and test data should be under the same distribution. Therefore, a learner trained by one institution\u2019s data may perform worse when it is applied to data from another institution. The normal way of tackling this problem is to annotate data from the new institution, but this is always expensive and time-consuming. Abandoning old data would also be a waste. The objective of this paper is to discuss approaches and strategies for clinical concept extraction from multiple sources. Using a training data set with a different distribution from one institution, we build a clinical concept extraction model for data from another institution. Transfer learning is a family of algorithms that can relax the traditional machine learning\u2019s same-distribution assumption. It leverages and transfers knowledge from the source domain to the target domain, and in this way, helps improve the model when the target domain\u2019s training data are insufficient. Specifically, we apply an instance-based transfer learning method \u2013 TrAdaBoost [3] \u2013 to the clinical concept extraction task. TrAdaBoost aims to re-weight the instances in the source domain in order to decrease the diversity between the data of the source domain and the target domain. It was originally created to solve binary classification problems, and we apply it to the sequence labeling problem with multiple labels. Additionally, to avoid the negative transfer problem caused by the over-discarded risk of TrAdaBoost, we integrate Bagging with TrAdaBoost to provide a \u201csofter\u201d weight update mechanism. Two data sets, BETH and PARTNERS, from the 2010 i2b2/VA challenge, as well as one data set we built by combining BETH and a biomedical literature data set (BIOLITERATURE), are used to verify the effectiveness of our method\u2019s transfer ability. Experiments show that with only a small amount of annotated training data from the target domain, our framework outperforms the baseline method, which simply combines data from the source domain and data from the target domain as training data. 2 Background Methods for clinical concept extraction generally fall into three categories: dictionary-based methods, rule-based methods and statistical machine learning methods [4]. Dictionary-based methods search through dictionaries such as UMLS [5] and SNOMED-CT [6] to extract clinical concepts. MedLEE [7] is a typical system that uses a domain-specific vocabulary and semantic grammar to extract and encode clinical information in narrative reports. A structured representation is then constructed by these clinical terms. It is adapted to extract the concepts in clinical documents, and these concepts are mapped to semantic categories and semantic structures [8]. MetaMap [9] is also an early dictionary-based program developed at the National Library of Medicine (NLM) to recognize and categorize entities in texts from the biomedical domain and then to map them to UMLS Metathesaurus. It is applied to both IR and data mining applications; additionally, it is used to index the biomedical literature at the NLM. Systems described in [10\u201312] also adopt dictionary-based methods. The advantage of these methods is that they are easy to implement, while the disadvantage is that they suffer from low recall since many concepts may fail to be covered by the dictionary. Rule-based methods require experts to define hand-coded rules or regular expressions for the extraction task. For example, in the sentence \u201csystemic granulomatous diseases such as Crohn\u2019s disease or saroiaosis\u201d, the phrase \u201csuch as\u201d implies that \u201cCrohn\u2019s disease\u201d and \u201csaroiaosis\u201d are disease names. Long [13] used regular expression to extract the diagnoses and procedures from the past medical history and discharge diagnoses in the discharge summary. Turchin et al. [14] designed a software tool to extract blood pressure values and anti-hypertensive treatment intensification from the texts of physician notes; regular expressions are also employed in their work. Rule-based methods are always difficult to achieve and time-consuming because rules have to be collected by hand. In recent years, more and more researchers have resorted to statistical machine learning methods for clinical concept extraction. Several models, such as the Hidden Markov Model (HMM) [15], Support Vector Machine (SVM) [16], Maximum Entropy Model (MEM) [17] and Conditional Random Fields (CRF) [18], have been used to solve the information extraction problem. CRF has been proven to be the state-of-art model among these models. Taira and Soderland [19] first used MEM for the task of knowledge acquisition, parsing, semantic interpretation and evaluation of radiology reports; then, they moved to a vector space model to extract concepts about anatomy defined in the UMLS. A set of 2551 unique anatomical concepts was finally extracted from brain radiology reports, and an F-score of 87% was achieved [20]. Sibanda et al. [21] employed SVM trained with syntactic, contextual clues and ontological information from UMLS to recognize semantic categories in discharge summaries. They extracted eight types of semantic categories, and an F-score above 90% was achieved. There are also some methods of multiple classifier fusion for this task. For example, Wang and Patrick [22] combined MEM, SVM and CRF to recognize 10 types of clinical entities from 311 admission summaries, and an F-score of 83.3% which is 3.35% higher than the baseline stand-only CRF model, was obtained. Li et al. [23] compared CRF with SVM for disorder named entity recognition in clinical texts, and the experimental results showed that CRF obtained a higher score than did SVM. All of the works described above are, however, not evaluated on the same data set, so it is difficult to compare them. The 2010 i2b2/VA challenge provides an opportunity for researchers to demonstrate their methods on a shared data set. Most of the submitted systems are based on machine learning methods. The best performance was achieved by a discriminative semi-Markov HMM that was trained by passive\u2013aggressive (PA) online updates. The system obtained an F-score of 0.8523 [24]. Roberts and Harabagiu [25] proposed a flexible feature selection mechanism that makes it easy to find a near-optimal subset of features for a task in their system. For more details about this challenge, refer to [2]. There have also been some works based on the data set after this challenge. Xu et al. [26] developed a system that outperforms the best system in the challenge. Their main contribution to concept extraction was using two separate CRF models to handle medical concepts and non-medical concepts. Chen et al. [27] applied active learning to assertion classification, and their experiments showed that a comparable performance can be achieved with fewer annotated training instances. Abacha and Zweigenbaum [28] compared three methods of medical entity recognition: a semantic method that relies on domain knowledge, a method that first extracts noun phrases and then uses SVM to classify their entity types, and a method that uses CRF to identify entity boundaries and types simultaneously. Their work showed that the hybrid method that combined machine learning and domain knowledge yielded the best results. Although statistical machine learning methods have obtained certain achievements, the lack of abundant annotated clinical documents and the diversity in clinical documents from multiple institutions present great challenges to researchers. One solution to this problem is to accomplish the task with fewer or even no training data. For example, Zhang and Elhadad [29] attempted an unsupervised method to extract named entities in both biological and clinical text without any rules or annotated data. The advantage of this method is that it is easy to use in different applications; however, it is not as competitive as supervised methods. Another solution is to achieve clinical concept extraction by increasing the training data. Torii et al. [30] found that the performance may be improved if more training data are available; however, they also found that the performance of a model trained on one institution\u2019s data degraded when data from another institution were tested. Their work inspires us to explore new machine learning methods to improve the performance of clinical concept extraction models with the help of training data from other sources with different distributions. Although generalization, which is the ability to perform accurately on unseen examples after having experienced a learning data set, is a core objective of machine learning, it is still a challenge to most machine learning methods because they are not designed to work appropriately when a distribution changes. Transfer learning [31] presents a possible way to improve the generalization ability by relaxing the restriction of traditional machine learning\u2019s same-distribution assumption, allowing the previous data to be reused for a new task. Transfer learning has attracted more and more researchers since it was first presented in a NIPS-95 workshop, and it is referred to by different names, such as \u201clearning to learn\u201d [32], \u201clife-long learning\u201d [33], and \u201cmulti-task learning\u201d [34]. It has been used in many applications such as sentiment classification [35] and image classification [36]. Currently, transfer learning is also applied in the bioinformatics and computational biology. Ganchev et al. [37] proposed a framework called Transfer Rule Learner (TRL) for the task of biomarker discovery, which aims to find measurable variables that can reflect and predict a disease state. TRL transferred knowledge in the form of rules from an old data set and used them to learn a new classifier on a new data set. The performance of their method exceeded that of using one data set alone and the union of the data sets. Lee et al. [38] applied transfer learning to flow cytometry, which is a technique for rapid cell analysis. An important process in flow cytometry is to label every cell as belonging or not belonging to the cell type of interest, which is called \u201cgating\u201d. They leveraged existing datasets that were previously gated by experts to automatically gate a new flow cytometry dataset. The most relevant research to our work is to recognize protein names from biological journals coming from two sources using a maximum entropy based transfer learning algorithm [39]. To the author\u2019s best knowledge, no transfer learning algorithm has been attempted to perform the clinical concept extraction task on clinical documents. 3 Task definition Clinical concept extraction aims to automatically identify the boundaries of concepts and assign the concept types to them. It can be seen as a sequence labeling problem that assigns each token a label indicating both the boundary and concept type. Given an unstructured text X = x 1,\u2026, xn and a label set Y, the statistical machine learning method\u2019s object is to obtain a probability P(y|xi ) to xi which is labeled as y. The 2010 i2b2/VA challenge defined three medical concept types: medical problems (e.g., diseases, viruses, abnormalities), treatments (e.g., drugs, procedures, medical devices) and tests (e.g., examinations and evaluations of the patient, physiologic measures and vital signs). We will follow the definitions proposed by this challenge in our work. In our clinical concept extraction task, Y = { B _ Pr , B _ Tr , B _ Te , I _ Pr , I _ Tr , I _ Te , O } . In this label denotation, Pr, Tr, Te are the category labels, indicating the label\u2019s type, that is, problem, treatment and test; B and I indicate a token is the beginning of a concept and the inside of a concept, respectively; O means that a token does not belong to a concept. An example is shown in Table 1 , in which \u201cchlorhexidine soap bath\u201d is labeled as a concept, and its type is treatment. To construct a prediction model, traditional machine learning methods must be trained by a training data set (Xtrain , Ytrain )={(x 1, y 1),\u2026,(xN , yN )}; then, the model will be designated to annotate test data set Xtest =(x 1,\u2026, xM ). The basic assumption of traditional machine learning is that Xtrain and Xtest must be under the same distribution D, that is, the marginal probability distributions P(X) between the training data set and test data set are the same. In the case of our clinical concept extraction task, that means distributions of words in clinical texts between the training data and the test data are identical (we consider distributions of words in clinical texts that are from domain vocabularies such as SNOMED). However, in practice, this assumption is always difficult to follow. For the clinical concept extraction task, in most cases, we have built a model using data from one institution but apply it directly to data from another institution, and this may lead to poor performance. Transfer learning can, however, allow the model to be applied to data sets drawn from some distribution different from the one upon which it was trained. Fig. 1 shows the difference between traditional machine learning and transfer learning. The main contribution of transfer learning is transferring knowledge from the source domain to target domain. We now formally define our task: we have two clinical data sets with different distributions D source and D target that are constructed by two institutions. Our task is to assign labels Y test target to test data X test target drawn from D target, given the training data X train source , Y train source drawn from D source. In addition, we have a tiny amount of training data X train target , Y train target drawn from D target, the quantity of these data is not sufficient to train a high-quality model alone but can help to initialize a rough model upon which transfer learning will further refine. Among the different approaches to transfer learning, we prefer instance-based transfer, which assumes that some instances in the source domain can be reused. By re-weighting weights of instances in the source domain, effects of dissimilar instances will be reduced, while similar instances will contribute more to the target domain and may thus lead to a more accurate model. For example, in our task, \u201cmedicine\u201d can be a similar instance between the source domain and the target domain because it is a common word, while \u201cAlzheimer\u201d can be a dissimilar instance between the source domain and the target domain because it only appears in some specific clinical documents. 4 Methods 4.1 Framework The framework of our work is shown in Fig. 2 . We have training data in both the source domain and target domain, but their distributions are not the same. Additionally, the quantity of training data in the target domain is not sufficient, which makes it impossible to learn an accurate model with these data alone. Our goal is to learn a model that will extract clinical concepts on test data in the target domain with high accuracy based on training data from the source domain and a tiny amount of training data from the target domain. We employ an instance-based transfer learning method named TrAdaBoost to learn a model with transfer ability. Similar to other transfer learning methods, TrAdaBoost cannot always transfer the right knowledge to the target domain, which sometimes causes lower system performance, called negative transfer. To prevent this situation, we adopt Bagging (Bootstrap aggregating), which takes K TrAdaBoost\u2019s results as base learners and aggregates them into the final learner. Under this schema, the risk of negative transfer will be averaged to K learners, resulting in a lower overall influence of negative transfer. In the end, the final learner will be used to extract concepts in the test data from the target domain. 4.2 TrAdaBoost TrAdaBoost (Transfer AdaBoost) [3] is an instance-based transfer learning method extended from Adaboost [40]. It allows users to leverage the training data from an old domain to construct a high-quality model for the new test data. The key idea is to re-weight instances from the source domain based on a few of annotated training instances from the target domain. Although under different distributions, some instances from the source domain may be helpful to construct the training data set combined with the instances from target domain. The algorithm uses boosting to filter out \u201cbad\u201d source domain instances while encouraging the \u201cgood\u201d ones to build a more accurate model in target domain. There are many choices in the family of transfer learning algorithms; among them, we prefer TrAdaBoost for three major reasons: first, it assumes feature spaces and labels between the source domain and target domain are exactly identical but distributions are different, which is consistent with our task; second, it is suitable for the condition that the two domains\u2019 dissimilarity is not too great, as is the case in our task; finally, TrAdaBoost is a flexible machine learning framework that can accommodate other machine learning models without modifying them, which increases the versatility of our method. As an instance transfer learning method, the goal of TrAdaBoost is to reuse T train source as much as possible by discovering which part of T train source is specific for the source domain and which part may be common between source and target domains. It boosts to re-weight the instances from both T train source and T train target . The mechanism of TrAdaBoost is shown in Fig. 3 . On the one hand, weights of instances from T train source that are wrongly predicted will be decreased in order to weaken their impacts; on the other hand, weights of instances from T train target that are wrongly predicted will be increased in order to emphasize them. 4.3 TrAdaBoost in clinical concept extraction TrAdaBoost is an extension from AdaBoost, which aims to train N weak learners in N rounds to improve the overall performance of these weak learners by re-weighting training instances. In each round, AdaBoost re-weights training instances depending on whether they are correctly classified by this weak learner, and weights of the wrongly classified instances will be increased by multiplying a parameter \u03b2t to strengthen their effects on the training of the next learner in the next round. After N rounds, N trained weak learners will be integrated to a final learner. A formal description of the TrAdaBoost-based algorithm in clinical concept extraction is shown in Fig. 4 . The inputs of this algorithm include clinical training data from two institutions T train source and T train target , test data to be labeled ( T test target , which is from the same institution with T train target ), and a LEARNER, which can be any machine learning model, such as MEM or CRF, that acts as the base learner in AdaBoost. The algorithm maintains a weight vector for training instances whose value at round t is w t = { w 1 t , \u2026 , w m + n t } , which is arbitrarily assigned with weight { w 1 1 , \u2026 , w m + n 1 } in the initializing step. w 1 t , \u2026 , w m t are weights for training instances from source domain while w m + 1 t , \u2026 , w m + n t are weights for training instances from target domain. The algorithm then iterates N times to update the weight vector. In each iteration round, a weak hypothesis ht :X \u2192 Y is learned in line 4 based on the training data set T train source \u222a T train target with normalized weight vector p t. Parameter \u03b5t is the error rate of the weak hypothesis ht on training data from the target domain. It is used to evaluate ht : the larger the \u03b5t is, the weaker is the ht . TrAdaBoost enables AdaBoost with transfer learning by adding another parameter \u03b2, whose function is to re-weight training instances in the source domain; \u03b2t , whose function is to re-weight training instances in the original AdaBoost algorithm, is diverted to re-weight training instances in target domain. \u03b2 and \u03b2t are set in line 6: \u03b2t is a function of \u03b5t : \u03b2t will have a larger value if ht has a higher error rate. The weight vector is then updated by multiplying by the two parameters. If training instances from T train source are incorrectly predicted, weights of these instances will be decreased by multiplying \u03b2 (\u03b2 \u220a(0,1]). Then, in the next round, the re-weighted \u201cbad\u201d training instances from T train source will have less impact than the current round. Meanwhile, weights of miss-predicted training instances from T train target will be increased by multiplying \u03b2 t - 1 in order to emphasize them in the next round. After N iterations, common instances between T train source and T train target will have higher weights, and the combined training set T train source \u222a T train target will be more suitable for training an accurate clinical concept extraction model. At the end of the algorithm, the final hypothesis hf (x) is voted by the latter half of these weak hypotheses with higher confidence. The main difference between our algorithm and the original TrAdaBoost exists in that we extended it to multi-class problems in order to tackle our clinical concept extraction task. It is easy to understand as shown in line 5, line 7 and the output step. Time complexity of line 3, line 5 and line 7 are O(n + m), O(m), and O(n + m), respectively. The overall time complexity of this algorithm is N \u00d7(2O(n + m)+ O(m)). 4.4 TrAdaBoost with Bagging Transfer learning is not guaranteed to improve the performance of the model. Sometimes, it even lowers the performance, which is called negative transfer; this phenomenon also occurs with TrAdaBoost. For the weights update mechanism of TrAdaBoost, weights of training instances from the source domain may decrease exponentially by multiplying \u03b2 after several iterations, and they may be too small to be effective. However, TrAdaBoost cannot ensure such instances are noisy, and the performance of the model may be negatively impacted because many training instances are discarded. To prevent the over-discarded risk of TrAdaBoost, a \u201csofter\u201d weights update mechanism is presented in this paper. Bootstrap aggregating (Bagging) [41] is a method that generates K base learners and aggregates them to a final learner to improve the final results. Suppose the size of the training data set is n. The K base learners are trained on K subsets of size \u03c1n(0< \u03c1 <1) by sampling with replacement from the original training data set, as shown in Fig. 5 . In this paper, we integrate Bagging with TrAdaBoost in order to decrease the possibility of negative transfer. TrAdaBoost serves as the base learner in Bagging. For the two domain\u2019s training data set in TrAdaBoost, we handle the source domain only because only weights of instances in this domain are decreased. As shown in Fig. 6 , K TrAdaBoost learners are generated on K subsets of training data from source domain along with the entire target training data. The final result is then voted by the K learners. Through this algorithm, the wrongly discarded instances in the source domain by a single TrAdaBoost learner have the opportunity to be averaged to different subsets; therefore, the risk of abandoning them will be reduced. Consequently, negative transfer could be avoided to some extent. 4.5 The overall system With the method described above, we constructed a clinical concept extraction system with transfer ability. A flow diagram of the overall system is shown in Fig. 7 . In contrast to traditional methods that have a single training data set, this system has clinical training data from both institution A and institution B. TrAdaBoost with Bagging is applied to transfer knowledge from institution A to institution B. The base learner of TrAdaBoost is MEM. For MEM, we employ \u201cA Maximum Entropy Modeling Toolkit for Python and C++\u201d package [42]. The parameters of MEM are set to be default. The major contribution of our work is to provide a framework with transfer ability. Feature engineering is not the key component we focus on. A fundamental set of features for MEM is listed in Table 2 . Among the features listed in Table 2, we provide further details for the following features: Word shape features: Tokens with similar word shape may be labeled as the same concepts. We convert uppercase letters and lowercase letters to \u201cA\u201d and \u201ca\u201d, respectively, and digital letters are converted to \u201c0\u201d. POS features: The POS of a token is always helpful; we use GENIA [43], which is trained on biological literature to do POS tagging. Sentence features: This feature includes whether a sentence ends with a colon and whether a sentence is in the past or the future tense. Section features: Tokens with all uppercase letters and ending with a colon are headings; tokens with mixed-case letters and ending with a colon are subsection headings. Headings are divided into eight classes in our work, namely, medication, diagnosis, illness, complication, review, allergy, regimen and procedure. 5 Experiments 5.1 Data sets Our experiments involve two data sets: one from the 2010 i2b2/VA challenge\u2019s data, and the other from the biomedical literature. The i2b2\u2019s data consist of four sets: three are discharge summaries from Beth Israel Deaconess Medical Center, Partners HealthCare, and the University of Pittsburgh Medical Center, which are called BETH, PARTNERS and UPMCD in this paper, respectively; and the last is progress notes from the University of Pittsburgh Medical Center, which is called UPMCP in this paper. UPMCD and UPMCP were not available by the end of the challenge; as a result, BETH and PARTNERS are used in our experiments. The two data sets come from two institutions, with different writing styles and vocabularies, and thus are under different distributions. To make the experimental results more convincing, we introduced an even more diverse data set in the biomedical domain, which was originally used for semantic relations classification, obtained from MEDLINE 2001 (we call it BIOLITERATURE) [44]. The data set consists of the first 100 titles and the first 40 abstracts from the 59 files named medline01n\u2217.xml in MEDLINE 2001 labeled by experts. We convert the labels in BIOLITERATURE to \u201ctreatment\u201d and \u201cproblem\u201d, which are consistent with the labels in the i2b2\u2019s data (there are no correspondent \u201ctest\u201d labels in BIOLITERATURE). We then combine the BETH data and the re-labeled BIOLITERATURE data into the third data set BETHBIO, which is more diverse than BETH and PARTNERS because of the importing of data from biomedical literature. These three data sets are illustrated in Table 3 . For our transfer learning experiments, we take BETH and BETHBIO as source domain training data sets. Additionally, we split PARTNERS into two parts: the larger part, consisting of 80% of the data, serves as target domain training data set, and the smaller part, consisting of 20% of the data, serves as target domain test data set. KL-divergence is introduced to quantify the diversity of data from different sets. Given two discrete distributions, their KL-divergence is defined as Eq. (1). (1) KL ( p ( x ) , q ( x ) ) = \u2211 x q ( x ) ln q ( x ) p ( x ) Table 4 shows the statistical information of the data sets in our transfer learning experiments. KL-divergences between different data sets are also presented in this table. For the same-distribution case, the KL-divergence is close to zero. In contrast, the KL-divergence between BETH and PARTNERS is 0.36. An even larger 0.79 KL-divergence between BETHBIO and PARTNERS demonstrates a larger diversity between the two data sets. Our framework aims to use a small amount of labeled corpus from target domain and a large amount of labeled corpus from source domain to build a more accurate concept extraction model. 5.2 Comparison methods Our method is compared with three baseline methods. The distinctions among these methods depends on their training data, while the test data in all methods are the same, that is, T test target . NoTr(S): Using training data from the source domain T train source alone to build a clinical concept extraction model. NoTr(T): Using a small amount of training data from the target domain T train target alone to build a clinical concept extraction model. NoTr(S\u222aT): Combining T train source with T train target to build a clinical concept extraction model without transfer learning. Our method: Similar to NoTr(S\u222aT), T train source and T train target are combined to build the training data, but we apply TrAdaBoost with Bagging to re-weight the instances in T train source in order to filter out \u201cbad\u201d instances while encouraging the \u201cgood\u201d ones. The description of the above methods is shown in Table 5 ; in each method, | T train target | \u226a | T train source | . We introduce a parameter \u201cr\u201d, which is the ratio between T train target and T train source , to observe how this value impacts the effect of transfer learning. Other parameters in our method are as follows: N =20, k =5, rho =0.8. Performances of these methods are evaluated using the three standard performance metrics: precision (P), recall (R), and F measure (F), as shown in Eqs. (2)\u2013(4). In the equations, TP stands for positives, FP stands for false positives, and FN stands for false negatives. (2) Precision ( P ) = TP / ( TP + FP ) (3) Recall ( R ) = TP / ( TP + FN ) (4) F = 2 \u00d7 P \u00d7 R / ( P + R ) To indicate the reliability of P, R and F, we introduce confidence interval (CI) for them. CI gives an estimated range of values, in which the true value of a population parameter p is likely to be included. For example, a usually used 95% CI means that there is a 95% probability that the calculated confidence interval encompasses the true value of the population parameter. Given the Central Limit Theorem for Bernouilli trials [45], then we can calculate the 95% confidence interval according to Eq. (5), in which p will be P, R or F, and n will be the size of the test data set. We use Eq. (5) because n is large enough to meet the Central Limit Theorem. Additionally, CI is symmetric when using Eq. (5). To decide whether two systems\u2019 performances are significantly different on a task, one just has to observe whether their confidence intervals overlap. (5) CI = \u00b1 1.96 p ( 1 - p ) / n 5.3 Results and analysis We design two groups of experiments to verify the effectiveness of our method. In the first group, we compare our method with the three baseline methods to demonstrate our method\u2019s transfer ability when the training data in the target domain is tiny; and in the second group, we reveal results of our method when the ratio between the training data in the target domain and the training data in the source domain changes by the means of parameter \u201cr\u201d. The results of the first group experiments are shown in Table 6 . Here, the ratio \u201cr\u201d between | T train target | and | T train source | is set to be 0.02 by randomly selecting part of the data from T train target . In table 6a, T train source and T train target are training data from BETH and the 80% PARTNERS, respectively, and T test target is test data from the 20% PARTNERS. NoTr(T) yields the worst results due to the insufficient training data. NoTr(S) performs better because of the much larger training data set; however, due to the different distributions between the source domain and the target domain, the result has the potential to be improved. NoTr(S\u222aT) imports some training data from the target domain, but the improvement is not obvious. Our method yields the best results, which demonstrates the effectiveness of its transfer ability. Table 6b presents the results of BETHBIO vs. PARTNERS. Similar results appear in Table 6b compared with Table 6a, whereas the improvement is more obvious because the difference between the two domains is much larger, which can be reflected by the KL-divergence in Table 4. On the one hand, the larger difference between them plays a negative role in the three baseline methods due to the noisy data in BETHBIO. On the other hand, the original intention of our method was to solve the different distribution problem between the source domain and the target domain, and this data set is more suitable for the verification of our method. As seen in the above two mentioned experiments, the CIs for our method do not overlap with the CIs for the baseline models in almost all cases, which suggests that the better performance of our method has statistical significance. The situation that CIs overlap appears three times in Table 6a, while just one time in Table 6b, which also suggests that our method is more effective in the second experiment, as discussed above. The results of the second group experiments are shown in Figs. 8 and 9 . Here, we can see how the ratio between | T train target | and | T train source | impacts the results of our method and the three baseline methods. In Fig. 8, when the ratio between the training data in PARTNERS and BETH increases from 0.02 to 0.5, the F-score of our method is always higher than NoTr(T) and NoTr(S). It exceeds NoTr(S\u222aT) when the ratio is less than 0.1 in either case. Additionally, CIs for the two methods do not overlap either. In such a situation, our method is effective. However, when the ratio is larger than 0.2, our method is a little worse than NoTr(S\u222aT) because the amount of data in T train target is more sufficient to train a satisfactory model. Therefore, there is no need to draw support from data in another domain. Training data with a different distribution may even be harmful to the model. Similar results appear in Fig. 9 for BETHBIO vs. PARTNERS. There are two differences compared with Fig. 8. First, the improvement is more obvious; second, our method outperforms the other baseline methods when the ratio is less than 0.4, which is a much larger value than the corresponding value in Fig. 8. The reason for these two differences is that BETHBIO has larger diversity that our method aims to reduce, and the latter data set is more suitable for revealing our method\u2019s effectiveness. In summary, we draw the following conclusions: first, one of the major advantages is that our method is appropriate for the situation in which we have sufficient clinical training data from the source institution but only a tiny amount of clinical training data from the target institution. It can be seen in Table 6 that our method improves the total F-score by 2.3% and 4.4% compared with the best results of the three baseline methods. It also suggests that our method has a good generalization ability that can perform accurately on new, unseen instances. Second, our method is more suitable to situations where the ratio between training data in target domain and training data in the source domain is small, which is depicted as in Figs. 8 and 9. In fact, when the ratio is large, there is no need to import training data from the other domain because the training data in the target domain are sufficient. Lastly, we believe the degree of diversity between the source domain and target domain, which can be measured by KL-divergence, will impact our method\u2019s transfer ability. From the results displayed above, we can see that the improvement of our method is more obvious in the data set BETHBIO vs. PARTNERS than BETH vs. PARTNERS. Intuitively, we hypothesize that our method will work more effectively when the two domains have a larger diversity. However, it is very likely to be beyond our method\u2019s ability when the diversity in the two domains is too large. Restricted by the data sets, we cannot discuss this problem in a quantified manner with more experiments on more data sets in this paper, but we believe it is necessary for further study. 6 Conclusion and future work This work presents a study using clinical documents from one institution to train a clinical concept extraction model for data from another institution. The two data sets from two institutions have different distributions, which violates traditional machine learning\u2019s basic assumption that training and test data must be under the same distribution. To address this problem, we applied TrAdaBoost, which is an instance-based transfer learning algorithm, to the clinical concept extraction task. Moreover, to prevent negative transfer, we combine Bagging with TrAdaBoost. Experiments show our framework is effective when using just a tiny amount of labeled training data from the target domain, and we can obtain a comparable clinical concept extraction system. Future work will be carried out for the following items: 1. to develop other transfer learning methods such as feature-based transfer learning; 2. to evaluate data from multiple source domains simultaneously to extend the work; and 3. to transfer knowledge from biomedical literature to clinical documents, which is more challenging compared with the current work. Acknowledgments Deidentified clinical records used in this research were provided by the i2b2 National Center for Biomedical Computing funded by U54LM008748 and were originally prepared for the Shared Tasks for Challenges in NLP for Clinical Data organized by Dr. Ozlem Uzuner, i2b2 and SUNY. We are also thankful for the reviewers\u2019 comments concerning our manuscript. These comments were valuable and very helpful for revising and improving our paper and have a profound guiding significance on our research. References [1] M.S. Simpson D. Demner-Fushman Biomedical text mining: a survey of recent progress C.C. Aggarwal C. Zhai Mining text data 2012 Springer US 465 517 [2] \u00d6. Uzuner B.R. South S. Shen S.L. DuVall 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text J Am Med Inform Assoc 18 5 2011 552 556 10.1136/amiajnl-2011-000203 [3] Dai W, Yang Q, Xue G-R, Yu Y. Boosting for transfer learning. In: Proceedings of the 24th international conference on machine learning. Corvalis, Oregon: ACM; 2007. p. 193\u2013200. [4] D. Demner-Fushman W.W. Chapman C.J. McDonald What can natural language processing do for clinical decision support? J Biomed Inform 42 5 2009 760 772 10.1016/j.jbi.2009.08.007 [5] Unified Medical Language System (UMLS). US National Library of Medicine, National Institutes of Health. <http://www.nlm.nih.gov/research/umls/>. [6] Stearns MQ, Price C, Spackman KA, Wang AY. SNOMED clinical terms: overview of the development process and project status. In: Proceedings of AMIA annual symposium. AIMA; 2001. [7] C. Friedman P.O. Alderson J.H.M. Austin J.J. Cimino S.B. Johnson A general natural-language text processor for clinical radiology J Am Med Inform Assoc 1 2 1994 161 174 10.1136/jamia.1994.95236146 [8] C. Friedman L. Shagina Y. Lussier G. Hripcsak Automated encoding of clinical documents based on natural language processing J Am Med Inform Assoc 11 5 2004 392 402 10.1197/jamia.M1552 [9] Aronson AR. Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. In: Proceedings of AMIA annual symposium; 2001. p. 17\u201321. [10] W.R. Hersh D. Hickam Information retrieval in medicine: the SAPHIRE experience J Am Soc Inf Sci 46 10 1995 743 747 10.1002/(SICI)1097-4571(199512)46:10<743::AID-ASI5>3.0.CO;2-C [11] X. Zhou X. Zhang X. Hu MaxMatcher: biological concept extraction using approximate dictionary lookup Q. Yang G. Webb PRICAI 2006: trends in artificial intelligence 2006 Springer Berlin, Heidelberg 1145 1149 [12] Zou Q, Chu WW, Morioka C, Leazer GH, Kangarloo H. IndexFinder: a method of extracting key concepts from clinical texts for indexing. In: Proceedings of AMIA annual symposium. AMIA; 2003. [13] Long W. Extracting diagnoses from discharge summaries. In: Proceedings of AMIA annual symposium. AMIA; 2005. [14] A. Turchin N.S. Kolatkar R.W. Grant E.C. Makhni M.L. Pendergrass J.S. Einbinder Using regular expressions to abstract blood pressure and treatment intensification information from the text of physician notes J Am Med Inform Assoc 13 6 2006 691 695 10.1197/jamia.M2078 [15] Bikel DM, Miller S, Schwartz R, Weischedel R. Nymble: a high-performance learning name-finder. In: Proceedings of the fifth conference on applied natural language processing. Washington, DC: Association for Computational Linguistics; 1997. p. 194\u2013201. [16] T. Joachims Making large-scale support vector machine learning practical. Advances in kernel methods 1999 MIT Press [17] McCallum A, Freitag D, Pereira F. Maximum entropy Markov models for information extraction and segmentation. In: Proceedings of the seventeenth international conference on machine learning; 2000. [18] J.D. Lafferty A. McCallum F.C.N. Pereira Conditional random fields: probabilistic models for segmenting and labeling sequence data Proceedings of the eighteenth international conference on machine learning 2001 Morgan Kaufmann Publishers Inc. 282 289 [19] Taira RK, Soderland SG. A statistical natural language processor for medical reports. In: Proceedings of AMIA annual symposium. AMIA; 1999. [20] Bashyam V, Taira RK. Indexing anatomical phrases in neuro-radiology reports to the UMLS. In: Proceedings of AMIA annual symposium. AMIA; 2005. [21] Sibanda T, He T, Szolovits P, Uzuner O. Syntactically-informed semantic category recognizer for discharge summaries. In: Proceedings of AMIA annual symposium. AMIA; 2006. [22] Wang Y, Patrick J. Cascading classifiers for named entity recognition in clinical notes. In: Proceedings of the workshop on biomedical information extraction. Borovets, Bulgaria: Association for Computational Linguistics; 2009. p. 42\u20139. [23] Li D, Kipper-Schuler K, Savova G. Conditional random fields and support vector machines for disorder named entity recognition in clinical texts. In: Proceedings of the workshop on current trends in biomedical natural language processing. Columbus, Ohio: Association for Computational Linguistics; 2008. p. 94\u20135. [24] B. De Bruijn C. Cherry S. Kiritchenko J. Martin X. Zhu Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010 J Am Med Inform Assoc 18 5 2011 557 562 10.1136/amiajnl-2011-000150 [25] K. Roberts S.M. Harabagiu A flexible framework for deriving assertions from electronic medical records J Am Med Inform Assoc 18 5 2011 568 573 10.1136/amiajnl-2011-000152 [26] Y. Xu K. Hong J. Tsujii E.I.-C. Chang Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries J Am Med Inform Assoc 19 5 2012 824 832 10.1136/amiajnl-2011-000776 [27] Y. Chen S. Mani H. Xu Applying active learning to assertion classification of concepts in clinical text J Biomed Inform 45 2 2012 265 272 10.1016/j.jbi.2011.11.003 [28] Abacha AB, Zweigenbaum P. Medical entity recognition: a comparison of semantic and statistical methods. In: Proceedings of BioNLP 2011 workshop. Portland, Oregon: Association for Computational Linguistics; 2011. p. 56\u201364. [29] S. Zhang N. Elhadad Unsupervised biomedical named entity recognition: experiments with clinical and biological texts J Biomed Inform 46 6 2013 1088 1098 10.1016/j.jbi.2013.08.004 [30] M. Torii K. Wagholikar H. Liu Using machine learning for concept extraction on clinical documents from multiple data sources J Am Med Inform Assoc 18 5 2011 580 587 10.1136/amiajnl-2011-000155 [31] P. Sinno Jialin Y. Qiang A survey on transfer learning IEEE Trans Knowledge Data Eng 22 10 2010 1345 1359 10.1109/TKDE.2009.191 [32] Schmidhuber J. On learning how to learn learning strategies; 1995. [33] Thrun S. Is learning the nth thing any easier than learning the first? Advances in neural information processing systems; 1996. p. 640\u20136. [34] R. Caruana Multitask learning Mach Learn 28 1 1997 41 75 10.1023/a:1007379606734 [35] Blitzer J, Dredze M, Pereira F. Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification. Annual meeting-association for computational linguistics; 2007. [36] Wu P, Dietterich TG. Improving SVM accuracy by training on auxiliary data sources. In: Proceedings of the twenty-first international conference on machine learning. Banff, Alberta, Canada: ACM; 2004. p. 110. [37] P. Ganchev D. Malehorn W.L. Bigbee V. Gopalakrishnan Transfer learning of classification rules for biomarker discovery and verification from molecular profiling studies J Biomed Inform 44 2011 S17 S23 10.1016/j.jbi.2011.04.009 [38] G. Lee L. Stoolman C. Scott Transfer learning for auto-gating of flow cytometry data J Mach Learn Res \u2013 Proc Track 27 2012 155 166 [39] Arnold A, Nallapati R, Cohen WW. A comparative study of methods for transductive transfer learning. In: Seventh IEEE international conference on data mining workshops. ICDM workshops 2007, 28\u201331 October 2007. [40] Y. Freund R.E. Schapire A decision-theoretic generalization of on-line learning and an application to boosting J Comput Syst Sci 55 1 1997 119 139 10.1006/jcss.1997.1504 [41] L. Breiman Bagging predictors Mach Learn 24 2 1996 123 140 10.1023/A:1018054314350 [42] Zhang L. A maximum entropy modeling toolkit for python and C++. <https://github.com/lzhang10/maxent>. [43] Y. Tsuruoka Y. Tateishi J.-D. Kim Developing a robust part-of-speech tagger for biomedical text P. Bozanis E. Houstis Advances in informatics 2005 Springer Berlin, Heidelberg 382 392 [44] Rosario B, Hearst MA. Classifying semantic relations in bioscience texts. In: Proceedings of the 42nd annual meeting on association for computational linguistics. Barcelona, Spain: Association for Computational Linguistics; 2004. p. 430. [45] Grinstead CM, Snell JL. Introduction to probability. 2nd ed. Providence (RI): American Mathematical Society.", "scopus-id": "84919846083", "pubmed-id": "24859154", "coredata": {"eid": "1-s2.0-S1532046414001233", "dc:description": "Abstract Machine learning methods usually assume that training data and test data are drawn from the same distribution. However, this assumption often cannot be satisfied in the task of clinical concept extraction. The main aim of this paper was to use training data from one institution to build a concept extraction model for data from another institution with a different distribution. An instance-based transfer learning method, TrAdaBoost, was applied in this work. To prevent the occurrence of a negative transfer phenomenon with TrAdaBoost, we integrated it with Bagging, which provides a \u201csofter\u201d weights update mechanism with only a tiny amount of training data from the target domain. Two data sets named BETH and PARTNERS from the 2010 i2b2/VA challenge as well as BETHBIO, a data set we constructed ourselves, were employed to show the effectiveness of our work\u2019s transfer ability. Our method outperforms the baseline model by 2.3% and 4.4% when the baseline model is trained by training data that are combined from the source domain and the target domain in two experiments of BETH vs. PARTNERS and BETHBIO vs. PARTNERS, respectively. Additionally, confidence intervals for the performance metrics suggest that our method\u2019s results have statistical significance. Moreover, we explore the applicability of our method for further experiments. With our method, only a tiny amount of labeled data from the target domain is required to build a concept extraction model that produces better performance.", "openArchiveArticle": "true", "prism:coverDate": "2014-12-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046414001233", "dc:creator": [{"@_fa": "true", "$": "Lv, Xinbo"}, {"@_fa": "true", "$": "Guan, Yi"}, {"@_fa": "true", "$": "Deng, Benyang"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046414001233"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046414001233"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(14)00123-3", "prism:volume": "52", "prism:publisher": "Elsevier Inc.", "dc:title": "Transfer learning based clinical concept extraction on data from multiple sources", "prism:copyright": "Copyright \u00a9 2014 Elsevier Inc. All rights reserved.", "prism:issueName": "Special Section: Methods in Clinical Research Informatics", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Clinical concept extraction"}, {"@_fa": "true", "$": "Transfer learning"}, {"@_fa": "true", "$": "TrAdaBoost"}, {"@_fa": "true", "$": "Bagging"}, {"@_fa": "true", "$": "Machine learning"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "55-64", "prism:endingPage": "64", "prism:coverDisplayDate": "December 2014", "prism:doi": "10.1016/j.jbi.2014.05.006", "prism:startingPage": "55", "dc:identifier": "doi:10.1016/j.jbi.2014.05.006", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "22", "@width": "184", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si42.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "932", "@ref": "si42", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "165", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si41.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "727", "@ref": "si41", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "199", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si40.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "953", "@ref": "si40", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si39.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "991", "@ref": "si39", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "42", "@width": "231", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si27.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1535", "@ref": "si27", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "48", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si67.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "424", "@ref": "si67", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "46", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si66.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "433", "@ref": "si66", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si65.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si65", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "98", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si64.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "647", "@ref": "si64", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si63.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si63", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "98", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si62.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "647", "@ref": "si62", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si61.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si61", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si60.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si60", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si59.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si59", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si58.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si58", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "52", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si57.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "446", "@ref": "si57", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "52", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si56.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "473", "@ref": "si56", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "54", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si55.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "465", "@ref": "si55", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si54.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si54", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si53.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si53", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si52.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si52", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si51.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si51", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "48", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si50.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "424", "@ref": "si50", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "98", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "733", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "46", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si49.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "433", "@ref": "si49", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si48.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si48", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si47.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si47", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si46.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si46", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si45.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si45", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "48", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si44.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "424", "@ref": "si44", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "46", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si43.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "433", "@ref": "si43", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "102", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "733", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si38.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si38", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si37.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si37", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "120", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si36.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "751", "@ref": "si36", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si35.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si35", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si34.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si34", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si33.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si33", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si32.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si32", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si31.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si31", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si30.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si30", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "42", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "397", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si29.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si29", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si28.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si28", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "98", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si26.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "647", "@ref": "si26", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si25.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si25", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si24.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si24", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "24", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si23.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "261", "@ref": "si23", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si22.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si22", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "387", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "98", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "647", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "111", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "503", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "80", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "411", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "109", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "542", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "149", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "623", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "131", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "857", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "401", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "393", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "276", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1154", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "1074", "@width": "2365", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "209050", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "822", "@width": "2213", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "380675", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1200", "@width": "1602", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr9_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "180535", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1204", "@width": "1604", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr8_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "183216", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "994", "@width": "2676", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr7_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "600602", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "881", "@width": "1281", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr6_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "232003", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1554", "@width": "2068", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "244934", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1474", "@width": "1379", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "393602", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "926", "@width": "1436", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "214404", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1624", "@width": "1521", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "287027", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "243", "@width": "534", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25987", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "186", "@width": "500", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "39800", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "271", "@width": "362", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "22312", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "272", "@width": "362", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "22242", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "224", "@width": "604", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "47354", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "199", "@width": "289", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25583", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "351", "@width": "467", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "29669", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "332", "@width": "311", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "45004", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "209", "@width": "324", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "20540", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "366", "@width": "343", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "30972", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "99", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4588", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "81", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7453", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5543", "@ref": "gr9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "218", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5558", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "81", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7709", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "151", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8323", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "218", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7981", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "153", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7307", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "141", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10423", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "153", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414001233-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6037", "@ref": "gr2", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84919846083"}}
{"scopus-eid": "2-s2.0-46649112949", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2008-01-11 2008-01-11 2010-10-07T15:33:45 1-s2.0-S1532046408000087 S1532-0464(08)00008-7 S1532046408000087 10.1016/j.jbi.2008.01.001 S300 S300.1 FULL-TEXT 1-s2.0-S1532046408X0005X 2015-05-15T06:30:58.184067-04:00 0 0 20080801 20080831 2008 2008-01-11T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes primabst ref alllist content oa subj ssids 1532-0464 15320464 41 41 4 4 Volume 41, Issue 4 15 636 654 636 654 200808 August 2008 2008-08-01 2008-08-31 2008 article fla Copyright \u00a9 2008 Elsevier Inc. All rights reserved. EXPLORINGHEDGEIDENTIFICATIONINBIOMEDICALLITERATURE MEDLOCK B 1 Introduction 2 The task 3 Related work 3.1 Hedge identification 3.2 Semi-supervised learning 4 Motivation 5 Acquisition 5.1 Probabilistic acquisition model 5.1.1 Interpretation 1: marginalised sample prior (MSP) 5.1.2 Interpretation 2: pointwise mutual information (PMI) 5.2 Acquisition for hedge identification 5.3 Comparison\u2014SVM Committee acquisition model 6 Classification 7 Sample representation 7.1 Part-of-speech tagging 7.2 Stemming 7.3 Bigrams 8 Experimental setup 8.1 Data 8.2 Annotation and agreement 8.3 Methodology 8.4 Parameter setting 8.5 Seed generation 9 Experimental results 9.1 Comparison with traditional feature selection 9.2 Seed refinement 9.3 Exploring nspec acquisition 9.4 Enriched sample representations 9.4.1 PoS tagging 9.4.2 Stemming 9.4.3 Bigrams 10 Error analysis 11 Conclusions and future work Acknowledgments References BLUM 1998 92 100 A COLT98PROCEEDINGSELEVENTHANNUALCONFERENCECOMPUTATIONALLEARNINGTHEORY COMBININGLABELEDUNLABELEDDATACOTRAINING FANO 1961 R TRANSMISSIONINFORMATION GOLDMAN 2000 327 334 S PROCEEDINGS17THINTERNATIONALCONFERENCEMACHINELEARNING ENHANCINGSUPERVISEDLEARNINGUNLABELEDDATA HRIPCSAK 2004 296 298 G HYLAND 1994 239 256 K HYLAND 1996 251 281 K JOACHIMS 1999 T ADVANCESINKERNELMETHODSSUPPORTVECTORMACHINES MAKINGLARGESCALESUPPORTVECTORMACHINELEARNINGPRACTICAL LEWIS 2004 361 397 D MUSLEA 2002 435 442 I ICML02PROCEEDINGSNINETEENTHINTERNATIONALCONFERENCEMACHINELEARNING ACTIVESEMISUPERVISEDLEARNINGROBUSTMULTIVIEWLEARNING NIGAM 2000 103 134 K PENG 2004 317 345 F KARLMICHAEL 2005 682 693 TAN 2002 529 546 C ZHANG 2004 581 588 Z CIKM04PROCEEDINGSTHIRTEENTHACMINTERNATIONALCONFERENCEINFORMATIONKNOWLEDGEMANAGEMENT WEAKLYSUPERVISEDRELATIONCLASSIFICATIONFORINFORMATIONEXTRACTION MEDLOCKX2008X636 MEDLOCKX2008X636X654 MEDLOCKX2008X636XB MEDLOCKX2008X636X654XB Full 2014-11-20T07:55:50Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(08)00008-7 S1532046408000087 1-s2.0-S1532046408000087 10.1016/j.jbi.2008.01.001 272371 2010-11-08T20:53:19.238951-05:00 2008-08-01 2008-08-31 1-s2.0-S1532046408000087-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/MAIN/application/pdf/bd8811461d2d8f45eb5a4f902c0a972d/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/MAIN/application/pdf/bd8811461d2d8f45eb5a4f902c0a972d/main.pdf main.pdf pdf true 712836 MAIN 19 1-s2.0-S1532046408000087-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/PREVIEW/image/png/12d79c9e4341496f344af89d8c0e264b/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/PREVIEW/image/png/12d79c9e4341496f344af89d8c0e264b/main_1.png main_1.png png 62550 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046408000087-si99.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bb25826b1080f4ca5bac1ccb549756ad/si99.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bb25826b1080f4ca5bac1ccb549756ad/si99.gif si99 si99.gif gif 696 13 39 ALTIMG 1-s2.0-S1532046408000087-si98.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1d1e09eb39c2c6534c98bc5fc14e58ab/si98.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1d1e09eb39c2c6534c98bc5fc14e58ab/si98.gif si98 si98.gif gif 450 9 10 ALTIMG 1-s2.0-S1532046408000087-si97.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1d1e09eb39c2c6534c98bc5fc14e58ab/si98.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1d1e09eb39c2c6534c98bc5fc14e58ab/si98.gif si97 si97.gif gif 450 9 10 ALTIMG 1-s2.0-S1532046408000087-si96.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/fd624deefe343cc2078f1d9aa6fb6ed2/si96.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/fd624deefe343cc2078f1d9aa6fb6ed2/si96.gif si96 si96.gif gif 1332 17 83 ALTIMG 1-s2.0-S1532046408000087-si95.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/b94f2bfb38136c2e024f5ef368ea798b/si95.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/b94f2bfb38136c2e024f5ef368ea798b/si95.gif si95 si95.gif gif 807 17 40 ALTIMG 1-s2.0-S1532046408000087-si94.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/fc0d8ef87b46d5abd8bd10724f0a5981/si94.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/fc0d8ef87b46d5abd8bd10724f0a5981/si94.gif si94 si94.gif gif 750 18 34 ALTIMG 1-s2.0-S1532046408000087-si93.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/dfd6f4f3839ed98e77378474d6e9dd98/si93.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/dfd6f4f3839ed98e77378474d6e9dd98/si93.gif si93 si93.gif gif 2766 18 207 ALTIMG 1-s2.0-S1532046408000087-si92.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/175ac83da964c071c6ee1222141d9bb7/si92.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/175ac83da964c071c6ee1222141d9bb7/si92.gif si92 si92.gif gif 2706 18 204 ALTIMG 1-s2.0-S1532046408000087-si91.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1d6c3af1b97432180cba7d868a39e1dc/si91.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1d6c3af1b97432180cba7d868a39e1dc/si91.gif si91 si91.gif gif 1800 18 94 ALTIMG 1-s2.0-S1532046408000087-si90.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/a5bf1c1d451e960ab5589527272d736e/si90.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/a5bf1c1d451e960ab5589527272d736e/si90.gif si90 si90.gif gif 1443 18 71 ALTIMG 1-s2.0-S1532046408000087-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/0e6947290b9b498d66d01eb59ba427cd/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/0e6947290b9b498d66d01eb59ba427cd/si9.gif si9 si9.gif gif 957 13 55 ALTIMG 1-s2.0-S1532046408000087-si89.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif si89 si89.gif gif 218 13 14 ALTIMG 1-s2.0-S1532046408000087-si88.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/5210ab29e2fb7bcf852b0607c97ec911/si88.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/5210ab29e2fb7bcf852b0607c97ec911/si88.gif si88 si88.gif gif 488 17 102 ALTIMG 1-s2.0-S1532046408000087-si87.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1b41e4e8dbaf533ed37d75c20740fd5d/si87.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1b41e4e8dbaf533ed37d75c20740fd5d/si87.gif si87 si87.gif gif 444 18 91 ALTIMG 1-s2.0-S1532046408000087-si86.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif si86 si86.gif gif 218 13 14 ALTIMG 1-s2.0-S1532046408000087-si85.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif si85 si85.gif gif 318 17 38 ALTIMG 1-s2.0-S1532046408000087-si84.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif si84 si84.gif gif 318 17 38 ALTIMG 1-s2.0-S1532046408000087-si83.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2e892e2c98755ad23d14bcbcad1ef49f/si111.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2e892e2c98755ad23d14bcbcad1ef49f/si111.gif si83 si83.gif gif 295 17 32 ALTIMG 1-s2.0-S1532046408000087-si82.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif si82 si82.gif gif 180 9 10 ALTIMG 1-s2.0-S1532046408000087-si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif si81 si81.gif gif 273 19 27 ALTIMG 1-s2.0-S1532046408000087-si80.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif si80 si80.gif gif 180 9 10 ALTIMG 1-s2.0-S1532046408000087-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/f25f8c0f9fc2e695e13e492d8751719c/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/f25f8c0f9fc2e695e13e492d8751719c/si12.gif si8 si8.gif gif 337 13 55 ALTIMG 1-s2.0-S1532046408000087-si79.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif si79 si79.gif gif 273 19 27 ALTIMG 1-s2.0-S1532046408000087-si78.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif si78 si78.gif gif 273 19 27 ALTIMG 1-s2.0-S1532046408000087-si77.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif si77 si77.gif gif 180 9 10 ALTIMG 1-s2.0-S1532046408000087-si76.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif si76 si76.gif gif 180 9 10 ALTIMG 1-s2.0-S1532046408000087-si75.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2b3a37e74aafa73818aad61b6b7c9813/si75.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2b3a37e74aafa73818aad61b6b7c9813/si75.gif si75 si75.gif gif 409 19 57 ALTIMG 1-s2.0-S1532046408000087-si74.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2dd30dff972b2baa437cac3c2fcdb28d/si74.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2dd30dff972b2baa437cac3c2fcdb28d/si74.gif si74 si74.gif gif 618 18 109 ALTIMG 1-s2.0-S1532046408000087-si73.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/6311be8c37c0be3a3e8fc736a35cf9a2/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/6311be8c37c0be3a3e8fc736a35cf9a2/si73.gif si73 si73.gif gif 2892 18 225 ALTIMG 1-s2.0-S1532046408000087-si72.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/be57208fd11a6189b0b61ba3df629178/si72.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/be57208fd11a6189b0b61ba3df629178/si72.gif si72 si72.gif gif 183 9 11 ALTIMG 1-s2.0-S1532046408000087-si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/ab3e339929578ba6d5845ec3516ae78e/si71.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/ab3e339929578ba6d5845ec3516ae78e/si71.gif si71 si71.gif gif 2565 18 200 ALTIMG 1-s2.0-S1532046408000087-si70.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/62411ad371699463f0696a68142610ad/si70.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/62411ad371699463f0696a68142610ad/si70.gif si70 si70.gif gif 3879 39 206 ALTIMG 1-s2.0-S1532046408000087-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif si7 si7.gif gif 257 13 39 ALTIMG 1-s2.0-S1532046408000087-si69.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/f2141331d9b977720d02819ae14dd9f0/si69.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/f2141331d9b977720d02819ae14dd9f0/si69.gif si69 si69.gif gif 6567 39 366 ALTIMG 1-s2.0-S1532046408000087-si68.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/5d5084afce57e799bdfcaea360637df0/si68.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/5d5084afce57e799bdfcaea360637df0/si68.gif si68 si68.gif gif 565 19 79 ALTIMG 1-s2.0-S1532046408000087-si67.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/d260e90a9587b93ec4deeed71fb53fd6/si67.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/d260e90a9587b93ec4deeed71fb53fd6/si67.gif si67 si67.gif gif 516 18 71 ALTIMG 1-s2.0-S1532046408000087-si66.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/f7e5e5f2773af04ad0b32f5ea0e29648/si66.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/f7e5e5f2773af04ad0b32f5ea0e29648/si66.gif si66 si66.gif gif 199 12 15 ALTIMG 1-s2.0-S1532046408000087-si65.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/a8dbd376ece62f0ded63e588a9ed4de3/si65.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/a8dbd376ece62f0ded63e588a9ed4de3/si65.gif si65 si65.gif gif 2544 39 142 ALTIMG 1-s2.0-S1532046408000087-si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/63078a3b7a4a693988783aa56c8bc988/si64.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/63078a3b7a4a693988783aa56c8bc988/si64.gif si64 si64.gif gif 411 17 53 ALTIMG 1-s2.0-S1532046408000087-si63.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/a135f332f80890bd08f20c14fa1db25a/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/a135f332f80890bd08f20c14fa1db25a/si63.gif si63 si63.gif gif 16617 212 351 ALTIMG 1-s2.0-S1532046408000087-si62.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/ffc7744e7128592ecee567d99a99e5c3/si62.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/ffc7744e7128592ecee567d99a99e5c3/si62.gif si62 si62.gif gif 8793 75 340 ALTIMG 1-s2.0-S1532046408000087-si61.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/afadf2fbadb19d54691667185ee36540/si61.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/afadf2fbadb19d54691667185ee36540/si61.gif si61 si61.gif gif 328 17 36 ALTIMG 1-s2.0-S1532046408000087-si60.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif si60 si60.gif gif 185 9 10 ALTIMG 1-s2.0-S1532046408000087-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/ae451c21e0a02101cfd20bd6a49a81c7/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/ae451c21e0a02101cfd20bd6a49a81c7/si6.gif si6 si6.gif gif 236 13 37 ALTIMG 1-s2.0-S1532046408000087-si59.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif si59 si59.gif gif 209 13 13 ALTIMG 1-s2.0-S1532046408000087-si58.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/0c3b73ca5292317f541d21644956a1aa/si58.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/0c3b73ca5292317f541d21644956a1aa/si58.gif si58 si58.gif gif 383 17 49 ALTIMG 1-s2.0-S1532046408000087-si57.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/20ab98be1ac93cb45c77b13531dabc57/si57.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/20ab98be1ac93cb45c77b13531dabc57/si57.gif si57 si57.gif gif 3747 39 196 ALTIMG 1-s2.0-S1532046408000087-si56.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/d88a551ffa716beae0e8a6a914e6b68e/si56.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/d88a551ffa716beae0e8a6a914e6b68e/si56.gif si56 si56.gif gif 2481 33 153 ALTIMG 1-s2.0-S1532046408000087-si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif si55 si55.gif gif 209 13 13 ALTIMG 1-s2.0-S1532046408000087-si54.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/b1b5cfe3572c8a70d20e7d8b341f3bb4/si54.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/b1b5cfe3572c8a70d20e7d8b341f3bb4/si54.gif si54 si54.gif gif 238 17 18 ALTIMG 1-s2.0-S1532046408000087-si53.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/561738b146e1a6c279e65e2a0e120791/si53.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/561738b146e1a6c279e65e2a0e120791/si53.gif si53 si53.gif gif 2088 40 109 ALTIMG 1-s2.0-S1532046408000087-si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1b7ddf54844d38359de275f97d9f70de/si52.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1b7ddf54844d38359de275f97d9f70de/si52.gif si52 si52.gif gif 5019 50 199 ALTIMG 1-s2.0-S1532046408000087-si51.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/7c2e0e21d18015359ee3449959619c5b/si51.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/7c2e0e21d18015359ee3449959619c5b/si51.gif si51 si51.gif gif 342 19 38 ALTIMG 1-s2.0-S1532046408000087-si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/c9f9a9dffe3fce7aa139fdb690d96b80/si50.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/c9f9a9dffe3fce7aa139fdb690d96b80/si50.gif si50 si50.gif gif 5370 41 305 ALTIMG 1-s2.0-S1532046408000087-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/9f55368ad207e81a7e156c2271dc2a86/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/9f55368ad207e81a7e156c2271dc2a86/si5.gif si5 si5.gif gif 267 13 39 ALTIMG 1-s2.0-S1532046408000087-si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/c55e32f3e6a91cc4b4a02ca0d0397bf7/si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/c55e32f3e6a91cc4b4a02ca0d0397bf7/si49.gif si49 si49.gif gif 3990 26 299 ALTIMG 1-s2.0-S1532046408000087-si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/c74c42bca90006f00775d1b5dfd237b4/si48.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/c74c42bca90006f00775d1b5dfd237b4/si48.gif si48 si48.gif gif 223 14 15 ALTIMG 1-s2.0-S1532046408000087-si47.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/aefe3092f9f3a06e3cc3f07a41bd77ab/si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/aefe3092f9f3a06e3cc3f07a41bd77ab/si47.gif si47 si47.gif gif 215 14 18 ALTIMG 1-s2.0-S1532046408000087-si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/7d26f644c92b12a637b5777f8d7d0e7b/si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/7d26f644c92b12a637b5777f8d7d0e7b/si46.gif si46 si46.gif gif 666 17 138 ALTIMG 1-s2.0-S1532046408000087-si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/23c887dc596c99ccf6bd85628c5ced87/si45.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/23c887dc596c99ccf6bd85628c5ced87/si45.gif si45 si45.gif gif 628 17 128 ALTIMG 1-s2.0-S1532046408000087-si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/23c887dc596c99ccf6bd85628c5ced87/si45.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/23c887dc596c99ccf6bd85628c5ced87/si45.gif si44 si44.gif gif 628 17 128 ALTIMG 1-s2.0-S1532046408000087-si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/39a1af6e05317f28581d2d0cd366c8ef/si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/39a1af6e05317f28581d2d0cd366c8ef/si43.gif si43 si43.gif gif 203 12 13 ALTIMG 1-s2.0-S1532046408000087-si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/aefe3092f9f3a06e3cc3f07a41bd77ab/si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/aefe3092f9f3a06e3cc3f07a41bd77ab/si47.gif si42 si42.gif gif 215 14 18 ALTIMG 1-s2.0-S1532046408000087-si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/27f1c51ed97dba32888a416448436252/si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/27f1c51ed97dba32888a416448436252/si41.gif si41 si41.gif gif 481 17 107 ALTIMG 1-s2.0-S1532046408000087-si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/0e37080a936e3b0d3d635626c5199c5f/si40.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/0e37080a936e3b0d3d635626c5199c5f/si40.gif si40 si40.gif gif 638 17 126 ALTIMG 1-s2.0-S1532046408000087-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif si4 si4.gif gif 185 9 10 ALTIMG 1-s2.0-S1532046408000087-si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2fe0c0233d88c6e51ffcfe3cd3538e17/si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2fe0c0233d88c6e51ffcfe3cd3538e17/si39.gif si39 si39.gif gif 328 15 51 ALTIMG 1-s2.0-S1532046408000087-si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/e027395fe2c103f3b34d1228b4159f60/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/e027395fe2c103f3b34d1228b4159f60/si38.gif si38 si38.gif gif 342 16 62 ALTIMG 1-s2.0-S1532046408000087-si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/d65c1a32a663b56e3dcae430395fb729/si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/d65c1a32a663b56e3dcae430395fb729/si37.gif si37 si37.gif gif 382 15 75 ALTIMG 1-s2.0-S1532046408000087-si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/688027d9189cac169bd24b001dcbc0f6/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/688027d9189cac169bd24b001dcbc0f6/si36.gif si36 si36.gif gif 473 17 105 ALTIMG 1-s2.0-S1532046408000087-si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1fed4806929cca3b01101f239cd748d6/si35.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1fed4806929cca3b01101f239cd748d6/si35.gif si35 si35.gif gif 204 12 14 ALTIMG 1-s2.0-S1532046408000087-si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/e994ba7e25cfa9396b30bc7b638604c4/si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/e994ba7e25cfa9396b30bc7b638604c4/si34.gif si34 si34.gif gif 1487 17 315 ALTIMG 1-s2.0-S1532046408000087-si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/3dcdba0dcfe9b0207f328c8985f9e8ca/si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/3dcdba0dcfe9b0207f328c8985f9e8ca/si33.gif si33 si33.gif gif 693 17 120 ALTIMG 1-s2.0-S1532046408000087-si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/4efec1ee97266aa13d50e5661691ff76/si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/4efec1ee97266aa13d50e5661691ff76/si32.gif si32 si32.gif gif 964 17 173 ALTIMG 1-s2.0-S1532046408000087-si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/ed16885b2346ad4a11ad69424235b665/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/ed16885b2346ad4a11ad69424235b665/si31.gif si31 si31.gif gif 1037 17 210 ALTIMG 1-s2.0-S1532046408000087-si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/9394d7495ea4329b7e80c6ae2776f34e/si30.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/9394d7495ea4329b7e80c6ae2776f34e/si30.gif si30 si30.gif gif 1079 17 195 ALTIMG 1-s2.0-S1532046408000087-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif si3 si3.gif gif 506 17 70 ALTIMG 1-s2.0-S1532046408000087-si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/fe80db68383b0e3d9f953969b4ec3105/si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/fe80db68383b0e3d9f953969b4ec3105/si29.gif si29 si29.gif gif 476 16 76 ALTIMG 1-s2.0-S1532046408000087-si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/df78e486ab2db1aff1e09c89210d62bc/si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/df78e486ab2db1aff1e09c89210d62bc/si28.gif si28 si28.gif gif 505 16 87 ALTIMG 1-s2.0-S1532046408000087-si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/aec1ca1c334623bc21f0db7e59a5e8dc/si27.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/aec1ca1c334623bc21f0db7e59a5e8dc/si27.gif si27 si27.gif gif 261 15 41 ALTIMG 1-s2.0-S1532046408000087-si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/91a0f1a8b06d0e75a4c52259e240b71c/si26.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/91a0f1a8b06d0e75a4c52259e240b71c/si26.gif si26 si26.gif gif 224 16 17 ALTIMG 1-s2.0-S1532046408000087-si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/3dd118f25788106716744d3bdafab6b2/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/3dd118f25788106716744d3bdafab6b2/si25.gif si25 si25.gif gif 211 16 16 ALTIMG 1-s2.0-S1532046408000087-si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/4faa58b0ff252d5e191a73da7c3f4780/si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/4faa58b0ff252d5e191a73da7c3f4780/si24.gif si24 si24.gif gif 619 17 139 ALTIMG 1-s2.0-S1532046408000087-si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/84ddf6b8e66f417b5370c3488530999c/si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/84ddf6b8e66f417b5370c3488530999c/si23.gif si23 si23.gif gif 625 17 121 ALTIMG 1-s2.0-S1532046408000087-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/aec1ca1c334623bc21f0db7e59a5e8dc/si27.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/aec1ca1c334623bc21f0db7e59a5e8dc/si27.gif si22 si22.gif gif 261 15 41 ALTIMG 1-s2.0-S1532046408000087-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/91a0f1a8b06d0e75a4c52259e240b71c/si26.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/91a0f1a8b06d0e75a4c52259e240b71c/si26.gif si21 si21.gif gif 224 16 17 ALTIMG 1-s2.0-S1532046408000087-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/82bc78bdc48529aa9bfc4846ea3f7005/si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/82bc78bdc48529aa9bfc4846ea3f7005/si20.gif si20 si20.gif gif 787 17 203 ALTIMG 1-s2.0-S1532046408000087-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2a55af5eb8772b081ede9e19c2b4894c/si2.gif si2 si2.gif gif 180 9 10 ALTIMG 1-s2.0-S1532046408000087-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/59e4287532634ea23a9052e8ddebf2e6/si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/59e4287532634ea23a9052e8ddebf2e6/si19.gif si19 si19.gif gif 563 17 119 ALTIMG 1-s2.0-S1532046408000087-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/3dd118f25788106716744d3bdafab6b2/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/3dd118f25788106716744d3bdafab6b2/si25.gif si18 si18.gif gif 211 16 16 ALTIMG 1-s2.0-S1532046408000087-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/3dd118f25788106716744d3bdafab6b2/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/3dd118f25788106716744d3bdafab6b2/si25.gif si17 si17.gif gif 211 16 16 ALTIMG 1-s2.0-S1532046408000087-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif si16 si16.gif gif 209 13 13 ALTIMG 1-s2.0-S1532046408000087-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/4b85a13c310c4609446b2946c3e12c21/si55.gif si15 si15.gif gif 209 13 13 ALTIMG 1-s2.0-S1532046408000087-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif si14 si14.gif gif 257 13 39 ALTIMG 1-s2.0-S1532046408000087-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif si13 si13.gif gif 506 17 70 ALTIMG 1-s2.0-S1532046408000087-si125.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif si125 si125.gif gif 506 17 70 ALTIMG 1-s2.0-S1532046408000087-si124.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif si124 si124.gif gif 257 13 39 ALTIMG 1-s2.0-S1532046408000087-si123.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bb70946ba56681b0057e5a5252dd9135/si123.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bb70946ba56681b0057e5a5252dd9135/si123.gif si123 si123.gif gif 276 13 43 ALTIMG 1-s2.0-S1532046408000087-si122.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/26c52c62dbce3d150255aedb859d9c99/si3.gif si122 si122.gif gif 506 17 70 ALTIMG 1-s2.0-S1532046408000087-si121.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/47657144e1d63f5f12a04b600785c43d/si121.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/47657144e1d63f5f12a04b600785c43d/si121.gif si121 si121.gif gif 337 16 52 ALTIMG 1-s2.0-S1532046408000087-si120.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/d7cb03c0f660b8f7d9c09aaa0d808a3b/si120.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/d7cb03c0f660b8f7d9c09aaa0d808a3b/si120.gif si120 si120.gif gif 383 16 60 ALTIMG 1-s2.0-S1532046408000087-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/f25f8c0f9fc2e695e13e492d8751719c/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/f25f8c0f9fc2e695e13e492d8751719c/si12.gif si12 si12.gif gif 337 13 55 ALTIMG 1-s2.0-S1532046408000087-si119.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/9942dd8488a1ee59fe5e0c385e19a2af/si119.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/9942dd8488a1ee59fe5e0c385e19a2af/si119.gif si119 si119.gif gif 349 16 54 ALTIMG 1-s2.0-S1532046408000087-si118.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/c524785c345a2706463e265e07d3fb52/si118.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/c524785c345a2706463e265e07d3fb52/si118.gif si118 si118.gif gif 311 19 31 ALTIMG 1-s2.0-S1532046408000087-si117.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/16ff7153b8ef7b99dc2dd47e6d51387a/si117.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/16ff7153b8ef7b99dc2dd47e6d51387a/si117.gif si117 si117.gif gif 418 18 54 ALTIMG 1-s2.0-S1532046408000087-si116.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/7c2e0e21d18015359ee3449959619c5b/si51.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/7c2e0e21d18015359ee3449959619c5b/si51.gif si116 si116.gif gif 342 19 38 ALTIMG 1-s2.0-S1532046408000087-si115.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/52e801726d12eb66ab7b8c4ac38da7f5/si115.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/52e801726d12eb66ab7b8c4ac38da7f5/si115.gif si115 si115.gif gif 568 27 63 ALTIMG 1-s2.0-S1532046408000087-si114.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/7c1ea27c04ae03541360f615254444b9/si114.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/7c1ea27c04ae03541360f615254444b9/si114.gif si114 si114.gif gif 296 13 47 ALTIMG 1-s2.0-S1532046408000087-si113.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/0ecd5d32f3fd34fd82d4c3d2445c1970/si113.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/0ecd5d32f3fd34fd82d4c3d2445c1970/si113.gif si113 si113.gif gif 445 17 70 ALTIMG 1-s2.0-S1532046408000087-si112.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif si112 si112.gif gif 318 17 38 ALTIMG 1-s2.0-S1532046408000087-si111.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/2e892e2c98755ad23d14bcbcad1ef49f/si111.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/2e892e2c98755ad23d14bcbcad1ef49f/si111.gif si111 si111.gif gif 295 17 32 ALTIMG 1-s2.0-S1532046408000087-si110.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/d260e90a9587b93ec4deeed71fb53fd6/si67.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/d260e90a9587b93ec4deeed71fb53fd6/si67.gif si110 si110.gif gif 516 18 71 ALTIMG 1-s2.0-S1532046408000087-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif si11 si11.gif gif 257 13 39 ALTIMG 1-s2.0-S1532046408000087-si109.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif si109 si109.gif gif 318 17 38 ALTIMG 1-s2.0-S1532046408000087-si108.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif si108 si108.gif gif 218 13 14 ALTIMG 1-s2.0-S1532046408000087-si107.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bd227aabfe358aacec6b77c6da193c53/si112.gif si107 si107.gif gif 318 17 38 ALTIMG 1-s2.0-S1532046408000087-si106.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/1a1337a625eb356aba8e80702bb3ea0b/si106.gif si106 si106.gif gif 218 13 14 ALTIMG 1-s2.0-S1532046408000087-si105.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/bb70946ba56681b0057e5a5252dd9135/si123.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/bb70946ba56681b0057e5a5252dd9135/si123.gif si105 si105.gif gif 276 13 43 ALTIMG 1-s2.0-S1532046408000087-si104.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif si104 si104.gif gif 185 9 10 ALTIMG 1-s2.0-S1532046408000087-si103.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif si103 si103.gif gif 185 9 10 ALTIMG 1-s2.0-S1532046408000087-si102.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/0e4e30e0777f4e47b908737538f30253/si102.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/0e4e30e0777f4e47b908737538f30253/si102.gif si102 si102.gif gif 2877 39 162 ALTIMG 1-s2.0-S1532046408000087-si101.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/91d2e076499b70ca43ad6ce0c4cbfdd1/si7.gif si101 si101.gif gif 257 13 39 ALTIMG 1-s2.0-S1532046408000087-si100.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/20b669e05de88d020d34699760acc4a6/si60.gif si100 si100.gif gif 185 9 10 ALTIMG 1-s2.0-S1532046408000087-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/51f52218d7309a0510bca55a40e26a02/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/51f52218d7309a0510bca55a40e26a02/si10.gif si10 si10.gif gif 624 17 94 ALTIMG 1-s2.0-S1532046408000087-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/STRIPIN/image/gif/8b763d1ea8c10e8b0c27cc9472a5498d/si1.gif si1 si1.gif gif 273 19 27 ALTIMG 1-s2.0-S1532046408000087-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr1/DOWNSAMPLED/image/jpeg/bcce3abd94bc5b430b62274f2ad87ab5/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr1/DOWNSAMPLED/image/jpeg/bcce3abd94bc5b430b62274f2ad87ab5/gr1.jpg gr1 gr1.jpg jpg 48886 446 536 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr1/THUMBNAIL/image/gif/1f5637b06f6f09ad6867e75ad63a70ce/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr1/THUMBNAIL/image/gif/1f5637b06f6f09ad6867e75ad63a70ce/gr1.sml gr1 gr1.sml sml 2565 93 112 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr2/DOWNSAMPLED/image/jpeg/9657579c94d218de874accab98ed216a/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr2/DOWNSAMPLED/image/jpeg/9657579c94d218de874accab98ed216a/gr2.jpg gr2 gr2.jpg jpg 21238 383 544 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr2/THUMBNAIL/image/gif/343a94a9f277ccb872bb9de8a37b73a7/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr2/THUMBNAIL/image/gif/343a94a9f277ccb872bb9de8a37b73a7/gr2.sml gr2 gr2.sml sml 1928 88 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr3/DOWNSAMPLED/image/jpeg/5219fc12be1a780b446b87cf7ee6e26b/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr3/DOWNSAMPLED/image/jpeg/5219fc12be1a780b446b87cf7ee6e26b/gr3.jpg gr3 gr3.jpg jpg 34154 409 541 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr3/THUMBNAIL/image/gif/00dd7c6294888be17a9e6f4f01e25c2c/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr3/THUMBNAIL/image/gif/00dd7c6294888be17a9e6f4f01e25c2c/gr3.sml gr3 gr3.sml sml 2243 93 123 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr4/DOWNSAMPLED/image/jpeg/63b15f1a08fa990dc43d6c82b0f54bc7/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr4/DOWNSAMPLED/image/jpeg/63b15f1a08fa990dc43d6c82b0f54bc7/gr4.jpg gr4 gr4.jpg jpg 27963 389 530 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr4/THUMBNAIL/image/gif/b05d456ffff0e12c7cb520d23fed846d/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr4/THUMBNAIL/image/gif/b05d456ffff0e12c7cb520d23fed846d/gr4.sml gr4 gr4.sml sml 2294 92 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr5/DOWNSAMPLED/image/jpeg/079e461cbe98d274f40bbfee6c43d907/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr5/DOWNSAMPLED/image/jpeg/079e461cbe98d274f40bbfee6c43d907/gr5.jpg gr5 gr5.jpg jpg 99613 306 641 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr5/THUMBNAIL/image/gif/2d1e888b0f1b0654a2dc582cbb0c13d6/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr5/THUMBNAIL/image/gif/2d1e888b0f1b0654a2dc582cbb0c13d6/gr5.sml gr5 gr5.sml sml 3351 60 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr6/DOWNSAMPLED/image/jpeg/3fff587cc57bdb4ece40e82a722aa604/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr6/DOWNSAMPLED/image/jpeg/3fff587cc57bdb4ece40e82a722aa604/gr6.jpg gr6 gr6.jpg jpg 33750 389 531 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr6/THUMBNAIL/image/gif/f0657eab2a8524b9443857c4d97e5329/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr6/THUMBNAIL/image/gif/f0657eab2a8524b9443857c4d97e5329/gr6.sml gr6 gr6.sml sml 2593 92 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr7/DOWNSAMPLED/image/jpeg/ffef10451e0bae1ec2b057f71856f96b/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr7/DOWNSAMPLED/image/jpeg/ffef10451e0bae1ec2b057f71856f96b/gr7.jpg gr7 gr7.jpg jpg 34822 388 532 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr7/THUMBNAIL/image/gif/03afce8327f56e096f2d9bbd72800992/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr7/THUMBNAIL/image/gif/03afce8327f56e096f2d9bbd72800992/gr7.sml gr7 gr7.sml sml 2543 91 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr8/DOWNSAMPLED/image/jpeg/e7ad209bb9fcad9429cbdf8a5f240635/gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr8/DOWNSAMPLED/image/jpeg/e7ad209bb9fcad9429cbdf8a5f240635/gr8.jpg gr8 gr8.jpg jpg 32152 389 531 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr8/THUMBNAIL/image/gif/c8c21f1a5ad930c523a95973aa502879/gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr8/THUMBNAIL/image/gif/c8c21f1a5ad930c523a95973aa502879/gr8.sml gr8 gr8.sml sml 2513 92 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408000087-gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr9/DOWNSAMPLED/image/jpeg/26cb189f879b4f81731cca585e41f036/gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr9/DOWNSAMPLED/image/jpeg/26cb189f879b4f81731cca585e41f036/gr9.jpg gr9 gr9.jpg jpg 27287 390 535 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408000087-gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000087/gr9/THUMBNAIL/image/gif/07fea1c84196494e6416e5ad9e6fd859/gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000087/gr9/THUMBNAIL/image/gif/07fea1c84196494e6416e5ad9e6fd859/gr9.sml gr9 gr9.sml sml 2234 91 125 IMAGE-THUMBNAIL YJBIN 1407 S1532-0464(08)00008-7 10.1016/j.jbi.2008.01.001 Elsevier Inc. Fig. 1 Comparative learning curves. Fig. 2 Learning curve for PMI acquisition model. Fig. 3 Learning curves\u2014feature selection as preprocessing step. Fig. 4 Learning curves for new nspec seed data. Fig. 5 nspec sentences chosen at 15th training iteration (some truncation). Fig. 6 Learning curves\u2014exploring nspec acquisition. Fig. 7 Learning curves for PoS tagged representation. Fig. 8 Learning curves for stemmed representations. Fig. 9 Learning curves for stemmed+bigram representations. Table 1 Agreement scores F 1 rel \u03ba Original 0.8293 0.9336 Corrected 0.9652 0.9848 Table 2 Features ranked by P ( spec | x k ) for varying \u03b1 Rank \u03b1 = 0 \u03b1 = 1 \u03b1 = 5 \u03b1 = 100 \u03b1 = 500 1 interacts with suggest suggest suggest suggest 2 TAFb likely likely likely likely 3 sexta may may may may 4 CRYs might might These These 5 DsRed seems seems results results 6 Nonautonomous suggests Taken might that 7 arva probably suggests observations be 8 inter-homologue suggesting probably Taken data 9 Mohanty possibly Together findings it 10 meld suggested suggesting Our Our 11 aDNA Taken possibly seems observations 12 Deer unlikely suggested together role 13 Borel Together findings Together most 14 substripe physiology observations role these 15 Failing modulated Given that together 16 uncommitted reflecting unlikely be might 17 dist&xAFnct destruction These it findings 18 descend cooperative reflect strongly more 19 excretions Preliminary results most function 20 actinC outcome Our data is Table 3 Features ranked by PMI ( x k , spec ) with and without scaling Rank \u03b1 = 5 \u03b1 = 100 Scaled Non-scaled Scaled Non-scaled 1 suggest interacts with suggest likely 2 likely Nonautonomous likely interacts with 3 Ix aDNA Taken Nonautonomous 4 LRTs EGFP Together aDNA 5 Taken learns findings EGFP 6 Cumulatively Adelsberger observations learns 7 impinges Ubxxs These Adelsberger 8 xCopenxD polytypic seems Ubxxs 9 FNIII hairing Our polytypic 10 Wingrove variegation results hairing 11 Zalfa dLglPAR together variegation 12 earlystage txBrotein Altogether dLglPAR 13 CRN Dor-dependent Collectively txBrotein 14 Pfalciparum icated Recent Dor-dependent 15 gel-like peptidelipid strongly icated 16 peroxisomalxD xBlightly conformational peptidelipid 17 polyQ-expanded PRATHER think xBlightly 18 misannotated Keen underestimate PRATHER 19 ratioxs CxBxBA most Keen 20 GENERAL C\u02dcxBxBA play CxBxBA Table 4 Single term+bigram features ranked by P ( spec | x k ) with \u03b1 = 5 1 suggest 31 may_not 61 is_unlik 91 unlik_that 2 suggest_that 32 idea_that 62 ask_whether 92 togeth_these 3 might 33 be_due 63 which_may 93 it_might 4 may_be 34 it_may 64 like 94 be_more 5 possibl_that 35 most_like 65 it_appear 95 more_like 6 might_be 36 result_indic 66 whether_thi 96 be_requir 7 appear_to 37 and_may 67 on_possibl 97 unlik 8 result_suggest 38 it_seem 68 we_suggest 98 thei_may 9 propos_that 39 hypothesi_that 69 studi_suggest 99 examin_whether 10 is_like 40 suggest_the 70 not_appear 100 suggest_to 11 thought_to 41 been_suggest 71 appear 101 these_observ 12 suggest_a 42 the_hypothesi 72 suggest_by 102 may_function 13 thi_suggest 43 we_propos 73 might_have 103 suggest_an 14 seem_to 44 test_whether 74 taken_togeth 104 may_act 15 whether_the 45 possibl 75 support_the 105 thu_it 16 whether 46 specul 76 unlik_to 106 that_these 17 data_suggest 47 that_may 77 a_possibl 107 may_contribut 18 like_to 48 observ_suggest 78 been_propos 108 gene_may 19 like_that 49 strongli_suggest 79 evid_suggest 109 which_suggest 20 may_have 50 possibl_is 80 be_a 110 al_suggest 21 may_also 51 rais_the 81 protein_may 111 there_may 22 seem 52 appear_that 82 propos_to 112 not_known 23 may 53 also_be 83 also_suggest 113 is_unclear 24 the_possibl 54 ar_thought 84 play_a 114 and_appear 25 thought 55 and_suggest 85 might_also 115 hypothesi 26 determin_whether 56 be_involv 86 may_play 116 be_respons 27 ar_like 57 thi_may 87 that_might 117 seem_like 28 is_possibl 58 propos 88 find_suggest 118 or_whether 29 is_thought 59 specul_that 89 idea 119 reflect_a 30 the_idea 60 a_role 90 may_reflect 120 to_act Exploring hedge identification in biomedical literature Ben Medlock benmedlock@cantab.net University of Cambridge, Computer Laboratory, William Gates Building, 15 JJ Thomson Avenue, Cambridge CB3 OFD, UK Abstract We investigate automatic identification of speculative language, or \u2018hedging\u2019, in scientific literature from the biomedical domain. Our contributions include a precise description of the task including annotation guidelines, theoretical analysis and discussion. We show that good agreement can be achieved using our guidelines and present a publicly available benchmark dataset for the task. We argue for separation of the acquisition and classification phases in semi-supervised machine learning, and present a probabilistic acquisition model which is evaluated both theoretically and experimentally. We explore the impact of different sample representations on classification accuracy across the learning curve and demonstrate the effectiveness of using machine learning for the hedge identification task. Finally, we examine the errors made by our approach and point toward avenues for future research. Keywords Hedging Classification Natural language processing Machine learning Semi-supervised learning Annotation Agreement 1 Introduction The automatic processing of scientific papers using natural language processing (NLP) and machine learning (ML) techniques is an increasingly important aspect of technical informatics. In the quest for a deeper machine-driven \u2018understanding\u2019 of the mass of scientific literature, a frequently occurring linguistic phenomenon that must be accounted for is the use of hedging to denote propositions of a speculative nature. As an example, consider the information conveyed by each of the following examples: 1. Our results prove that XfK89 inhibits Felin-9. 2. Our results suggest that XfK89 might inhibit Felin-9. The second example contains a hedge, signalled by the use of suggest and might, which renders the proposition inhibit(XfK89 \u2192 Felin-9) speculative. For an example of why analysis of hedging is important for automatic text processing, consider a system designed to identify and extract interactions between genetic entities in the biomedical domain. Case 1 above provides clear textual evidence of such an interaction and justifies extraction of inhibit(XfK89 \u2192 Felin-9), whereas case 2 provides only weak evidence and would probably not justify extraction. Hedging occurs across the entire spectrum of scientific literature, though it is particularly common in the experimental natural sciences. In this study we consider the problem of learning to automatically classify sentences containing instances of hedging, given only a very limited amount of annotator-labeled \u2018seed\u2019 data. This falls within the semi-supervised ML framework, for which a range of techniques have been previously explored. The contributions of our work are as follows: 1. We provide a clear description of the problem of hedge identification and offer an improved and expanded set of annotation guidelines, along with illustrative examples, which as we demonstrate experimentally are sufficient to induce a high level of agreement between independent annotators. 2. We discuss the specificities of hedge identification as a semi-supervised ML task. 3. We argue for the separation of the acquisition and classification phases in semi-supervised learning. 4. We derive a probabilistic acquisition model and use it to motivate our approach. 5. We analyse the techniques presented both theoretically and experimentally, reporting promising results for the task on a new publicly available full-text dataset. 1 Available from http://www.cl.cam.ac.uk/research/nl/nl-download/hedging.html 1 The work presented in this article draws and expands upon prior research presented in a recent paper by the author Medlock and Briscoe [22]. 2 The task Given a collection of sentences, S , the task is to label each sentence as either speculative or non-speculative (spec or nspec henceforth). Specifically, S is to be partitioned into two disjoint sets, one representing sentences that contain some form of hedging, and the other representing those that do not. It should be noted that by nature of the task definition, a speculative sentence may contain an arbitrary number of non-speculative assertions, leading to the question of whether hedge identification should be carried out at the granularity of assertions rather than sentences. While there is a strong argument in favour of this approach, it requires the identification of assertion boundaries, thus adding an extra level of complexity to all aspects of the task, from annotation to evaluation. In fact, even if the end goal is to label assertions, sentence level hedge identification can be viewed as an initial stage, after which potentially speculative sentences can be further examined to identify speculative constituents. In an effort to further elucidate the nature of the task and to aid annotation, we have developed a new set of guidelines, building on the work of [19]. It is important to note that at least on a conceptual level, speculative assertions are not to be identified on the basis of the presence of certain designated hedge terms, rather the assessment is made based on a judgement of the author\u2019s intended meaning, as revealed by the text. We begin with the hedge definition given by [19] (item 1) and introduce a set of further guidelines to help elucidate various \u2018grey areas\u2019 and tighten the task specification. The following ARE considered instances of hedging: 1. Any assertion relating to a result that does not necessarily follow from the work presented, but could be extrapolated from it [19], e.g.: This unusual substrate specificity may explain why Dronc is resistant to inhibition by the pan-caspase inhibitor. Indeed, most mitochondria released all their cytochrome c, suggesting that an enzymatic transport mechanism is probably not involved. Our results provide the first direct evidence linking RAG1 and RSSs to a specific superfamily of DNA transposons and indicate that the V(D)J machinery evolved from transposons. A reduction of coverage could be the result of a reduction in dendrite outgrowth. Thus, nervy likely regulates multiple aspects of neuronal differentiation. 2. Relay of hedge made in previous work, e.g.: Dl and Ser have been proposed to act redundantly in the sensory bristle lineage. 3. Statements of knowledge paucity, e.g.: How endocytosis of Dl leads to the activation of N remains to be elucidated. Biochemical analysis of the ubiquitination events regulated by D-mib will be needed to further define the mechanism by which D-mib regulates the endocytosis of Ser in vivo. There is no clear evidence for cytochrome c release during apoptosis in Caenorhabditis elegans or Drosophila. There is no apparent need for cytochrome c release in C. elegans, since CED-4 does not require it to activate CED-3. 4. Speculative questioning, e.g.: A second important question is whether the roX genes have the same, overlapping or complementing functions. 5. Statement of speculative hypothesis, e.g.: To test whether the reported sea urchin sequences represent a true RAG1-like match, we cut off the ring finger motif and repeated the BLASTP search against all GenBank proteins. 6. Anaphoric hedge, e.g.: This hypothesis is supported by our finding that both pupariation rate and survival of\u2026 The rescue of the D-mib mutant phenotype by ectopic expression of Neur strongly supports this interpretation. The following are NOT considered instances of hedging: 1. Indication of experimentally observed non-universal behaviour, e.g.: Proteins with single BIR domains can also have functions in cell cycle regulation and cytokinesis. These results demonstrate that ADGF-A overexpression can partially rescue the effects of constitutively active Toll signalling in larvae. IAPs contain at least one BIR domain, and often a carboxy-terminal RING domain. 2. Confident assertion based on external work, e.g.: Two distinct E3 ubiquitin ligases have been shown to regulate Dl signalling in Drosophila melanogaster. 3. Statement of existence of proposed alternatives, e.g.: Different models have been proposed to explain how endocytosis of the ligand, which removes the ligand from the cell surface, results in N receptor activation. 4. Confirmation of previous speculation, e.g.: Here we show that the hemocytes (blood cells) are the main regulator of adenosine in the Drosophila larva, as was speculated previously for mammals. 5. Confirmation of already firmly-stated conclusion This conclusion is further supported by the even more efficient rescue achieved by\u2026 6. Negation of previous hedge Although the adgf-a mutation leads to larval or pupal death, we have shown that this is not due to the adenosine or deoxyadenosine simply blocking cellular proliferation or survival, as the experiments in vitro would suggest. 3 Related work 3.1 Hedge identification While there is a certain amount of literature within the linguistics community on the use of hedging in scientific text, e.g. [13], there is little of direct relevance to the task of classifying speculative language from an NLP/ML perspective. The most clearly relevant study is [19], where the hedge identification problem is introduced using examples drawn from the biomedical domain. They address the question of whether there is sufficient agreement among humans about what constitutes a speculative assertion to make the task viable from a computational perspective. At first they attempt to distinguish between two shades of speculation: strong and weak, but fail to garner sufficient agreement for such a distinction to be reliably annotated. However, they conclude that it is feasible to draw a reliable distinction between speculative and non-speculative sentences. They focus on introducing the problem, exploring annotation issues and outlining potential applications rather than on the specificities of the ML approach, though they do present some results using a manually crafted substring matching classifier and a supervised SVM on a collection of Medline abstracts. We will draw on this work throughout our presentation of the task. Analysis of hedging in the context of citation function is carried out in [23], though they do not directly consider the task of hedge identification. 3.2 Semi-supervised learning Recent years have witnessed a significant growth of research into semi-supervised ML techniques for NLP applications. Different approaches are often characterised as either multi- or single-view, where the former generate multiple \u2018views\u2019 on the data and perform mutual bootstrapping. This idea was formalised by [5] in their presentation of co-training which they show to be a powerful approach given the assumptions that: (1) each view is sufficient for classification and (2) the views are conditionally independent given the class label. These assumptions very rarely hold in real data, but co-training can still be effective under related but weaker conditions [1]. Co-training has also been used for named entity recognition (NER) [8], coreference resolution [26], text categorisation [27] and improving gene name data [32]. A number of researchers have proposed variants on the co-training idea. For example, rather than partitioning the feature space [11], generate multiple views by utilising two different machine learners, each of which is then used to bootstrap the other. Conversely, single-view learning models operate without an explicit partition of the feature space. Perhaps the most well known of such approaches is expectation maximisation (EM), used by [27] in the context of learning from a combination of labeled and unlabeled data for text categorization. Others have proposed variations on the basic EM algorithm, for instance [26] present a two-tiered boostrapping approach (EM-FS) in which EM is combined with a feature selection procedure to enhance its performance. Another single-view algorithm occurring in the literature is called self-training, in which a labeled pool is incrementally enlarged with unlabeled samples for which the learner is most confident. Early work by [35] falls within this framework. He proposed a bootstrapping algorithm for learning new patterns given existing ones in an iterative process, utilising the redundancy inherent in the fact that the sense of a word is constrained by its current discourse usage (one sense per discourse), and also by local contextual cues. \u2018Bagging\u2019 and agreement are used to measure confidence on unlabeled samples in [3], and more recently [21] use self-training for improving parse reranking. Other relevant recent work includes [36], in which random feature projection and a committee of SVM classifiers is used in a hybrid co/self-training strategy for semi-supervised relation classification and [7] where a graph based algorithm called label propagation is employed to perform semi-supervised relation extraction. 4 Motivation In this section we provide some justification as to why the task of hedge identification is at least potentially tractable from a semi-supervised ML perspective. The acquisition of new information about a particular target function from unlabeled data depends upon the existence of redundancy in the specification of the target function, even if the feature space cannot be explicitly partitioned into conditionally independent sets. This idea can be formalised as follows: given a particular feature, whose presence we will denote by f 1 , a target function Y and a learned hypothesis H, let us suppose that f 1 is a good indicator of a certain target function value y, e.g. P ( Y = y \u2223 f 1 ) \u2248 1 . We will also assume that this is known to the learner, e.g. P ( H = y \u2223 f 1 ) = P ( Y = y \u2223 f 1 ) . To infer new information about Y using an unlabeled source, there must exist some feature f 2 , also a good indicator of Y = y , such that the following conditions hold: 1. P ( f 2 \u2223 f 1 ) > P ( f 2 ) 2. P ( f 2 \u2223 f 1 , Y = y ) < 1 Condition 1 states that the features must not be negatively correlated, i.e. it must be possible to infer from instances containing f 1 that f 2 is also a good indicator of Y = y , while condition 2 states that the positive correlation between the two features, conditioned on the target class, must not be too tight, otherwise the learning process will grind to a halt. We can generalise from single features to \u2018rules\u2019 or \u2018views\u2019 that combine multiple features, but the same principles apply. Taken together, these conditions are a less precise, but for our task more intuitive version of the weak rule dependence condition of [1], which is itself a relaxed version of the conditional independence assumption of [5]. Analysis of the hedge identification task reveals potential redundancy of the above form that should be exploitable by a suitably chosen semi-supervised learner. We begin by assuming that features in our model are single terms, based on the intuition that many hedge cues are single terms (suggest, likely, etc.) and due to the success of \u2018bag-of-words\u2019 (BOW) representations in many learning tasks to date. Later, we will consider possible techniques for enriching the representation. Consider again the example speculative sentence from earlier: \u201cThese results suggest that XfK89 might inhibit Felin-9.\u201d Both suggest and might are hedge cues, and it is plausible to assume that they also occur within speculative sentences in other contexts, for instance \u201cWe suspect there might be an interaction between XfK89 and Felin-9.\u201d. Now, for f 1 = suggest and f 2 = might , we can examine the conditions specified above: 1. P ( might | suggest ) > P ( might ) 2. P ( might | suggest , Y = spec ) < 1 The required values can be estimated from our data, yielding the following: P ( might | suggest ) = 0.037 and P ( might ) = 0.012 . Given the (reasonable) approximation that suggest is always used as a hedge cue, P ( might | suggest ) = P ( might | suggest , Y = spec ) and both conditions hold. While such evidence suggests that the task is feasible, there are a number of factors that make our formulation of hedge identification both interesting and challenging from a semi-supervised learning perspective. Firstly, each sample contains a potentially large number of irrelevant features, as hedging modifies the certainty with which an assertion is made, but in general does not modify the assertion itself, rendering most of the actual content of an assertion irrelevant. However, hedge cues come from a wide range of linguistic categories [14], mitigating against techniques such as traditional stopword filtering, and take many different forms. Consequently there are no obvious methods of removing irrelevant features without also losing potential hedge cues. Exacerbating this problem is the fact that speculative sentences may contain many non-speculative assertions, each potentially adding a large number of irrelevant features. Such characteristics are in contrast to much previous work on semi-supervised learning, where for instance in the case of text categorization [5,27] almost all content terms are to some degree relevant, and irrelevant features are usually stopwords and can easily be filtered out. In the same vein, for the case of entity/relation extraction and classification [8,36,7] the context of the entity or entities in consideration provides a highly relevant feature space, and such studies are often set up such that only entities which fulfil some contextual criteria are considered [8]. Another interesting factor in our formulation of hedge identification that sets it apart from previous work is that the class of non-speculative sentences is defined on the basis of the absence of hedging, rather than on any positive characteristic. This makes it difficult to model the nspec class directly, and also hard to select a reliable set of nspec seed sentences, as by definition at the beginning of the learning cycle the learner has little knowledge about what a hedge looks like. The nspec seed problem is addressed in Section 8.5. In this study we will develop a semi-supervised learning strategy based around the principle of iteratively predicting labels for unlabeled training samples. This is the basic paradigm for both co-training and self-training; however we will generalise by framing the task in terms of the acquisition of labeled training data, from which a supervised classifier can subsequently be trained to distinguish those sentences that contain hedging from those that don\u2019t. It is our contention that there are good reasons for making the distinction between acquiring training data and classification, based on the observation that, while clearly related, the tasks are not the same. This distinction will become clearer in the next section when we develop a formal model for the learning procedure; however, using the arguments put forward in this discussion one can see informally where some of the distinctions lie. As we have seen, redundancy in the representation is crucial for acquiring new training samples; however this is not the case for classification. The aim of a classifier is to learn an accurate mapping between samples and target classes, and this does not require feature redundancy; in fact it is often beneficial to reduce redundancy by using features that specify the target classes more precisely. Given this insight, it may be advantageous to use different representations for the acquisition and classification phases, in addition to employing different model types. A related, though somewhat orthogonal argument can be made from the point of view of data sparsity. At the start of the acquisition phase, there is only a very limited amount of training data (the seed samples), and a complex representation is likely to suffer excessively from issues of data sparsity. However, once a sufficiently large training set has been induced, this becomes much less of an issue, and a more complex representation might indeed be beneficial. 5 Acquisition Having informally motivated the separation of the acquisition and classification phases in semi-supervised learning, we now present two variants of a simple probabilistic acquisition model, along with a brief description of an extant approach for purposes of experimental comparison. 5.1 Probabilistic acquisition model Given: \u2022 sample space X \u2022 set of target concept classes Y = { y 1 \u2026 y N } \u2022 target function Y : X \u2192 Y \u2022 set of seed samples for each class S 1 \u2026 S N where S i \u2282 X and \u2200 x \u2208 S i [ Y ( x ) = y i ] \u2022 set of unlabeled samples U = { x 1 \u2026 x K } Aim: Infer a set of training samples T i for each concept class y i such that \u2200 x \u2208 T i [ Y ( x ) = y i ] Now, it follows that \u2200 x \u2208 T i [ Y ( x ) = y i ] is satisfied in the case that \u2200 x \u2208 T i [ P ( y i | x ) = 1 ] , which leads to a model in which T i is initialised to S i and then iteratively augmented with the unlabeled sample(s) for which the posterior probability of class membership is maximal. Formally:At each iteration: (1) T i \u2190 x j ( \u2208 U ) where j = arg max j [ P ( y i | x j ) ] Expansion with Bayes\u2019 Rule yields: (2) arg max j [ P ( y i | x j ) ] = arg max j P ( x j | y i ) \u00b7 P ( y i ) P ( x j ) An interesting observation regarding Eq. (2) is the importance of the sample prior P ( x j ) in the denominator, often ignored for classification purposes because of its invariance to class. This provides a more formal qualification of the distinction between acquisition and classification. At this point, we will explore two different ways of interpreting (2), the first by marginalising the sample prior and the second by estimating it directly. These interpretations will lead us to somewhat different approaches to the acquisition task. 5.1.1 Interpretation 1: marginalised sample prior (MSP) Under this interpretation, we expand (2) by marginalising over the classes in the sample prior (denominator): (3) arg max j P ( x j | y i ) \u00b7 P ( y i ) \u2211 n = 1 N P ( y n ) P ( x j | y n ) leaving the class priors and class-conditional likelihoods to be estimated from the data, which can be made tractable under limited dependence assumptions. The class priors can be estimated based on the relative distribution sizes derived from the current training sets: (4) P ( y i ) = | T i | \u2211 k | T k | where | S | is the number of samples in training set S . If we assume feature independence we can simplify the class-conditional likelihood in the well known manner: (5) P ( x j | y i ) = \u220f k P ( x jk | y i ) and then estimate the likelihood for each feature: (6) P ( x k | y i ) = \u03b1 P ( y i ) + f ( x k , T i ) \u03b1 P ( y i ) + | T i | where f ( x , S ) is the number of samples in training set S in which feature x is present, and \u03b1 is a universal smoothing constant, scaled by the class prior. This scaling is motivated by the principle that without knowledge of the true distribution of a particular feature it makes sense to include knowledge of the class distribution in the smoothing mechanism. Smoothing is particularly important in the early stages of the learning process when the amount of training data is severely limited resulting in unreliable frequency estimates. 5.1.2 Interpretation 2: pointwise mutual information (PMI) Under this interpretation, we retain the sample prior from (2) in its unmarginalised form and eliminate the class prior P ( y i ) from the numerator owing to its invariance with respect to the sample. Then, by taking the log of the result we derive the expression for the pointwise mutual information (PMI) [10,30] between the sample and the class: (7) arg max j P ( x j | y i ) \u00b7 P ( y i ) P ( x j ) \u221d arg max j log P ( x j | y i ) P ( x j ) \u221d arg max j [ PMI ( x j , y i ) ] Thus we see that sample selection by maximal class posterior is equivalent to selection by maximal PMI. Under the feature independence assumption, the sample prior can be factorised into a product of its individual feature priors in a similar manner to the factorisation of the class-conditional likelihood (5). Rearrangement yields: (8) arg max j log P ( x j | y i ) P ( x j ) = arg max j log \u220f k P ( x jk | y i ) \u220f k P ( x jk ) = arg max j log \u220f k P ( x jk | y i ) P ( x jk ) = arg max j \u2211 k log P ( x jk | y i ) P ( x jk ) = arg max j \u2211 k PMI ( x jk , y i ) We are left with a summation over the PMI values for the individual features within each sample. P ( x k | y i ) (the per-feature class-conditional likelihood) is estimated by (6) and we use a similar estimate for the feature prior: (9) P ( x k ) = \u03b1 + f ( x k , T ) \u03b1 + | T | where T represents the set containing all the training data, both labeled and unlabeled. This calculation is both efficient and highly perspicuous as the contributions of individual features are simply added together. However, the great advantage of this approach is that it allows (in principle) sample ranking proportional to P ( spec | x j ) without requiring an estimate of P ( nspec | x j ) , and thus avoiding the potentially problematic generation of nspec seeds (Section 8.5). The acquisition models we have presented (especially the MSP interpretation) are related to the multinomial Na\u00efve Bayesian models occurring throughout the NLP and machine learning literature, e.g. [20,9,29], usually in the context of classification. As far as we are aware, this is the first study to specifically examine the data acquisition task in a probabilistic framework. The smoothing technique we describe is based on Laplacian smoothing [20] where a small value (often 1) is added to each feature count, though the prior-based scaling is a novel addition. Alternative techniques for smoothing the Na\u00efve Bayesian parameter estimates include backing-off and interpolation [16,28]. Further exploration is a potential avenue for future research. 5.2 Acquisition for hedge identification We will now consider how to apply the acquisition models to the hedge identification task. As discussed earlier, the speculative/non-speculative distinction hinges on the presence or absence of a few hedge cues within the sentence. Working on this premise, all features are ranked according to their probability of \u2018hedge cue-ness\u2019, given by the spec feature posterior in the MSP interpretation: (10) P ( spec | x k ) = P ( x k | spec ) \u00b7 P ( spec ) P ( spec ) P ( x k | spec ) + P ( nspec ) P ( x k | nspec ) which can be computed directly using (4) and (6), and the feature-class PMI in the PMI interpretation: (11) PMI ( spec | x k ) = log P ( x k | spec ) P ( x k ) computed using (6) and (9). The m most probable features are then selected from each sentence to compute (2) and the rest are ignored. This has the dual benefit of removing irrelevant features and also potentially reducing dependence between features, as the selected features will often be non-local and thus not too tightly correlated. Note that this idea differs from traditional feature selection in two important ways: 1. Only features indicative of the spec class are retained, or to put it another way, nspec class membership is inferred from the absence of strong spec features. 2. Feature selection in this context is not a preprocessing step. The classes are not re-modelled after selection; rather the original estimates are used. This has the effect of heavily skewing the posterior estimates in favour of the spec class, but this is acceptable for ranking purposes. Of course, this \u2018one-sided\u2019 feature selection technique could be carried out prior to class estimation as a preprocessing step; however, we would not expect this to be effective, as the nspec class would then be severely misrepresented, and the spec estimates would suffer accordingly. Later we demonstrate this to be the case experimentally (Section 9.1). 5.3 Comparison\u2014SVM Committee acquisition model To provide a comparison for the acquisition models presented here, we also implement a more traditional acquisition procedure drawn from the semi-supervised learning literature. At each iteration a committee of five support vector machine (SVM) classifiers is trained on randomly generated overlapping subsets of the training data and their cumulative confidence used to select items for augmenting the labeled training data. For more detailed description of this approach see [3,36]. 6 Classification The acquisition procedure returns a labeled dataset for each class, from which a classifier can be trained to identify sentences containing hedges. We experiment with two separate classification approaches: \u2022 Support Vector Machine: we use the SVM implementation in Joachims\u2019 SVM light [15], due to its efficiency and proven accuracy in classification tasks [33,18]. \u2022 Probabilistic: we derive a simple probabilistic classifier using the estimates from the acquisition model: (12) x j \u2192 spec if P ( spec | x j ) > \u03c3 where \u03c3 is an arbitrary threshold used to control the precision/recall balance. Under the second acquisition model interpretation we use the PMI estimates instead of the posterior: (13) x j \u2192 spec if PMI ( x j , spec ) > \u03c3 As a baseline, we also use the substring matching classifier of [19], which labels a sentence as spec if it contains one or more of the following: suggest, potential, likely, may, at least, in part, possibl, further investigation, unlikely, putative, insights, point toward, promise, propose. 7 Sample representation We use the single term bag-of-words (BOW) sample representation as a baseline, and additionally examine the following methods of enriching the representation: 7.1 Part-of-speech tagging There is theoretical motivation for using part-of-speech (PoS) tags to augment the BOW representation from the point of view of sense disambiguation. Terms such as potential are highly indicative of hedging when used in adjectival form but less so in nominal form. For example, consider the following sentence: An overview of the local backbone potential is shown in Fig. 5 . In this context the nominal use of potential does not indicate hedging and the sentence is quite clearly non-speculative. Contrast with: The transient cmg transcription in midgut and Malpighian tubules suggests a potential function in cell junction formation and in epithelial tissue patterning. where potential is quite clearly used as a hedge. PoS information will not always help though; consider a further example: The UAS-brk transgene was amplified from potential mutants by PCR and sequenced. It is clear (at least in the authors\u2019 opinion) that this sentence is non-speculative and that the adjectival use of potential is not a hedge but rather part of the experimental description. To create the new representation we suffixed each term with its respective part-of-speech tag using the RASP PoS component, based on a sequential HMM tagger and the CLAWS2 tagset. 2 www.comp.lancs.ac.uk/ucrel/claws2tags.html 2 7.2 Stemming We also experimented with stemming (using the Porter stemmer 3 http://www.tartarus.org/martin/PorterStemmer 3 ). The motivation for stemming in hedge identification is that distinct morphological forms of (particularly verbal) hedge cues are often used to convey the same semantics, for instance: Thus these data suggest that dpp signalling interacts with the retinal determination pathway. and There is a certain amount of evidence suggesting that dpp signalling interacts with the retinal determination pathway. both convey clear speculation through variants of the root verb suggest. Verbal forms of nominal hedge cues (and vice-versa) and collapsed in this representation, so for instance hypothesis and hypothesize are both reduced to hypothesi. We generate representations that use both stemming on its own (including case normalisation) and in combination with PoS tagging. 7.3 Bigrams There are many instances where combinations of terms represent more reliable hedge cues than just single terms. For instance, consider the following sentence: In addition several studies indicate that in mammals the Rel proteins could probably be involved in CNS processes such as neuronal development and synaptic plasticity. Analysis reveals that \u2018indicate that\u2019 is a fairly reliable hedge cue, whereas indicate on its own is not, because of instances such as the following: In the row marked dgqa the stippled exons indicate regions that are not found in the dgqa cDNAs identified by us. Notice that it is not the presence of indicate and that in the same sentence that is important here (both sentences fulfil that criterion), rather it is their adjacency. This suggests that bigram features may be useful, and could potentially enhance the sample representation. Using bigrams results in a well known explosion of the feature space ( O ( n ) \u2192 O ( n 2 ) ) and this often prohibits their usefulness due to issues of data sparsity. However the hedge identification problem possesses some characteristics that work to its advantage in this regard. Because the number of hedge cues is relatively small, the explosion occurs mostly in the space of irrelevant features, and with a reasonably large amount of data we would expect to see the same hedge constructions occurring often enough to yield at least fairly reliable statistics. Almost all of the research into complex feature generation has concluded that improvements are only gained through combining bigrams and single terms [31,24,4]. This has the added advantage that in our case such a scheme is guaranteed to at least retain the redundancy of the original representation, and almost certainly to increase it. We include all adjacent bigrams and allow the learning models to select (explicitly or implicitly) the relevant ones. 8 Experimental setup 8.1 Data For our experiments, we used an archive of 5579 full-text papers from the functional genomics literature relating to D. melanogaster (the fruit fly). The papers were converted to XML and linguistically processed using the RASP toolkit 4 www.informatics.susx.ac.uk/research/nlp/rasp 4 [6]. We annotated six of the papers to form a test set with a total of 380 spec sentences and 1157 nspec sentences, and randomly selected 300,000 sentences from the remaining papers as training data for the semi-supervised learner. The unlabeled sentences were chosen under the constraints that they must be at least 10 words long and contain a main verb. 8.2 Annotation and agreement Two separate annotators were commissioned to label the sentences in the test set, firstly one of the authors and secondly a domain expert with no prior input into the guideline development process. The two annotators labeled the data independently using the guidelines outlined in Section 2. Relative F 1 ( F 1 rel ) and Cohen\u2019s Kappa ( \u03ba ) were then used to quantify the level of agreement. For brevity we refer the reader to [2] and [12] for formulation and discussion of \u03ba and F 1 rel , respectively. The two metrics are based on different assumptions about the nature of the annotation task. F 1 rel is founded on the premise that the task is to recognise and label spec sentences from within a background population, and does not explicitly model agreement on nspec instances. It ranges from 0 (no agreement) to 1 (no disagreement). Conversely, \u03ba gives explicit credit for agreement on both spec and nspec instances. The observed agreement is then corrected for \u2018chance agreement\u2019, yielding a metric that ranges between \u22121 and 1. Given our definition of hedge identification and assessing the manner in which the annotation was carried out, we suggest that the founding assumption of F 1 rel fits the nature of the task better than that of \u03ba . Following initial agreement calculation, the instances of disagreement were examined. It turned out that the large majority of cases of disagreement were due to negligence on behalf of one or other of the annotators (i.e. cases of clear hedging that were missed), and that the cases of genuine disagreement were actually quite rare. New labelings were then created with the negligent disagreements corrected, resulting in significantly higher agreement scores. Values for the original and negligence-corrected labelings are reported in Table 1 . Annotator conferral violates the fundamental assumption of annotator independence, and so the latter agreement scores do not represent the true level of agreement; however, it is reasonable to conclude that the actual agreement is approximately lower bounded by the initial values and upper bounded by the latter values. In fact even the lower bound is well within the range usually accepted as representing \u2018good\u2019 agreement, and thus we are confident in accepting human annotation as a gold-standard for the hedge identification task. For our experiments, we use the labeling of the genetics expert, corrected for negligent instances. 8.3 Methodology In each of our experiments we use the following method: Given: \u2022 seed sets S spec and S nspec ( S nspec not required for PMI acquisition) \u2022 unlabeled sample set U 1. Initialise training data: T spec \u2190 S spec and T nspec \u2190 S nspec 2. Iterate: \u2022 Order U by ranking metric: \u2013 P ( spec | x j ) for MSP interpretation (Section 5.1.1) \u2013 PMI ( x j , spec ) for PMI interpretation (Section 5.1.2) \u2013 Cumulative SVM confidence for committee-based approach (Section 5.3) \u2022 T spec \u2190 most probable batch \u2022 T nspec \u2190 least probable batch \u2022 Train classifier using T spec and T nspec \u2022 Compute spec recall/precision BEP (break-even point) on the test data The batch size for each iteration is set to 0.001 * | U | . After each learning iteration, we compute the precision/recall BEP for the spec class using both classifiers trained on the current labeled data. We use BEP because it helps to mitigate against misleading results due to discrepancies in classification threshold placement. Disadvantageously, BEP does not measure a classifier\u2019s performance across the whole of the recall/precision spectrum (as can be obtained, for instance, from receiver-operating characteristic (ROC) curves), but for our purposes it provides a clear, abstracted overview of a classifier\u2019s accuracy given a particular training set. 8.4 Parameter setting The training and classification models we have presented require the setting of two parameters: the smoothing parameter \u03b1 and the number of features per sample m. Analysis of the effect of varying \u03b1 on feature ranking reveals that when \u03b1 = 0 , low frequency terms with spurious class correlation dominate and as \u03b1 increases, high frequency terms become increasingly dominant, eventually smoothing away genuine low-to-mid frequency correlations. This effect is illustrated in Table 2 , and from this analysis we chose \u03b1 = 5 as an appropriate level of smoothing for the MSP interpretation. In Section 5.1 we introduced the idea of prior-scaled smoothing. Under the PMI interpretation it plays a crucial role in the emergence of useful feature-class correlations. Table 3 demonstrates this phenomenon. To obtain these results we also used the following non-scaled formulation of the per-feature class-conditional likelihood: (14) P ( x k | y i ) = \u03b1 + f ( x k , T i ) \u03b1 + | T i | Few, if any useful correlations emerge when using 14; however, when using scaled smoothing, genuine correlations do emerge. Note that we must use a higher value of \u03b1 under the PMI interpretation. The reason for the effectiveness of scaled smoothing is that the amount of smoothing is related to the current estimate of the focus class prior in relation to the whole body of training data, which at the start of the learning process is low. This encourages variation in the per-feature class-conditional estimate, while utilising the higher \u03b1 value to dampen the effect of low frequency terms in the feature prior. We use m = 5 for both acquisition model interpretations, based on the intuition that five is a rough upper bound on the number of hedge cue features likely to occur in any one sentence. We do not contend that these are necessarily optimal parameter values for the task, rather that they are sensible. We use the linear kernel for SVM light with the default setting for the regularization parameter C. We construct binary valued, L 2-normalised (unit length) input vectors to represent each sentence, as this resulted in better performance than using frequency-based weights and concords with our presence/absence feature estimates. 8.5 Seed generation The models we have presented require a set of seeds for each class. To generate seeds for the spec class, we extracted all sentences from U containing either (or both) of the terms suggest or likely, as these are very good (though not perfect) hedge cues, yielding 6423 spec seeds. Generating seeds for nspec is much more difficult, as integrity requires the absence of hedge cues, and this cannot be done automatically. Thus, we used the following procedure to obtain a set of nspec seeds: 1. Create initial S nspec by sampling randomly from U . 2. Manually remove more \u2018obvious\u2019 speculative sentences using pattern matching. 3. Iterate: \u2022 Order S nspec by P ( spec | x j ) using estimates from S spec and current S nspec . \u2022 Examine most probable sentences and remove speculative instances. We started with 8830 sentences and after a couple of hours work reduced this down to a (still somewhat noisy) nspec seed set of 7541 sentences. 9 Experimental results In this section we present results for the acquisition and classification models introduced in this study using the experimental setup described above. Firstly, we compare various configurations of the probabilistic (MSP interpretation) and SVM committee-based acquisition models with the baseline classifier. Fig. 1 plots accuracy as a function of the acquisition iteration. After 150 iterations, all of the semi-supervised approaches are significantly more accurate than the baseline classifier according to a binomial sign test ( p < 0.01 ) , though there is clearly still much room for improvement. The baseline classifier achieves a BEP of 0.60 while both classifiers reach approximately 0.76 BEP using the probabilistic acquisition model, with the SVM performing slightly better overall. The weakest combination is the SVM committee-based acquisition model with an SVM classifier. Interestingly though, the probabilistic classifier with the SVM committee-based acquisition model performs competitively with the other approaches. Overall, these results favour a framework in which the acquisition and classification phases are carried out by different models. The PMI acquisition model did not fare as well as the MSP interpretation. Fig. 2 plots the learning curve for the PMI acquisition model and derived classifier, using the smoothing parameter values \u03b1 = 25 and 75. For clarity we omit alternative configurations, as they yielded similar results. An explanation for the weakness of this model follows from an examination of its theoretical properties. Samples are chosen on the basis of PMI, given by log P ( x j | y i ) P ( x j ) . While our estimate of the sample prior P ( x j ) is quite reliable (given the independence assumption), the class-conditional likelihood estimate P ( x j | y i ) is unreliable at the beginning of the learning cycle as it is estimated only from the seed data. In particular, many genuine feature-class correlations are weak, and even with the scaled smoothing they tend to be \u2018drowned out\u2019 when competing with prior estimates from the entire training corpus. Conversely, under the MSP interpretation, both the class conditional and prior estimates are weak at the start of the learning cycle which allows genuine spec correlations to emerge much more readily as the marginalised prior estimates are drawn only from the augmented spec and nspec seed data. 9.1 Comparison with traditional feature selection The results presented in Fig. 1 for the probabilistic classifier use the one-sided feature selection technique outlined in Section 5.2, while the SVM results are obtained without feature selection. Fig. 3 plots the results of experiments in which we carry out one-sided feature selection for both classifiers as a preprocessing step, in order to test its expected ineffectiveness when used in the traditional way. As anticipated, both classifiers perform worse in this scenario, with a particularly dramatic decrease in accuracy for the SVM. We attribute this phenomenon to the fact that in the one-sided feature selection scenario, the SVM must discriminate between classes that are both represented by features indicative of the spec class; a task at which it is intuitively destined to fail. We also carried out experiments (not reported here) using traditional feature selection on both classes (with \u03c7 max 2 ) for the SVM classifier, and this resulted in poorer performance than using all features. 9.2 Seed refinement Given the results obtained using the seed data described in Section 8.5, we wanted to measure the accuracy gained by additional manual improvement of the nspec seed data. Our aim was to examine the hypothesis that even a relatively small number of spurious spec sentences amongst the nspec seeds could cause the learner to erroneously disregard some of the more subtle spec class-feature correlations and thus significantly degrade the diversity of the induced training data. We again employed the iterative refinement method described above (Section 8.5), and additionally used the substring classifier of [19] to extract a list of further potentially speculative sentences from which we removed the genuinely speculative ones and returned the rest to the nspec seed set. We spent around 2\u20133hours refining the nspec seeds and succeeded in removing 260 spurious instances, yielding a new nspec seed set of 7281 nspec sentences. Running the probabilistic acquisition model and SVM classifier using the new nspec seeds yielded the results shown in Fig. 4 . There is an improvement of around 1\u20132% BEP. 9.3 Exploring nspec acquisition Examining the sentences chosen by our acquisition model for augmenting the nspec training data reveals a noticeable homogeneity of form. Fig. 5 shows a batch of sentences chosen by the learner for the nspec class on the 15th training iteration. Almost all of these are descriptions of experimental methodology, and as such exhibit certain common features, such as past tense predicate constructions. Adding increasing numbers of methodology sentences to the nspec training data would appear less than optimal in terms of modelling the nspec class, as there are many nspec sentences in other sections. To compensate for this acquisition bias we explored a number of methods of guiding the learner to choose a wider range of nspec sentence types: 1. Remove a significant proportion (around 25,000) of the methodology sentences from the unlabeled pool using source paper markup. 2. Filter the unlabeled pool to contain only sentences identified by the source paper markup as coming from one of the following sections: Summary, Introduction, Discussion, Results and Conclusions, leaving 108,694 sentences in the pool. These are the sections in which speculations are most likely to be made [23], and the idea is that the learner chooses nspec sentences that are of a similar type to the spec ones, thus giving the classifier more chance of discriminating between the difficult instances. From Fig. 6 it can be seen that neither approach (designated \u2018Filtered pool (1)\u2019 and \u2018Filtered pool (2)\u2019, respectively) was able to provide a clear improvement over the original unfiltered pool. The danger of the second approach is that the learner is also more likely to acquire spurious nspec sentences; it is also possible that in this scenario a significant proportion of useful spec sentences are removed from the pool, which may contribute to the decrease in performance. We also tested a scenario in which the nspec training data is fixed in its initial seed state and only the spec training set is augmented, denoted by \u2018Fixed nspec\u2019. It is interesting that this has only a marginal negative impact on performance which suggests that a relatively small amount is learned about the nspec class through the acquisition process, beyond the information already contained in the seed data. 9.4 Enriched sample representations 9.4.1 PoS tagging The results for the augmented PoS representation are given in Fig. 7 . The addition of PoS tags does yield slightly better accuracy in later training iterations than the basic term-based representation, but the improvements are marginal and not statistically significant. In practice, the benefits derived from PoS tags in terms of word sense disambiguation are not as pronounced as theory might suggest. For example, earlier we argued that the term potential when used as an adjective is much more likely to represent hedging than when used as a nominal. While this is undoubtedly true, our test data contains no instances of the nominal form of potential, and both the spec and nspec sentences contain the same number of adjectival instances (five). Consider the following: There was considerable excitement in the field when potential mammalian and Drosophila homologues for ced- and egl- were discovered. The annotators decided that the use of potential in this instance did not represent an authorial hedge because potentiality is by necessity a property of homology. 5 Biological homology refers to structural similarity resulting from shared ancestry, which cannot be established beyond question due to inherent lack of observability; thus is only ever \u2018potential\u2019. 5 This exemplifies the notion that whether a particular term acts as a hedge cue is quite often a rather subtle function of its sense usage, in which case the distinctions may well not be captured by PoS tagging. 9.4.2 Stemming Fig. 8 shows that the combined stemming/PoS representation follows much the same pattern as the original, which is unsurprising given that PoS tagging counteracts the generalisation achieved by stemming. For example, there are separate PoS tags for different verb tenses, which is precisely the sort of information that is discarded by stemming. The interesting case is when stemming is used alone. Over early training iterations, the accuracy of the classifier is significantly lower; however performance continues to improve in latter iterations, yielding a peak result of around 0.8 BEP. Carrying out a binomial sign test comparing the performance of the original and stemmed representations around their relative peaks (80 training iterations for the original representation and 120 for the stemmed variant) showed a weakly significant improvement ( p < 0.2 ) for the stemmed representation. 9.4.3 Bigrams We use the best performing stemmed single term representation and augment it with all adjacent bigrams. An example of a sentence and its representation is as follows: Several lines of evidence suggest that upregulation of RD gene expression by dpp and ey is likely to account for the synergy that we have observed. sever line of evid suggest that upregul of rd gene express by dpp and ey is like to account for the synergi that we have observ sever_line line_of of_evid evid_suggest suggest_that that_upregul upregul_of of_rd rd_gene gene_express express_by by_dpp dpp_and and_ey ey_is is_like like_to to_account account_for for_the the_synergi synergi_that that_we we_have have_observ The results are shown in Fig. 9 , and demonstrate that including bigrams yields a clear improvement in accuracy across most of the acquisition curve, with a new peak performance of around 0.82 BEP. According to the binomial sign test, this indicates a statistically significant improvement over both the original representation ( p < 0.01 ) and the previous best performing stemmed representation ( p < 0.1 ). Table 4 shows the 120 highest ranked features according to P ( spec | x k ) in the combined single term/bigram representation after 100 learning iterations. There are 13 single terms and 107 bigrams, and it is interesting to note that in some cases neither of the constituent single terms in a given bigram is a likely hedge cue while the combined feature clearly is; for instance \u2018not_known\u2019 (rank 112), which is a cue for the knowledge paucity hedge. 10 Error analysis We examined the errors made by the SVM classifier after 100 iterations of the probabilistic acquisition model using the stem+adjacency bigram sample representation ( m = 5 , \u03b1 = 5 ). A BEP of 0.816 was obtained at this stage, equating to 310 correctly classified instances out of 380 for the spec class and 1087 out of 1157 for the nspec class (70 misclassified instances in each class). A significant proportion (approx. 20%) of the missed spec instances were statements of knowledge paucity. These ranged from quite common forms, e.g.: The role of the roX genes and roX RNAs in this process is still unclear. to more unusual variants, e.g.: This brings us to the largest of all mysteries, namely how the DCC is spread along the X chromosome. Such instances are further in construction from the spec seed sentences and thus somewhat harder to acquire training data for. A possible way of capturing these instances would be to include specific knowledge paucity seeds. Some of the missed spec instances were due to cases where speculativity is indicated by a particular term, while the general construction of the sentence does not fit the usual spec mold. For example: We then tested the putative RNA-binding property of MOF directly using electromobility shift assays. This instance looks much like a typical \u2018materials and methods\u2019 sentence, except that the use of putative renders it speculative (in the annotators\u2019 opinion). In some cases, genuine hedge cues were not induced with enough certainty, leading to missed spec instances, for example: Invertebrates in vivo RAG-mediated transpositions are strongly suppressed, probably to minimize potential harm to genome function. The term probably is actually a fairly reliable hedge cue, but it only appears at rank 1268 in the list of features ranked according to P ( spec | x k ) , estimated from the automatically acquired training data. Quite a number of missed spec instances were just hard to classify, for example: Mutants that pupariated usually showed typical GFP expectoration indicating the presence of a high premetamorphic peak of ecdysteroids. It could certainly be argued that this is in fact an instance of observed non-universal behaviour, rather than a hedge. Another example is the following: Some of the intermediate stages of RAG evolution can be inferred from analysis of the sea urchin in which RAG-like proteins were recently observed, and from analysis of the lancelet starlet sea anemone and hydra genomes. This instance could be interpreted as a sort of \u2018meta speculation\u2019, stating that speculations about RAG evolution could be made from recent experimental findings. However, it is unclear as to whether this should constitute a hedge in itself. The majority of false positives (nspec instances labeled as spec) were due to constructions that are hard to distinguish due to similarity of form, for example: IAPs were first discovered in baculovirus but have since been shown to play a vital role in blocking apoptosis in Drosophila as well as in mammals. Variants of the phrase \u2018play a role\u2019 are quite often used as hedge cues, and hence this instance looks like a hedge, though the annotators decided that in fact it is not. Another example of confusion due to similarity of construction is the following: Three Drosophila BIRPs have been shown to be inhibitors of apoptosis Diap Diap and Deterin. The infinitive \u2018to be\u2019 and the verb be are in general quite reliable hedge cues (ranked 142 and 217, respectively) whereas in this instance they are not used to signal speculativity. This is also a potential indicator of the disadvantage of combining single terms and bigrams in terms of feature independence violation (though our results show that the benefits outweigh the disadvantages). In some cases, the classifier actually identified spuriously labeled instances, for example the following were labeled by the annotators as nspec when they clearly contain hedges: Caspases can also be activated with the aid of Apaf, which in turn appears to be regulated by cytochrome c and dATP. and Further insight into a possible mechanism for IAP function was recently gained when IAPs were observed to have ubiquitin ligase activity. We found that around 10% of the false positives were actually due to spurious manual labeling. 11 Conclusions and future work We have shown that semi-supervised ML is applicable to the problem of hedge identification and that a reasonable level of accuracy can be achieved. Our main contributions are: \u2022 We provide improved and expanded annotation guidelines for the hedge identification task, sufficient to induce a high level of agreement between independent annotators. \u2022 We argue for the separation of the acquisition and classification phases in semi-supervised learning. \u2022 We derive two different interpretations of a simple but novel probabilistic acquisition model and use it to motivate our approach. \u2022 We use novel smoothing and feature selection strategies motivated by the specificities of the hedge identification task. \u2022 We analyse the presented techniques both theoretically and experimentally, reporting promising results for the task on a new publicly available full-text dataset. 6 Available from http://www.cl.cam.ac.uk/research/nl/nl-download/hedging.html 6 The work presented here has direct application in the biomedical research community. A key motivation for this study is to incorporate hedge identification into an interactive system for aiding curators in the construction and population of gene databases [17]. The system utilises sophisticated GUI (graphical user interface) and NLP technology to highlight key results within biomedical literature for expert curation. Our aim is to include a component that identifies when a result is presented in a speculative manner and should not be extracted. Recent research [23] suggests that approximately 30% of sentences in the results and discussion sections of biomedical papers contain speculative assertions, and this figure increases to around 40% for the conclusions section. Our analysis supports these estimates, and it is clear that interactive bioinformation systems that take account of hedging can render a significantly more effective service to curators and researchers alike. We have presented our initial results on the hedge identification task in the hope that this will encourage others to carry the investigation further. Some potential avenues for future research are as follows: \u2022 Active learning: Given a classifier trained on acquired data, a profitable subsequent step would be to apply active learning to further augment the training data with instances about which the classifier is uncertain. The combination of semi-supervised and active learning has been explored in various contexts, e.g. [20,25], and careful consideration would need to given to how best to combine the different models. It is our intuition that applying semi-supervised and active learning in series may be the best approach for our setting, rather than the more common method of combining them in parallel. \u2022 Alternative semi-supervised learning strategies: It would be interesting to apply a completely different model type to the problem, for example label propagation as a variant of the semi-supervised paradigm. This would also facilitate the application of existing methods of combining semi-supervised and active learning in the graph based framework, for instance [37]. \u2022 Representation: There are various possibilities for enriching the sample representation, perhaps to take account of context, e.g. which section of the paper a given sentence was drawn from, and whether its surrounding sentences are speculative. Explicit inclusion of negation might also be beneficial for improving recall of knowledge paucity hedges. \u2022 Acquisition phase stopping criteria: An issue we have not addressed is that of whether the acquisition model can be automatically stopped at an optimal, or close to optimal point. Various methods have been investigated to address this problem, such as \u2018counter-training\u2019 [34] and committee agreement thresholding [36]; more work is needed to establish whether these or related ideas can be applied in our setting. \u2022 Assertion level hedge identification: As mentioned earlier, rather than just knowing whether or not a sentence contains a hedge, it would be beneficial to know which assertion a given hedge scopes over. We propose that a sensible method would be to perform further analysis on the (relatively small) subset of sentences identified as belonging to the spec class to find the assertion boundaries and the scope of likely hedge cues. This would probably require a degree of syntactic analysis which could be derived from a dependency parser such as RASP. Acknowledgments This work was partially supported by the FlySlip project, BBSRC Grant BBS/B/16291, and we thank Ted Briscoe, Nikiforos Karamanis and Ruth Seal for thorough annotation and helpful discussion. The author is supported by a University of Cambridge Millennium Scholarship. References [1] Abney S. Bootstrapping. In: Proceedings of 40th annual meeting of the association for computational linguistics; 2002. p. 360\u20137. [2] Artstein R, Poesio M. Kappa3 =alpha (or beta). Technical report, University of Essex, Department of Computer Science; 2005. [3] Banko M, Brill E. Scaling to very very large corpora for natural language disambiguation. In: Meeting of the association for computational linguistics; 2001. p. 26\u201333. [4] Bekkerman R, Allan J. Using bigrams in text categorization. Technical report 408, CIIR; 2005. [5] A. Blum T. Mitchell Combining labeled and unlabeled data with co-training COLT\u2019 98: proceedings of the eleventh annual conference on computational learning theory 1998 ACM Press New York, NY, USA 92 100 [6] Briscoe T, Carroll J, Watson R. The second release of the rasp system. In: Proceedings of the COLING/ACL on interactive presentation sessions, Morristown, NJ, USA; 2006. Association for Computational Linguistics. p. 77\u201380. [7] Chen J, Ji D, Tan CL, Niu Z. Relation extraction using label propagation based semi-supervised learning. In: Proceedings of the 21st international conference on computational linguistics and 44th annual meeting of the association for computational linguistics. Association for Computational Linguistics; 2006. p. 129\u201336. [8] Collins M, Singer Y. Unsupervised models for named entity classification. In: Proceedings of the joint SIGDAT conference on empirical methods in natural language processing and very large corporation; 1999. [9] Eyheramendy S, Lewis D, Madigan D. On the Naive Bayes model for text categorization. In: Paper presented at the artificial intelligence and statistics conference, Key West, FL; 2003. [10] R. Fano Transmission of information 1961 MIT Press Cambridge (MA) [11] S. Goldman Y. Zhou Enhancing supervised learning with unlabeled data Proceedings of 17th international conference on machine learning 2000 Morgan Kaufmann San Francisco (CA) 327 334 [12] G. Hripcsak A. Rothschild Agreement, the f-measure, and reliability in information retrieval J Am Med Inform Assoc 12 3 2004 296 298 [13] K. Hyland Hedging in academic writing and eap textbooks English Specif Purp 13 1994 239 256 [14] K. Hyland Talking to the academy: forms of hedging in science research articles Writ Commun 13 1996 251 281 [15] T. Joachims Making large-scale support vector machine learning practical A.S.B. Sch\u00f6lkopf C. Burges Advances in Kernel methods: support vector machines 1999 MIT Press Cambridge (MA) [16] Juan A, Ney H. Reversing and smoothing the multinomial Naive Bayes text classifier. In: Proceedings of the 2nd international workshop on pattern recognition in information systems (PRIS 2002), Alacant (Spain); 2002. p. 200\u201312. [17] Karamanis N, Lewin I, Seal R, Drysdale R, Briscoe T. Integrating natural language processing with FlyBase curation. In: Proceedings of PSB 2007; 2007. p. 245\u201356. [18] David D. Lewis Yiming Yang Tony G. Rose Fan Li RCV1: a new benchmark collection for text categorization research J Mach Learn Res 5 2004 361 397 [19] Light M, Qiu X, Srinivasan P. The language of bioscience: facts, speculations, and statements in between. In: Proceedings of BioLink 2004 workshop on linking biological literature, ontologies and databases: tools for users, Boston, May 2004; 2004. [20] McCallum A, Nigam K. A comparison of event models for naive bayes text classification. In: AAAI-98 workshop on learning for text categorization; 1998. [21] McClosky D, Charniak E, Johnson M. Effective self-training for parsing. In: Proceedings of the main conference on human language technology conference of the North American chapter of the association of computational linguistics, Morristown, NJ, USA; 2006. Association for Computational Linguistics. p. 152\u20139. [22] Medlock B, Briscoe T. Weakly supervised learning for hedge classification in scientific literature. In: Proceedings of the 45rd annual meeting of the association for computational linguistics (ACL\u201907), Prague; June 2007. Association for Computational Linguistics. [23] Mercer RE, Marco CD. A design methodology for a biomedical literature indexing tool using the rhetoric of science. In: LT-NAACL 2004 workshop: Biolink 2004, linking biological literature, ontologies and databases; 2004. [24] Moschitti A, Basili R. Complex linguistic features for text classification: a comprehensive study. In: ECIR; 2004. p. 181\u2013196. [25] I. Muslea S. Minton C.A. Knoblock Active+semi-supervised learning=robust multi-view learning ICML\u201902: proceedings of the nineteenth international conference on machine learning 2002 Morgan Kaufmann Publishers Inc. San Francisco, CA, USA 435 442 [26] Ng V, Cardie C. Weakly supervised natural language learning without redundant views. In: NAACL\u201903: proceedings of the 2003 conference of the North American chapter of the association for computational linguistics on human language technology, Morristown, NJ, USA; 2003. Association for Computational Linguistics. p. 94\u2013101. [27] K. Nigam A.K. McCallum S. Thrun T.M. Mitchell Text classification from labeled and unlabeled documents using EM Mach Learn 39 2/3 2000 103 134 [28] Fuchun Peng Dale Schuurmans Shaojun Wang Augmenting Naive Bayes classifiers with statistical language models Inf Retrieval 7 3\u20134 2004 317 345 [29] Karl-Michael Schneider Techniques for improving the performance of Naive Bayes for text classification Comput Linguist Intell Text Process 2005 682 693 [30] Su Q, Xiang K, Wang H, Sun B, Yu S. Using pointwise mutual information to identify implicit features in customer review. In: ICCPOL 2006, Singapore, December 17\u201319; 2006. [31] C.-M. Tan Y.-F. Wang C.-D. Lee The use of bigrams to enhance text categorization Inf Process Manage 38 4 2002 529 546 [32] Wellner B. Weakly supervised learning methods for improving the quality of gene name normalization data. In: Proceedings of the ACL-ISMB workshop on linking biological literature, ontologies and databases: mining biological semantics, Detroit; June 2005. Association for Computational Linguistics. p. 1\u20138. [33] Yang Y, Liu X. A re-examination of text categorization methods. In: Proceedings of the 22nd annual international ACM SIGIR conference on research and development in information retrieval; 1999. p. 42\u20139. [34] Yangarber R. Counter-training in discovery of semantic patterns. In: Hinrichs E, Roth D, editors. Proceedings of the 41st annual meeting of the association for computational linguistics; 2003. p. 343\u201350. [35] Yarowsky D. Unsupervised word sense disambiguation rivaling supervised methods. In: Proceedings of the 33rd annual meeting on association for computational linguistics, Morristown, NJ, USA; 1995. Association for Computational Linguistics. p. 189\u201396. [36] Z. Zhang Weakly-supervised relation classification for information extraction CIKM\u201904: proceedings of the thirteenth ACM international conference on information and knowledge management 2004 ACM Press New York, NY, USA 581 588 [37] Zhu X, Lafferty J, Ghahramani Z. Combining active learning and semi-supervised learning using gaussian fields and harmonic functions. In: Proceedings of the ICML 2003 workshop on the continuum from labeled to unlabeled data in machine learning and data mining; 2003.", "scopus-id": "46649112949", "pubmed-id": "18280796", "coredata": {"eid": "1-s2.0-S1532046408000087", "dc:description": "Abstract We investigate automatic identification of speculative language, or \u2018hedging\u2019, in scientific literature from the biomedical domain. Our contributions include a precise description of the task including annotation guidelines, theoretical analysis and discussion. We show that good agreement can be achieved using our guidelines and present a publicly available benchmark dataset for the task. We argue for separation of the acquisition and classification phases in semi-supervised machine learning, and present a probabilistic acquisition model which is evaluated both theoretically and experimentally. We explore the impact of different sample representations on classification accuracy across the learning curve and demonstrate the effectiveness of using machine learning for the hedge identification task. Finally, we examine the errors made by our approach and point toward avenues for future research.", "openArchiveArticle": "true", "prism:coverDate": "2008-08-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046408000087", "dc:creator": {"@_fa": "true", "$": "Medlock, Ben"}, "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046408000087"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046408000087"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(08)00008-7", "prism:volume": "41", "prism:publisher": "Elsevier Inc.", "dc:title": "Exploring hedge identification in biomedical literature", "prism:copyright": "Copyright \u00a9 2008 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "4", "dcterms:subject": [{"@_fa": "true", "$": "Hedging"}, {"@_fa": "true", "$": "Classification"}, {"@_fa": "true", "$": "Natural language processing"}, {"@_fa": "true", "$": "Machine learning"}, {"@_fa": "true", "$": "Semi-supervised learning"}, {"@_fa": "true", "$": "Annotation"}, {"@_fa": "true", "$": "Agreement"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "4", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "636-654", "prism:endingPage": "654", "prism:coverDisplayDate": "August 2008", "prism:doi": "10.1016/j.jbi.2008.01.001", "prism:startingPage": "636", "dc:identifier": "doi:10.1016/j.jbi.2008.01.001", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "13", "@width": "39", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si99.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "696", "@ref": "si99", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si98.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "450", "@ref": "si98", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si97.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "450", "@ref": "si97", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "83", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si96.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1332", "@ref": "si96", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si95.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "807", "@ref": "si95", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "34", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si94.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "750", "@ref": "si94", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "207", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si93.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2766", "@ref": "si93", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "204", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si92.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2706", "@ref": "si92", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "94", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si91.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1800", "@ref": "si91", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "71", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si90.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1443", "@ref": "si90", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "55", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "957", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si89.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "218", "@ref": "si89", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "102", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si88.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "488", "@ref": "si88", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "91", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si87.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "444", "@ref": "si87", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si86.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "218", "@ref": "si86", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si85.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si85", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si84.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si84", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "32", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si83.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "295", "@ref": "si83", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si82.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "180", "@ref": "si82", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "27", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si81.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "273", "@ref": "si81", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si80.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "180", "@ref": "si80", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "55", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "337", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "27", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si79.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "273", "@ref": "si79", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "27", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si78.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "273", "@ref": "si78", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si77.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "180", "@ref": "si77", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si76.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "180", "@ref": "si76", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si75.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "409", "@ref": "si75", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "109", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si74.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "618", "@ref": "si74", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "225", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si73.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2892", "@ref": "si73", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si72.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "183", "@ref": "si72", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "200", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si71.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2565", "@ref": "si71", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "206", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si70.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3879", "@ref": "si70", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "39", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "257", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "366", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si69.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "6567", "@ref": "si69", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "79", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si68.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "565", "@ref": "si68", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "71", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si67.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "516", "@ref": "si67", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si66.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "199", "@ref": "si66", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "142", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si65.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2544", "@ref": "si65", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "53", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si64.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "411", "@ref": "si64", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "212", "@width": "351", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si63.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "16617", "@ref": "si63", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "75", "@width": "340", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si62.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "8793", "@ref": "si62", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "36", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si61.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "328", "@ref": "si61", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si60.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "185", "@ref": "si60", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "37", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "236", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si59.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si59", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "49", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si58.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si58", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "196", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si57.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3747", "@ref": "si57", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "33", "@width": "153", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si56.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2481", "@ref": "si56", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si55.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si55", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si54.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "238", "@ref": "si54", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "40", "@width": "109", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si53.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2088", "@ref": "si53", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "50", "@width": "199", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si52.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "5019", "@ref": "si52", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si51.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "342", "@ref": "si51", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "41", "@width": "305", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si50.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "5370", "@ref": "si50", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "39", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "267", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "26", "@width": "299", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si49.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3990", "@ref": "si49", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si48.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "223", "@ref": "si48", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si47.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "215", "@ref": "si47", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "138", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si46.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "666", "@ref": "si46", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "128", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si45.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "628", "@ref": "si45", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "128", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si44.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "628", "@ref": "si44", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si43.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "203", "@ref": "si43", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si42.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "215", "@ref": "si42", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "107", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si41.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "481", "@ref": "si41", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "126", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si40.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "638", "@ref": "si40", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "185", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "51", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si39.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "328", "@ref": "si39", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "62", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si38.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "342", "@ref": "si38", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "75", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si37.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "382", "@ref": "si37", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "105", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si36.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "473", "@ref": "si36", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si35.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "204", "@ref": "si35", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "315", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si34.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1487", "@ref": "si34", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "120", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si33.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "693", "@ref": "si33", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "173", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si32.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "964", "@ref": "si32", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "210", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si31.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1037", "@ref": "si31", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "195", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si30.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1079", "@ref": "si30", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "506", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "76", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si29.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "476", "@ref": "si29", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "87", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si28.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "505", "@ref": "si28", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si27.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "261", "@ref": "si27", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si26.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "224", "@ref": "si26", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "16", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si25.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si25", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "139", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si24.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "619", "@ref": "si24", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "121", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si23.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "625", "@ref": "si23", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si22.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "261", "@ref": "si22", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "224", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "203", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "787", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "180", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "119", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "563", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "16", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "16", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "39", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "257", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "506", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si125.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "506", "@ref": "si125", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "39", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si124.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "257", "@ref": "si124", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "43", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si123.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "276", "@ref": "si123", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si122.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "506", "@ref": "si122", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "52", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si121.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "337", "@ref": "si121", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "60", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si120.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si120", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "55", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "337", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "54", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si119.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "349", "@ref": "si119", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "31", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si118.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "311", "@ref": "si118", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "54", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si117.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "418", "@ref": "si117", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si116.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "342", "@ref": "si116", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "27", "@width": "63", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si115.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "568", "@ref": "si115", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "47", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si114.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "296", "@ref": "si114", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si113.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "445", "@ref": "si113", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si112.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si112", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "32", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si111.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "295", "@ref": "si111", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "71", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si110.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "516", "@ref": "si110", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "39", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "257", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si109.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si109", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si108.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "218", "@ref": "si108", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si107.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si107", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si106.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "218", "@ref": "si106", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "43", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si105.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "276", "@ref": "si105", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si104.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "185", "@ref": "si104", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si103.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "185", "@ref": "si103", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "162", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si102.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2877", "@ref": "si102", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "39", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si101.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "257", "@ref": "si101", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si100.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "185", "@ref": "si100", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "94", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "624", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "27", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "273", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "446", "@width": "536", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "48886", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "93", "@width": "112", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2565", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "383", "@width": "544", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "21238", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "88", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "1928", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "409", "@width": "541", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "34154", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "93", "@width": "123", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2243", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "389", "@width": "530", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "27963", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "92", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2294", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "306", "@width": "641", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "99613", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "60", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3351", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "389", "@width": "531", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "33750", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "92", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2593", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "388", "@width": "532", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "34822", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "91", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2543", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "389", "@width": "531", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "32152", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "92", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2513", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "390", "@width": "535", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "27287", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "91", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000087-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2234", "@ref": "gr9", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/46649112949"}}
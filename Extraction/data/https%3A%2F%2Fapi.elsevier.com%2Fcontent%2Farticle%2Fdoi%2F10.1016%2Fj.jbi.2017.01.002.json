{"scopus-eid": "2-s2.0-85009374183", "originalText": "serial JL 272371 291210 291682 291870 291901 31 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2017-01-07 2017-01-07 2017-01-16 2017-01-16 2017-02-16T08:19:49 1-s2.0-S1532046417300023 S1532-0464(17)30002-3 S1532046417300023 10.1016/j.jbi.2017.01.002 S300 S300.1 FULL-TEXT 1-s2.0-S1532046416X00081 2018-02-02T01:20:01.705964Z 0 0 20170201 20170228 2017 2017-01-07T02:47:15.492651Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid highlightsabst primabst ref specialabst 1532-0464 15320464 true 66 66 C Volume 66 18 148 158 148 158 201702 February 2017 2017-02-01 2017-02-28 2017 Original research papers article fla \u00a9 2017 Elsevier Inc. ANEWMETHODCONTENTBASEDMEDICALIMAGERETRIEVALAPPLICATIONSCTIMAGINGSIGNRETRIEVAL MA L 1 Introduction 2 Related work 3 The proposed CBMIR method: FCSS 3.1 Visual similarity 3.2 Semantic similarity 3.3 Shortest path based retrieval 3.3.1 Weighted graph establishment 3.3.2 Shortest path computation and retrieval process 3.4 Application to CISL retrieval 4 Experiments 4.1 Experimental setup 4.1.1 Datasets 4.1.2 Evaluation criterion 4.1.3 Compared algorithms 4.2 Algorithm tuning 4.2.1 The selection of distance measures 4.2.2 The selection of kernel function for SVM 4.2.3 Parameter setting 4.3 Experimental results 4.3.1 Comparisons on top ranked results 4.3.2 Comparisons on AP and MAP 4.3.3 Comparisons on PR graph 4.3.4 Comparisons on retrieval examples 4.3.5 Comparisons on efficiency 5 Conclusions Acknowledgments References PARKIN 1999 33 64 D ABERLE 2001 65 68 D MA 2015 39 48 L MULLER 2004 1 23 H WANG 2011 1996 2011 J BALDI 2009 18 A QUELLEC 2010 227 241 G SUGANYA 2012 938 R ANDRE 2012 1276 1288 B YANG 2010 30 44 L OLIVEIRA 2010 289 297 D RAHMAN 2008 95 108 M AKAKIN 2012 758 769 H BAI 2010 861 874 X WANG 2011 2367 2374 J CORMEN 2000 T INTRODUCTIONALGORITHMS TRAVIS 2015 1243 1260 W MULLERHERMELINK 2004 146 147 H PATHOLOGYGENETICSTUMOURSLUNGPLEURATHYMUSHEARTINWORLDHEALTHORGANIZATIONCLASSIFICATIONTUMORS LIU 2015 635 647 X HAN 2015 648 656 G MAX2017X148 MAX2017X148X158 MAX2017X148XL MAX2017X148X158XL Full 2018-02-02T00:52:38Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ 2018-01-16T00:00:00.000Z UnderEmbargo http://creativecommons.org/licenses/by-nc-nd/4.0/ \u00a9 2017 Elsevier Inc. This article is made available under the Elsevier license. item S1532-0464(17)30002-3 S1532046417300023 1-s2.0-S1532046417300023 10.1016/j.jbi.2017.01.002 272371 2017-02-16T03:23:59.171376-05:00 2017-02-01 2017-02-28 1-s2.0-S1532046417300023-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/MAIN/application/pdf/34d354d8526423243bd16117879e467e/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/MAIN/application/pdf/34d354d8526423243bd16117879e467e/main.pdf main.pdf pdf true 2217713 MAIN 11 1-s2.0-S1532046417300023-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/PREVIEW/image/png/ef4f9e6a913ffb4a34ca1ad56134ebcc/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/PREVIEW/image/png/ef4f9e6a913ffb4a34ca1ad56134ebcc/main_1.png main_1.png png 59370 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046417300023-gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr10/THUMBNAIL/image/gif/04e261247b5e16d06ab78f47284eea04/gr10.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr10/THUMBNAIL/image/gif/04e261247b5e16d06ab78f47284eea04/gr10.sml gr10 gr10.sml sml 14756 164 194 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr11/THUMBNAIL/image/gif/80e2aa04233f5f8638690c7b05b9c335/gr11.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr11/THUMBNAIL/image/gif/80e2aa04233f5f8638690c7b05b9c335/gr11.sml gr11 gr11.sml sml 15781 164 186 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr2/THUMBNAIL/image/gif/07b5b25cc627aefd46ca8b736e9656bb/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr2/THUMBNAIL/image/gif/07b5b25cc627aefd46ca8b736e9656bb/gr2.sml gr2 gr2.sml sml 13300 121 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr3/THUMBNAIL/image/gif/c40cab8b521b4df9d5c5a55db7c147c7/gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr3/THUMBNAIL/image/gif/c40cab8b521b4df9d5c5a55db7c147c7/gr3.sml gr3 gr3.sml sml 6860 152 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr4/THUMBNAIL/image/gif/7409a84e4c0f2d140aa05c0c149a753a/gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr4/THUMBNAIL/image/gif/7409a84e4c0f2d140aa05c0c149a753a/gr4.sml gr4 gr4.sml sml 6980 151 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr5/THUMBNAIL/image/gif/51da68bd08fa0b78144fd2bb38df12dc/gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr5/THUMBNAIL/image/gif/51da68bd08fa0b78144fd2bb38df12dc/gr5.sml gr5 gr5.sml sml 22170 163 204 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr6/THUMBNAIL/image/gif/a760637a5453dcfbd2fd79ff9ed7bbff/gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr6/THUMBNAIL/image/gif/a760637a5453dcfbd2fd79ff9ed7bbff/gr6.sml gr6 gr6.sml sml 13720 157 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr7/THUMBNAIL/image/gif/45deb3684598bb412fcfa5bdcfe5c248/gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr7/THUMBNAIL/image/gif/45deb3684598bb412fcfa5bdcfe5c248/gr7.sml gr7 gr7.sml sml 6678 145 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr8/THUMBNAIL/image/gif/d488c4b6eee0a632feb68a4e7a3a9818/gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr8/THUMBNAIL/image/gif/d488c4b6eee0a632feb68a4e7a3a9818/gr8.sml gr8 gr8.sml sml 15593 164 205 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr9/THUMBNAIL/image/gif/16cbc844ff66dd9360ba2cc849a3bd57/gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr9/THUMBNAIL/image/gif/16cbc844ff66dd9360ba2cc849a3bd57/gr9.sml gr9 gr9.sml sml 17207 144 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/fx1/THUMBNAIL/image/gif/75c126df216d05740d19322e98ecbc04/fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/fx1/THUMBNAIL/image/gif/75c126df216d05740d19322e98ecbc04/fx1.sml fx1 true fx1.sml sml 14793 88 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr1/THUMBNAIL/image/gif/83e96702d98f111de449e85c71c99d8f/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr1/THUMBNAIL/image/gif/83e96702d98f111de449e85c71c99d8f/gr1.sml gr1 gr1.sml sml 4996 105 219 IMAGE-THUMBNAIL 1-s2.0-S1532046417300023-gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr10/DOWNSAMPLED/image/jpeg/c2fa2af45b668a481949fc9ee99989e9/gr10.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr10/DOWNSAMPLED/image/jpeg/c2fa2af45b668a481949fc9ee99989e9/gr10.jpg gr10 gr10.jpg jpg 60692 451 534 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr11/DOWNSAMPLED/image/jpeg/72a252acbf85364bab098340f5f42f01/gr11.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr11/DOWNSAMPLED/image/jpeg/72a252acbf85364bab098340f5f42f01/gr11.jpg gr11 gr11.jpg jpg 74627 470 533 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr2/DOWNSAMPLED/image/jpeg/1a685972e47fb746dce49e3aa0d5f138/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr2/DOWNSAMPLED/image/jpeg/1a685972e47fb746dce49e3aa0d5f138/gr2.jpg gr2 gr2.jpg jpg 63268 368 667 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr3/DOWNSAMPLED/image/jpeg/8114db7eba23a0552d755c448dbd22cd/gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr3/DOWNSAMPLED/image/jpeg/8114db7eba23a0552d755c448dbd22cd/gr3.jpg gr3 gr3.jpg jpg 21790 248 357 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr4/DOWNSAMPLED/image/jpeg/7c690acf03021b442a6f429e889e7491/gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr4/DOWNSAMPLED/image/jpeg/7c690acf03021b442a6f429e889e7491/gr4.jpg gr4 gr4.jpg jpg 21917 246 357 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr5/DOWNSAMPLED/image/jpeg/6acafdaee76501221b017b0e476005ba/gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr5/DOWNSAMPLED/image/jpeg/6acafdaee76501221b017b0e476005ba/gr5.jpg gr5 gr5.jpg jpg 62858 428 534 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr6/DOWNSAMPLED/image/jpeg/4f338acc59b413b6f92b1b04d3c064f3/gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr6/DOWNSAMPLED/image/jpeg/4f338acc59b413b6f92b1b04d3c064f3/gr6.jpg gr6 gr6.jpg jpg 29608 254 355 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr7/DOWNSAMPLED/image/jpeg/596cba42c459fbc50b6c6ffdef17bef9/gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr7/DOWNSAMPLED/image/jpeg/596cba42c459fbc50b6c6ffdef17bef9/gr7.jpg gr7 gr7.jpg jpg 16995 235 355 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr8/DOWNSAMPLED/image/jpeg/70537cf26ccdfc78cf77816a11f85945/gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr8/DOWNSAMPLED/image/jpeg/70537cf26ccdfc78cf77816a11f85945/gr8.jpg gr8 gr8.jpg jpg 28673 290 364 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr9/DOWNSAMPLED/image/jpeg/718909bb51c78d1e9591f85a98d58c31/gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr9/DOWNSAMPLED/image/jpeg/718909bb51c78d1e9591f85a98d58c31/gr9.jpg gr9 gr9.jpg jpg 86681 512 778 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/fx1/DOWNSAMPLED/image/jpeg/413ae83a112ab74be51357fd16c617ad/fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/fx1/DOWNSAMPLED/image/jpeg/413ae83a112ab74be51357fd16c617ad/fx1.jpg fx1 true fx1.jpg jpg 42647 200 500 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr1/DOWNSAMPLED/image/jpeg/727b01eabddf6f1d45a2fc4f88a1cbf7/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr1/DOWNSAMPLED/image/jpeg/727b01eabddf6f1d45a2fc4f88a1cbf7/gr1.jpg gr1 gr1.jpg jpg 15806 171 356 IMAGE-DOWNSAMPLED 1-s2.0-S1532046417300023-gr10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr10/HIGHRES/image/jpeg/979d08ef2a5d692255ae5c2ecb2beb4e/gr10_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr10/HIGHRES/image/jpeg/979d08ef2a5d692255ae5c2ecb2beb4e/gr10_lrg.jpg gr10 gr10_lrg.jpg jpg 381312 1997 2363 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr11_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr11/HIGHRES/image/jpeg/44e6a76c33500b000ec6335a3b88ec20/gr11_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr11/HIGHRES/image/jpeg/44e6a76c33500b000ec6335a3b88ec20/gr11_lrg.jpg gr11 gr11_lrg.jpg jpg 510008 2084 2362 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr2/HIGHRES/image/jpeg/bbd6357494a4eee03fafb5b986036f18/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr2/HIGHRES/image/jpeg/bbd6357494a4eee03fafb5b986036f18/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 202331 994 1801 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr3/HIGHRES/image/jpeg/aa4b4dde276fdd2523521dc2f78cf4f3/gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr3/HIGHRES/image/jpeg/aa4b4dde276fdd2523521dc2f78cf4f3/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 157502 1100 1581 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr4/HIGHRES/image/jpeg/760b1011ad028e93d4a49addc06db8de/gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr4/HIGHRES/image/jpeg/760b1011ad028e93d4a49addc06db8de/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 157113 1089 1581 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr5/HIGHRES/image/jpeg/fddf881c11d53b6e7a2b2fdb9e8721fe/gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr5/HIGHRES/image/jpeg/fddf881c11d53b6e7a2b2fdb9e8721fe/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 400273 1897 2367 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr6/HIGHRES/image/jpeg/b7b696616f531459746158f45da75f06/gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr6/HIGHRES/image/jpeg/b7b696616f531459746158f45da75f06/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 78794 686 959 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr7/HIGHRES/image/jpeg/a5abd492b9653bd769b9c8bc22c84301/gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr7/HIGHRES/image/jpeg/a5abd492b9653bd769b9c8bc22c84301/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 101045 1041 1575 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr8/HIGHRES/image/jpeg/41bd0aef5b5b1eff3bca92803b244601/gr8_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr8/HIGHRES/image/jpeg/41bd0aef5b5b1eff3bca92803b244601/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 69042 786 985 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr9/HIGHRES/image/jpeg/a393b202ba980dc8883216e404f2d18f/gr9_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr9/HIGHRES/image/jpeg/a393b202ba980dc8883216e404f2d18f/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 258090 1383 2101 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/fx1/HIGHRES/image/jpeg/eab5cfd7e0c471661b5234ae313a991f/fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/fx1/HIGHRES/image/jpeg/eab5cfd7e0c471661b5234ae313a991f/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 104433 531 1328 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/gr1/HIGHRES/image/jpeg/922d8cb6ed95e46e2d9a683000edb143/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/gr1/HIGHRES/image/jpeg/922d8cb6ed95e46e2d9a683000edb143/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 104940 756 1578 IMAGE-HIGH-RES 1-s2.0-S1532046417300023-si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/d7479da553880b18b7988eb1c159f425/si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/d7479da553880b18b7988eb1c159f425/si1.gif si1 si1.gif gif 198 15 10 ALTIMG 1-s2.0-S1532046417300023-si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/7e36df60ed0702ab072b813201e322ec/si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/7e36df60ed0702ab072b813201e322ec/si10.gif si10 si10.gif gif 243 15 20 ALTIMG 1-s2.0-S1532046417300023-si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/b9b81b8366fc3d1d3a26e5d67f62bb75/si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/b9b81b8366fc3d1d3a26e5d67f62bb75/si13.gif si13 si13.gif gif 208 11 14 ALTIMG 1-s2.0-S1532046417300023-si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/1ca4fa23d8789738d03a8323d3f04f6b/si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/1ca4fa23d8789738d03a8323d3f04f6b/si14.gif si14 si14.gif gif 203 14 10 ALTIMG 1-s2.0-S1532046417300023-si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/c5b92bd12d05355dcd268968b0d43339/si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/c5b92bd12d05355dcd268968b0d43339/si15.gif si15 si15.gif gif 202 12 14 ALTIMG 1-s2.0-S1532046417300023-si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/fc92fbdbdea91cd676cd9b87b98a45cc/si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/fc92fbdbdea91cd676cd9b87b98a45cc/si16.gif si16 si16.gif gif 208 11 14 ALTIMG 1-s2.0-S1532046417300023-si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/26e4ece7eabb107e43a16d825b5d6719/si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/26e4ece7eabb107e43a16d825b5d6719/si17.gif si17 si17.gif gif 221 13 14 ALTIMG 1-s2.0-S1532046417300023-si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/9402a961d7d63a9d2f3541d804b68cc5/si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/9402a961d7d63a9d2f3541d804b68cc5/si18.gif si18 si18.gif gif 316 17 40 ALTIMG 1-s2.0-S1532046417300023-si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/a36c2e7a0d19da5e0738c7c06bb448f1/si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/a36c2e7a0d19da5e0738c7c06bb448f1/si19.gif si19 si19.gif gif 216 15 15 ALTIMG 1-s2.0-S1532046417300023-si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/2a969c9fec8ac5526703d43dd9193199/si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/2a969c9fec8ac5526703d43dd9193199/si2.gif si2 si2.gif gif 204 17 10 ALTIMG 1-s2.0-S1532046417300023-si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/b83ec1904bc248e4097dc3e7e311426e/si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/b83ec1904bc248e4097dc3e7e311426e/si20.gif si20 si20.gif gif 662 17 121 ALTIMG 1-s2.0-S1532046417300023-si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/cdcaf5d3203f85f3f3417de79b1df308/si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/cdcaf5d3203f85f3f3417de79b1df308/si21.gif si21 si21.gif gif 389 17 46 ALTIMG 1-s2.0-S1532046417300023-si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/b4f4f2ddc7431b1e1339096411905e65/si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/b4f4f2ddc7431b1e1339096411905e65/si24.gif si24 si24.gif gif 217 17 13 ALTIMG 1-s2.0-S1532046417300023-si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/af4f89a95cbb59f89990455421f82ae9/si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/af4f89a95cbb59f89990455421f82ae9/si25.gif si25 si25.gif gif 212 14 13 ALTIMG 1-s2.0-S1532046417300023-si26.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/8decb1cbc909524360245f81df644d18/si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/8decb1cbc909524360245f81df644d18/si26.gif si26 si26.gif gif 245 18 20 ALTIMG 1-s2.0-S1532046417300023-si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/b4139d4487adf0fda4a4c4dbd2443f10/si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/b4139d4487adf0fda4a4c4dbd2443f10/si28.gif si28 si28.gif gif 451 18 58 ALTIMG 1-s2.0-S1532046417300023-si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/03578cc1a4bfe8a26da459950936b507/si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/03578cc1a4bfe8a26da459950936b507/si29.gif si29 si29.gif gif 303 17 36 ALTIMG 1-s2.0-S1532046417300023-si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/4c77c80f861547642c880317a4a71e6b/si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/4c77c80f861547642c880317a4a71e6b/si3.gif si3 si3.gif gif 293 23 21 ALTIMG 1-s2.0-S1532046417300023-si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/577a40dc6e9e9e4d249b534f97518527/si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/577a40dc6e9e9e4d249b534f97518527/si31.gif si31 si31.gif gif 437 17 73 ALTIMG 1-s2.0-S1532046417300023-si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/65cf6f735895fff3739c708f0923ffae/si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/65cf6f735895fff3739c708f0923ffae/si32.gif si32 si32.gif gif 728 17 196 ALTIMG 1-s2.0-S1532046417300023-si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/395880781f04dcaef59eb7a76d8d76ab/si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/395880781f04dcaef59eb7a76d8d76ab/si33.gif si33 si33.gif gif 318 13 33 ALTIMG 1-s2.0-S1532046417300023-si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/c354303e7a13e1fcd39f14420a5775c7/si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/c354303e7a13e1fcd39f14420a5775c7/si34.gif si34 si34.gif gif 259 15 21 ALTIMG 1-s2.0-S1532046417300023-si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/235d25659042eb3691f52fec3d9b4022/si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/235d25659042eb3691f52fec3d9b4022/si38.gif si38 si38.gif gif 286 23 19 ALTIMG 1-s2.0-S1532046417300023-si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/2a94b4904d3db852ebe07e23c3f71bbd/si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/2a94b4904d3db852ebe07e23c3f71bbd/si39.gif si39 si39.gif gif 195 10 11 ALTIMG 1-s2.0-S1532046417300023-si40.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si40.gif si40 si40.gif gif 211 16 11 ALTIMG 1-s2.0-S1532046417300023-si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/050d6865b84ec1a289fe07093f54855a/si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/050d6865b84ec1a289fe07093f54855a/si42.gif si42 si42.gif gif 249 15 24 ALTIMG 1-s2.0-S1532046417300023-si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/f46b107e01ff1b4ea28ed73ff4ea0362/si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/f46b107e01ff1b4ea28ed73ff4ea0362/si43.gif si43 si43.gif gif 247 15 24 ALTIMG 1-s2.0-S1532046417300023-si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/8537d955851815b1129123b618479362/si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/8537d955851815b1129123b618479362/si46.gif si46 si46.gif gif 465 17 54 ALTIMG 1-s2.0-S1532046417300023-si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/208c195793a90f96e71c10096a9c8e77/si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/208c195793a90f96e71c10096a9c8e77/si49.gif si49 si49.gif gif 460 17 60 ALTIMG 1-s2.0-S1532046417300023-si52.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/494a69825159d532d5e3b09e6590fde2/si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/494a69825159d532d5e3b09e6590fde2/si52.gif si52 si52.gif gif 252 15 20 ALTIMG 1-s2.0-S1532046417300023-si54.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/4edad6c6d3f28b6c199f8849ecd6a244/si54.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/4edad6c6d3f28b6c199f8849ecd6a244/si54.gif si54 si54.gif gif 208 9 15 ALTIMG 1-s2.0-S1532046417300023-si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/8ffdba008c5034cd3460c0b1290f839c/si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/8ffdba008c5034cd3460c0b1290f839c/si55.gif si55 si55.gif gif 269 16 40 ALTIMG 1-s2.0-S1532046417300023-si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/eb9e379b9a306c4e8379c41c0cc94c92/si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/eb9e379b9a306c4e8379c41c0cc94c92/si6.gif si6 si6.gif gif 212 14 14 ALTIMG 1-s2.0-S1532046417300023-si64.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/d591f916e142f25210b1f1a43be50797/si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/d591f916e142f25210b1f1a43be50797/si64.gif si64 si64.gif gif 335 16 33 ALTIMG 1-s2.0-S1532046417300023-si69.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/972c1b1471483d00741a075d407f9c6a/si69.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/972c1b1471483d00741a075d407f9c6a/si69.gif si69 si69.gif gif 974 30 179 ALTIMG 1-s2.0-S1532046417300023-si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/885ee69436a9fcebe76170db83baec8b/si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/885ee69436a9fcebe76170db83baec8b/si7.gif si7 si7.gif gif 221 17 14 ALTIMG 1-s2.0-S1532046417300023-si70.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/a0136dad34be2cc12d17a94ab37d7b4b/si70.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/a0136dad34be2cc12d17a94ab37d7b4b/si70.gif si70 si70.gif gif 736 23 150 ALTIMG 1-s2.0-S1532046417300023-si71.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/542a4ee66357132466caf94bee9f6355/si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/542a4ee66357132466caf94bee9f6355/si71.gif si71 si71.gif gif 890 24 170 ALTIMG 1-s2.0-S1532046417300023-si72.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/9b1fcee4bb0840c752fca2af5e3f1a8b/si72.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/9b1fcee4bb0840c752fca2af5e3f1a8b/si72.gif si72 si72.gif gif 833 38 141 ALTIMG 1-s2.0-S1532046417300023-si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/6a05078a5baade80a8a67015f57a0684/si73.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/6a05078a5baade80a8a67015f57a0684/si73.gif si73 si73.gif gif 1336 38 252 ALTIMG 1-s2.0-S1532046417300023-si74.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/ba77d659322f64e56822866da5ae975e/si74.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/ba77d659322f64e56822866da5ae975e/si74.gif si74 si74.gif gif 896 22 207 ALTIMG 1-s2.0-S1532046417300023-si75.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/d62c32bb1b43e9fcf20ee512ef1188c4/si75.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/d62c32bb1b43e9fcf20ee512ef1188c4/si75.gif si75 si75.gif gif 302 13 41 ALTIMG 1-s2.0-S1532046417300023-si76.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/650e0eb5ebba0d31a378538577945af1/si76.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/650e0eb5ebba0d31a378538577945af1/si76.gif si76 si76.gif gif 602 22 110 ALTIMG 1-s2.0-S1532046417300023-si77.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/839c9a747fb21cda3d87090e44385c01/si77.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/839c9a747fb21cda3d87090e44385c01/si77.gif si77 si77.gif gif 720 20 139 ALTIMG 1-s2.0-S1532046417300023-si78.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/67af232014e1e17ef1cdd2f039981f27/si78.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/67af232014e1e17ef1cdd2f039981f27/si78.gif si78 si78.gif gif 693 17 138 ALTIMG 1-s2.0-S1532046417300023-si79.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/40f1069cb89d5c93de448778ef2381ea/si79.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/40f1069cb89d5c93de448778ef2381ea/si79.gif si79 si79.gif gif 548 17 134 ALTIMG 1-s2.0-S1532046417300023-si81.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/b709796ef1212d014608d28893c53ca3/si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/b709796ef1212d014608d28893c53ca3/si81.gif si81 si81.gif gif 418 17 86 ALTIMG 1-s2.0-S1532046417300023-si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/51d28067989c710f0055b0208c5c3728/si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/51d28067989c710f0055b0208c5c3728/si12.gif si12 si12.gif gif 1243 48 194 ALTIMG 1-s2.0-S1532046417300023-si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/08abfe26970c72bc1db39595e5cc5914/si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/08abfe26970c72bc1db39595e5cc5914/si23.gif si23 si23.gif gif 2047 47 290 ALTIMG 1-s2.0-S1532046417300023-si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/18a62b3cd17263778148f71504abc62e/si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/18a62b3cd17263778148f71504abc62e/si41.gif si41 si41.gif gif 3279 55 461 ALTIMG 1-s2.0-S1532046417300023-si48.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/5576311bed61fc2b6f12f6d46f08be0e/si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/5576311bed61fc2b6f12f6d46f08be0e/si48.gif si48 si48.gif gif 1220 45 181 ALTIMG 1-s2.0-S1532046417300023-si50.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/5bffcbfbecaa431328976c971021762d/si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/5bffcbfbecaa431328976c971021762d/si50.gif si50 si50.gif gif 2032 44 369 ALTIMG 1-s2.0-S1532046417300023-si51.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/e58252efc8b90793fe983a1f0a06c157/si51.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/e58252efc8b90793fe983a1f0a06c157/si51.gif si51 si51.gif gif 1642 47 258 ALTIMG 1-s2.0-S1532046417300023-si53.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046417300023/STRIPIN/image/gif/dc6b58d0edb9b433142258849c337e1b/si53.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046417300023/STRIPIN/image/gif/dc6b58d0edb9b433142258849c337e1b/si53.gif si53 si53.gif gif 1116 46 154 ALTIMG YJBIN 2703 S1532-0464(17)30002-3 10.1016/j.jbi.2017.01.002 Elsevier Inc. Fig. 1 The illustration of the limitation of pairwise similarity measure and the advantage of context-sensitive similarity measure, where the boxes denote the query images, the circles denote the database images. (a) The retrieval result obtained by the pairwise similarity measures; (b) the retrieval result by the context-sensitive similarity measures. Fig. 2 An overview of the proposed retrieval method, FCSS. Fig. 3 The illustration of the weighted graph, where the gray node Q denotes the query image and the white nodes denote the images in the database. Fig. 4 The illustration of the final similarity between the query image and the images in the database, where the red lines denote the shortest paths. Fig. 5 The instances of nine CISL categories. The smaller rectangular boxes in lung CT images are magnified to show the details of the images. Fig. 6 The values of parameters and the resultant MAP values from our method, where x-axis, y-axis, and z-axis represent the value of \u03b1 , \u03b2 , and MAP, respectively. Fig. 7 the comparisons of average p @ n at five top ranks from the results obtained by our method and other methods under comparison. Fig. 8 PR graphs from M1, M2, M3 and FCSS over the query set. Fig. 9 PR graphs from M1, M2, M3 and our method FCSS over: (a)-(f) a subset of the query set, in which the classification accuracies is 0%, 11.11%, 33.33%, 55.56%, 77.78% and 100%, respectively. Fig. 10 The top 5 images in the retrieval results of method M1, M2, M3 and our method FCSS for the query example classified correctly, where the blue boxes indicate irrelevant images and the others are relevant. Fig. 11 The top 5 images in the retrieval results of method M1, M2, M3 and our method FCSS for the example classified incorrectly, where the blue boxes indicate irrelevant images and the others are relevant. Table 1 The considered distance measure functions. Euclidean D ij V = \u2211 k = 1 L ( F i , k - F j , k ) 2 City block D ij V = \u2211 k = 1 L | F i , k - F j , k | Chebychev D ij V = MAX k { | F i , k - F j , k | } Cosine D ij V = 1 - F i F j \u2032 ( F i F i \u2032 ) ( F j F j \u2032 ) Correlation D ij V = 1 - ( F i - F \u00af i ) ( F j - F \u00af j ) \u2032 ( F i - F \u00af i ) ( F i - F \u00af i ) \u2032 ( F j - F \u00af j ) ( F j - F \u00af j ) \u2032 , where F \u00af i = 1 L \u2211 k = 1 L F ik , F \u00af j = 1 L \u2211 k = 1 L F jk Table 2 The numbers of examples and patients for each CISL. CISL S1 S2 NoS NoP NoS NoP GGO 22 13 23 12 Lobulation 21 12 20 9 Calcification 23 12 24 8 CV 74 36 73 39 Spiculation 14 9 15 9 PI 40 13 40 13 AB 12 12 11 10 BMP 40 13 41 16 OP 9 9 9 7 Total 255 129 256 123 Table 3 The MAPs from M1 with different distance measure functions, where the bold value is the maximum value of average MAP for the different distance measure functions. Euclidean City block Chebychev Correlation Cosine MAP(10) 0.8798 0.8884 0.8594 0.8896 0.8915 MAP(20) 0.8147 0.8192 0.7868 0.8139 0.8221 MAP(30) 0.7724 0.7734 0.7443 0.7669 0.7785 MAP(50) 0.7256 0.7148 0.6948 0.7137 0.7256 MAP(100) 0.6523 0.6439 0.6260 0.6443 0.6568 Average 0.7690 0.7679 0.7423 0.7657 0.7749 Table 4 The experimental results from the SVM with the different kernels and parameters, where the bold value is the maximum accuracy for the SVM with different kernels and parameters. Linear Polynomial Gaussian Sigmoid Function u \u2032 \u2217 v ( g \u2217 u \u2032 \u2217 v + c ) d exp ( - g \u2217 | | u - v | | 2 ) tanh ( g \u2217 u \u2032 \u2217 v + c ) Parameters g = 1 , c = 0 , d = 3 g = 1 c = 0 , d = 3 Accuracy (%) 81.96 81.96 86.27 75.29 Table 5 The APs for each CISL and MAP for all CISLs from our method and compared methods, M1, M2, and M3. M1 M2 M3 FCSS M1 M2 M3 FCSS AP(GGO) N=10 0.75 0.7692 0.5 1 AP(lobulation) N=10 0.71 0.7179 0.5 0.95 N=20 0.65 0.6923 0.5 0.95 N=20 0.652 0.6634 0.5 0.775 N=30 0.5 0.5299 0.5 0.7167 N=30 0.4861 0.4957 0.5 0.5667 N=50 0.32 0.3393 0.43 0.43 N=50 0.3 0.3177 0.43 0.36 N=100 0.17 0.1744 0.215 0.215 N=100 0.155 0.1592 0.215 0.21 AP(calcification) N=10 0.4 0.4013 0.5 0.55 AP(CV) N=10 0.4 0.411 0.5 0.55 N=20 0.25 0.2564 0.6 0.5 N=20 0.575 0.5128 0.5 0.525 N=30 0.2331 0.2222 0.5 0.3667 N=30 0.4667 0.479 0.5 0.5167 N=50 0.22 0.2051 0.33 0.26 N=50 0.47 0.4873 0.59 0.52 N=100 0.135 0.1381 0.195 0.215 N=100 0.411 0.4513 0.53 0.58 AP(speculation) N=10 0.3 0.2564 0.5 0.55 AP(PI) N=10 0.6 0.6102 0.5 0.65 N=20 0.225 0.2262 0.375 0.3 N=20 0.52 0.5285 0.575 0.65 N=30 0.2 0.188 0.25 0.2167 N=30 0.4651 0.5128 0.6333 0.6833 N=50 0.16 0.1538 0.17 0.16 N=50 0.46 0.4615 0.58 0.61 N=100 0.12 0.1282 0.13 0.11 N=100 0.3406 0.349 0.355 0.365 AP(AB) N=10 0.45 0.4915 0.45 0.4 AP(BMP) N=10 0.74 0.767 0.55 0.55 N=20 0.25 0.2801 0.225 0.225 N=20 0.7276 0.74 0.75 0.775 N=30 0.1667 0.188 0.15 0.15 N=30 0.7 0.7009 0.75 0.85 N=50 0.14 0.1333 0.09 0.1 N=50 0.55 0.5846 0.58 0.82 N=100 0.08 0.0818 0.07 0.055 N=100 0.31 0.357 0.31 0.41 AP(OP) N=10 0.45 0.4598 0.45 0.5 MAP N=10 0.5333 0.5427 0.4944 0.6333 N=20 0.3 0.3607 0.225 0.275 N=20 0.4611 0.4734 0.4722 0.5528 N=30 0.2163 0.2051 0.15 0.1833 N=30 0.3815 0.3912 0.437 0.4722 N=50 0.16 0.1333 0.09 0.15 N=50 0.3089 0.3128 0.3656 0.3789 N=100 0.0841 0.0872 0.08 0.1 N=100 0.2006 0.2140 0.2333 0.2511 Table 6 The comparison of running time (millisecond) between our method and the others. Methods M1 M2 M3 FCSS Time 0.19 44.50 0.19 46.61 A new method of content based medical image retrieval and its applications to CT imaging sign retrieval Ling Ma a Xiabi Liu a \u204e liuxiabi@bit.edu.cn Yan Gao a Yanfeng Zhao b Xinming Zhao b Chunwu Zhou b a Beijing Lab of Intelligent Information Technology, School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China Beijing Lab of Intelligent Information Technology School of Computer Science and Technology Beijing Institute of Technology Beijing 100081 China b Dept. of Imaging Diagnosis, Cancer Hospital, Chinese Academy of Medical Sciences, Beijing 100021, China Dept. of Imaging Diagnosis Cancer Hospital Chinese Academy of Medical Sciences Beijing 100021 China \u204e Corresponding author. Graphical abstract Highlights \u2022 Common CT Imaging Signs of Lung Diseases (CISL) play important roles in the diagnosis of lung diseases. \u2022 It is a new content based medical image retrieval method for retrieving the CISLs. \u2022 It combines the visual similarity and semantic similarity for a more accurate pairwise similarity measure. \u2022 It applies the shortest path algorithm to capture the intrinsic structure of the data manifold. \u2022 Our method is robust and real-time. Abstract This paper proposes a new method of content based medical image retrieval through considering fused, context-sensitive similarity. Firstly, we fuse the semantic and visual similarities between the query image and each image in the database as their pairwise similarities. Then, we construct a weighted graph whose nodes represent the images and edges measure their pairwise similarities. By using the shortest path algorithm over the weighted graph, we obtain a new similarity measure, context-sensitive similarity measure, between the query image and each database image to complete the retrieval process. Actually, we use the fused pairwise similarity to narrow down the semantic gap for obtaining a more accurate pairwise similarity measure, and spread it on the intrinsic data manifold to achieve the context-sensitive similarity for a better retrieval performance. The proposed method has been evaluated on the retrieval of the Common CT Imaging Signs of Lung Diseases (CISLs) and achieved not only better retrieval results but also the satisfactory computation efficiency. Keywords Medical image retrieval Content-based image retrieval Lung CT images Semantic information Visual information Shortest path Common CT Imaging Signs of Lung Diseases (CISLs) 1 Introduction Lung diseases are one of the most common causes of death and disability worldwide [1]. Since CT imaging can provide the necessary information for displaying whether the lung tissue is normal or abnormal, it is used by radiologists as a basis to recognize the lung diseases [2]. However, it is labor-consuming or even difficult for radiologists, especially for junior ones, to detect diseases by analyzing CT scans. If we can provide relevant past cases to radiologists, the diagnosis efficiency and accuracy can be improved. This problem can be addressed by using the content-based medical image retrieval (CBMIR) technique. In this paper, we propose a new CBMIR method by capturing the geometry of the underlying manifold. The proposed method is called FCSS (Fused Context-Sensitive Similarity) for short. Firstly, we obtain the semantic similarity between the query image and the database image according to the classification information, then calculate their visual similarities according to their distance in the visual feature space. Based on the two types of similarities above, we achieve the fused pairwise similarity. Secondly, a weighted graph involving the query image and all database images is constructed, and the shortest path over the graph is computed as the context-sensitive similarity between the query image and each database image. Finally, the database images are ranked and returned according to fused context-sensitive similarity. We apply the proposed CBMIR method to retrieve Common CT Imaging Signs of Lung Diseases (CISLs), which frequently appear in patients\u2019 lung CT findings and play important roles in the diagnosis of lung diseases [3]. Our method can provide a useful tool for not only diagnostics but also medical research and teaching. A radiologist can make a diagnosis by reading the CT findings and analyzing the CISLs. But the correlation between CT imaging signs and diseases is complicated. The same category of CT imaging signs may be observed in the images corresponding to different diseases. Different categories of CT imaging signs may also appear in the images with the same disease. Since our retrieval method can search some similar historical CT scans and their diagnosis reports, the radiologist can improve the diagnosis accuracy by analyzing similar cases. In addition, by analyzing the retrieved similar historical CT scans and their reports, medical students can learn how to identify the CISLs and make a diagnosis of disease, and the researchers can study the relationship between the CISLs and diseases for improved diagnostic accuracy. In summary, our retrieval method is promising for applications in the computer aided diagnosis, medical research and teaching. Furthermore, compared with CT images, radiographs use a small amount of radiation that passes through the body to quickly capture a single image of the anatomy. If we apply our method, which is based on the image information, on the radiograph, our effectiveness could be affected by its blended contours. Even some CISLs, such as small GGO, are not visualized on chest radiographs, so it is difficult to apply our method for the CISLs retrieval to the radiographs. Hence, our method is not recommended for the retrieval on the radiographs. The rest of this paper is organized as follows. Section 2 reviews related works on CBMIR. Section 3 presents our method and its applications to CISL retrieval. The experiments are discussed in Section 4. We conclude in Section 5. 2 Related work As pointed out by M\u00fcller et al. [4,5] and Depeursinge et al. [6], CBMIR has become increasingly important and the current methods can be organized into two main categories on the basis of the types of extracted features: low-level (visual features) based and high-level (semantic information) based. The low-level features based CBMIR methods [7\u201310] complete the retrieval of medical images according to the similarities between low-level image features. Wang et al. [7] assigned local descriptors to visual words by quadratic programming (QP) assignment, weighed the visual words by the boosting method and used the enhanced Jensen-Shannon divergence as the similarity measure to improve discriminative power. Ballerini et al. [8] extracted low-level features, including color covariance-based features and texture features, and used the Bhattacharyya distance metric and Euclidean distance to measure the similarity of those features, respectively. Then, they aggregated the two similarity distance measures into a final similarity matching function in a weighted-sum form to search for similar skin lesions. Baldi et al. [9] developed a CBMIR method based on color and texture features and a hierarchical multi-scale computation of the Bhattacharyya distance measure. Quellec et al. [10] built image signatures based on wavelet features of images, then defined a distance function to measure their similarity and perform medical image retrieval. The high-level based methods retrieve images according to their semantic categories, such as disease categories, diagnosis of diseases (benign or malignant), etc. Rahman et al. [11] mapped low-level features, including color and texture moment-based features, to semantic concepts, and involved the correlations and structural relationships among these visual concepts to construct new features. Then they computed the Euclidean distance of these new features as their similarities to retrieve medical images. Suganya et al. [12] applied the Support Vector Machine (SVM) to classify semantic concepts, such as liver cyst, alcoholic cirrhosis, carcinoma and normal liver. The returned results are the images having the same semantic concept with the query one. Andr\u00e9 et al. [13] transformed visual words into semantic signatures by using their intuitive Fisher-based method. Then they used L2 norm as the semantic similarity distance of semantic signatures for retrieval. Yang et al. [14] used the side information, which was a form of pairwise similarity constraints of the semantic concepts, to learn an optimal distance metric to retrieve similar medical images. Oliveira et al. [15] used the probability output by SVM as the similarities between the database images and the query image to perform mammography retrieval. Rahman et al. [16] trained a SVM classifier to output the vector of confidence probabilities of pre-defined image categories. Then, they computed the cosine distance of the vectors of the query image and database images as their similarities to complete the retrieval process. As described above, the existing methods usually utilize the low-level features or high-level semantic information individually. However, there is a semantic gap between low-level image features and high-level semantic concepts. Thus it could be better to combine the visual features and semantic ones for retrieval, such as the work of Akakin et al. [17]. They introduced a hierarchical strategy to combine the two sources of information for retrieval. In the first tier, the query image is classified into Neuroblastoma or follicular lymphoma. In the second tier, they computed the visual similarities of the images in the same class with the query one obtained in the first tier, to complete the retrieval. Furthermore, the existing CBMIR methods usually focus on only pairwise similarity, i.e., focus on the relationship between the query image and each database image, but ignore the structure of the underlying data manifold. Actually the underlying structure of the database is important and can be used to improve the retrieval performance. We show a toy problem in Fig. 1 to illustrate the importance of the data manifold for retrieval. In Fig. 1, the red and green boxes Q1 and Q2 represent two query images, respectively, and the circles represent the images in the database. The retrieval results are marked in the same color as the corresponding query one. We obtain the retrieval results by computing the pairwise similarity and the context-sensitive similarity. We show them in Fig.1a and b, respectively. Sometimes the images in the database are related to each other, in such cases the retrieval result based on the pairwise similarity is unsatisfactory, as shown in Fig.1a. We can obtain the context sensitive similarity by propagating the pairwise similarity through the manifold to improve the performance, as shown in Fig.1b. Therefore, retrieval methods aim at capturing the intrinsic structure of the data manifold in recent work [18\u201320]. Donoser et al. [21] revisited these existing methods based on the context sensitive similarity and introduced a generic similarity diffusion framework. At present, the existing context-sensitive similarity based methods focus on only visual relationship of images and ignore the semantic information. As indicated above, combining the visual and semantic information is also important for improving retrieval performance. Thus, in our proposed CBMIR method, we not only combine the visual and semantic information together to overcome their limitation, but also utilize the underlying structure of the database for a better retrieval performance. To our knowledge, this is the first such work on medical image retrieval. 3 The proposed CBMIR method: FCSS The architecture of the proposed retrieval method called Fused Context-Sensitive Similarity (FCSS) is schematized in Fig. 2 . To obtain a better retrieval performance, we consider two parts. One improves the pairwise measure by simultaneously combining the visual similarity and semantic similarity. Based on the fused pairwise similarity, a weighted graph is constructed to represent the query and database images. Then, we capture the intrinsic structure of the data manifold by applying the shortest path algorithm over the graph to achieve the context-sensitive similarity, according to which we can discover the similarity between the query image and each image in the database with more accuracy. 3.1 Visual similarity We apply commonly used distance metrics to evaluate the visual similarity between two images, including Euclidean, City block, Chebychev, Cosine and Correlation. Let I i and I j be two images, D ij V be the visual similarity between I i and I j , F i and F j be the feature vectors from I i and I j , respectively, F ik be the k-th element in F i , and L be the dimension of feature vectors, then the computation equations of these distances are listed in Table 1 . 3.2 Semantic similarity We can derive the semantic concepts by using an available classifier. In this work, we choose SVM [22] as the classifier owing to the fact that the SVM is powerful for problems characterized by small samples. SVM was first designed for binary classification and the optimization problem is generalized to learn a hyperplane for separating two classes of data points with maximum margin. The hyperplane function is defined by (1) g ( x ) = \u2211 i = 1 N a i y i K ( x i , X ) + b , where N is the number of training samples, a i and b are the parameters learned from the training data, X and x i is the classified pattern and the i-th training sample, respectively, y i is the label of the i-th sample, which is 1 or -1, and K ( \u00b7 , \u00b7 ) is a kernel function. In practice, we often have to tackle problems involving more than 2 classes, such as the classification of CISLs in this paper. We use the SVM binary classifiers to build a SVM multi-class classifier. Let NoC be the number of classes and C i be the i-th class. We employ an one-versus-one method to train NoC ( NoC - 1 ) / 2 different two-class SVMs on all possible pairs of classes and combine them to estimate the final output, including the classification decision and the probability estimate P ( C i | I ) for pattern I and each class C i . Then the semantic similarity between the query image and the images in the database is computed as (2) D qd S = D S ( I q , I d ) = - log ( P ( C I d | I q ) ) \u2211 i = 1 NoC - log ( P ( C i | I q ) ) , where I q and I d represent the query image and an image in the database, respectively, C I d represent the true category of the image I d in the database. Obviously, the higher P ( C I d | I q ) is, the more similar they are. Hence, we use the operator \u2018 - log \u2019 to transform the semantic similarity into a value which is in inverse proportion to P ( C I d | I q ) , and normalize the semantic similarity to between 0 and 1. 3.3 Shortest path based retrieval 3.3.1 Weighted graph establishment Based on the visual and semantic similarities described above, we construct a weighted graph G = ( V , E ) , which is illustrated in Fig. 3 . Node Q labeled with gray background represents the query image and the nodes { I 1 , \u2026 , I i , I i + 1 , I i + 2 , \u2026 , I NoD } ( NoD is the number of images in the databases) with white background represent the database images, respectively. As shown in this example, we consider not only the similarities between the query image and images in the databases, but also those between the database images. For the weights between each pair of database images, we only consider the visual similarity between them. As for the weights between the query image and database images, we consider both the visual and semantic similarities between them. Let w ij be the edge weight between I i and I j , D ij V and D ij S be the visual and semantic similarity described in s 3.1\u20133.2, \u03b1 and \u03b2 be two coefficients to make a tradeoff between the impacts of the two types of similarities, and their sum be one. Then the weights between nodes are computed as (3) w ij = \u03b1 D ij S + \u03b2 D ij V if I i or I j is a query image D ij V if both I i and I j are the database images 3.3.2 Shortest path computation and retrieval process The final similarity between the query image and each database image can be calculated based on the shortest path between them in the weighted graph. We employ the well-known Dijkstra\u2019s algorithm [23] to construct a shortest path tree, where the root node and the leaf nodes represent the query image and database images, respectively, the path from the root to the leaf is its shortest path, and its length is their final similarity value. Fig. 4 illustrates an example of shortest path computation, where the red lines represent the shortest paths and the corresponding length values are taken as their similarities. For example, the final similarity score between Q and I i + 2 in Fig. 4 is not the pairwise similarity between them, but the sum of the similarity score between Q and I i + 3 and that between I i + 2 and I i + 3 . It shows that our final similarity is a context-sensitive similarity which propagates the visual-semantic fused pairwise similarity through the data manifold. According to the computed final similarities between the query image and the images in the database, we complete the retrieval by returning the top ranked images in ascending order of their similarities. 3.4 Application to CISL retrieval The CISLs are the well-known categories of CT imaging signs of lung diseases that frequently appear in patients\u2019 lung CT images and play important roles in the diagnosis of lung diseases. Nine categories of CISLs are considered, including Ground Glass Opacity (GGO), lobulation, Cavity & Vacuolous (CV), spiculation, Pleural Indentation (PI), Obstructive Pneumonia (OP), calcification, Air Bronchogram (AB), and Bronchial Mucus Plugs (BMP) [3]. Although that taxonomy is not complete, the nine CT signs are really often encountered and widely used in the diagnosis of lung diseases [24\u201325]. Ground glass opacity (GGO), small non-solid nodules, can be identified as areas of increased opacification with distinct borders, not completely obscuring the underlying lung parenchyma on CT scan. Resection of GGOs has shown a range of pathology including benign disease in up to 30%, atypical adenomatous hyperplasia in 10\u201377%, bronchioloalveolar carcinoma in up to 50% and invasive adenocarcinoma in 10\u201325% of cases. Lobulation is dependent on the ingrowth of connective tissue septa containing fibroblasts derived from perithymic mesenchyme. It is one of the microscopic features of the squamous dysplasia and carcinoma in situ. Cavity and Vacuolous (CV) is a gas-filled space, seen as a lucency or low-attenuation area. They may exist in the pulmonary synovial sarcoma or squamous cell papilloma. Speculation is a roughly set of lines radiating from a central point or region. It is caused by the intrusion of cancer into surrounding tissue. Pleural Indentation (PI) shows that the pleural is dragged toward the lung area by the spiculation. It is associated with adenosquamous carcinoma. Obstructive Pneumonia (OP) could be present in lung carcinoma, pulmonary metastases, or inflammatory myofibroblastic tumour. Calcification may be seen in pulmonary synovial sarcoma or chondroma. Air Bronchogram (AB) is a tubular outline of an airway made visible by filling of the surrounding alveoli by fluid or inflammatory exudates. It is associated with the lymphohistiocytic tumors. Bronchial Mucus Plugs (BMP) shows that the intrabronchial air is replaced by the mucus. It is associated with the allergic bronchopulmonary aspergillosis. We illustrate the nine categories of CISLs in Fig. 5 . In this paper, we apply the proposed FCSS method to search the similar CISLs in the Regions of Interest (ROIs) in lung CT images. According to the FCSS method, our CISL retrieval process includes two stages: off-line and on-line. In the off-line stage, we extract the low-level visual features of CISLs, including the Bag-of-visual-words based on the HOG, wavelet features, Local Binary Pattern (LBP) and histogram of CT values, and select the optimal sub-features from them by using a feature selection method based on Fisher criterion and Genetic optimization [26]. Then, we train the SVM for classifying CISLs on the training data and compute the visual similarities between each pair of database images. In the on-line stage, we use the classifier SVM to compute the possibilities of classifying the query ROI into each CISL category, and get the semantic similarities. Then we constructed the corresponding weighted graph involving the query image and all the database images. Finally, the shortest path between the query image and each database image is computed and used for the retrieval of CISLs. 4 Experiments 4.1 Experimental setup 4.1.1 Datasets The LISS database of CISLs [27] was used in the experiments. In the database, the instances of nine categories of CISLs were collected from the Cancer Institute and Hospital at the Chinese Academy of Medical Sciences. All the lung CT images were in the DICOM form and were taken by slice thickness of 5mm with 512\u00d7512 in plane pixel matrices. The rectangular ROIs wrapping CISLs are manually labeled and annotated by an experienced radiologist to produce a gold standard. The resultant number of ROIs is 511. In our experiments, the set of all these available instances is split into 2 disjoint subsets nearly evenly. The first one (we denote it as S1) is taken as the training set for the algorithm tuning as well as SVM training. The second one (let it be denoted as S2) is taken as the test set for the retrieval of CISL. The numbers of examples in datasets S1 and S2 for each CISL, and the corresponding numbers of patients, are listed in Table 2 , where \u201cNoS\u201d and \u201cNoP\u201d mean \u201cthe number of samples\u201d and \u201cthe number of patients\u201d, respectively. Notice that the data in S1 and S2 are guaranteed to come from different patients to avoid the bias in evaluating retrieval performance. 4.1.2 Evaluation criterion The performance of the algorithm is evaluated by the four commonly used evaluation criterions for CBMIR methods: the precision at position n ( p @ n ( q ) ), Average Precision (AP), Mean Average Precision (MAP) and Precision-Recall Graph (PR Graph). \u2022 Let p @ n ( q ) be the precision at position n, which measures the proportion of the relevant images in the n returned images for the query q. It is determined by (4) p @ n ( q ) = 1 n \u2211 i = 1 n rele ( q , i ) , where rele ( q , i ) indicates the relevancy between image q and the i-th returned image: (5) rele ( q , i ) = 1 , if i - th image is relevant to q 0 , others , \u2022 AP is computed as (6) AP ( q ) = 1 N R \u2211 n = 1 N p @ n ( q ) \u00d7 rele ( q , n ) , where N and N R are the number of returned images and relevant images, respectively. \u2022 MAP is the mean of the APs over all the queries. It is sensitive to the entire ranking and contains both precision and recall oriented aspects. Based on AP, it can be computed as (7) MAP = 1 | w | \u2211 q \u2208 w AP ( q ) , where w is the set of query images. \u2022 PR Graph is a line graph plotted from the precision-recall values. The precision is the fraction of retrieved images that are relevant to the query, while the recall is the fraction of relevant images which has been retrieved. 4.1.3 Compared algorithms In order to show the effectiveness of the proposed method, we compare it with the following three related ones: \u2022 The method based on the pairwise visual similarity (denoted as M1 method). M1 searches for similar images based on the pairwise visual similarity. It computes the distance between the visual features of query image and each image in the database, then the images in the database are ranked in ascending order of distances and the top ones are returned as the retrieval results. Its key advantage is the speed while it may has the shortcoming of poor retrieval performance due to the ignorance of the effect of semantic information. \u2022 The method based on the visual context sensitive similarity diffused through shortest path computation (denoted as M2 method). M2 is an extended method of M1. Based on the pairwise visual similarity obtained by M1, M2 exploits the context sensitive similarities to improve the retrieval performance. It builds a weighted graph and finds the shortest paths over the graph to capture the context similarity like our proposed method. The difference from our method is M2 uses the visual similarity and our proposed method uses the combination of visual and semantic similarity. Although M2 can improve the retrieval performance by capturing context similarity, it is difficult for M2 to obtain the better retrieval results because of absence of semantic information. \u2022 The method based on the separated combination of semantic and visual similarity (denoted as M3 method). M3 is a hierarchical retrieval method by separately considering the semantic and visual similarity. On the first level, it classifies the query image and obtains the similar images with the same category of query image. On the second level, it ranks the images, which are gotten on the first level, based on their visual similarity for the final retrieval result. M3 can improve the retrieval performance by combining the semantic and visual similarity, but it could produce bad retrieval results due to misclassification on the first level. Through comparing with the above methods, we will show the usefulness of shortest path computation and the necessity of combination of visual and semantic similarity. First, by comparing the results of M1 and M2, we confirm that the context-sensitive similarity obtained by shortest path algorithm can improve the retrieval performance. Second, we can see the advantage of the fused visual-semantic pairwise similarity by comparing the results of M2 and those of our FCSS method. In the end, through comparing the retrieval results of M3 and the FCSS, we can illustrate the advantage of simultaneous combination of them over the separated combination. 4.2 Algorithm tuning We test the parameters in the training set S1 and the optimal parameters determined in the S1 are used to complete the retrieval process in the testing set S2. 4.2.1 The selection of distance measures In order to find the best visual similarity measure from the five distance metrics, Euclidean, City block, Chebychev, and Cosine and Correlation, we compute the MAP of the M1 algorithm at five top ranks, including 10, 20, 30, 50, and 100, to evaluate these distance functions. The resultant MAPs are shown in Table 3 . So we choose the Cosine distance having the highest MAP as our visual similarity measure in the following experiments. 4.2.2 The selection of kernel function for SVM To obtain the best classification results from the SVM, we select the suitable kernels and parameters in the SVM. We tested four kernels including linear (dot product), polynomial, Gaussian, and Sigmoid and evaluate their performance. The functions, the chosen parameters, and the average accuracy on the training set S1 are shown in Table 4 . From it, we find that the best one leading to the highest accuracy is Gaussian kernel with g = 1 , which were used in the following experiments. 4.2.3 Parameter setting Values for parameters, \u03b1 and \u03b2 in Eq. (3), were obtained empirically. We increase \u03b1 and \u03b2 from 0.1 to 1 at the step of 0.1, respectively, and guarantee that their sum equals to 1. We take each image in the training set S1 as query image. We perform our FCSS on them for recording their MAPs at the five top ranks, 10, 20, 30, 50, and 100, and average them to obtain the means. We show the means of MAP and the corresponding values of \u03b1 and \u03b2 in Fig. 6 , where the x-axis, y-axis and z-axis represents the values of \u03b1 , \u03b2 and the resultant MAP, respectively. From Fig. 6, we can see that the pair of 0.2 and 0.8 corresponds to the highest MAP, which were used in the following experiments. 4.3 Experimental results We choose two examples in the test set S2 for each CISL category to construct a query set. In order to demonstrate the robustness of our method, in these two examples, one is chosen from those identified correctly by the classifier and the other is chosen from those identified falsely. Since the number of CISLs is 9, the numbers of all the query examples is 18. We perform the retrieval by using each query example and evaluate the performance of other methods and our method under the same condition. 4.3.1 Comparisons on top ranked results First, we compare average p @ n at each of five top ranks {10, 20, 30, 50, 100}. The comparison results are shown in Fig. 7 . In Fig. 7, on the one hand, we can see the advantage of shortest path computation. We find that p @ n of M2 are always higher than the ones of M1. Since the only difference between M2 and M1 is that M2 involves the shortest path algorithm to achieve a context-sensitive similarity, we can conclude that the context-sensitive similarity can improve the retrieval performance. On the other hand, we can see the advantage of fused pairwise similarity. We find that the results gotten by FCSS are always better than the ones of M2. The only difference between them is that M2 only uses the visual similarity while FCSS uses visual similarity and semantic similarity simultaneously. Our results are better than the ones of M3, so it also proves that our simultaneous combination of visual similarity and semantic similarity perform better than the hierarchical combination. Thus we can say that FCSS can narrow the semantic gap and mitigate the influence of misclassification by combining the visual and semantic similarity, and improve the retrieval performance by involving the shortest path algorithm. 4.3.2 Comparisons on AP and MAP Second, we record the APs for each CISL and the MAP for all CISLs. They are shown in Table 5 . We find that our APs are the highest ones in most cases. In addition, our minimum AP is 0.1, which is higher than that of M1 (0.08), M2 (0.0818), M3 (0.07), and our maximum AP is 1, which is the highest one compared with M1 (0.75), M2 (0.7692), M3 (0.6333), respectively. Our method can produce the highest lower bound and upper bound, which demonstrates that our method can obtain the better retrieval results even in the worst case. Moreover, our MAP is always the highest one among all the methods. 4.3.3 Comparisons on PR graph Third, we draw the PR graphs for these methods. The results are shown in Figs. 8 and 9 , where the black, green, blue and red curves correspond to M1, M2, M3 and our FCSS method, respectively. The Areas Under the Curves (AUC) are shown in the right top corner or left bottom corner of these PR graphs. In Fig. 8, we can see that the PR curves of our FCSS method are always above the curves of other methods. Accordingly, our AUC is the highest one, 0.4854, which is obviously bigger than the AUC of M1 (0.3778), M2 (0.3818), and M3 (0.3810). As indicated above, one of the reasons why our method can achieve better performance is the combination of visual and semantic information. It can reduce the influence of misclassification. In order to see how deeply the retrieval performance is affected by the classification accuracy, we perform these methods on six subsets with different classification accuracies and show the corresponding PR graphs in Fig.9a-f. Each of the six query subsets is the subset of the query set and contains nine samples which are corresponding to nine CISLs. The difference among them is that the numbers of the samples recognized accurately. They have zero, one, three, five, seven and nine samples recognized accurately, respectively, and that means that the corresponding classification accuracy of query subset is 0%, 11.11%, 33.33%, 55.56%, 77.78% and 100%, respectively. Based on the experimental results shown in Figs. 8 and 9, we can see the advantage of FCSS more clearly. In most of cases, our curves are higher than not only the ones of M2 which involves only visual information, but also the ones of M3 which combines visual and semantic information hierarchically. For the query subset in which all the query samples are recognized correctly by the classifier, M3 can return the satisfactory results shown in Fig.9f. But if all the query samples are recognized incorrectly, in the first tier, it could filter the images with the same semantic concept with the query ones because of misclassification, and lead to bad results as shown in Fig.9a. So M3 is sensitive to the classification accuracy. Since our fused pairwise similarity contains the semantic and visual information simultaneously, it can improve the performance by reducing the impact of misclassification. 4.3.4 Comparisons on retrieval examples We further tested the robustness of our method by showing the retrieval results for the query ROIs. We search two examples, one of which is classified correctly, and the other one incorrectly. We show the retrieval results obtained by the compared method, M1, M2, M3 and our method FCSS in Figs. 10 and 11 . In Figs. 10 and 11, the images in the first row are the query images with ROIs manually delineated by a user. The images from the second and the fifth row are the top 5 images returned by M1, M2, M3 and our method for the query ROI. And the blue boxes indicate irrelevant images and the others are relevant. By comparing the two examples, we can find that the results are influenced by the classification. If the query image can be identified correctly, each method can give good results. However, if the query image is identified incorrectly, all the methods fail to search similar images except our FCSS. That proves that other methods are sensitive to the error classification while our method is robust to the misclassification. 4.3.5 Comparisons on efficiency Finally, we compare our method with the others from the view of computation efficiency. We record the average running time of four methods in milliseconds, respectively. The results are shown in Table 6 . Notice that all the algorithms are implemented with Matlab and run in a PC with 2.33GHz CPU and 4GB Memory. Table 6 shows that M1 is the speediest one, because it only computes the pairwise distance. M3 requires recognition and ranking based on distance similarities, so it takes more time than M1 and less time than the others. Our method costs a little more time than M2 because it involves semantic similarity computation. Although our method does not run fastest, it trades speed for accuracy. However, it should be noted that although our method is performed on the CISLs database in a real time, it will be time-consuming if it is performed on a huge database, because it requires a lot of time to compute the shortest paths on a huge weighted graph. A possible way of improving the efficiency is to utilize clustering algorithm to divide the images in the database into k clusters and construct a weighted graph with the k nodes, where the nodes represents the clusters and the edge represents the similarity between two clusters. In this way we can greatly reduce the size of weighted graph and reduce the execution time of shortest path calculation, and consequently reduce the retrieval time. We intend to explore this strategy in future work. 5 Conclusions This paper has proposed a new method of content-based medical image retrieval, called FCSS, for the retrieval of Common CT Imaging Signs of Lung Diseases (CISLs). Our fused pairwise similarity can measure the pairwise similarity more accurately, and on this basis, we use the context-sensitive similarity to improve the retrieval performance. Our main contributions are summarized as follows. \u2022 The semantic similarity and visual similarity are combined simultaneously. Our fused pairwise similarity can take advantage of semantic similarity and visual similarity to narrow down the semantic gap and tolerate the misclassification. In comparison to retrieval methods based on only visual similarity or hierarchical combination, our method achieves better performance. \u2022 The structure of the data manifold underlying database images is captured by using the shortest path computation over the graph. We use the lengths of shortest paths as the context-sensitive similarities of query image and the ones in the database to complete the retrieval process. The experimental results show that our method outperforms the retrieval method ignoring the structure of the data manifold. It confirms that the shortest path algorithm can be used to achieve a better retrieval result. \u2022 The proposed method, FCSS, is applied to search for similar Common CT Imaging Signs of Lung Diseases (CISLs). Since CISLs are associated with lung diseases, CISLs play important roles in the diagnosis of lung diseases. Our method can be used to retrieve similar CISLs from historical CT scans and return the related information for computer aided diagnosis, medical research and teaching. In the future, we plan to improve the retrieval efficiency. We can cluster the images in the database into groups to create a smaller graph. By reducing the running time of shortest path computation, our method can be implemented on a huge database in real time. In addition, in this paper, we perform our method on the single-label data, a lesion containing one CISL, but a lesion region may present several CISLs, e.g., a nodule may contain speculation, lobulation, and calcification. We can call that type of data multi-label data. Hence, in the next work, we will perform our method on the multi-label CISLs. We will involve a transformation processing. We plan to transform the multi-label learning into single-label learning, repeat the proposed retrieval method multiple times, and fuse these retrieval results for the final retrieval results. Acknowledgments This research was partially supported by National Natural Science Foundation of China (Grant nos. 60973059, 81171407), Program for New Century Excellent Talents in University of China (Grant no. NCET-10-0044). References [1] D.M. Parkin P. Pisani J. Ferlay Global cancer statistics CA Cancer J. Clin. 49 1 1999 33 64 [2] D.R. Aberle A consensus statement of the Society of Thoracic Radiology: screening for lung cancer with helical computed tomography J. Thorac. Imaging 16 1 2001 65 68 [3] L. Ma A new classifier fusion method based on historical and on-line classification reliability for recognizing common CT imaging signs of lung diseases Comput. Med. Imaging Graph. 40 2015 39 48 [4] H. M\u00fcller et al., Overview of the imageCLEF 2012 medical image retrieval and classification tasks, in: CLEF (Online Working Notes/Labs/Workshop), 2012. pp. 1\u201316. [5] H. M\u00fcller A review of content-based image retrieval systems in medical applications\u2014clinical benefits and future directions Int. J. Med. Inform. 73 1 2004 1 23 [6] A. Depeursinge et al., Overview of the second workshop on medical content-based retrieval for clinical decision support, in: Medical Content-Based Retrieval for Clinical Decision Support, 2012. pp. 1\u201311. [7] J. Wang Bag-of-features based medical image retrieval via multiple assignment and visual words weighting IEEE Trans. Med. Imaging 30 11 2011 1996 2011 [8] L. Ballerini et al., A query-by-example content-based image retrieval system of non-melanoma skin lesions, in: Medical Content-based Retrieval for Clinical Decision Support, 2010, pp. 31\u201338. [9] A. Baldi Definition of an automated content-based image retrieval (CBIR) system for the comparison of dermoscopic images of pigmented skin lesions Biomed. Eng. Online 8 1 2009 18 [10] G. Quellec Wavelet optimization for content-based image retrieval in medical databases Med. Image Anal. 14 2 2010 227 241 [11] M.M. Rahman, S.K. Antani, G.R. Thoma, A medical image retrieval framework in correlation enhanced visual concept feature space, in: 22nd IEEE International Symposium on Computer-Based Medical Systems, 2009, pp. 1\u20134. [12] R. Suganya S. Rajaram Content based image retrieval of ultrasound liver diseases based on hybrid approach Am. J. Appl. Sci. 9 6 2012 938 [13] B. Andr\u00e9 Learning semantic and visual similarity for endomicroscopy video retrieval IEEE Trans. Med. Imaging 31 6 2012 1276 1288 [14] L. Yang A boosting framework for visuality-preserving distance metric learning and its application to medical image retrieval IEEE Trans. Pattern Anal. Machine Intell. 32 1 2010 30 44 [15] De. Oliveira MammoSys: a content-based image retrieval system using breast density patterns Comput. Methods Programs Biomed. 99 3 2010 289 297 [16] M.M. Rahman B.C. Desai P. Bhattacharya Medical image retrieval with probabilistic multi-class support vector machine classifiers and adaptive similarity fusion Comput. Med. Imaging Graph. 32 2 2008 95 108 [17] H.C. Akakin M.N. Gurcan Content-based microscopic image retrieval system for multi-image queries IEEE Trans. Inform. Technol. Biomed. 16 4 2012 758 769 [18] X. Bai Learning context-sensitive shape similarity by graph transduction IEEE Trans. Pattern Anal. Machine Intell. 32 5 2010 861 874 [19] J. Wang Learning context-sensitive similarity by shortest path propagation Pattern Recogn. 44 10 2011 2367 2374 [20] J. Jiang, B. Wang, Z. Tu, Unsupervised metric learning by self-smoothing operator, in: IEEE International Conference on Computer Vision (ICCV), 2011, pp. 794\u2013801. [21] M. Donoser, H. Bischof, Diffusion processes for retrieval revisited, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013, pp. 1320\u20131327. [22] V. Vapnik, The Nature of Statistical Learning Theory, Springer Science & Business Media, 2013. [23] T.H. Cormen Introduction to Algorithms vol. 2 2000 MIT Press Cambridge [24] W.D. Travis The 2015 World Health Organization classification of lung tumors: impact of genetic, clinical and radiologic advances since the 2004 classification J. Thorac. Oncol. 10 9 2015 1243 1260 [25] H.K. M\u00fcller-Hermelink Pathology & genetics, tumours of the lung, pleura, thymus and heart, in: World Health Organization Classification of Tumors 2004 IARC Press Lyon France 146 147 [26] X. Liu Recognizing common CT imaging signs of lung diseases through a new feature selection method based on Fisher criterion and genetic optimization IEEE J. Biomed. Health Inform. 19 2 2015 635 647 [27] G. Han The LISS\u2014a public database of common imaging signs of lung diseases for computer-aided detection and diagnosis research and medical education IEEE Trans. Biomed. Eng. 62 2 2015 648 656", "scopus-id": "85009374183", "pubmed-id": "28069515", "coredata": {"eid": "1-s2.0-S1532046417300023", "dc:description": "Abstract This paper proposes a new method of content based medical image retrieval through considering fused, context-sensitive similarity. Firstly, we fuse the semantic and visual similarities between the query image and each image in the database as their pairwise similarities. Then, we construct a weighted graph whose nodes represent the images and edges measure their pairwise similarities. By using the shortest path algorithm over the weighted graph, we obtain a new similarity measure, context-sensitive similarity measure, between the query image and each database image to complete the retrieval process. Actually, we use the fused pairwise similarity to narrow down the semantic gap for obtaining a more accurate pairwise similarity measure, and spread it on the intrinsic data manifold to achieve the context-sensitive similarity for a better retrieval performance. The proposed method has been evaluated on the retrieval of the Common CT Imaging Signs of Lung Diseases (CISLs) and achieved not only better retrieval results but also the satisfactory computation efficiency.", "openArchiveArticle": "true", "prism:coverDate": "2017-02-28", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046417300023", "dc:creator": [{"@_fa": "true", "$": "Ma, Ling"}, {"@_fa": "true", "$": "Liu, Xiabi"}, {"@_fa": "true", "$": "Gao, Yan"}, {"@_fa": "true", "$": "Zhao, Yanfeng"}, {"@_fa": "true", "$": "Zhao, Xinming"}, {"@_fa": "true", "$": "Zhou, Chunwu"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046417300023"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046417300023"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(17)30002-3", "prism:volume": "66", "prism:publisher": "Elsevier Inc.", "dc:title": "A new method of content based medical image retrieval and its applications to CT imaging sign retrieval", "prism:copyright": "\u00a9 2017 Elsevier Inc.", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Medical image retrieval"}, {"@_fa": "true", "$": "Content-based image retrieval"}, {"@_fa": "true", "$": "Lung CT images"}, {"@_fa": "true", "$": "Semantic information"}, {"@_fa": "true", "$": "Visual information"}, {"@_fa": "true", "$": "Shortest path"}, {"@_fa": "true", "$": "Common CT Imaging Signs of Lung Diseases (CISLs)"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "148-158", "prism:endingPage": "158", "prism:coverDisplayDate": "February 2017", "prism:doi": "10.1016/j.jbi.2017.01.002", "prism:startingPage": "148", "dc:identifier": "doi:10.1016/j.jbi.2017.01.002", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "164", "@width": "194", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr10.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "14756", "@ref": "gr10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "186", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr11.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "15781", "@ref": "gr11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "121", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "13300", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "152", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6860", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "151", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6980", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "204", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "22170", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "157", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "13720", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "145", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6678", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "205", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "15593", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "144", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "17207", "@ref": "gr9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "88", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "14793", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "105", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4996", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "451", "@width": "534", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr10.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "60692", "@ref": "gr10", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "470", "@width": "533", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr11.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "74627", "@ref": "gr11", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "368", "@width": "667", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "63268", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "248", "@width": "357", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "21790", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "246", "@width": "357", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "21917", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "428", "@width": "534", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62858", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "254", "@width": "355", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "29608", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "235", "@width": "355", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "16995", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "290", "@width": "364", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "28673", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "512", "@width": "778", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "86681", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "200", "@width": "500", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "42647", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "171", "@width": "356", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "15806", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1997", "@width": "2363", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr10_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "381312", "@ref": "gr10", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2084", "@width": "2362", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr11_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "510008", "@ref": "gr11", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "994", "@width": "1801", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "202331", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1100", "@width": "1581", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "157502", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1089", "@width": "1581", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "157113", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1897", "@width": "2367", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "400273", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "686", "@width": "959", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr6_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "78794", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1041", "@width": "1575", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr7_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "101045", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "786", "@width": "985", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr8_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "69042", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1383", "@width": "2101", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr9_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "258090", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "531", "@width": "1328", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "104433", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "756", "@width": "1578", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "104940", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "15", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "198", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "243", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "208", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "203", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "202", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "208", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "221", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "316", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "216", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "204", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "121", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "662", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "46", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "389", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si24.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "217", "@ref": "si24", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si25.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si25", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si26.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "245", "@ref": "si26", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "58", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si28.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "451", "@ref": "si28", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "36", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si29.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "303", "@ref": "si29", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "21", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "293", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "73", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si31.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "437", "@ref": "si31", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "196", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si32.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "728", "@ref": "si32", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "33", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si33.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si33", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "21", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si34.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "259", "@ref": "si34", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si38.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "286", "@ref": "si38", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "10", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si39.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "195", "@ref": "si39", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si40.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si40", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "24", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si42.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "249", "@ref": "si42", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "24", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si43.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "247", "@ref": "si43", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "54", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si46.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "465", "@ref": "si46", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "60", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si49.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "460", "@ref": "si49", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si52.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "252", "@ref": "si52", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "9", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si54.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "208", "@ref": "si54", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si55.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "269", "@ref": "si55", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "33", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si64.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "335", "@ref": "si64", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "30", "@width": "179", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si69.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "974", "@ref": "si69", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "221", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "150", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si70.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "736", "@ref": "si70", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "24", "@width": "170", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si71.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "890", "@ref": "si71", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "38", "@width": "141", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si72.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "833", "@ref": "si72", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "38", "@width": "252", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si73.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1336", "@ref": "si73", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "22", "@width": "207", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si74.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "896", "@ref": "si74", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si75.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "302", "@ref": "si75", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "22", "@width": "110", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si76.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "602", "@ref": "si76", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "139", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si77.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "720", "@ref": "si77", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "138", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si78.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "693", "@ref": "si78", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "134", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si79.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "548", "@ref": "si79", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "86", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si81.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "418", "@ref": "si81", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "48", "@width": "194", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1243", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "47", "@width": "290", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si23.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2047", "@ref": "si23", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "55", "@width": "461", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si41.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3279", "@ref": "si41", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "45", "@width": "181", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si48.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1220", "@ref": "si48", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "44", "@width": "369", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si50.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2032", "@ref": "si50", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "47", "@width": "258", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si51.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1642", "@ref": "si51", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "46", "@width": "154", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046417300023-si53.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1116", "@ref": "si53", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85009374183"}}
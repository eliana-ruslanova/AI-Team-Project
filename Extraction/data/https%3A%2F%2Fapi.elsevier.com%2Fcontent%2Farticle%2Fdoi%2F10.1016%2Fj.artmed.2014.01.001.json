{"scopus-eid": "2-s2.0-84904321212", "originalText": "serial JL 271219 291210 291682 291866 31 90 Artificial Intelligence in Medicine ARTIFICIALINTELLIGENCEINMEDICINE 2014-01-25 2014-01-25 2014-07-14T16:45:13 1-s2.0-S0933365714000037 S0933-3657(14)00003-7 S0933365714000037 10.1016/j.artmed.2014.01.001 S300 S300.1 FULL-TEXT 1-s2.0-S0933365714X00060 2015-05-15T03:29:23.905283-04:00 0 0 20140701 20140731 2014 2014-01-25T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype subheadings tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes orcid primabst ref alllist content oa subj ssids 0933-3657 09333657 UNLIMITED NIH true 61 61 3 3 Volume 61, Issue 3 4 137 144 137 144 201407 July 2014 2014-07-01 2014-07-31 2014 Text Mining and Information Analysis of Health Documents Hanna Suominen Special issue Articles article fla Copyright \u00a9 2014 The Authors. Published by Elsevier B.V. CUEBASEDASSERTIONCLASSIFICATIONFORSWEDISHCLINICALTEXTDEVELOPINGALEXICONFORPYCONTEXTSWE VELUPILLAI S 1 Introduction 2 Background 2.1 Negation and uncertainty classification 2.2 Negation cue detection and scope 2.3 Uncertainty cue detection and scope 2.4 pyConTextNLP 3 Materials and methods 3.1 Constructing a cue lexicon 3.1.1 Cue coverage 3.1.2 Cue combinations 3.1.3 Manual cue classification 3.2 Evaluating and improving lexicon on a development set 3.3 Evaluation 4 Results 4.1 Construction of cue lexicon 4.2 Evaluating and improving lexicon on development set 4.2.1 Results from error analysis 4.2.2 Cue lexicon coverage 4.3 Evaluation 5 Discussion 6 Conclusions Conflict of interest statement Acknowledgements References HORN 1989 L ANATURALHISTORYNEGATIONVOL960 UZUNER 2011 552 556 O FARKAS 2010 1 12 R PROC14THCONLL CONLL2010SHAREDTASKLEARNINGDETECTHEDGESSCOPEINNATURALLANGUAGETEXT KIM 2009 1 9 J BIONLP09 OVERVIEWBIONLP09SHAREDTASKEVENTEXTRACTION SKEPPSTEDT 2011 S3 M TANUSHI 2013 387 397 H PROC19THNODALIDANEALT NEGATIONSCOPEDELIMITATIONINCLINICALTEXTUSINGTHREEAPPROACHESNEGEXPYCONTEXTNLPSYNNEG DELEGER 2012 697 702 L PROC2NDACMSIGHITINTLHEALTHINFORMATICS2012 DETECTINGNEGATIONMEDICALPROBLEMINFRENCHCLINICALNOTES VELUPILLAI 2011 559 563 S PROC23RDMIE FACTUALITYLEVELSDIAGNOSESINSWEDISHCLINICALTEXT VELUPILLAI 2011 S PROC4THLBM AUTOMATICCLASSIFICATIONFACTUALITYLEVELSACASESTUDYSWEDISHDIAGNOSESIMPACTLOCALCONTEXT VINCZE 2008 S9 V CHAPMAN 2011 728 737 B VELUPILLAI 2013 S PROCLOUHI2013 PORTINGARULEBASEDASSERTIONCLASSIFIERFORCLINICALTEXTENGLISHSWEDISH FRIEDMAN 1994 161 174 C DEBRUIJN 2011 557 562 B CHAPMAN 2001 301 310 W MUTALIK 2001 598 609 P ARONOW 1999 393 411 D UZUNER 2009 109 115 O CLARK 2011 563 567 C GOLDIN 2003 I PROCWORKSHOPTEXTANALYSISSEARCHFORBIOINFORMATICS26THACMSIGIRCONFERENCE LEARNINGDETECTNEGATIONNOTINMEDICALTEXTS MORANTE 2008 715 724 R PROCEMNLP08 LEARNINGSCOPENEGATIONINBIOMEDICALTEXTS AGARWAL 2010 696 701 S KILICOGLU 2008 S10 H HARKEMA 2009 839 851 H WILSON 2011 R PRESENTEDRADIOLOGICALSOCIETYNAMERICASCIENTIFICASSEMBLYANNUALMEETING AUTOMATEDCAPTUREPULMONARYEMBOLISMSPATIALLOCATIONINDICTATEDREPORTSUSINGCONTEXTALGORITHM GENTILI 2011 A PRESENTEDRADIOLOGICALSOCIETYNAMERICASCIENTIFICASSEMBLYANNUALMEETING USEPYCONTEXTCLASSIFYREPORTSCONTAININGCRITICALRESULTS GENTILI 2012 A PRESENTEDRADIOLOGICALSOCIETYNAMERICASCIENTIFICASSEMBLYANNUALMEETING USEPYCONTEXTASSISTINAUDITINGFORCHESTBIOPSYCOMPLICATIONS DALIANIS 2012 17 18 H PROC4THSLTC STOCKHOLMEPRCORPUSACLINICALDATABASEUSEDIMPROVEHEALTHCARE VELUPILLAI 2012 S SHADESCERTAINTYANNOTATIONCLASSIFICATIONSWEDISHMEDICALRECORDS INTERNATIONALHEALTHTERMINOLOGYSTANDARDSDEVELOPMENTORGANISATIONIHTSDO 2008 SNOMEDCT KNUTSSON 2003 O PROC14THNODALIDA AROBUSTSHALLOWPARSERFORSWEDISH VELUPILLAIX2014X137 VELUPILLAIX2014X137X144 VELUPILLAIX2014X137XS VELUPILLAIX2014X137X144XS Full 2014-01-23T05:54:13Z Author http://creativecommons.org/licenses/by-nc-nd/3.0/ item S0933-3657(14)00003-7 S0933365714000037 1-s2.0-S0933365714000037 10.1016/j.artmed.2014.01.001 271219 2014-07-14T15:59:07.027169-04:00 2014-07-01 2014-07-31 UNLIMITED NIH 1-s2.0-S0933365714000037-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/MAIN/application/pdf/5f80899b94eb9161e2b5eea7aa33ab97/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/MAIN/application/pdf/5f80899b94eb9161e2b5eea7aa33ab97/main.pdf main.pdf pdf true 942886 MAIN 8 1-s2.0-S0933365714000037-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/PREVIEW/image/png/3b236624cb10ffab761b67d89f778533/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/PREVIEW/image/png/3b236624cb10ffab761b67d89f778533/main_1.png main_1.png png 59199 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0933365714000037-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/gr2/HIGHRES/image/jpeg/12a302002dea2fb3132123455c37d202/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/gr2/HIGHRES/image/jpeg/12a302002dea2fb3132123455c37d202/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 455057 2417 2833 IMAGE-HIGH-RES 1-s2.0-S0933365714000037-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/gr1/HIGHRES/image/jpeg/2880b16cec1deea8b6588bfeb8e9e3b6/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/gr1/HIGHRES/image/jpeg/2880b16cec1deea8b6588bfeb8e9e3b6/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 297652 1983 2500 IMAGE-HIGH-RES 1-s2.0-S0933365714000037-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/gr2/DOWNSAMPLED/image/jpeg/ce043f80469a974d53c729734dccab15/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/gr2/DOWNSAMPLED/image/jpeg/ce043f80469a974d53c729734dccab15/gr2.jpg gr2 gr2.jpg jpg 65247 546 640 IMAGE-DOWNSAMPLED 1-s2.0-S0933365714000037-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/gr1/DOWNSAMPLED/image/jpeg/8903b52617caafa53ffce2fd6e65accc/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/gr1/DOWNSAMPLED/image/jpeg/8903b52617caafa53ffce2fd6e65accc/gr1.jpg gr1 gr1.jpg jpg 46282 448 565 IMAGE-DOWNSAMPLED 1-s2.0-S0933365714000037-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/gr2/THUMBNAIL/image/gif/b73e8ef4d9315ff0b04129be75bf0cf0/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/gr2/THUMBNAIL/image/gif/b73e8ef4d9315ff0b04129be75bf0cf0/gr2.sml gr2 gr2.sml sml 4651 164 192 IMAGE-THUMBNAIL 1-s2.0-S0933365714000037-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0933365714000037/gr1/THUMBNAIL/image/gif/37047fa1a3a391e7110769877b49069e/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0933365714000037/gr1/THUMBNAIL/image/gif/37047fa1a3a391e7110769877b49069e/gr1.sml gr1 gr1.sml sml 3940 164 207 IMAGE-THUMBNAIL ARTMED 1327 S0933-3657(14)00003-7 10.1016/j.artmed.2014.01.001 The Authors Fig. 1 Overview of the steps taken in this study. Cue lexicons were created, including a filtering step on the Diagnostic Statement (DS) set. Cues from PyContextNLP and the BioScope corpus were translated to Swedish. These lexicons were applied with pyConTextSwe on the development set (Dev set). The improved lexicon (Final) was also used for final evaluation in the evaluation set (Eval set). The development and evaluation set are subsets of the Stockholm EPR Diagnosis uncertainty corpus (SEPR-DUC). Fig. 2 F-Score results at different cut-off points for classification into the four assertion classification classes: definite existence, probable existence, definite negated existence, and probable negated existence. Cut-off values represent cut-off points based on the most frequent occurrences of the cues, i.e., cut-off=10 means the top 10 most frequent cues are used (per class). No cut-off (extended) =added, modified cues from external resources. Extended+comb =added, modified cues from external resources + generated combinations. Final =added, modified cues from error analysis. EA=error analysis. Table 1 Data set: number of classified diagnostic statements, development (devel) and evaluation (eval) set, with original annotation classes and mapped output values. Mapping is based on previous studies [8]. Gold devel eval Mapped devel eval Certainly positive 1291 780 Definite existence 1291 780 Probably positive 442 261 Probable existence 767 468 Possibly positive 261 170 Possibly negative 64 37 Probably negative 240 130 Probable negated existence 240 130 Certainly negative 276 147 Definite negated existence 276 147 Total 2574 1525 2574 1525 Table 2 Cues: sources and assertion classes in the final lexicon. Sources=PyConTextNLP [11], BioScope [10], Stockholm EPR sentence uncertainty corpus (SEPR-SUC) [29], SNOMED CT [30]. def = definite existence, prob = probable existence, prob neg = probable negated existence, def neg = definite negated existence, term = termination cues, ps-neg = pseudo negation. The number of cues occurring at least once in the Diagnostic Statement (DS) set is shown. For PyConTextNLP, BioScope, and SNOMED CT, also additional cues not found in the DS set were manually classified. For these, the total number of cues, including cues not found in the DS set, is shown in parenthesis. Source def prob prob neg def neg term ps-neg pyContextNLP 3 (8) 45 (92) 20 (83) 29 (69) 48 (109) 3 (13) BioScope 1 (1) 39 (71) 1 (3) 4 (7) 0 (0) 0 (0) SEPR-SUC 9 (9) 64 (72) 9 (10) 2 (3) 1 (1) 0 (0) SNOMED 2 5 1 4 0 1 inflections 13 81 17 20 43 2 combinations 2 43 44 24 5 3 error analysis 3 74 48 17 8 6 \u2211 33 351 140 100 105 15 Table 3 Results (precision (%), recall (%), F-score (%)): all four classes definite existence (def_existence), probable existence (prob_existence), probable negated existence (prob_negated), and definite negated existence (def_negated). baseline =corrected, translated cues from PyConTextNLP [11], extended =added, modified cues from external resources. final =added, modified cues from error analysis and generated combinations. Cues=cues in lexicon (number of cues actually found by pyConTextSwe). 95% CI = 95% Confidence intervals. Statistically different class accuracies (\u03b1 =0.05), using McNemar's test with continuity correction, are marked with *. Annotation class Cue set Cues Precision (95% CI) Recall (95% CI) F-score def_existence baseline 5 (None) 67.83 \u00b11.80 90.01 \u00b11.16 77.36 extended* 30 (12) 84.83 \u00b11.39 84.90 \u00b11.38 84.86 final* 33 (15) 91.50 \u00b11.08 90.09 \u00b11.15 90.79 final (eval) 33 (14) 88.80 \u00b11.58 87.44 \u00b11.66 88.11 prob_existence baseline 87 (24) 62.15 \u00b11.87 25.68 \u00b11.69 36.34 extended* 224 (92) 71.68 \u00b11.74 69.62 \u00b11.78 70.63 final* 351 (162) 82.00 \u00b11.48 81.36 \u00b11.50 81.68 final (eval) 351 (106) 81.60 \u00b11.94 80.56 \u00b11.99 81.08 prob_negated baseline 91 (10) 39.29 \u00b11.89 9.17 \u00b11.11 14.87 extended* 57 (18) 56.12 \u00b11.92 22.92 \u00b11.62 32.55 final 140 (62) 55.81 \u00b11.92 60.00 \u00b11.89 57.83 final (eval) 140 (27) 54.48 \u00b12.50 56.15 \u00b12.49 55.30 def_negated baseline 98 (20) 48.98 \u00b11.93 86.59 \u00b11.32 62.57 extended* 59 (24) 53.08 \u00b11.93 84.42 \u00b11.40 65.18 final* 100 (45) 70.07 \u00b11.77 72.10 \u00b11.73 71.07 final (eval) 100 (31) 60.25 \u00b12.46 65.99 \u00b12.38 62.99 Table 4 Results (precision (%), recall (%), F-score (%)): existence yes/no and uncertainty yes/no. extended =added, modified cues from external resources. final =added, modified cues from error analysis. 95% CI=95% Confidence intervals. Statistically different class accuracies (\u03b1 =0.05), using McNemar's test with continuity correction, are marked with *. Annotation class Precision (%) (95% CI) Recall (%) (95% CI) F-score existence_yes (extended) 96.12 \u00b10.75 95.14 \u00b10.83 95.63 (final)* 97.88 \u00b10.56 96.65 \u00b10.70 97.26 (final on evaluation set) 97.72 \u00b10.75 96.31 \u00b10.95 97.01 existence_no (extended) 81.38 \u00b11.50 84.69 \u00b11.39 83.00 (final)* 87.27 \u00b11.29 91.67 \u00b11.07 89.42 (final on eval) 84.41 \u00b11.82 89.89 \u00b11.51 87.06 uncertainty_yes (extended) 76.75 \u00b11.63 64.25 \u00b11.85 69.95 (final)* 81.06 \u00b11.51 82.03 \u00b11.48 81.54 (final on eval) 78.52 \u00b12.06 78.26 \u00b12.07 78.39 uncertainty_no (extended) 79.20 \u00b11.57 87.49 \u00b11.28 83.14 (final)* 88.36 \u00b11.24 87.68 \u00b11.27 88.02 (final on eval) 86.01 \u00b11.74 86.19 \u00b11.73 86.10 \u2606 This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial-No Derivative Works License, which permits non-commercial use, distribution, and reproduction in any medium, provided the original author and source are credited. Cue-based assertion classification for Swedish clinical text\u2014Developing a lexicon for pyConTextSwe Sumithra Velupillai a \u204e sumithra@dsv.su.se Maria Skeppstedt a mariask@dsv.su.se Maria Kvist a b maria.kvist@karolinska.se Danielle Mowery c dlm31@pitt.edu Brian E. Chapman d brian.chapman@utah.edu Hercules Dalianis a hercules@dsv.su.se Wendy W. Chapman e wendy.chapman@utah.edu a Department of Computer and Systems Sciences (DSV), Stockholm University, Forum 100, 164 40 Kista, Sweden Department of Computer and Systems Sciences (DSV), Stockholm University Forum 100 Kista 164 40 Sweden b Department of Learning, Informatics, Management and Ethics (LIME), Karolinska Institutet, Widerstr\u00f6m Building, Tomtebodav\u00e4gen 18A, Solna, Sweden Department of Learning, Informatics, Management and Ethics (LIME), Karolinska Institutet Widerstr\u00f6m Building, Tomtebodav\u00e4gen 18A Solna Sweden c Department of Biomedical Informatics, University of Pittsburgh, 5607 Baum Boulevard, BAUM 423, Pittsburgh, PA 15206-3701, United States Department of Biomedical Informatics, University of Pittsburgh 5607 Baum Boulevard, BAUM 423 Pittsburgh PA 15206-3701 United States d Department of Radiology, University of Utah, 729 Arapeen Drive, Salt Lake City, UT 84108, United States Department of Radiology, University of Utah 729 Arapeen Drive Salt Lake City UT 84108 United States e Department of Biomedical Informatics, University of Utah, 26 South 2000 East, Room 5775 HSEB, Salt Lake City, UT 84112-5775, United States Department of Biomedical Informatics, University of Utah 26 South 2000 East, Room 5775 HSEB Salt Lake City UT 84112-5775 United States \u204e Corresponding author. Tel.: +46 8161174. Abstract Objective The ability of a cue-based system to accurately assert whether a disorder is affirmed, negated, or uncertain is dependent, in part, on its cue lexicon. In this paper, we continue our study of porting an assertion system (pyConTextNLP) from English to Swedish (pyConTextSwe) by creating an optimized assertion lexicon for clinical Swedish. Methods and material We integrated cues from four external lexicons, along with generated inflections and combinations. We used subsets of a clinical corpus in Swedish. We applied four assertion classes (definite existence, probable existence, probable negated existence and definite negated existence) and two binary classes (existence yes/no and uncertainty yes/no) to pyConTextSwe. We compared pyConTextSwe's performance with and without the added cues on a development set, and improved the lexicon further after an error analysis. On a separate evaluation set, we calculated the system's final performance. Results Following integration steps, we added 454 cues to pyConTextSwe. The optimized lexicon developed after an error analysis resulted in statistically significant improvements on the development set (83% F-score, overall). The system's final F-scores on an evaluation set were 81% (overall). For the individual assertion classes, F-score results were 88% (definite existence), 81% (probable existence), 55% (probable negated existence), and 63% (definite negated existence). For the binary classifications existence yes/no and uncertainty yes/no, final system performance was 97%/87% and 78%/86% F-score, respectively. Conclusions We have successfully ported pyConTextNLP to Swedish (pyConTextSwe). We have created an extensive and useful assertion lexicon for Swedish clinical text, which could form a valuable resource for similar studies, and which is publicly available. Keywords Assertion classification Clinical text mining Dictionaries Medical Language Processing Information extraction Electronic health records 1 Introduction The concept of negation and the use of negations have puzzled humans for thousands of years. Plato wrote about the concept in the Sophist, Aristotle in several of his writings, among numerous other philosophers [1, pp. 1\u201399]. A negation phrase or cue changes the semantics of an expression in different ways depending on the context in which it is conveyed. Negation interpretation is considered a difficult task in natural language processing (NLP). Negation strength is also diverse: it can be weak or strong or uncertain at various levels. The introduction of electronic health records has prompted the need for accurate NLP in the health care sector. Asserting whether a disorder mention in clinical text is negated or uncertain plays a critical role in, for example, information extraction and document retrieval. Clinical applications that can benefit from assertion classifications include chart review, diagnostic coding, and problem list generation. For instance, filtering positively asserted disorder mentions from negative or uncertain disorder mentions would be useful for many clinical tasks. Although assertion classification for English has received considerable attention with shared tasks [2\u20134], assertion research for other languages is still in its early stages [5\u20139]. The development of algorithms for a new language faces several challenges. Obtaining and annotating a data set takes time and resources. Developing and validating a system has trade-offs between model complexity and system accuracy. Leveraging existing lexical and system resources developed for another language could reduce this burden. Indeed, some studies have successfully exploited lexical cues from openly available data sets such as BioScope [10] and lexical knowledge generated from existing systems such as NegEx for other languages such as Swedish and French [5] and [7]. In a previous study, we ported an existing assertion classifier (pyConTextNLP [11]) from English to Swedish (pyConTextSwe [12]). We observed promising results (development set: 82% F-score; evaluation set: 74% F-score), but our error analysis revealed the need for more lexical cues. We hypothesize that adding cues from other lexical resources and expanding our lexicon can improve pyConTextSwe's predictive performance. We aim to continue our feasibility study of porting existing lexical resources and assertion systems from English to Swedish for assertion classification with the following three goals: (1) develop an assertion lexicon for NLP of Swedish clinical texts based on translations of existing English lexicons; (2) expand the lexicon from additional resources and cues found through error analysis, and also learn which cues real clinical data actually use; and (3) provide an analysis of the issues involved in cue-based classification and lexicon development for this task. To address these goals, we integrated lexical cues from existing lexical resources and expanded our evaluation of pyConTextSwe on Swedish clinical texts. 2 Background In clinical reality, care providers do not always have sufficient information to assert whether a disorder is negated or affirmed with high certainty, for example, due to the knowledge that some examination methods include error margins. Care providers make use of epistemic modality and linguistic hedging to indicate a level of certainty or uncertainty about whether a disorder exists. Researchers acknowledge this relationship between negation and uncertainty by modeling these phenomena as a continuum ranging from definitely positive to definitely negative [8,13,11]. For instance, in \u201cPatient most likely has pneumonia,\u201d the care provider asserts that pneumonia is a probable diagnosis with certainty expressed as a high probability. To automatically identify a disorder mention and assert the degree to which it is being negated or affirmed continues to be an active research question. 2.1 Negation and uncertainty classification Negation and uncertainty classification was the focus of several recent shared tasks including the 2010 i2B2/VA Challenge [2], CoNLL-2010 [3], and BioNLP 2009 [4] in clinical, biomedical, and biological texts, respectively. Each of these tasks commonly applied rule-based and machine-learning approaches. The shared task closest to clinical negation and uncertainty classification for disorder mentions is the 2010 i2B2/VA Challenge [2]. For the challenge, participants developed systems for asserting whether a disorder was present, absent, or possible among other assertion labels. The highest performing systems used custom dictionaries and rule-based systems\u2019 output as feature sources for machine-learning algorithms. The best assertion classifier achieved a 94% F-score with a multi-class support vector machine [14]. Researchers have also developed a number of negation and uncertainty detection systems, independently of shared tasks. For instance, NegEx [15], NegFinder [16], and NegExpander [17] achieve high performance for detecting negated disorders, using cue lexicons and heuristics. For uncertainty, NLP tools achieve moderate to high performance for asserting the uncertainty level of disorders, using rule-based and machine-learning approaches, including StAC [18], CARAFE [19], pyConTextNLP [11], and others [9]. Traditionally, assertion classification consists of two processing steps: (1) detecting an assertion cue (e.g. \u201cnot\u201d and \u201cdenies\u201d for negation and \u201cmost likely\u201d and \u201cpossibility of\u201d for uncertainty) and (2) predicting its scope. 2.2 Negation cue detection and scope Researchers have used both rule-based and machine-learning approaches to study negation cues and their scope [6,20\u201322]. Goldin and Chapman compare naive Bayes and decision trees to learn scope patterns for the frequent cue \u201cnot\u201d and achieve 81% and 88% precision, respectively, compared to 60% for a token distance-based method [20]. Morante et al. used a supervised inductive algorithm based on k-nearest neighbor to predict whether a token is a negation term and to learn its scope using token (morphological and syntactic information) and token context (morphological and syntactic information of three preceding and succeeding tokens) in biomedical texts [21]. They observed that correctly identifying negation terms beyond \u201cno\u201d and \u201cnot\u201d can improve detection of negation signals with F-scores improving 7 points. Agarwal and Yu describe a systematic analysis of negation terms and scope for predicting the negation status of disorder mentions on the NegEx test data using their systems NegCue and NegScope [22]. The major source of false negatives for NegCue were entities preceded by \u201cdenied\u201d or \u201cdenies;\u201d these negation cues did not occur in the BioScope training corpus. After incorporating these negation cues, the F-score of the system increased by about 7 points. The authors found the majority of remaining errors were scope errors, not errors due to missing cues. 2.3 Uncertainty cue detection and scope Understanding coverage and scope of uncertainty cues is perhaps more complex due to the varying degrees of uncertainty and the lexicosyntactic patterns used to express them [23]. Several studies have described the effect of coverage and scope of uncertainty cues for uncertainty classification tasks [9,11,18,19]. Uzuner et al. developed StAC, a support vector machine trained with lexical and syntactic features, to assert whether a disorder was positive, negative, or uncertain [18]. They compared StAC's performance against an extended version of NegEx called ENegEx. Some of ENegEx's most frequent mistakes were the result of an incomplete lexicon, for example, missing uncertainty cues such as \u201cmost likely.\u201d StAC outperformed ENegEx using a \u00b14 word window and section headings for addressing cue scope. They observed that a \u00b12 syntactic link window reduces the number of false positives created when a negation cue such as \u201cno\u201d modifies the head noun phrase and not the adjectival, prepositional noun phrase as in \u201cno intervention due to cardiovascular disease.\u201d Clark et al. integrated CARAFE, a conditional random fields model trained to detect negation and uncertainty cues and their scopes, with a rule-based module to assert whether a disorder was present, absent, or possible [19]. Word features such as unigrams within the disorder as well as words within a \u00b13 token window of the disorder contributed most to assertion performance, resulting in an F-score of 91%. Most possible assertions were incorrectly classified as present due to missing uncertainty cues. For instance, the uncertainty cue \u201cpossibility of\u201d was not among the certainty cues learned from the BioScope corpus. In other cases, the effect of the scope of the cue was not terminated, so a disorder was incorrectly asserted as possible. For instance, a cue term such as \u201cquestion of\u201d should have only modified the first noun phrase in a series of enumerated noun phrases in the sentence. 2.4 pyConTextNLP The existing assertion classifier used in this study is pyConTextNLP, a Python library that is a partial implementation of the ConText algorithm [24] that generalizes the concepts of targets and cues to include any type of relationship specified by the user. pyConTextNLP has previously been used for a variety of medical-text-processing tasks including identifying and characterizing pulmonary embolism findings in computed tomography (CT) pulmonary angiography reports (disease state, uncertainty, and temporality) [11], determining CT exam quality [11], identifying spatial location of pulmonary emboli findings [25], identifying critical findings in radiology reports [26], auditing chest biopsy complications [27], and identifying ancillary cancers in history and physical exam reports [11]. pyConTextNLP processes sentences to identify targets and modifiers. Targets are phrases in the sentence that represent the primary items to be extracted (e.g., pneumonia or stenosis). Modifiers, as the name indicates, are phrases in the sentence that modify other phrases. In pyConTextNLP, each modifier has a rule that determines the scope of influence the modifier has within the sentence. Currently the rules have four values: (1) backward, (2) forward, (3) bidirectional, and (4) terminate. The first three rules indicate that the modifier interacts with targets and define the scope of the modifier within the sentence (i.e., before and/or after the modifier). The terminate rule indicates that the modifier interacts with other modifiers by terminating their scope. Modifiers are grouped into classes such as temporality, existence, locality, or severity. Termination modifiers (e.g., \u201cbut\u201d or \u201cyet\u201d) terminate the scope of a modifier. Modifiers act upon a particular target if the target lies within the scope of the modifier. Targets, modifiers, and conjunctions are all identified within the text using Python regular expressions. pyConTextNLP uses a graph (G) to represent the sentence markup. When a target or modifier phrase is identified within a sentence, a node (n i ) is added to the graph for that identified phrase. Phrases that are subsets of other marked phrases are deleted from the graph. For example, in the sentence fragment \u201cThere is no definite evidence of...,\u201d both \u201cno\u201d and \u201cno definite evidence\u201d would be identified as modifiers from the provided lexicon and each have a node added to G, but the node for \u201cno\u201d would be deleted from G because it is a subset of \u201cno definite evidence.\u201d If a modifier (n i ) modifies a target or another modifier (n j ), an edge e (i,j) is added between n i and n j . All of its predecessor nodes determine the state of an identified target. If a target is not modified by any nodes, we assume a default state for the target. 3 Materials and methods For this study, we used three subsets of a clinical corpus in Swedish, the Stockholm electronic patient record (EPR) Corpus (SEPR-C) [28]. 1 1 Approved by the Regional Ethical Review Board in Stockholm (Etikpr\u00f6vningsn\u00e4mnden i Stockholm), permission number 2009/1742-31/5. All subsets are assessment entries (years 2006\u20132010) from emergency departments at Karolinska University Hospital, Stockholm, Sweden, authors unknown. We used two subsets from the Stockholm EPR diagnosis uncertainty corpus (SEPR-DUC) [29], annotated for uncertainty and negation on a diagnostic-statement level [8], as development and evaluation sets (see Sections 3.2 and 3.3). We used a third, previously unused, larger subset to study cue coverage (see Section 3.1.1). In addition to this data, we used cue resources (see Section 3.1). We took the following steps in this study: (1) construct a cue lexicon, (2) improve this lexicon on the development set, and (3) final evaluation on the evaluation set (see Fig. 1 ). 3.1 Constructing a cue lexicon We obtained uncertainty and negation cues from seven different sources: (1) cues from the English version of pyConTextNLP [11], (2) cues from the clinical part of the English BioScope corpus [10], (3) cues from the Stockholm EPR sentence uncertainty corpus (SEPR-SUC) [29], (4) cues from Swedish SNOMED CT [30], (5) automatically generated inflections of cues obtained through sources 1\u20134, (6) automatically generated cue combinations from cues obtained through sources 1\u20135, and (7) cues obtained from error analysis on the development set. Cues from pyContextNLP and from the BioScope corpus were translated into Swedish with Google translate and thereafter manually corrected. In cases in which several translation candidates were generated, we added all correct translation suggestions to the list of translated cues. From SEPR-SUC, we added negation and uncertainty cues annotated by three annotators. From SNOMED CT, we extracted the preferred term of descendants of the nodes Finding context value, Certainties, Absence findings, Reason and justification, General information qualifier, and Presence findings. Swedish is a more inflective language than, for example, English. To address Swedish inflections, we expanded the cue list with automatically generated inflections using the Granska inflector [31]. An alternative would be to lemmatize text and cues, which, however, would result in a possible loss of information, because one inflected form might be a suitable cue word, whereas other forms might not. 3.1.1 Cue coverage To limit the cue lexicon, we counted the frequency of each cue on a separate subset of the SEPR-C. The aim was to determine which cues are actually used in real data. To mimic the development and evaluation set (see Sections 3.2 and 3.3), we obtained this subset by extracting sentences containing at least one of the predefined diagnostic statements used in these sets, resulting in a total of 48,512 sentences. We extracted the subset, hereafter called the diagnostic statement (DS) set, on completely new assessment entries from the SEPR-C. We excluded from the lexicon cues that were not found in the DS set. 3.1.2 Cue combinations We also used the DS set for finding combinations of cues. All cues that occurred as least once in the corpus were split into separate tokens and added to a list of possible tokens to include in negation and uncertainty cues. We then extracted all cue phrases that could be constructed with combinations of these tokens and that occurred frequently in the corpus. A combination cue phrase was allowed to have a maximum of five tokens, and combinations occurring seven times or more in the DS set were gathered as potential candidates for the cue lexicon. For instance, from the tokens in the cues l\u00e5g sannolikhet (\u201clow probability\u201d = probable negated existence), and misstanke om (\u201csuspicion for\u201d = probable existence), the combination cue l\u00e5g misstanke om (\u201clow suspicion for\u201d = probable negated existence) was generated. 3.1.3 Manual cue classification Collected cues were manually classified for assertion level and directionality by two persons (a physician, and a researcher trained in linguistics). A cue could also be classified as a pseudo negation (e.g., \u201cno change\u201d) or termination cue (e.g., \u201cbut\u201d). A third person (a computational linguistics researcher) resolved disagreements. 3.2 Evaluating and improving lexicon on a development set We used pyContextSwe [12] to evaluate the assertion classification lexicons. As described above, PyConTextNLP marks all modifiers (i.e., cues) found for a given target (i.e., diagnostic statement). In many cases, several cues can be found for a given target. For handling such potentially conflicting cues, we have defined a number of precedence rules in pyConTextSwe. For instance, the system identifies the two cues ej (\u201cnot\u201d = definite negated existence) and sannolik (\u201clikely\u201d = probable existence) in the sentence, \u201cThis is not likely a heart attack,\u201d with the target diagnostic statement heart attack, which through the precedence rules generates the output value probable negated existence. For development and later for evaluation, we used two subsets from SEPR-DUC. These sets are annotated on a diagnostic-statement level for uncertainty and negation in six classes: two polarities (positive and negative) and three levels of certainty (certain, probable, possible). We used a predefined set of diagnostic statements (approx. 300), 2 2 The result of a previous annotation study for identification of diagnostic statements from the SEPR-C. This set includes misspellings, inflections, etc. and the annotation task was to assign an assertion class to each diagnostic statement, for example, \u201cPatient with diabetes. No clear signs of pneumonia.\u201d would result in the annotations diabetes = certainly positive and pneumonia = probably negative [8]. For this study, the six original classes were mapped into four assertion levels: definite existence, probable existence, probable negated existence, and definite negated existence, in order to better accommodate to the original pyConTextNLP assertion cue classes. The default assertion class is definite existence. The development set consists of a total of 2574 instances (diagnostic statements) in their original context (Table 1 ). For a qualitative error analysis, we used results of assertion classification using pyConTextSwe on the development set. The main purpose of this error analysis was to find missing, misclassified, or erroneous cues. We used these findings to extend and correct the cue lexicon. Moreover, the error analysis gave insights on error themes and other higher-level, non-lexical, error types. 3.3 Evaluation As a last step, pyConTextSwe with the extended and corrected cue lexicon was evaluated on an evaluation set consisting of 1525 diagnostic statements (Table 1). We compared results with a baseline (translated and corrected cues from pyConTextNLP [12]) and measured results on the development set with lexicons before and after the error analysis. We performed assertion classification in the four classes definite existence, probable existence, probable negated existence, and definite negated existence as well as two binary classifications, existence yes/no (definite + probable existence = existence yes and definite negated + probable negated existence = existence no) and uncertainty yes/no (definite + definite negated existence = uncertainty no and probable + probable negated existence = uncertainty yes). We evaluated results with precision, recall, and F-score. We calculated 95% confidence intervals for precision and recall. We applied McNemar's test with continuity correction to assess whether different lexicon models produced statistically different class accuracy on the development set (using \u03b1 =0.05). 4 Results We created three incremental versions of a cue lexicon: extended, extended+comb, and after error analysis, final. We used all three lexicons to evaluate the performance of pyConTextSwe on the development set and compared the results with the baseline. We also used the final lexicon to evaluate pyConTextSwe on the evaluation set (Table 2 ). 4.1 Construction of cue lexicon From the four external cue resources, pyConTextNLP, BioScope, SEPR-SUC, and SNOMED CT, we obtained a total of 551 cues for the classes definite existence, probable existence, probable negated existence, definite negated existence, termination, and pseudo negation. Through the coverage analysis (Section 3.1.1), a number of cues were removed because they were not found in the DS set, resulting in a lexicon of 278 cues. 3 3 We observed no difference in results when we also included these cues in the lexicon. Generating inflections on these cues resulted in a lexicon consisting of 454 cues in total (Table 3 ). This lexicon is called the extended lexicon. In addition to these cues, we created combinations of the cues in the extended lexicon, resulting in a total of 575 cues. This lexicon is called extended+comb. The class probable existence contained the highest number of cues, whereas cues for definite existence and pseudo negation were scarcer. However, note that definite existence is the default class for pyConTextSwe, thus specific cues are not as necessary for this class. 4.2 Evaluating and improving lexicon on development set Overall results for the assertion classification into the four levels of certainty using the extended lexicon were 74% F-score on the development set, a statistically significant improvement over the baseline (63%) (Table 3). Using the extended+comb lexicon slightly improved results further: 75%. For definite negated existence, baseline results were similar to results with the extended lexicon (63% versus 65%), but the improvement was statistically significant. Results for probable existence were substantially improved with the extended lexicon: 71% compared to 36% (baseline). In particular, recall was much higher (70% versus 26%), without much loss in precision. 4.2.1 Results from error analysis The most common errors found through the error analysis were of two types: (1) missing cues and (2) borderline cues, in particular for the distinction between definite negated existence and probable negated existence. Also, errors arose from scoping errors, annotation mistakes, and misspelled cues. Missing cues were either completely new, for example, prelimin\u00e4rt (\u201ctentatively\u201d), behandlingsindikation (\u201ctreatment indication\u201d), or variations of existing cues, for example, ingen som helst misstanke (\u201cno suspicion at all\u201d), med all sannolikhet ingen (\u201cwith all certainty no\u201d), that were not properly captured through the individual cues combined with precedence rules and directionality. The missing cues also included abbreviated forms of existing cues, for example, trol (\u201cprobably,\u201d abbreviation of troligen), susp (\u201csuspected,\u201d abbreviation of suspekt). Missing cues were added to the lexicon. Some termination cues were also added, for example, p.g.a (\u201cbecause of,\u201d a common abbreviation of p\u00e5 grund av). The error analysis also resulted in a change of class for some borderline cues, such as inga tecken p\u00e5 (\u201cno signs of\u201d), inga h\u00e5llpunkter f\u00f6r (\u201cno evidence for\u201d), visar inte (\u201cdoes not show/reveal\u201d), from definite negated existence to probable negated existence, or vice versa. However, these borderline cues are in general problematic because such cues indicate definite negation or probable negation differently depending on context, for example, the type of target (diagnostic statement) and/or examination method. Some errors were due to complex sentences, and not the cues themselves. Also, the scope was too long in some cases, for example, sentences with many subordinate clauses that were only marked by commas, or lack of suitable termination cues. Only a few errors were due to misspelled cues. Some misclassified instances in the gold standard also occurred. The precedence rules resulted in some erroneous classifications. The error analysis resulted in a lexicon with some modifications in directionality and class for existing cues, removal of some problematic cues, and added cues (in total 155). This lexicon is called final (Table 2). 4.2.2 Cue lexicon coverage The number of cues actually found in the development and evaluation sets using the extended lexicon was much lower than the number of cues in the lexicon itself (Table 3), for example, 92 for probable existence (compared to 224 in the extended lexicon). To study how many cues were actually needed in the lexicon, we studied the effect of including only the n most frequent cues, starting with n = 5, and gradually increasing n. Fig. 2 shows the effect of different cut-off points using the extended lexicon before and after the error analysis (final lexicon). For probable existence, adding more cues steadily improved results, and a leap in performance occurred between the cut-off points 80\u201390 using the extended lexicon. This cut-off point changed to between 90 and 100 when using the final lexicon. For this class, adding more cues improved performance in general. We did not find the same effect for the other classes. For instance, the number of cues for probable negated existence found by pyConTextSwe was never greater than 62 (Table 3), but results leveled out already at a cut-off point of 40. Fig. 2 also clearly illustrates the relationship between the two negative polarity classes, probable negated existence and definite negated existence. Before the error analysis, using the extended lexicon, results for definite negated existence were higher at all cut-off points compared with using these cues after the error analysis (the final lexicon), whereas results for probable negated existence were slightly lower. We obtained the best results for all classes on the development set, using the final lexicon. This lexicon consists of a total of 744 unique cues (Table 2) in the four assertion classes plus termination cues and pseudo negations, out of which 284 were actually found by pyConTextSwe in the development set. From these 284 found cues, 46% originate from the external resources, 19% from the generated combinations, and 35% from the added cues from the error analysis. When counting types instead, we find 59% originate from the external resources, 26% from combinations, and 15% from the error analysis. 4.3 Evaluation When using the final lexicon, overall results for the assertion classification into the four assertion levels were 83% F-score on the development set and 81% on the evaluation set. Results for all four classes improved with the final lexicon compared to the extended lexicon on the development set, and were statistically significant, except for the results for probable negated existence (Table 3). The results on the evaluation set were close to the upper ceiling (using the final lexicon on the development set) for three of the four classes: 88% versus 91% (definite existence), 81% versus 82% (probable existence), and 55% versus 58% (probable negated existence). Only for definite negated existence, we found a somewhat larger performance difference, 63% versus 71% (Table 3). When looking at the binary classifications existence yes/no and uncertainty yes/no (Table 4 ), results on the development set for uncertainty yes improved and were statistically significant when using the final lexicon compared to the extended, from 70% to 81% F-score, where recall accounted for the greatest improvement (from 64% to 82%). The results for the binary classifications on the evaluation set were close to the performance on the development set. The class existence no (corresponding roughly to a negation identification task) resulted in an F-score of 89% on the development set and 87% on the evaluation set, which is a smaller difference compared to the drop in performance for the individual class definite negated existence. 5 Discussion This study shows that adding cues from external lexical resources, generated inflections, and combinations, and developing a final lexicon through an error analysis does improve pyConTextSwe's predictive performance. Results for the four-level assertion classification on the final evaluation set show an improvement compared with previous findings [12]. Although the classification task differs slightly, results are also comparable to a machine-learning-based approach trained and evaluated on a larger subset of the SEPR-DUC [9]. Compared to approaches taken for English, results are lower than those reported by, for example, de Bruijn et al. [14]. However, that study does not employ the same four-level definition of assertion classification. Chapman et al. [11] report results for certainty-level classification as 94% recall, which is higher compared to overall results reported in our study, although assertion classification is performed on a document level. The SEPR-DUC was created with a focus on clinical reality, not from a linguistic perspective, which is one of the reasons borderline cues such as \u201cno signs of\u201d and \u201cno evidence of\u201d in some cases were annotated as probable negated existence, and in other cases as definite negated existence. Context, as well as clinical knowledge, plays an important role for determining the meaning of these cues. We have done an extensive study on Swedish uncertainty cues, and conclude that finding all cues and/or combinations is almost impossible. In particular, one can express probability in the positive polarity (probable existence) in innumerable ways. However, many cues are frequent; thus reasonable results can be obtained given limited resources. On the other hand, for the negative polarity, the number of cues is more limited. However, the distinction between probable and definite negated is not trivial, particularly in tasks such as this, that is, assertion classification on a diagnostic-statement level. For this type of task, other aspects influence results, for example, the type of disorder and the type of examination method (e.g., screening or lab tests) used. For translation and portability from English to Swedish, manual correction is needed. For instance, inflections need to be added or handled differently for Swedish compared to English. Once a potential cue is found, manually assigning an assertion class without context is relatively simple. Only some corrections were necessary after the error analysis in this study. However, manually assigning the appropriate assertion class to new cues is a time-consuming task. One way to minimize this work load is to perform a cue coverage study on larger data sets, thus limiting the number of cues that need to be classified. Moreover, in almost all cases, the class assignment was the same for Swedish as it was for English, but this similarity may not hold for other languages. Generating new combinations from existing multi-word cues is also useful. However, this process also results in a lot of noise that needs to be manually checked. Multi-word cues are also related to scope, which has not been the focus of this study. However, some errors arise from the fact that suitable termination cues are not in the lexicon. The nature of this type of clinical text is informal and telegraphic, with many cases of incorrect syntax, which generates complex sentences, for example, subordinate clauses not containing conjunctions, or incompleteness. 6 Conclusions We have successfully ported PyContextNLP to Swedish (pyContextSwe). Fully capturing borderline cues in the negative polarity is difficult in a lexicon-based system, because context plays an important role in these cases. We have created an extensive and useful assertion lexicon for Swedish clinical text, which is publicly available. 4 4 http://dsv.su.se/health/dictionaries. Obtaining cues through external resources is worth the effort; many cues identified by pyConTextSwe stemmed from these. However, for improved results, an error analysis is essential to further enrich the lexicon. This lexicon could form a valuable resource for similar studies. Other features are also important for this task, for example, scope, which we plan to study further separately. Conflict of interest statement We certify that there is no conflict of interest with any financial organization or personal relationship regarding the material discussed in the manuscript. Acknowledgements The study is funded by the V\u00e5rdal Foundation, NIH grant 1R01LM010964, NLM Fellowship 5T15LM007059. We acknowledge the Interlock project, funded by the Stockholm University Academic Initiative. References [1] L.R. Horn A natural history of negation, vol. 960 1989 University of Chicago Press Chicago [2] \u00d6. Uzuner B. South S. Shen S. DuVall 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text JAMIA 18 2011 552 556 [3] R. Farkas V. Vincze G. M\u00f3ra J. Csirik G. Szarvas The CoNLL-2010 shared task: learning to detect hedges and their scope in natural language text R. Farkas Proc. 14th CoNLL ACL, Stroudsburg, PA, USA 2010 1 12 [4] J.-D. Kim T. Ohta S. Pyysalo Y. Kano J. Tsujii Overview of BioNLP\u201909 shared task on event extraction K.B. Cohen D. Demner-Fushman S. Ananiadou J. Pestian J. Tsujii B. Webber BioNLP \u201809 ACL, Stroudsburg, PA, USA 2009 1 9 [5] M. Skeppstedt Negation detection in Swedish clinical text: an adaption of NegEx to Swedish Journal of Biomedical Semantics 2 2011 S3 [6] H. Tanushi H. Dalianis M. Duneld M. Kvist M. Skeppstedt S. Velupillai Negation scope delimitation in clinical text using three approaches: NegEx, PyConTextNLP and SynNeg S. Oepen K. Hagen J. Bondi Johannessen Proc. 19th NODALIDA, NEALT 2013 Link\u00f6ping University Electronic Press, Link\u00f6ping Sweden 387 397 [7] L. Del\u00e9ger C. Grouin Detecting negation of medical problem in French clinical notes G. Luo J. Liu C.C. Yang Proc. 2nd ACM SIGHIT, Intl. health informatics, 2012 ACM, New York, NY, USA 2012 697 702 [8] S. Velupillai H. Dalianis M. Kvist Factuality Levels of Diagnoses in Swedish Clinical Text A. Moen S.K. Andersen J. Aarts P. Hurlen Proc. 23rd MIE 2011 IOS Press Amsterdam, The Netherlands 559 563 [9] S. Velupillai Automatic classification of factuality levels\u2014a case study on Swedish diagnoses and the impact of local context Proc. 4th LBM Singapore 2011 [10] V. Vincze G. Szarvas R. Farkas G. M\u00f3ra J. Csirik The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes BMC Bioinformatics 9 2008 S9 [11] B. Chapman S. Lee H. Kang W. Chapman Document-level classification of CT pulmonary angiography reports based on an extension of the ConText algorithm J Biomed Inform 44 2011 728 737 [12] S. Velupillai M. Skeppstedt M. Kvist D. Mowery B.E. Chapman H. Dalianis W.W. Chapman Porting a rule-based assertion classifier for clinical Text from English to Swedish H. Suominen Proc. Louhi 2013 Sydney, Australia 2013 [13] C. Friedman O. Alderson H. Austin J. Cimino B. Johnson A general natural language text processor for clinical radiology JAMIA 1 1994 161 174 [14] B. deBruijn C. Cherry S. Kiritchenko J. Martin X. Zhu Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010 JAMIA 2011 557 562 [15] W.W. Chapman W. Bridewell P. Hanbury G.F. Cooper B.G. Buchanan A simple algorithm for identifying negated findings and diseases in discharge summaries J Biomed Inform 2001 301 310 [16] P. Mutalik A. Deshpande P. Nadkarni Use of general-purpose negation detection to augment concept indexing of medical documents a quantitative study using the umls JAMIA 8 2001 598 609 [17] D. Aronow F. Feng W.B. Croft Ad-hoc classification of radiology reports JAMIA 1999 393 411 [18] \u00d6 Uzuner X. Zhang T. Sibanda Machine learning and rule-based approaches to assertion classification JAMIA 16 2009 109 115 [19] C. Clark J. Aberdeen M. Coarr D. Tresner-Kirsch B. Wellner A. Yeh L. Hirschman MITRE system for clinical assertion status classification JAMIA 18 2011 563 567 [20] I.M. Goldin W.W. Chapman Learning to detect negation with \u2018Not\u2019 in Medical Texts E. Brown W. Hersh A. Valencia Proc. Workshop on Text Analysis and Search for Bioinformatics at the 26th ACM SIGIR Conference 2003 [21] R. Morante A. Liekens W. Daelemans Learning the scope of negation in biomedical texts M. Lapata H. Tou Ng Proc. EMNLP '08 ACL, Stroudsburg, PA, USA 2008 715 724 [22] S. Agarwal H. Yu Biomedical negation scope detection with conditional random fields. JAMIA 17 2010 696 701 [23] H. Kilicoglu S. Bergler Recognizing speculative language in biomedical research articles: a linguistically motivated perspective BMC Bioinformatics 9 Suppl. 11 2008 S10 [24] H. Harkema J.N. Dowling T. Thornblade W.W. Chapman Context: an algorithm for determining negation, experiencer, and temporal status from clinical reports J Biomed Inform 42 2009 839 851 [25] R. Wilson B. Chapman Automated capture of pulmonary embolism spatial location in dictated reports using the ConText algorithm Presented at: Radiological Society of N. America Scientific Assembly and Annual Meeting 2011 [26] A. Gentili B. Chapman Use of pyConText to classify reports containing critical results Presented at: Radiological Society of N. America Scientific Assembly and Annual Meeting 2011 [27] A. Gentili B. Chapman Use of pyConText to Assist in Auditing for Chest Biopsy Complications Presented at: Radiological Society of N. America Scientific Assembly and Annual Meeting 2012 [28] H. Dalianis M. Hassel A. Henriksson M. Skeppstedt Stockholm EPR Corpus: a clinical Database used to improve health care P. Nugues Proc. 4th SLTC Lund 2012 17 18 [29] S. Velupillai Shades of Certainty \u2013 Annotation and Classification of Swedish Medical Records 2012 Department of Computer and Systems Sciences, Stockholm University Stockholm, Sweden [Doctoral thesis] [30] International Health Terminology Standards Development Organisation (IHTSDO) SNOMED-CT 2008 http://www.ihtsdo.org/snomed-ct [31] O. Knutsson J. Bigert V. Kann A robust shallow parser for Swedish Proc. 14th NODALIDA Reykjavik, Iceland 2003", "scopus-id": "84904321212", "pubmed-id": "24556644", "coredata": {"eid": "1-s2.0-S0933365714000037", "dc:description": "Abstract Objective The ability of a cue-based system to accurately assert whether a disorder is affirmed, negated, or uncertain is dependent, in part, on its cue lexicon. In this paper, we continue our study of porting an assertion system (pyConTextNLP) from English to Swedish (pyConTextSwe) by creating an optimized assertion lexicon for clinical Swedish. Methods and material We integrated cues from four external lexicons, along with generated inflections and combinations. We used subsets of a clinical corpus in Swedish. We applied four assertion classes (definite existence, probable existence, probable negated existence and definite negated existence) and two binary classes (existence yes/no and uncertainty yes/no) to pyConTextSwe. We compared pyConTextSwe's performance with and without the added cues on a development set, and improved the lexicon further after an error analysis. On a separate evaluation set, we calculated the system's final performance. Results Following integration steps, we added 454 cues to pyConTextSwe. The optimized lexicon developed after an error analysis resulted in statistically significant improvements on the development set (83% F-score, overall). The system's final F-scores on an evaluation set were 81% (overall). For the individual assertion classes, F-score results were 88% (definite existence), 81% (probable existence), 55% (probable negated existence), and 63% (definite negated existence). For the binary classifications existence yes/no and uncertainty yes/no, final system performance was 97%/87% and 78%/86% F-score, respectively. Conclusions We have successfully ported pyConTextNLP to Swedish (pyConTextSwe). We have created an extensive and useful assertion lexicon for Swedish clinical text, which could form a valuable resource for similar studies, and which is publicly available.", "openArchiveArticle": "false", "prism:coverDate": "2014-07-31", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/3.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0933365714000037", "dc:creator": [{"@_fa": "true", "$": "Velupillai, Sumithra"}, {"@_fa": "true", "$": "Skeppstedt, Maria"}, {"@_fa": "true", "$": "Kvist, Maria"}, {"@_fa": "true", "$": "Mowery, Danielle"}, {"@_fa": "true", "$": "Chapman, Brian E."}, {"@_fa": "true", "$": "Dalianis, Hercules"}, {"@_fa": "true", "$": "Chapman, Wendy W."}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0933365714000037"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0933365714000037"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0933-3657(14)00003-7", "prism:volume": "61", "prism:publisher": "The Authors. Published by Elsevier B.V.", "dc:title": "Cue-based assertion classification for Swedish clinical text\u2014Developing a lexicon for pyConTextSwe", "prism:copyright": "Copyright \u00a9 2014 The Authors. Published by Elsevier B.V.", "prism:issueName": "Text Mining and Information Analysis of Health Documents", "openaccess": "1", "prism:issn": "09333657", "prism:issueIdentifier": "3", "dcterms:subject": [{"@_fa": "true", "$": "Assertion classification"}, {"@_fa": "true", "$": "Clinical text mining"}, {"@_fa": "true", "$": "Dictionaries"}, {"@_fa": "true", "$": "Medical Language Processing"}, {"@_fa": "true", "$": "Information extraction"}, {"@_fa": "true", "$": "Electronic health records"}], "openaccessArticle": "true", "prism:publicationName": "Artificial Intelligence in Medicine", "prism:number": "3", "openaccessSponsorType": "Author", "prism:pageRange": "137-144", "prism:endingPage": "144", "prism:coverDisplayDate": "July 2014", "prism:doi": "10.1016/j.artmed.2014.01.001", "prism:startingPage": "137", "dc:identifier": "doi:10.1016/j.artmed.2014.01.001", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "high", "@height": "2417", "@width": "2833", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0933365714000037-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "455057", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1983", "@width": "2500", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0933365714000037-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "297652", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "546", "@width": "640", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0933365714000037-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "65247", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "448", "@width": "565", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0933365714000037-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "46282", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "192", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0933365714000037-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4651", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "207", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0933365714000037-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3940", "@ref": "gr1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84904321212"}}
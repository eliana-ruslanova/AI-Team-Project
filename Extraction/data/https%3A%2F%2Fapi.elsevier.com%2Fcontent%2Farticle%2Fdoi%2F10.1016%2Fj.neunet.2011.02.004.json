{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608011000566", "dc:identifier": "doi:10.1016/j.neunet.2011.02.004", "eid": "1-s2.0-S0893608011000566", "prism:doi": "10.1016/j.neunet.2011.02.004", "pii": "S0893-6080(11)00056-6", "dc:title": "Learning parametric dynamic movement primitives from multiple demonstrations ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "24", "prism:issueIdentifier": "5", "prism:startingPage": "493", "prism:endingPage": "500", "prism:pageRange": "493-500", "prism:number": "5", "dc:format": "application/json", "prism:coverDate": "2011-06-30", "prism:coverDisplayDate": "June 2011", "prism:copyright": "Copyright \u00a9 2011 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Matsubara, Takamitsu"}, {"@_fa": "true", "$": "Hyon, Sang-Ho"}, {"@_fa": "true", "$": "Morimoto, Jun"}], "dc:description": "\n               Abstract\n               \n                  Learning from demonstration has shown to be a suitable approach for learning control policies (CPs). However, most previous studies learn CPs from a single demonstration, which results in limited scalability and insufficient generalization toward a wide range of applications in real environments. This paper proposes a novel approach to learn highly scalable CPs of basis movement skills from multiple demonstrations. In contrast to conventional studies with a single demonstration, i.e., dynamic movement primitives (DMPs), our approach efficiently encodes multiple demonstrations by shaping a parametric-attractor landscape in a set of differential equations. Assuming a certain similarity among multiple demonstrations, our approach learns the parametric-attractor landscape by extracting a small number of common factors in multiple demonstrations. The learned CPs allow the synthesis of novel movements with novel motion styles by specifying the linear coefficients of the bases as parameter vectors without losing useful properties of the DMPs, such as stability and robustness against perturbations. For both discrete and rhythmic movement skills, we present a unified learning procedure for learning a parametric-attractor landscape from multiple demonstrations. The feasibility and highly extended scalability of DMPs are demonstrated on an actual dual-arm robot.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Imitation learning"}, {"@_fa": "true", "$": "Movement primitives"}, {"@_fa": "true", "$": "Motion styles"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608011000566", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608011000566", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "79953692970", "scopus-eid": "2-s2.0-79953692970", "pubmed-id": "21388784", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/79953692970", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20110216", "$": "2011-02-16"}}}}}
{"scopus-eid": "2-s2.0-85057047743", "originalText": "serial JL 271763 291210 291781 291792 31 90 Environment International ENVIRONMENTINTERNATIONAL 2018-11-22 2018-11-22 2018-12-26 2018-12-26 2019-11-27T16:44:54 1-s2.0-S0160412018322001 S0160-4120(18)32200-1 S0160412018322001 10.1016/j.envint.2018.11.042 S300 S300.4 FULL-TEXT 1-s2.0-S0160412018X00129 2020-03-05T12:18:49.422577Z 0 0 20190101 20190131 2019 2018-11-22T19:45:20.998095Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure body acknowledge affil articletitle auth authfirstini authfull authlast grantsponsor grantsponsorid highlightsabst misctext orcid primabst ref 0160-4120 01604120 UNLIMITED NONE true 122 122 C Volume 122 3 3 10 3 10 201901 January 2019 2019-01-01 2019-01-31 2019 Short Review article ssu \u00a9 2018 The Authors. Published by Elsevier Ltd. APICTURETELLSATHOUSANDEXPOSURESOPPORTUNITIESCHALLENGESDEEPLEARNINGIMAGEANALYSESINEXPOSURESCIENCEENVIRONMENTALEPIDEMIOLOGY WEICHENTHAL S 1 Introduction 2 How does deep learning work? 3 A not so black box 4 Outdoor air pollution estimation using deep convolutional neural networks 5 Motivating examples from other disciplines 6 Data sources 6.1 Google street view images 6.2 Satellite images and remote sensing 6.3 Beyond images 7 Future opportunities and challenges 7.1 Opportunities 7.1.1 Multiple data streams for multiple exposures 7.1.2 Audio data 7.2 Challenges 7.2.1 Building databases 8 Conclusions Funding References ANGERMUELLER 2016 878 C APTE 2017 6999 7008 J ARHAMI 2013 4777 4789 M ARTHUR 2018 e0189327 R ASIMINA 2018 155 S AYKANAT 2017 M BELLINGER 2017 907 C BODDAPATI 2017 2048 2056 V BRAUER 2014 526 527 M BRAUER 2012 652 660 M CHAKMA 2017 3949 3952 A 2017IEEEINTERNATIONALCONFERENCEIMAGEPROCESSINGICIPBEIJING IMAGEBASEDAIRQUALITYANALYSISUSINGDEEPCONVOLUTIONALNEURALNETWORK CHOLLET 2018 F DEEPLEARNINGR CHOW 2014 e110042 C CHRISTIANSEN 2018 792 803 E COSTA 2018 1080 D CRUZROA 2017 46450 A DEFRIES 1994 3567 3586 R DENG X DING 2016 19481 19494 W EDWARDS 2013 22 30 N ESTEVA 2017 115 118 A FALLAHSHORSHANI 2018 10777 10786 M FAN 2017 J GAN 2012 W GEBRU 2018 13108 13113 T GOODFELLOW 2017 I DEEPLEARNING GULSHAN 2016 2402 2410 V HAN 2015 Y ACOUSTICSCENECLASSIFICATIONUSINGCONVOLUTIONALNEURALNETWORKSMULTIPLEWIDTHFREQUENCYDELTADATAAUGMENTATION HENDERSON 2011 1266 1271 S HENRIKSEN 2018 e110 A JEAN 2016 790 794 N KANG 2018 8 16 G KNIBBS 2014 204 211 L LANDRIGAN 2018 462 512 P LARKIN 2017 6957 6964 A LECUN 2015 436 444 Y LI 2018 109 119 X LI 2015 Y USINGUSERGENERATEDONLINEPHOTOSESTIMATEMONITORAIRPOLLUTIONINMAJORCITIES LI 2015 675 685 X LI 2016 22408 22417 X LI 2017 997 1004 X LIU 2016 e0145955 C MAHARANA 2018 e181535 A MOONEY 2014 626 635 S NAIK 2017 7571 7576 N NOVOTNY 2011 4407 4414 E NYHAN 2016 9671 9681 M NYHAN 2018 M PATTERSON 2016 35 43 Z PATTON 2015 6051 6060 A PENN 2015 47 55 S PICHAI S PICZAK 2015 K IEEE25THINTERNATIONALWORKSHOPMACHINELEARNINGFORSIGNALPROCESSINGMLSP2015BOSTONMA ENVIRONMENTALSOUNDCLASSIFICATIONCONVOLUTIONALNEURALNETWORKS POPLIN 2018 158 164 R QI 2017 Z RAWAT 2017 2352 2449 W RUGEL 2017 E RYAN 2007 127 133 P SCHOOTMAN 2016 20 M SIMONYAN 2013 K DEEPINSIDECONVOLUTIONALNETWORKSVISUALISINGIMAGECLASSIFICATIONMODELSSALIENCYMAPSARXIV13126034CSCV TAO 2016 e0161389 Z VIENNEAU 2013 13555 13564 D VONFISCHER 2017 4091 4099 J VOPHAM 2018 40 T WEICHENTHAL 2016 241 248 S XIE 2018 e94 J ZHANG 2018 601 615 C ZHU 2018 5 D WEICHENTHALX2019X3 WEICHENTHALX2019X3X10 WEICHENTHALX2019X3XS WEICHENTHALX2019X3X10XS Full 2018-11-17T22:09:19Z Author http://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license. \u00a9 2018 The Authors. Published by Elsevier Ltd. 2020-02-29T12:18:33.406Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp Canadian Urban Environmental Health Research Consortium Wellcome Trust WT Wellcome Trust http://data.elsevier.com/vocabulary/SciValFunders/100010269 http://sws.geonames.org/2635167/ CIHR CIHR Canadian Institutes of Health Research http://data.elsevier.com/vocabulary/SciValFunders/501100000024 http://sws.geonames.org/6251999/ NSERC NSERC Natural Sciences and Engineering Research Council of Canada http://data.elsevier.com/vocabulary/SciValFunders/501100000038 http://sws.geonames.org/6251999/ FRQS FRQS Fonds de Recherche du Qu\u00c3\u00a9bec - Sant\u00c3\u00a9 http://data.elsevier.com/vocabulary/SciValFunders/501100000156 http://sws.geonames.org/6251999/ Cancer Research Society CRS Cancer Research Society http://data.elsevier.com/vocabulary/SciValFunders/100009326 http://sws.geonames.org/6251999/ Ministry of Economy, Science and Innovation Dr. Weichenthal received research support from an NSERC Discovery Grant, a CIHR Foundation Grant, and a GRePEC salary award funded by the Cancer Research Society, the Quebec Ministry of Economy, Science and Innovation, and FRQS (Fonds de Recherche du Qu?bec- Sant?). Dr. Brauer is supported in part by the British Columbia Lung Association Professorship.We acknowledge intellectual and financial contributions of the Canadian Urban Environmental Health Research Consortium (CANUE), and the study team of the Pathways to Equitable Healthy Cities project (supported by the Wellcome Trust). In particular, discussions with Dr. Esra Suel and Dr. Eleanor Setton were helpful in articulating potential applications of image analysis for environmental exposure assessment. Mr. Tristan Goodbody created all of the figures included in this manuscript. item S0160-4120(18)32200-1 S0160412018322001 1-s2.0-S0160412018322001 10.1016/j.envint.2018.11.042 271763 2019-11-27T18:00:29.0774Z 2019-01-01 2019-01-31 UNLIMITED NONE 1-s2.0-S0160412018322001-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/MAIN/application/pdf/a4add74f971a655fdb5883643620eb30/main.pdf main.pdf pdf true 1833861 MAIN 8 1-s2.0-S0160412018322001-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/PREVIEW/image/png/531285c516be3342c8fb22abdbad15e7/main_1.png main_1.png png 51746 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0160412018322001-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr1/THUMBNAIL/image/gif/de8c321eea8cb8e273fd47832d54e2eb/gr1.sml gr1 gr1.sml sml 8878 140 219 IMAGE-THUMBNAIL 1-s2.0-S0160412018322001-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr2/THUMBNAIL/image/gif/8e8c81481ccdee8bfea021944f90902d/gr2.sml gr2 gr2.sml sml 22379 164 206 IMAGE-THUMBNAIL 1-s2.0-S0160412018322001-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr3/THUMBNAIL/image/gif/d4a00cadaab6b04b1bf8f55b99a85b6c/gr3.sml gr3 gr3.sml sml 10238 163 101 IMAGE-THUMBNAIL 1-s2.0-S0160412018322001-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr1/DOWNSAMPLED/image/jpeg/05f29ea1723217012e1f0ad29d092e69/gr1.jpg gr1 gr1.jpg jpg 60929 427 669 IMAGE-DOWNSAMPLED 1-s2.0-S0160412018322001-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr2/DOWNSAMPLED/image/jpeg/7e864ed8b6c054e31202c58c5f57c5a7/gr2.jpg gr2 gr2.jpg jpg 117548 532 669 IMAGE-DOWNSAMPLED 1-s2.0-S0160412018322001-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr3/DOWNSAMPLED/image/jpeg/1797c17570d1ff7116f296659b500837/gr3.jpg gr3 gr3.jpg jpg 216034 1024 633 IMAGE-DOWNSAMPLED 1-s2.0-S0160412018322001-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr1/HIGHRES/image/jpeg/ff8f4d12c2c8b4e07506109df5198fab/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 216454 1136 1778 IMAGE-HIGH-RES 1-s2.0-S0160412018322001-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr2/HIGHRES/image/jpeg/f36acf386f2d68f8ed8189d094e6dea4/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 514378 1414 1778 IMAGE-HIGH-RES 1-s2.0-S0160412018322001-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0160412018322001/gr3/HIGHRES/image/jpeg/ca1597d7017d4f5bae8117f244c48c33/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 838417 2723 1683 IMAGE-HIGH-RES 1-s2.0-S0160412018322001-am.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10HH6TPD6FS/MAIN/application/pdf/7be72c698207f6d14a1f9fe10197e657/am.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/egi:10HH6TPD6FS/MAIN/application/pdf/7be72c698207f6d14a1f9fe10197e657/am.pdf am am.pdf pdf false 523069 AAM-PDF EI 4393 S0160-4120(18)32200-1 10.1016/j.envint.2018.11.042 The Authors Fig. 1 Principles of physically-based and geostatistical models. Fig. 1 Fig. 2 Heat maps can be used to highlight areas of images used to make predictions (simulated example). Fig. 2 Fig. 3 Deep convolutional neural networks can have multiple inputs and multiple outputs. The top panel illustrates a model developed using local images, satellite images, and audio data. Pre-trained models can be applied to new images to make predictions for multiple exposures (bottom panel). Fig. 3 A picture tells a thousand\u2026exposures: Opportunities and challenges of deep learning image analyses in exposure science and environmental epidemiology Scott Weichenthal a \u204e scott.weichenthal@mcgill.ca Marianne Hatzopoulou b Michael Brauer c a McGill University, Department of Epidemiology, Biostatistics and Occupational Health, Montreal, QC, Canada McGill University Department of Epidemiology Biostatistics and Occupational Health Montreal QC Canada b University of Toronto, Department of Civil Engineering, Toronto, ON, Canada University of Toronto Department of Civil Engineering Toronto ON Canada c University of British Columbia, School of Population and Public Health, Vancouver, BC, Canada University of British Columbia School of Population and Public Health Vancouver BC Canada \u204e Corresponding author at: Faculty of Medicine, Department of Epidemiology, Biostatistics, and Occupational Health, McGill University, 1110 avenue des Pins Ouest, Montreal, QC H3A 1A3, Canada. Faculty of Medicine Department of Epidemiology, Biostatistics, and Occupational Health McGill University 1110 avenue des Pins Ouest Montreal QC H3A 1A3 Canada Handling Editor: Robert Letcher Abstract Background Artificial intelligence (AI) is revolutionizing our world, with applications ranging from medicine to engineering. Objectives Here we discuss the promise, challenges, and probable data sources needed to apply AI in the fields of exposure science and environmental health. In particular, we focus on the use of deep convolutional neural networks to estimate environmental exposures using images and other complementary data sources such as cell phone mobility and social media information. Discussion Characterizing the health impacts of multiple spatially-correlated exposures remains a challenge in environmental epidemiology. A shift toward integrated measures that simultaneously capture multiple aspects of the urban built environment could improve efficiency and provide important insights into how our collective environments influence population health. The widespread adoption of AI in exposure science is on the frontier. This will likely result in new ways of understanding environmental impacts on health and may allow for analyses to be efficiently scaled for broad coverage. Image-based convolutional neural networks may also offer a cost-effective means of estimating local environmental exposures in low and middle-income countries where monitoring and surveillance infrastructure is limited. However, suitable databases must first be assembled to train and evaluate these models and these novel approaches should be complemented with traditional exposure metrics. Conclusions The promise of deep learning in environmental health is great and will complement existing measurements for data-rich settings and could enhance the resolution and accuracy of estimates in data poor scenarios. Interdisciplinary partnerships will be needed to fully realize this potential. Highlights \u2022 Characterizing the health impacts of multiple correlated exposures remains a challenge \u2022 Deep learning image analysis may offer an alternative means of estimating multiple exposures \u2022 Large databases of paired image-exposure data must be developed to support this initiative \u2022 Methods are now available to integrate multiple data streams to support exposure science and environmental epidemiology \u2022 High quality training data remains a priority 1 Introduction Environmental pollution has an important impact on the overall global burden of disease with economic impacts measured in billions of dollars each year (Landrigan et al., 2018). Traditionally, spatial and temporal variations in human exposures to environmental pollutants have been estimated separately for individual pollutants (e.g. noise, air pollution) using ground-based monitors or statistical models that combine various land-use, built environment, and/or remote sensing data to predict parameters of interest (Brauer et al., 2012; Weichenthal et al., 2016). While there will always be a need for research focused on individual chemical contaminants, it remains difficult to separate the individual health effects of multiple spatially correlated exposures (e.g. gaseous pollutants, particulate pollutants, noise, heat, etc.) in urban environments. Alternatively, integrated measures that capture the collective impact of the broader built environment on chemical/physical exposures may provide new insights into how multiple neighbourhood characteristics simultaneously interact to impact population health (Brauer & Hystad, 2014). New methods will be needed to facilitate this approach. One option is the application of deep learning methods including deep convolutional neural networks to estimate environmental exposures from large databases of street-level digital images (Gebru et al., 2018), aerial images from remote sensing (Jean et al., 2016), and other complementary information such as cell phone mobility data (Nyhan et al., 2016; Nyhan et al., 2018), personal activity sensors/other sensors (Asimina et al., 2018; Henriksen et al., 2018; Xie et al., 2018), or social media data (Schootman et al., 2016; Tao et al., 2016; Arthur et al., 2018; Costa et al., 2018). The aim of this brief review is to provide an overview of how deep learning image analyses may be used to integrate multiple data streams to predict variations in environmental pollutants influenced by the urban built environment. In doing so, we highlight the opportunities and expected challenges along the way. As an illustrative example, consider traditional approaches to estimating spatial variations in environmental pollutants using physically based models (e.g. dispersion models) or geostatistical methods (e.g. land use regression models) (Fig. 1 ). Physically based models require input data on sources and their activity levels, and factors determining atmospheric fate and transport such as modifying factors of the environment (e.g. 3D building data) and meteorology (Gan et al., 2012; Penn et al., 2015). In the case of geostatistical approaches, multi-variable linear models are built by conducting large-scale spatial monitoring campaigns, extracting geographic information system (GIS) data around each sampling location, and using these parameters as predictors of pollutant concentrations in final models. These approaches generally work well (Ryan & LeMasters, 2007), but the GIS parameters needed for model development and application are often available on a limited spatial scale and models are not generalizable across cities (Patton et al., 2015). In the case of physical models, large amounts of input data are required which may be difficult to access and/or not collected in all locations. Alternatively, information on land use, traffic, the built environment, and interactions between these factors are also encoded in images which can be captured both locally (i.e. at street level) (Fig. 2 ) and in a spatially continuous fashion through satellite imagery (Fig. 3 ). As such, large databases of paired pollutant-image samples may serve as a resource to train deep learning networks to predict environmental exposures on local scales. Moreover, this approach has the potential for scaling up to global coverage through the widespread availability of images in urban areas and by combining with remote sensing information. As images are readily available (and inexpensive to collect), this approach would not be subject to the spatial limitations of GIS data and could reveal previously unrecognized patterns in how environmental exposures are influenced by the collective built environment as it exists in real-life (as opposed to a selected subset of GIS parameters). Once developed, such models may also serve as an efficient means of predicting future/past exposures based on known or anticipated changes in land use, traffic, or the built environment or to prioritize areas for detailed monitoring and/or surveillance. However, such applications will depend on the availability of historical satellite/street-level images and thus may be more useful moving forward than for estimating exposures many years in the past. Here we discuss the promise and challenges of applying deep learning image analysis in the fields of exposure science and environmental epidemiology. We begin by providing a brief overview of deep learning methods, deep convolutional neural networks, and how they are applied to make predictions. Next, we discuss the small number of studies to date that have used these methods to evaluate factors related to environmental exposures and/or the urban built environment and highlight recent examples from other disciplines that may serve as motivation for future applications. We conclude by discussing probable data sources for training and evaluating deep learning models for estimating environmental exposures and highlight future opportunities and challenges. Other recent papers have discussed topics related to machine learning/data mining in air pollution epidemiology (excluding deep learning) (Bellinger et al., 2017), geospatial artificial intelligence (Vopham et al., 2018), and neural networks for time-series estimation of air pollution concentrations (Arhami et al., 2013; Ding et al., 2016; Li et al., 2017; Fan et al., 2017; Li et al., 2016; Qi et al., 2017; Kang et al., 2018; Zhu et al., 2018). 2 How does deep learning work? Deep learning is a form of supervised machine learning whereby large data sets are used to automatically learn representations linking inputs and outputs using non-linear transformations of raw data over successive layers of the network (Fig. 3) (Goodfellow et al., 2017; Chollet & Allaire, 2018; LeCun et al., 2015). The number of layers of representations in a given model determines the \u201cdepth\u201d of the model. During the training procedure, the computer is shown repeated examples of inputs and expected outputs and learns weights for each layer that define the input-output function of the machine (LeCun et al., 2015). These weights are learned/adjusted using a feedback signal over an iterative training process (or training loop) which aims to minimize error between predictions and the known output labels in the training dataset (a procedure called stochastic gradient descent) (LeCun et al., 2015). After training, models are tested on new data to evaluate the generalizability of model predictions to situations not encountered during the training process. A deep convolutional neural network for image classification starts with the image data (a matrix of pixel values) followed by a series of convolution and pooling layers: representations extracted during this process are fed into a final fully connected layer to output a prediction/class label (LeCun et al., 2015; Rawat & Wang, 2017). The role of convolution layers is feature extraction. This is performed by a series of convolution operations (hence the name) that apply small \u201cfilters\u201d (i.e. smaller matrices) across the original input matrices (starting with the input image) to generate new matrices called feature maps. Different values of the filter matrix will produce different feature maps; units in a given feature map are connected to local regions in the feature maps of previous layers through a set of trainable weights called a filter bank (LeCun et al., 2015). It is these \u201cfilters\u201d that are learned by the machine to facilitate predictions through an iterative training process that compares predictions to known values and adjusts weights to minimize prediction error (LeCun et al., 2015; Rawat & Wang, 2017). A detailed description of this process is available elsewhere (Rawat & Wang, 2017). 3 A not so black box An important function of deep convolutional neural networks is the possibility to investigate which image characteristics are used to make predictions. For example, in a network used to predict air pollution or noise from images, specific aspects such as traffic may be prominent (Fig. 2). A detailed description of how this is implemented is provided elsewhere (Chollet & Allaire, 2018; Simonyan et al., 2013). Briefly, it is possible to extract the feature maps from a model to examine portions of the image that are used to make predictions. However, these images become more abstract as the depth of the layer increases, and as a result become less intelligible to the human user. Other options include generating heat maps that highlight areas of the input image used to make a prediction (Chollet & Allaire, 2018). This capability suggests the possibility for convolutional neural networks to predict exposures as well as their determinants (Fig. 3). Moreover, this capability may help to identify new exposures of interest if certain image characteristics (e.g. neighbourhood features) are found to directly influence health outcomes. In this way, deep learning models may help to identify priority regions for in-depth monitoring of environmental pollutants and characteristics and thus contribute to our understanding of how environmental factors impact public health. 4 Outdoor air pollution estimation using deep convolutional neural networks A small number of studies have applied deep convolutional neural networks to estimate ambient air pollution concentrations from image data (other studies have used images to estimate \u201chaze\u201d conditions via light scattering (Li et al., 2015a; Liu et al., 2016) but are not discussed here). Specifically, Chakma et al. (Chakma et al., 2017) used images from Beijing, China between 2013 and 2017 to classify airborne concentrations of fine particulate air pollution (PM2.5) as good (<75\u202f\u03bcg/m3), moderate (75\u2013115\u202f\u03bcg/m3), or severe (>115\u202f\u03bcg/m3) and reported a classification accuracy of 68.74% based on data from 2364 images. In a related study, Zhang et al. (Zhang et al., 2018) applied deep convolutional neural networks to estimate PM2.5 and PM10 concentrations (across 6 categories) using images from Beijing. This analysis was based on >30,000 images and the authors reported average classification errors ranging from approximately 0.3\u20130.4 across 6 categories. While the categories of PM2.5 classification were very broad (1: <35\u202f\u03bcg/m3; 2: 25\u201375\u202f\u03bcg/m3; 3: 75\u2013115\u202f\u03bcg/m3; 4: 115\u2013150\u202f\u03bcg/m3; 5: 150\u2013250\u202f\u03bcg/m3; 6: >250\u202f\u03bcg/m3), these results support the feasibility of classifying temporal variations in ambient PM2.5 concentrations using images. 5 Motivating examples from other disciplines While few studies have applied deep convolutional neural networks to estimate environmental exposures from images, there is a recent history of using images for virtual audits of built environment factors that are known to influence environmental exposures. For example, Chow et al. (Chow et al., 2014) developed the Environmental Profile of a Community Health (EPOCH) tool to evaluate built environment features using a set of standardized images. Using 5 photos per neighbourhood, most items covering neighbourhood density, aesthetics, disorder, pedestrian safety, and bicycle infrastructure had high levels of inter-rater reliability (intra-class correlation\u202f\u2265\u202f0.70). In a second example, Mooney et al. (Mooney et al., 2014) used Google StreetView images to assess 9 previously identified built environment measures of physical disorder and reported that virtual audits were internally consistent, with composite disorder measures correlated with census unemployment and housing vacancy measures. Similarly, remote sensing and street level images have been combined with other readily available (web-based) information to develop a reliable desktop park quality audit tool (POSDAT) (Edwards et al., 2013) which was successfully applied to assess the quality of 200 parks (Rugel et al., 2017). Similarly, Naik et al. (Naik et al., 2017) used StreetView images to evaluate changes in quality of the built environment over time and demonstrated that these changes were predicted by different neighbourhood characteristics (e.g. education of residents) available from census or other data available at more coarse spatial scales. Additional examples are also available in medicine. For example, Poplin et al. (Poplin et al., 2018) applied deep convolutional neural networks to predict a number of cardiovascular risk factors using retinal image data from >200,000 patients in the United Kingdom and the United States. In particular, this model was able to predict risk factors including age, gender, smoking status, and blood pressure and provided reasonable estimates of the risk of major cardiovascular events within 5\u202fyears (area under the receiver operator curve\u202f=\u202f0.70). A number of other examples are also available in the medical literature including the use of deep convolutional neural networks to detect/classify skin cancer lesions (Esteva et al., 2017), diabetic retinopathy (Gulshan et al., 2016), and invasive breast cancer on slide images (Cruz-Roa et al., 2017). More recently, Christiansen et al. (Christiansen et al., 2018) described the use of deep convolutional neural networks to predict the locations of fluorescent labels in unlabelled light microscope images and reported that this method was capable of accurately identifying cell states (alive/dead), types, and subcellular features. Numerous other examples are discussed in a recent review on deep learning for computational biology (Angermueller et al., 2016). 6 Data sources A number of data sources are outlined below that may serve as a resource to begin developing large databases to implement deep convolutional neural networks (and other machine learning methods) in exposure science and environmental epidemiology. This list is not meant to be exhaustive, buy may serve as a starting point in this process. 6.1 Google street view images Pairing environmental exposure measurements Google Street View images may be the most efficient way to begin developing databases for the purpose of using deep learning models. In particular, incorporating environmental exposure measurements (e.g. noise, air pollution, temperature, light) with directly onto Google Street View vehicles as standard practice could greatly facilitate this process as recently demonstrated for methane leak detection in multiple cities (von Fischer et al., 2017) and for air pollutants in Oakland, California (Apte et al., 2017). A global database of paired image/exposure data from these vehicles would provide an ideal resource for training deep learning models of environmental exposures worldwide. 6.2 Satellite images and remote sensing Satellite remote sensing data has revolutionized global exposure estimation for ambient air pollution and these data (combined with satellite images) may also serve as an important resource as inputs for deep convolutional neural networks. Currently, remote sensing data for aerosol optical depth are combined with chemical transport models (e.g. GEOS-Chem) to estimate ground level PM2.5 concentrations (Brauer et al., 2012). However, chemical transport models cannot capture all possible sources of pollution and the combined use of remote sensing data with satellite images may be advantageous if images can provide complementary data reflecting emission sources missing from chemical transport models. Moreover, as satellite images capture a larger spatial scale than local images, it may be advantageous to include both local and satellite images as input data to capture the potential impact of local and regional sources of environmental pollutants/risk factors. Indeed, true color remote sensing images have been used to detect plumes from wildfire smoke (Henderson et al., 2011) and to derive predictors (e.g. vegetation, impervious surfaces) to be used in continental-scale (Novotny et al., 2011; Vienneau et al., 2013; Knibbs et al., 2014) or global land use regression models (Larkin et al., 2017). Similarly, greenness measures, which have increasingly been associated with health benefits, are most commonly derived from remote sensing (Defries & Townshend, 1994), with more recent applications of street-level images (Li et al., 2015b; Li & Ratti, 2018). 6.3 Beyond images The smart city paradigm has given rise to ubiquitous networks of data pertaining to traffic counts and human mobility which may provide a rich source of information in estimating population exposures to environmental pollutants. For example, traffic counts are typically collected in real-time at a limited set of locations in an urban area; deep convolutional neural networks can help with the development of spatio-temporal interpolations of traffic counts or mode share across an urban area. Similarly, GPS data collected by taxis, ride hailing services (such as Uber) or the general public can be used to generate measures of traffic speeds and congestion, which typically influence the amount of air contaminants emitted by on-road vehicles. Finally, various applications have been developed to collect daily mobility information (Patterson & Fitzsimons, 2016). These data can be used to impute mobility patterns for the population and refine existing measures of environmental exposures (Fallah-Shorshani et al., 2018). 7 Future opportunities and challenges 7.1 Opportunities 7.1.1 Multiple data streams for multiple exposures Deep learning models can have multiple inputs and multiple outputs. Therefore, if multiple exposures are assigned to large image databases, deep convolutional neural networks could be used to predict all of these factors simultaneously (Fig. 3). Furthermore, it may be possible to combine inputs from multiple data streams including images (local and satellite), location data, point of interest data, traffic data, audio data (discussed below), social media text/trends (e.g. smog alerts, forest fires), and other relevant factors to jointly model multiple environmental exposures. Moreover, recent evidence suggests that it is possible to predict street-level images using satellite data (Deng et al., n.d.) and this may provide a cost-effective means of generating a continuous database of ground level images using remote sensing. Once developed, such models could be integrated into smartphone applications to provide real-time environmental exposure estimation using data collected from the smartphone's camera, GPS, microphone, and social media applications. In addition, similar tools could be applied by knowledge users to inform urban planning/policy development and thus have a positive impact on population health. 7.1.2 Audio data Like images, sound also encodes important information related to environmental exposures (and their sources) and can be easily collected using smartphones or other methods. Deep convolutional neural networks can be used to classify audio files and have been applied to classify lung sounds (Aykanat et al., 2017), environmental sounds (e.g. car horn, engine idling) (Piczak, 2015), and acoustic scenes (e.g. home, parks, grocery store, metro station) (Han & Lee, 2015). Interestingly, other studies have classified environmental sounds by first converting audio files into spectral images and applying deep convolutional neural networks to the resulting image files (Boddapati et al., 2017). As with image data discussed above, audio data may provide an interesting avenue for the evaluation of environmental exposures or as an alternative method of tracking time-activity patterns determined by \u201cacoustic scenes\u201d. Images as Integrators of Multiple Exposures: Linking Images Directly to Health Outcomes. Given small-scale spatial information on disease rates (e.g. county-level disease rates) it may be possible to directly evaluate the relationship between images and disease incidence on an ecological level as recently illustrated for obesity and the neighbourhood built environment in the United States (Maharana & Nsoesie, 2018). This approach would have all of the same limitations as traditional ecological analyses but could provide important insights into how our collective environments impact public health if we can identify specific portions of images used for predictions. However, this approach will also have potential ethical challenges as labeling a given neighbourhood as \u201cgood\u201d or \u201cbad\u201d based on image analyses may be of little use if corrective interventions are not readily apparent or easily inferred from study results. Indeed, the ethical implications of the wide spread use of artificial intelligence are an important societal concern and Google recently released a list of ethical principles to guide the development of this technology including: 1) Being socially beneficial; 2) Avoiding the creation/reinforcement of unfair biases; 3) Apply strong safety and security practices; 4) Being accountable to people; 5) Incorporating privacy design principles; 6) Upholding high standards of scientific excellence; and 7) Being available for uses that support these principles (Pichai, 2018). These principles, while already prominent in environmental health research must also be considered when applying artificial intelligence approaches. 7.2 Challenges 7.2.1 Building databases The validity of predictions made from any modeling process depends entirely on the quality of information entered in to the model. As such, while moving toward the construction of paired image/audio/exposure databases it is important to ensure that the exposure information is of the highest quality and corresponds to the temporal/spatial resolution of the image. Real-time monitoring equipment and small portable cameras/audio recorders will make it easy to generate large databases of short-term temporal variations for some exposures; however, large databases of paired image/audio/exposure data for long-term exposures over large spatial gradients will be more difficult to collect. It would be advantageous for the research community to develop an open and efficient means of pooling data for the purpose of linking images to environmental exposure measures on a global scale. A number of other challenges are also apparent. For example, in order to be effective, we must be able to interpret and generalize associations discovered using deep learning methods. It is not enough to predict the presence of a hazard/risk if we cannot identify the underlying causes or suitable interventions. As noted above, relationships identified through the application of deep convolutional neural networks may help to highlight combinations of neighbourhood characteristics likely to have a positive/negative impact on health; however, traditional environmental/biological monitoring will still be needed to identify the specific chemical/physical contaminants of concern. Moreover, images themselves have limitations as most databases reflect daytime hours, outdoors, and thus exclude behavioural aspects of exposure including time spent indoors. Ultimately, the success of this approach will rely on high quality training data that captures the wide range of environments/exposures we encounter on a daily basis. 8 Conclusions Artificial intelligence is changing the world we live in and already impacts many aspects of our daily lives with applications spanning disciplines from medicine to engineering. To date, few studies have integrated deep learning methods into environmental exposure assessment, but user-friendly tools are now available to support such applications. The opportunities and challenges are great, but new methods are needed to evaluate the combined health impacts of multiple spatially-correlated exposures and deep convolutional neural networks may provide new insights into this important question. In particular, as images, audio, and location data all encode important information related to environmental exposures, their combined use in deep learning models are a logical starting point to begin this process. In doing so, we must not lose sight of the importance of high-quality exposure measurements as the validity of input-output relationship in deep-learning models will depend on accurate and reliable estimates of the exposures of interest. Funding Dr. Weichenthal received research support from an NSERC Discovery Grant, a CIHR Foundation Grant, and a GRePEC salary award funded by the Cancer Research Society, the Quebec Ministry of Economy, Science and Innovation, and FRQS (Fonds de Recherche du Qu\u00e9bec- Sant\u00e9). Dr. Brauer is supported in part by the British Columbia Lung Association Professorship. Acknowledgements We acknowledge intellectual and financial contributions of the Canadian Urban Environmental Health Research Consortium (CANUE), and the study team of the Pathways to Equitable Healthy Cities project (supported by the Wellcome Trust). In particular, discussions with Dr. Esra Suel and Dr. Eleanor Setton were helpful in articulating potential applications of image analysis for environmental exposure assessment. Mr. Tristan Goodbody created all of the figures included in this manuscript. Conflict of interest None. References Angermueller et al., 2016 C. Angermueller T. Parnamaa L. Parts O. Stegle Deep learning for computational biology Mol. Syst. Biol. 12 2016 878 Apte et al., 2017 J.S. Apte K.P. Messier S. Gani M. Brauer T.W. Kirchstetter M.M. Lunden High-resolution air pollution mapping with Google Street View cars: exploiting big data Environ. Sci. Technol. 51 2017 6999 7008 Arhami et al., 2013 M. Arhami N. Kamali M.M. Rajabi Predicting hourly air pollutant levels using artificial neural networks coupled with uncertainty analysis by Monte Carlo simulations Environ. Sci. Pollut. Res. 20 2013 4777 4789 Arthur et al., 2018 R. Arthur C.A. Boulton H. Shotton H.T.P. Williams Social sensing of floods in the UK PLoS One 13 2018 e0189327 Asimina et al., 2018 S. Asimina D. Chapizanis S. Karakitsios P. Kontoroupis D.N. Asimakopoulos T. Maggos Assessing and enhancing the utility of low-cost activity and location sensors for exposure studies Environ. Monit. Assess. 190 2018 155 Aykanat et al., 2017 M. Aykanat O. Kilic B. Kurt S. Saryal Classification of lung sounds using convolutional neural networks EURASIP J. Image Video Process. 65 2017 10.1186/s13640-017-0213-2 Bellinger et al., 2017 C. Bellinger M.S.M. Jabbar O. Zaiane A. Osornio-Vargas A systematic review of data mining and machine learning for air pollution epidemiology BMC Public Health 17 2017 907 Boddapati et al., 2017 V. Boddapati A. Petef J. Rasmusson L. Lundberg Classifying environmental sounds using image recognition networks Progr. Comput. Sci. Appl. Logic 112 2017 2048 2056 Brauer and Hystad, 2014 M. Brauer P. Hystad Commentary: cities and health\u2026let me count the ways Epidemiology 25 2014 526 527 Brauer et al., 2012 M. Brauer M. Amann R.T. Burnett A. Cohen F. Dentener M. Ezzati S.B. Henderson M. Krzyanowski R.V. Martin R. Van Dingenen A. van Donkelaar S.D. Thurston Exposure assessment for estimation of the global burden of disease attributable to outdoor air pollution Environ. Sci. Technol. 46 2012 652 660 Chakma et al., 2017 A. Chakma B. Vizena T. Cao J. Lin J. Zhang Image-based air quality analysis using deep convolutional neural network 2017 IEEE International Conference on Image Processing (ICIP), Beijing 2017 3949 3952 10.1109/ICIP.2017.8297023 Chollet and Allaire, 2018 F. Chollet J.J. Allaire Deep Learning With R 2018 Manning Publications Shelter Island, NY Chow et al., 2014 C.K. Chow D.J. Corsi K. Lock M. Madhavan P. Mackie W. Li A novel method to evaluate the community built environment using photographs \u2013 environmental profile of a community health (EPOCH) photo neighbourhood evaluation tool PLoS One 9 2014 e110042 Christiansen et al., 2018 E.M. Christiansen S.J. Yang D.M. Ando A. Javaherian G. Skibinski S. Lipnick In silico labeling: predicting fluorescent labels in unlabeled images Cell 173 2018 792 803 Costa et al., 2018 D. Costa C. Duran-Faundez D. Andrade J. Rocha-Junior J. Peixoto TwitterSensing: an event-based approach for wireless sensor networks optimization exploiting social media in Smart City Applications Sensors 18 2018 1080 Cruz-Roa et al., 2017 A. Cruz-Roa H. Gilmore A. Basavanhally M. Feldman S. Ganesan N.N.C. Shih Accurate and reproducible invasive breast cancer detection in whole slide images: a deep learning approach for quantifying tumour extent Sci. Rep. 7 2017 46450 Defries and Townshend, 1994 R.S. Defries J.R.G. Townshend NDVI-derived land cover classifications at a global scale Int. J. Remote Sens. 15 1994 3567 3586 Deng et al., n.d X. Deng Y. Zhu S. Newsam What Is It Like Down There? Generating Dense Ground Level Views and Image Features From Overhead Imagery Using Conditional Generative Adversarial Networks arxiv.org/abs/1806.05129 Ding et al., 2016 W. Ding J. Zhang Y. Leung Prediction of air pollutant concentration based on sparse response back-propagation training feedforward neural networks Environ. Sci. Pollut. Res. 23 2016 19481 19494 Edwards et al., 2013 N. Edwards P. Hooper G.S.A. Trapp F. Bull B. Boruff B. Giles-Corti Development of a Public Open Space Desktop Auditing Tool (POSDAT): a remote sensing approach Appl. Geogr. 38 2013 22 30 Esteva et al., 2017 A. Esteva B. Kuprel R.A. Novoa J. Ko S.M. Swetter H.M. Blau S. Thrun Dermatologist-level classification of skin cancer with deep neural networks Nature 542 2017 115 118 Fallah-Shorshani et al., 2018 M. Fallah-Shorshani M. Hatzopoulou N.A. Ross Z. Patterson S. Weichenthal Evaluating the impact of neighbourhood characteristics on differences between residential and mobility-based exposures to outdoor air pollution Environ. Sci. Technol. 52 2018 10777 10786 Fan et al., 2017 J. Fan Q. Li J. Hou X. Feng H. Karimian S. Lin A spatiotemporal prediction framework for air pollution based on deep RNN ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci. 2017 10.5194/isprs-annals-IV-4-W2-15-2017 Gan et al., 2012 W.Q. Gan K. McLean M. Brauer S.A. Chiarello H.W. Davies Modeling population exposure to community noise and air pollution in a large metropolitan area Environ. Res. 116 2012 Gebru et al., 2018 T. Gebru J. Krause Y. Wang D. Chen J. Deng E.L. Aiden Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States Proc. Natl. Acad. Sci. 114 2018 13108 13113 Goodfellow et al., 2017 I. Goodfellow B. Yoshua A. Courville Deep Learning 2017 MIT Press Cambridge, MA Gulshan et al., 2016 V. Gulshan L. Peng M. Coram M.C. Stumpe D. Wu A. Narayanaswamy Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs JAMA 316 2016 2402 2410 Han and Lee, 2015 Y. Han K. Lee Acoustic Scene Classification Using Convolutional Neural Networks and Multiple-width Frequency-delta Data Augmentation 2015 (arXiv:1607.02383v1 [cs.SD]) Henderson et al., 2011 S.B. Henderson M. Brauer Y.C. MacNab S.M. Kennedy Three measures of forest fire smoke exposure and their associations with respiratory and cardiovascular health outcomes in a population-based cohort Environ. Health Perspect. 119 2011 1266 1271 Henriksen et al., 2018 A. Henriksen M. Haugen Mikalsen A.Z. Woldaregay M. Muzny G. Hartvigsen L.A. Hopstock Using fitness trackers and smartwatches to measure physical activity in research: analysis of consumer wrist-worn wearables J. Med. Internet Res. 20 2018 e110 Jean et al., 2016 N. Jean M. Burke M. Xie W.M. Davis D.B. Lobell S. Ermon Combining satellite imagery and machine learning to predict poverty Science 353 2016 790 794 Kang et al., 2018 G.K. Kang J.Z. Gau S. Chiao S. Lu G. Xie Air quality prediction: big data and machine learning approaches Int. J. Environ. Sci. Dev. 9 2018 8 16 Knibbs et al., 2014 L.D. Knibbs M.G. Hewson M.J. Bechle J.D. Marshall A.G. Barnett A national satellite-based land-use regression model for air pollution exposure assessment in Australia Environ. Res. 135 2014 204 211 Landrigan et al., 2018 P.J. Landrigan R. Fuller N.J.R. Acosta The Lancet commission on pollution and health Lancet 391 2018 462 512 Larkin et al., 2017 A. Larkin J.A. Geddes R.V. Martin Q. Xiao Y. Liu J.D. Marshall Global land use regression model for nitrogen dioxide air pollution Environ. Sci. Technol. 51 2017 6957 6964 LeCun et al., 2015 Y. LeCun Y. Bengio G. Hinton Deep learning Nature 521 2015 436 444 Li and Ratti, 2018 X. Li C. Ratti Mapping the spatial distribution of shade provision of street trees in Boston using Google Street View panoramas Urban For. Urban Green. 31 2018 109 119 Li et al., 2015a Yuncheng Li J. Huang J. Luo Using user generated online photos to estimate and monitor air pollution in major cities Proceedings of the 7th International Conference on Internet Multimedia Computing and Service (ICIMCS '15) 2015 ACM New York, NY, USA 10.1145/2808492.2808564 (Article 79) Li et al., 2015b X. Li C. Zhang W. Li R. Ricard Q. Meng W. Zhang Assessing street-level urban greenery using Google Street View and a modified green view index Urban For. Urban Green. 14 2015 675 685 Li et al., 2016 X. Li L. Peng Y. Hu J. Shao T. Chi Deep learning architecture for air quality predictions Environ. Sci. Pollut. Res. 23 2016 22408 22417 Li et al., 2017 X. Li L. Peng X. Yao S. Cui Y. Hu C. You T. Chi Long short-term memory neural network for air pollutant concentration predictions: method development and evaluation Environ. Pollut. 231 2017 997 1004 Liu et al., 2016 C. Liu F. Tsow N. Tao Particle pollution estimation based on image analysis PLoS One 11 2016 e0145955 Maharana and Nsoesie, 2018 A. Maharana E.O. Nsoesie Use of deep learning to examine the association of the built environment with prevalence of neighbourhood adult obesity JAMA Netw. Open 1 2018 e181535 Mooney et al., 2014 S.J. Mooney M.D.M. Bader G.S. Lovasi K.M. Neckerman J.O. Teitler A.G. Rundle Validity of an ecometric neighborhood physical disorder measure constructed by virtual street audit Am. J. Epidemiol. 180 2014 626 635 Naik et al., 2017 N. Naik S.D. Kominers R. Raskar E.L. Glaeser C.A. Hidalgo Computer vision uncovers predictors of physical urban change Proc. Natl. Acad. Sci. 114 2017 7571 7576 Novotny et al., 2011 E.V. Novotny M.J. Bechle D.B. Millet J.D. Marshall National satellite-based land-use regression: NO2 in the United States Environ. Sci. Technol. 45 2011 4407 4414 Nyhan et al., 2016 M. Nyhan S. Grauwin R. Britter B. Misstear A. McNabola F. Laden \u201cExposure track\u201d\u2014the impact of mobile-device-based mobility patterns on quantifying population exposure to air pollution Environ. Sci. Technol. 50 2016 9671 9681 Nyhan et al., 2018 M.M. Nyhan I. Kloog R. Britter C. Ratti P. Koutrakis Quantifying population exposure to air pollution using individual mobility patterns inferred from mobile phone data J. Expo. Sci. Environ. Epidemiol. 2018 10.1038/s41370-018-0038-9 (Apr 27, Epub ahead of print) Patterson and Fitzsimons, 2016 Z. Patterson K. Fitzsimons DataMobile: smartphone travel survey experiment J. Transp. Res. Board 2594 2016 35 43 Patton et al., 2015 A.P. Patton W. Zamore E.N. Naumova J.I. Levy D. Brugge J.L. Durant Transferability and generalizability of regression models of ultrafine particles in urban neighbourhoods in the Boston area Environ. Sci. Technol. 49 2015 6051 6060 Penn et al., 2015 S.L. Penn S. Arunachalam Y. Tripodis W. Heiger-Bernays J.I. Levy A comparison between monitoring and dispersion modeling approaches to assess the impact of aviation on concentrations of black carbon and nitrogen oxides at Los Angeles International Airport Sci. Total Environ. 527\u2013528 2015 47 55 Pichai, 2018 S. Pichai AI at Google: our principles Available: https://blog.google/technology/ai/ai-principles/ June 7, 2018 Piczak, 2015 K.J. Piczak Environmental sound classification with convolutional neural networks IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP), 2015, Boston, MA 2015 10.1109/MLSP.2015.7324337 Poplin et al., 2018 R. Poplin A.V. Varadarajan K. Blumer Y. Liu M.V. McConnell G.S. Corrado Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning Nat. Biomed. Eng. 2 2018 158 164 Qi et al., 2017 Z. Qi T. Wang G. Song W. Hu X. Li Z.M. Zhang Deep air learning: interpolation, prediction, and feature analysis of fine-grained air quality IEEE Trans. Knowl. Data Eng. 2017 10.1109/TKDE.2018.2823740 Rawat and Wang, 2017 W. Rawat Z. Wang Deep convolutional neural networks for image classification: a comprehensive review Neural Comput. 29 2017 2352 2449 Rugel et al., 2017 E.J. Rugel S.B. Henderson R.M. Carpiano M. Brauer Beyond the Normalized Difference Vegetation Index (NDVI): developing a Natural Space Index for population-level health research Environ. Res. 159 2017 Ryan and LeMasters, 2007 P.H. Ryan G.K. LeMasters A review of land-use regression models for characterizing intraurban air pollution exposure Inhal. Toxicol. 19 Suppl. 1 2007 127 133 Schootman et al., 2016 M. Schootman E.J. Nelson K. Werner E. Shacham M. Elliott K. Ratnapradipa Emerging technologies to measure neighborhood conditions in public health: implications for interventions and next steps Int. J. Health Geogr. 15 2016 20 Simonyan et al., 2013 K. Simonyan A. Vedaldi A. Zisserman Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. arXiv:1312.6034 [cs.CV] 2013 Tao et al., 2016 Z. Tao A. Kokas R. Zhang D.S. Cohan D. Wallach Inferring atmospheric particulate matter concentrations from Chinese social media data PLoS One 11 2016 e0161389 Vienneau et al., 2013 D. Vienneau K. de Hoogh M.J. Bechle R. Beelen A. van Donkelaar R.V. Martin Western European land use regression incorporating satellite- and ground-based measurements of NO2 and PM10 Environ. Sci. Technol. 47 2013 13555 13564 von Fischer et al., 2017 J.C. von Fischer D. Cooley S. Chamberlain A. Gaylord C.J. Griebenow S.P. Hamburg Rapid, vehicle-based identification of location and magnitude of urban natural gas pipeline leaks Environ. Sci. Technol. 51 2017 4091 4099 Vopham et al., 2018 T. Vopham J.E. Hart F. Laden Y.Y. Chiang Emerging trends in geospatial artificial intelligence (geoAI): potential applications for environmental epidemiology Environ. Health 17 2018 40 Weichenthal et al., 2016 S. Weichenthal K. Van Ryswyk A. Goldstein M. Shekarrizfard M. Hatzopoulou Characterizing the spatial distribution of ambient ultrafine particles in Toronto, Canada: a land use regression model Environ. Pollut. 208 2016 241 248 Xie et al., 2018 J. Xie D. Wen L. Liang Y. Jia L. Gao J. Lei Evaluating the validity of current mainstream wearable devices in fitness tracking under various physical activities: comparative study JMIR mHealth uHealth 6 2018 e94 Zhang et al., 2018 C. Zhang J. Yan C. Li H. Wu R. Bie End-to-end learning for image-based air quality level estimation Mach. Vis. Appl. 29 2018 601 615 Zhu et al., 2018 D. Zhu C. Cai T. Yang X. Zhou A machine learning approach for air quality prediction: model regularization and optimization Big Data Cogn. Comput. 2 2018 5", "scopus-id": "85057047743", "pubmed-id": "30473381", "coredata": {"eid": "1-s2.0-S0160412018322001", "dc:description": "Abstract Background Artificial intelligence (AI) is revolutionizing our world, with applications ranging from medicine to engineering. Objectives Here we discuss the promise, challenges, and probable data sources needed to apply AI in the fields of exposure science and environmental health. In particular, we focus on the use of deep convolutional neural networks to estimate environmental exposures using images and other complementary data sources such as cell phone mobility and social media information. Discussion Characterizing the health impacts of multiple spatially-correlated exposures remains a challenge in environmental epidemiology. A shift toward integrated measures that simultaneously capture multiple aspects of the urban built environment could improve efficiency and provide important insights into how our collective environments influence population health. The widespread adoption of AI in exposure science is on the frontier. This will likely result in new ways of understanding environmental impacts on health and may allow for analyses to be efficiently scaled for broad coverage. Image-based convolutional neural networks may also offer a cost-effective means of estimating local environmental exposures in low and middle-income countries where monitoring and surveillance infrastructure is limited. However, suitable databases must first be assembled to train and evaluate these models and these novel approaches should be complemented with traditional exposure metrics. Conclusions The promise of deep learning in environmental health is great and will complement existing measurements for data-rich settings and could enhance the resolution and accuracy of estimates in data poor scenarios. Interdisciplinary partnerships will be needed to fully realize this potential.", "openArchiveArticle": "false", "prism:coverDate": "2019-01-31", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0160412018322001", "dc:creator": [{"@_fa": "true", "$": "Weichenthal, Scott"}, {"@_fa": "true", "$": "Hatzopoulou, Marianne"}, {"@_fa": "true", "$": "Brauer, Michael"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0160412018322001"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0160412018322001"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0160-4120(18)32200-1", "prism:volume": "122", "prism:publisher": "The Authors. Published by Elsevier Ltd.", "dc:title": "A picture tells a thousand\u2026exposures: Opportunities and challenges of deep learning image analyses in exposure science and environmental epidemiology", "prism:copyright": "\u00a9 2018 The Authors. Published by Elsevier Ltd.", "openaccess": "1", "prism:issn": "01604120", "openaccessArticle": "true", "prism:publicationName": "Environment International", "openaccessSponsorType": "Author", "prism:pageRange": "3-10", "prism:endingPage": "10", "prism:coverDisplayDate": "January 2019", "prism:doi": "10.1016/j.envint.2018.11.042", "prism:startingPage": "3", "dc:identifier": "doi:10.1016/j.envint.2018.11.042", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "140", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8878", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "206", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "22379", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "101", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10238", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "427", "@width": "669", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "60929", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "532", "@width": "669", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "117548", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "1024", "@width": "633", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "216034", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1136", "@width": "1778", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "216454", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1414", "@width": "1778", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "514378", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2723", "@width": "1683", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "838417", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0160412018322001-am.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "AAM-PDF", "@size": "523069", "@ref": "am", "@mimetype": "application/pdf"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85057047743"}}
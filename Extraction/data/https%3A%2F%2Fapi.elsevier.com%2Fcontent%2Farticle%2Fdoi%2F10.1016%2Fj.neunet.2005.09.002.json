{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608005002480", "dc:identifier": "doi:10.1016/j.neunet.2005.09.002", "eid": "1-s2.0-S0893608005002480", "prism:doi": "10.1016/j.neunet.2005.09.002", "pii": "S0893-6080(05)00248-0", "dc:title": "Comparison of recent methods for inference of variable influence in neural networks ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "19", "prism:issueIdentifier": "4", "prism:startingPage": "500", "prism:endingPage": "513", "prism:pageRange": "500-513", "prism:number": "4", "dc:format": "application/json", "prism:coverDate": "2006-05-31", "prism:coverDisplayDate": "May 2006", "prism:copyright": "Copyright \u00a9 2005 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Papadokonstantakis, Stavros"}, {"@_fa": "true", "$": "Lygeros, Argyrios"}, {"@_fa": "true", "$": "Jacobsson, Sven P."}], "dc:description": "\n               Abstract\n               \n                  Neural networks (NNs) belong to \u2018black box\u2019 models and therefore \u2018suffer\u2019 from interpretation difficulties. Four recent methods inferring variable influence in NNs are compared in this paper. The methods assist the interpretation task during different phases of the modeling procedure. They belong to information theory (ITSS), the Bayesian framework (ARD), the analysis of the network's weights (GIM), and the sequential omission of the variables (SZW). The comparison is based upon artificial and real data sets of differing size, complexity and noise level. The influence of the neural network's size has also been considered. The results provide useful information about the agreement between the methods under different conditions. Generally, SZW and GIM differ from ARD regarding the variable influence, although applied to NNs with similar modeling accuracy, even when larger data sets sizes are used. ITSS produces similar results to SZW and GIM, although suffering more from the \u2018curse of dimensionality\u2019.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Variable influence in neural networks"}, {"@_fa": "true", "$": "Information theoretic approach"}, {"@_fa": "true", "$": "Sequential zeroing of weights"}, {"@_fa": "true", "$": "General influence measure"}, {"@_fa": "true", "$": "Automatic relevance determination"}, {"@_fa": "true", "$": "Sensitivity analysis"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608005002480", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608005002480", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "33744944043", "scopus-eid": "2-s2.0-33744944043", "pubmed-id": "16352417", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/33744944043", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20051213", "$": "2005-12-13"}}}}}
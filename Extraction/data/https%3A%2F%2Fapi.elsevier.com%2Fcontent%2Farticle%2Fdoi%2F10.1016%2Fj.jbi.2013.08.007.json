{"scopus-eid": "2-s2.0-84888198561", "originalText": "serial JL 272371 291210 291682 291870 291901 31 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2013-09-13 2013-09-13 2014-10-01T00:19:33 1-s2.0-S1532046413001226 S1532-0464(13)00122-6 S1532046413001226 10.1016/j.jbi.2013.08.007 S300 S300.3 FULL-TEXT 1-s2.0-S1532046413X00073 2015-05-15T06:30:58.629321-04:00 0 0 20131201 20131231 2013 2013-09-13T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor highlightsabst primabst ref specialabst 1532-0464 15320464 true 46 46 6 6 Volume 46, Issue 6 19 1125 1135 1125 1135 201312 December 2013 2013-12-01 2013-12-31 2013 Special Section: Social Media Environments Alejandro Rodr\u00edguez Gonz\u00e1lez Miguel Angel Mayer Jesualdo Tom\u00e1s Fern\u00e1ndez-Breis Regular Research Papers article fla Copyright \u00a9 2013 Elsevier Inc. All rights reserved. LEARNINGCLASSIFICATIONMODELSMULTIPLEEXPERTS VALIZADEGAN H 1 Introduction 2 Background 2.1 Related work 3 Methodology 3.1 Multiple Experts Support Vector Machines (ME-SVM) 3.2 Optimization 4 Experimental evaluation 4.1 Data 4.2 Temporal feature extraction 4.3 Experimental set-up 4.4 Results and discussion 4.4.1 Learning consensus model 4.4.2 Modeling individual experts 4.4.3 Self-consistency and consensus-consistency 5 Conclusion Acknowledgements Appendix A Derivation of Eq. (4) from Eq. (3) Appendix B Features used for constructing the predictive models References BATAL 2012 280 288 I PROCEEDINGSINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMINING MININGRECENTTEMPORALPATTERNSFOREVENTDETECTIONINMULTIVARIATETIMESERIESDATA BATAL 2011 358 365 I IEEEINTERNATIONALCONFERENCEBIOINFORMATICSBIOMEDICINEBIBM APATTERNMININGAPPROACHFORCLASSIFYINGMULTIVARIATETEMPORALDATA BEZDEK 2002 288 300 J PROCEEDINGS2002AFSSINTERNATIONALCONFERENCEFUZZYSYSTEMS NOTESALTERNATINGOPTIMIZATION BISHOP 2006 C PATTERNRECOGNITIONMACHINELEARNING BOYD 2004 S CONVEXOPTIMIZATION COMBI 2010 C TEMPORALINFORMATIONSYSTEMSINMEDICINE DAWID 1979 20 28 A EVGENIOU 2004 109 117 T PROCEEDINGSINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMINING REGULARIZEDMULTITASKLEARNING HAUSKRECHT 2013 47 55 M KOLLER 2009 D PROBABILISTICGRAPHICALMODELSPRINCIPLESTECHNIQUES RAYKAR 2010 1297 1322 V SCHOLKOPF 2001 B LEARNINGKERNELSSUPPORTVECTORMACHINESREGULARIZATIONOPTIMIZATIONBEYOND SCHOLKOPF 2002 B LEARNINGKERNELSSUPPORTVECTORMACHINESREGULARIZATIONOPTIMIZATIONBEYOND SHENG 2008 614 622 V PROCEEDINGSINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMINING GETANOTHERLABELIMPROVINGDATAQUALITYDATAMININGUSINGMULTIPLENOISYLABELERS SNOW 2008 254 263 R CONFERENCEEMPIRICALMETHODSNATURALLANGUAGEPROCESSING CHEAPFASTBUTGOODEVALUATINGNONEXPERTANNOTATIONSFORNATURALLANGUAGETASKS VALIZADEGAN 2007 1417 1424 H ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS GENERALIZEDMAXIMUMMARGINCLUSTERINGUNSUPERVISEDKERNELLEARNING VAPNIK 1995 V NATURESTATISTICALLEARNINGTHEORY WARKENTIN 2003 535 555 T WARKENTIN 2000 1703 1708 T VALIZADEGANX2013X1125 VALIZADEGANX2013X1125X1135 VALIZADEGANX2013X1125XH VALIZADEGANX2013X1125X1135XH Full 2014-12-01T00:02:24Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(13)00122-6 S1532046413001226 1-s2.0-S1532046413001226 10.1016/j.jbi.2013.08.007 272371 2014-10-01T02:41:15.28077-04:00 2013-12-01 2013-12-31 1-s2.0-S1532046413001226-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/MAIN/application/pdf/affc5c9bc087e422358f73ff7545217e/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/MAIN/application/pdf/affc5c9bc087e422358f73ff7545217e/main.pdf main.pdf pdf true 1093731 MAIN 11 1-s2.0-S1532046413001226-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/PREVIEW/image/png/2c492bcae559fe20c6de6f8e58a74419/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/PREVIEW/image/png/2c492bcae559fe20c6de6f8e58a74419/main_1.png main_1.png png 61559 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046413001226-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif si9 si9.gif gif 260 20 17 ALTIMG 1-s2.0-S1532046413001226-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/2586cfaeb66a9e0c1c4a21d7b7c78117/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/2586cfaeb66a9e0c1c4a21d7b7c78117/si8.gif si8 si8.gif gif 1308 23 240 ALTIMG 1-s2.0-S1532046413001226-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/a84748b614d5417827c4083d2ade1a2b/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/a84748b614d5417827c4083d2ade1a2b/si7.gif si7 si7.gif gif 1093 23 193 ALTIMG 1-s2.0-S1532046413001226-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/30c32f784fe89ce884ca1848352250b8/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/30c32f784fe89ce884ca1848352250b8/si6.gif si6 si6.gif gif 1013 21 187 ALTIMG 1-s2.0-S1532046413001226-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f50486d6a1031d68aa3a9b27aa6d1c46/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f50486d6a1031d68aa3a9b27aa6d1c46/si5.gif si5 si5.gif gif 591 19 102 ALTIMG 1-s2.0-S1532046413001226-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/aa9059555865dbc53bc692773df5eba5/si4.gif si4 si4.gif gif 260 20 17 ALTIMG 1-s2.0-S1532046413001226-si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/44b97bde3c6a70dd2417f81c88a79fdf/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/44b97bde3c6a70dd2417f81c88a79fdf/si38.gif si38 si38.gif gif 4607 153 425 ALTIMG 1-s2.0-S1532046413001226-si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/84de4678cf12c5bff1aa0302eb652b30/si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/84de4678cf12c5bff1aa0302eb652b30/si37.gif si37 si37.gif gif 500 17 96 ALTIMG 1-s2.0-S1532046413001226-si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/d6315637aa3e81e61d07b8e659ed6497/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/d6315637aa3e81e61d07b8e659ed6497/si36.gif si36 si36.gif gif 6437 301 296 ALTIMG 1-s2.0-S1532046413001226-si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/9c1513805bc274e4c650d15f1bde34c7/si35.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/9c1513805bc274e4c650d15f1bde34c7/si35.gif si35 si35.gif gif 8967 277 393 ALTIMG 1-s2.0-S1532046413001226-si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/5e63b45daadc0dd2572d8f794f0857db/si34.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/5e63b45daadc0dd2572d8f794f0857db/si34.gif si34 si34.gif gif 873 17 162 ALTIMG 1-s2.0-S1532046413001226-si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/acff6997f37027df2fa45c8e40d2535e/si33.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/acff6997f37027df2fa45c8e40d2535e/si33.gif si33 si33.gif gif 10708 293 497 ALTIMG 1-s2.0-S1532046413001226-si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/80d104cba30782e7984692877c976ca1/si32.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/80d104cba30782e7984692877c976ca1/si32.gif si32 si32.gif gif 371 20 50 ALTIMG 1-s2.0-S1532046413001226-si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif si31 si31.gif gif 249 20 17 ALTIMG 1-s2.0-S1532046413001226-si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si30 si30.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f3d2378e7a37c09cd3cfee37cf0b7342/si3.gif si3 si3.gif gif 249 20 17 ALTIMG 1-s2.0-S1532046413001226-si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/3587364fb64a82582ce781da6571133c/si29.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/3587364fb64a82582ce781da6571133c/si29.gif si29 si29.gif gif 1007 46 168 ALTIMG 1-s2.0-S1532046413001226-si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/ded0c55235c5a7f39873b905b52f894f/si28.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/ded0c55235c5a7f39873b905b52f894f/si28.gif si28 si28.gif gif 1143 48 151 ALTIMG 1-s2.0-S1532046413001226-si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si27 si27.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si26 si26.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/bd1cbe7b326c01d85ac77222b8ab531b/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/bd1cbe7b326c01d85ac77222b8ab531b/si25.gif si25 si25.gif gif 7202 327 397 ALTIMG 1-s2.0-S1532046413001226-si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/d4c54fe3146b2858a168fd90380fea55/si24.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/d4c54fe3146b2858a168fd90380fea55/si24.gif si24 si24.gif gif 1222 65 171 ALTIMG 1-s2.0-S1532046413001226-si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/b840bdbdaa78d3298d63873c6c1ea587/si23.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/b840bdbdaa78d3298d63873c6c1ea587/si23.gif si23 si23.gif gif 1139 30 191 ALTIMG 1-s2.0-S1532046413001226-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0033ce8501733d83e5938502303dc1bb/si22.gif si22 si22.gif gif 235 20 15 ALTIMG 1-s2.0-S1532046413001226-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/ca98ea188b4e6c5c77b99f8eee1c5ad4/si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/ca98ea188b4e6c5c77b99f8eee1c5ad4/si21.gif si21 si21.gif gif 858 21 148 ALTIMG 1-s2.0-S1532046413001226-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/709450b889c3f519fd150ea7d5c0b14c/si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/709450b889c3f519fd150ea7d5c0b14c/si20.gif si20 si20.gif gif 5975 158 569 ALTIMG 1-s2.0-S1532046413001226-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/f82711249776a999a758997c54b18218/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/f82711249776a999a758997c54b18218/si2.gif si2 si2.gif gif 773 23 128 ALTIMG 1-s2.0-S1532046413001226-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/185f97b383706f5e568784f7750c96a1/si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/185f97b383706f5e568784f7750c96a1/si19.gif si19 si19.gif gif 5586 158 529 ALTIMG 1-s2.0-S1532046413001226-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/396ccfaccc49c51e44ead67f131e9ce2/si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/396ccfaccc49c51e44ead67f131e9ce2/si18.gif si18 si18.gif gif 936 30 229 ALTIMG 1-s2.0-S1532046413001226-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6680d894a90d44b4394af86ca8e8ae72/si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6680d894a90d44b4394af86ca8e8ae72/si17.gif si17 si17.gif gif 911 30 234 ALTIMG 1-s2.0-S1532046413001226-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/27b53238cb595195f421376f31a37c87/si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/27b53238cb595195f421376f31a37c87/si16.gif si16 si16.gif gif 3926 52 662 ALTIMG 1-s2.0-S1532046413001226-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/98fdb2f29a9842287f1e056bea5a149f/si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/98fdb2f29a9842287f1e056bea5a149f/si15.gif si15 si15.gif gif 616 17 120 ALTIMG 1-s2.0-S1532046413001226-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/844a8d3f7692f1a3ef78585728bea411/si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/844a8d3f7692f1a3ef78585728bea411/si14.gif si14 si14.gif gif 231 14 21 ALTIMG 1-s2.0-S1532046413001226-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/0918f8f246d93f994edbf7f5b4e5bf2a/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/0918f8f246d93f994edbf7f5b4e5bf2a/si13.gif si13 si13.gif gif 249 17 19 ALTIMG 1-s2.0-S1532046413001226-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6e05328527648f8b9962eb15d1bcedff/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6e05328527648f8b9962eb15d1bcedff/si12.gif si12 si12.gif gif 236 15 21 ALTIMG 1-s2.0-S1532046413001226-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/ef17778371696c5eefefdcacc2a16ffb/si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/ef17778371696c5eefefdcacc2a16ffb/si11.gif si11 si11.gif gif 254 18 19 ALTIMG 1-s2.0-S1532046413001226-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6ea41257769968ec331f1be799f6b83d/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6ea41257769968ec331f1be799f6b83d/si10.gif si10 si10.gif gif 1641 44 169 ALTIMG 1-s2.0-S1532046413001226-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/STRIPIN/image/gif/6332f2e4bbb7a8080507a9054bebd612/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/STRIPIN/image/gif/6332f2e4bbb7a8080507a9054bebd612/si1.gif si1 si1.gif gif 620 19 111 ALTIMG 1-s2.0-S1532046413001226-gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr7/HIGHRES/image/jpeg/d8e86f87ba787ba4b66e38edf30fa468/gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr7/HIGHRES/image/jpeg/d8e86f87ba787ba4b66e38edf30fa468/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 617281 1892 2624 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr6/HIGHRES/image/jpeg/6054a70706c5020ad6ec347dc9554030/gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr6/HIGHRES/image/jpeg/6054a70706c5020ad6ec347dc9554030/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 810544 1884 3369 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr5/HIGHRES/image/jpeg/90873e868b8554ab2135b14ca3ef5b2e/gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr5/HIGHRES/image/jpeg/90873e868b8554ab2135b14ca3ef5b2e/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 309781 1020 2529 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr4/HIGHRES/image/jpeg/4bab60e7c9bad379f2dddd5bd03c894c/gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr4/HIGHRES/image/jpeg/4bab60e7c9bad379f2dddd5bd03c894c/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 195072 728 2382 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr3/HIGHRES/image/jpeg/0160137c11a414ab7f85d04971c6b854/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr3/HIGHRES/image/jpeg/0160137c11a414ab7f85d04971c6b854/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 76045 536 1562 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr2/HIGHRES/image/jpeg/6d666756904ed5581ca9d581efb554fc/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr2/HIGHRES/image/jpeg/6d666756904ed5581ca9d581efb554fc/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 163099 1307 1597 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr1/HIGHRES/image/jpeg/d3ce9ac011979d2be4ccb59a9cae284b/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr1/HIGHRES/image/jpeg/d3ce9ac011979d2be4ccb59a9cae284b/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 62585 446 1423 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/fx1/HIGHRES/image/jpeg/2b5a6c4282ba6478cb7f658b963af5b7/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/fx1/HIGHRES/image/jpeg/2b5a6c4282ba6478cb7f658b963af5b7/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 185828 886 1450 IMAGE-HIGH-RES 1-s2.0-S1532046413001226-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr7/DOWNSAMPLED/image/jpeg/41651547804466dc9caca2ba748c58f3/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr7/DOWNSAMPLED/image/jpeg/41651547804466dc9caca2ba748c58f3/gr7.jpg gr7 gr7.jpg jpg 82629 428 593 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr6/DOWNSAMPLED/image/jpeg/9f55841a36e306a5028f2e7eacc08d82/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr6/DOWNSAMPLED/image/jpeg/9f55841a36e306a5028f2e7eacc08d82/gr6.jpg gr6 gr6.jpg jpg 99644 426 761 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr5/DOWNSAMPLED/image/jpeg/0230d02d132479e86ab5d37d7c5bc958/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr5/DOWNSAMPLED/image/jpeg/0230d02d132479e86ab5d37d7c5bc958/gr5.jpg gr5 gr5.jpg jpg 37512 230 571 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr4/DOWNSAMPLED/image/jpeg/4aa395521105c697d117ff1ad82856ac/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr4/DOWNSAMPLED/image/jpeg/4aa395521105c697d117ff1ad82856ac/gr4.jpg gr4 gr4.jpg jpg 31759 170 556 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr3/DOWNSAMPLED/image/jpeg/18be4a6c34951d4caf05b62c6655572d/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr3/DOWNSAMPLED/image/jpeg/18be4a6c34951d4caf05b62c6655572d/gr3.jpg gr3 gr3.jpg jpg 16784 121 353 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr2/DOWNSAMPLED/image/jpeg/1dd412bfc5dd368358f9d7cdf09c9044/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr2/DOWNSAMPLED/image/jpeg/1dd412bfc5dd368358f9d7cdf09c9044/gr2.jpg gr2 gr2.jpg jpg 32398 305 373 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr1/DOWNSAMPLED/image/jpeg/a6d118f94c057bd5165c22ed8561de5c/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr1/DOWNSAMPLED/image/jpeg/a6d118f94c057bd5165c22ed8561de5c/gr1.jpg gr1 gr1.jpg jpg 13878 103 329 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/fx1/DOWNSAMPLED/image/jpeg/fd9627eddf7f32de2e0e1847050da6b3/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/fx1/DOWNSAMPLED/image/jpeg/fd9627eddf7f32de2e0e1847050da6b3/fx1.jpg fx1 true fx1.jpg jpg 30438 200 327 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413001226-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr7/THUMBNAIL/image/gif/98a07bea9de63ec7638fbf45ecbd5392/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr7/THUMBNAIL/image/gif/98a07bea9de63ec7638fbf45ecbd5392/gr7.sml gr7 gr7.sml sml 8379 158 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr6/THUMBNAIL/image/gif/34e626844214d8669b5bcda96c0376e5/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr6/THUMBNAIL/image/gif/34e626844214d8669b5bcda96c0376e5/gr6.sml gr6 gr6.sml sml 6646 122 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr5/THUMBNAIL/image/gif/c061eb121e0f7958357e67617600bd3a/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr5/THUMBNAIL/image/gif/c061eb121e0f7958357e67617600bd3a/gr5.sml gr5 gr5.sml sml 4730 88 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr4/THUMBNAIL/image/gif/73254e1dd95d53c8328817267512b319/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr4/THUMBNAIL/image/gif/73254e1dd95d53c8328817267512b319/gr4.sml gr4 gr4.sml sml 3814 67 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr3/THUMBNAIL/image/gif/4d3f9ac4cbad6ef28883d49c20bde155/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr3/THUMBNAIL/image/gif/4d3f9ac4cbad6ef28883d49c20bde155/gr3.sml gr3 gr3.sml sml 3607 75 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr2/THUMBNAIL/image/gif/b5a6219d63ac2f064a54e1bd871598fb/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr2/THUMBNAIL/image/gif/b5a6219d63ac2f064a54e1bd871598fb/gr2.sml gr2 gr2.sml sml 5079 164 200 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/gr1/THUMBNAIL/image/gif/83aab7fc2c5f4dfe828e2793c54619e6/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/gr1/THUMBNAIL/image/gif/83aab7fc2c5f4dfe828e2793c54619e6/gr1.sml gr1 gr1.sml sml 2059 69 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413001226-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413001226/fx1/THUMBNAIL/image/gif/afc7ff45f080d4fe8e172282d9367c05/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413001226/fx1/THUMBNAIL/image/gif/afc7ff45f080d4fe8e172282d9367c05/fx1.sml fx1 true fx1.sml sml 8004 134 219 IMAGE-THUMBNAIL YJBIN 2049 S1532-0464(13)00122-6 10.1016/j.jbi.2013.08.007 Elsevier Inc. Fig. 1 The consensus model and its relation to individual expert models. Fig. 2 The experts\u2019 specific linear models w k are generated from the consensus linear model u. The circles show instances that are mislabeled with respect to individual expert\u2019s models and are used to define the model self consistency. Fig. 3 Graphical representation of the auxiliary probabilistic model that is related to our objective function. The circles in the graph represent random variables. Shaded circles are observed variables, regular (unshaded) circles denote hidden (or unobserved) random variables. The rectangles denote plates that represent structure replications, that is, there are k different expert models w k , and each is used to generate labels for N k examples. Parameters not enclosed in circles (e.g. \u03b7) denote the hyperparameters of the model. Fig. 4 The figure illustrates a subset of 10 temporal features used for mapping time-series for numerical lab tests. Fig. 5 Effect of the number of training examples on the quality of the model when: (Left) every example is labeled by just one expert and (Right) every example is labeled by all three experts. Fig. 6 Learning of expert-specific models. The figure shows the results for three expert specific models generated by the ME-SVM and the standard SVM methods, and compares them to models generated by the Majority\u2217 and Raykar\u2217 methods. First line: different examples are given to different experts and Second line: the same examples are given to all experts. Fig. 7 (left-top) Agreement of experts with labels given by the senior expert; (right-top) learned self-consistency parameters for Experts 1\u20133; (left-bottom) learned consensus-consistency parameters for Experts 1\u20133; (right-bottom) cumulative self and consensus consistencies for Expert 1\u20133. Table 1 Features used for constructing the predictive models. The features were extracted from time series data in electronic health records using methods from Hauskrecht et al. [11,20,12]. Clinical variables Features Platelet count (PLT) 1 Last PLT value measurement 2 Time elapsed since last PLT measurement 3 Pending PLT result 4 Known PLT value result indicator 5 Known trend PLT results 6 PLT difference for last two measurements 7 PLT slope for last two measurements 8 PLT % drop for last two measurements 9 Nadir HGB value 10 PLT difference for last and nadir values 11 Apex PLT value 12 PLT difference for last and apex values 13 PLT difference for last and baseline values 14 Overall PLT slope Hemoglobin (HGB) 15 Last HGB value measurement 16 Time elapsed since last HGB measurement 17 Pending HGB result 18 Known HGB value result indicator 19 Known trend HGB results 20 HGB difference for last two measurements 21 HGB slope for last two measurements 22 HGB % drop for last two measurements 23 Nadir HGB value 24 HGB difference for last and nadir values 25 Apex HGB value 26 HGB difference for last and apex values 27 HGB difference for last and baseline values 28 Overall HGB slope White Blood Cell count (WBC) 29 Last WBC value measurement 30 Time elapsed since last WBC measurement 31 Pending WBC result 32 Known WBC value result indicator 33 Known trend WBC results 34 WBC difference for last two measurements 35 WBC slope for last two measurements 36 WBC % drop for last two measurements 37 Nadir WBC value 38 WBC difference for last and nadir values 39 Apex WBC value 40 WBC difference for last and apex values 41 WBC difference for last and baseline values 42 Overall WBC slope Heparin 43 Patient on Heparin 44 Time elapsed since last administration of Heparin 45 Time elapsed since first administration of Heparin 46 Time elapsed since last change in Heparin administration Major heart procedure 47 Patient had a major heart procedure in past 24h 48 Patient had a major heart procedure during the stay 49 Time elapsed since last major heart procedure 50 Time elapsed since first major heart procedure Learning classification models from multiple experts Hamed Valizadegan hamed@cs.pitt.edu Quang Nguyen quang@cs.pitt.edu Milos Hauskrecht \u204e milos@cs.pitt.edu Department of Computer Science, University of Pittsburgh, United States Department of Computer Science University of Pittsburgh United States \u204e Corresponding author. Tel.: +1 412 624 8845. Graphical abstract Highlights \u2022 Learning of classification models when labels are provided by multiple experts. \u2022 A new multi-expert learning approach that gives: (a) consensus and (b) experts models. \u2022 Tests the approach on clinical data with three expert reviewers and one meta-reviewer. \u2022 The results show the improved learning of the consensus model. \u2022 The results show the improved learning of individual expert models. Abstract Building classification models from clinical data using machine learning methods often relies on labeling of patient examples by human experts. Standard machine learning framework assumes the labels are assigned by a homogeneous process. However, in reality the labels may come from multiple experts and it may be difficult to obtain a set of class labels everybody agrees on; it is not uncommon that different experts have different subjective opinions on how a specific patient example should be classified. In this work we propose and study a new multi-expert learning framework that assumes the class labels are provided by multiple experts and that these experts may differ in their class label assessments. The framework explicitly models different sources of disagreements and lets us naturally combine labels from different human experts to obtain: (1) a consensus classification model representing the model the group of experts converge to, as well as, and (2) individual expert models. We test the proposed framework by building a model for the problem of detection of the Heparin Induced Thrombocytopenia (HIT) where examples are labeled by three experts. We show that our framework is superior to multiple baselines (including standard machine learning framework in which expert differences are ignored) and that our framework leads to both improved consensus and individual expert models. Keywords Classification learning with multiple experts Consensus models 1 Introduction The availability of patient data in Electronic Health Records (EHRs) gives us a unique opportunity to study different aspects of patient care, and obtain better insights into different diseases, their dynamics and treatments. The knowledge and models obtained from such studies have a great potential in health care quality improvement and health care cost reduction. Machine learning and data mining methods and algorithms play an important role in this process. The main focus of this paper is on the problem of building (learning) classification models from clinical data and expert defined class labels. Briefly, the goal is to learn a classification model f: x \u2192 y that helps us to map a patient instance x to a binary class label y, representing, for example, the presence or absence of an adverse condition, or the diagnosis of a specific disease. Such models, once they are learned can be used in patient monitoring, or disease and adverse event detection. The standard machine learning framework assumes the class labels are assigned to instances by a uniform labeling process. However, in the majority of practical settings the labels come from multiple experts. Briefly, the class labels are either acquired (1) during the patient management process and represent the decision of the human expert that is recorded in the EHR (say diagnosis) or (2) retrospectively during a separate annotation process based on past patient data. In the first case, there may be different physicians that manage different patients, hence the class labels naturally originate from multiple experts. Whilst in the second (retrospective) case, the class label can in principle be provided by one expert, the constraints on how much time a physician can spend on patient annotation process often requires to distribute the load among multiple experts. Accepting the fact that labels are provided by multiple experts, the complication is that different experts may have different subjective opinion about the same patient case. The differences may be due to experts\u2019 knowledge, subjective preferences and utilities, and expertise level. This may lead to disagreements in their labels, and variation in the patient case labeling due to these disagreements. However, we would like to note that while we do not expect all experts to agree on all labels, we also do not expect the expert\u2019s label assessment to be random; the labels provided by different experts are closely related by the condition (diagnosis, an adverse event) they represent. Given that the labels are provided by multiple experts, two interesting research questions arise. The first question is whether there is a model that would represent well the labels the group of experts would assign to each patient case. We refer to such a group model as to the (group) consensus model. The second question is whether it is possible to learn such a consensus model purely from label assessments of individual experts, that is, without access to any consensus/meta labels, and this as efficiently as possible. To address the above issues, we propose a new multi-expert learning framework that starts from data labeled by multiple experts and builds: (1) a consensus model representing the classification model the experts collectively converge to, and (2) individual expert models representing the class label decisions exhibited by individual experts. Fig. 1 shows the relations between these two components: the experts\u2019 specific models and the consensus model. We would like to emphasize again that our framework builds the consensus model without access to any consensus/meta labels. To represent relations among the consensus and expert models, our framework considers different sources of disagreement that may arise when multiple experts label a case and explicitly represents them in the combined multi-expert model. In particular our framework assumes the following sources for expert disagreements: \u2022 Differences in the risks annotators associate with each class label assignment: diagnosing a patient as not having a disease when the patient has disease, carries a cost due to, for example, a missed opportunity to treat the patient, or longer patient discomfort and suffering. A similar, but different cost is caused by incorrectly diagnosing a patient. The differences in the expert-specific utilities (or costs) may easily explain differences in their label assessments. Hence our goal is to develop a learning framework that seeks a model consensus, and that, at the same time, permits experts who have different utility biases. \u2022 Differences in the knowledge (or model) experts use to label examples: while diagnoses provided by different experts may be often consistent, the knowledge they have and features they consider when making the disease decision may differ, potentially leading to differences in labeling. It is not rare when two expert physicians disagree on a complex patient case due to differences firmly embedded in their knowledge and understanding of the disease. These differences are best characterized as differences in their knowledge or model they used to diagnose the patient. \u2022 Differences in time annotators spend when labeling each case: different experts may spend different amount of time and care to analyze the same case and its subtleties. This may lead to labeling inconsistency even within the expert\u2019s own model. We experiment with and test our multi-expert framework on the Heparin Induced Thrombocytopenia (HIT) [23] problem where our goal is to build a predictive model that can, as accurately as possible, assess the risk of the patient developing the HIT condition and predict HIT alerts. We have obtained the HIT alert annotations from three different experts in clinical pharmacy. In addition we have also acquired a meta-annotation from the fourth (senior) expert who in addition to patient cases have seen the annotations and assessments given by other three experts. We show that our framework outperforms other machine learning frameworks (1) when it predicts a consensus label for future (test) patients and (2) when it predicts individual future expert labels. 2 Background The problem of learning accurate classification models from clinical data that are labeled by human experts with respect to some condition of interest is important for many applications such as diagnosis, adverse event detection, monitoring and alerting, and the design of recommender systems. Standard classification learning framework assumes the training data set D = { ( x i , y i ) } i = 1 n consists of n data examples, where x i is a d-dimensional feature vector and y i is a corresponding binary class label. The objective is to learn a classification function: f: x \u2192 y that generalizes well to future data. The key assumption for learning the classification function f in the standard framework is that examples in the training data D are independent and generated by the same (identical) process, hence there are no differences in the label assignment process. However, in practice, especially in medicine, the labels are provided by different humans. Consequently, they may vary and are subject to various sources of subjective bias and variations. We develop and study a new multi-expert classification learning framework for which labels are provided by multiple experts, and that accounts for differences in subjective assessments of these experts when learning the classification function. Briefly, we have m different experts who assign labels to examples. Let D k = x i k , y i k i = 1 n k denotes training data specific for the expert k, such that x i k is a d-dimensional input example and y i k is binary label assigned by expert k. Given the data from multiple experts, our main goal is to learn the classification mapping: f: x \u2192 y that would generalize well to future examples and would represent a good consensus model for all these experts. In addition, we can learn the expert specific classification functions g k : x \u2192 y k for all k =1,\u2026, m that predicts as accurately as possible the label assignment for that expert. The learning of f is a difficult problem because (1) the experts\u2019 knowledge and reliability could vary and (2) each expert can have different preferences (or utilities) for different labels, leading to different biases towards negative or positive class. Therefore, even if two experts have the same relative understanding of a patient case their assigned labels may be different. Under these conditions, we aim to combine the subjective labels from different experts to learn a good consensus model. 2.1 Related work Methodologically our multi-expert framework builds upon models and results in two research areas: multi-task learning and learning-from-crowds, and combines them to achieve the above goals. The multi-task learning framework [9,27] is applied when we want to learn models for multiple related (correlated) tasks. This framework is used when one wants to learn more efficiently the model by borrowing the data, or model components from a related task. More specifically, we can view each expert and his/her labels as defining a separate classification task. The multi-task learning framework then ties these separate but related tasks together, which lets us use examples labeled by all experts to learn better individual expert models. Our approach is motivated and builds upon the multi-task framework proposed by Evgeniou and Pontil [9] that ties individual task models using a shared task model. However, we go beyond this framework by considering and modeling the reliability and biases of the different experts. The learning-from-crowds framework [17,18] is used to infer consensus on class labels from labels provided jointly by multiple annotators (experts). The existing methods developed for the problem range from the simple majority approach to more complex consensus models representing the reliability of different experts. In general the methods developed try to either (1) derive a consensus of multiple experts on the label of individual examples or (2) build a model that defines the consensus for multiple experts and can be applied to future examples. We will review these in the following. The simplest and most commonly used approach for defining the label consensus on individual examples is the majority voting. Briefly, the consensus on the labels for an example is the label assigned by the majority of reviewers. The main limitation of the majority voting approach is that it assumes all experts are equally reliable. The second limitation is that although the approach defines the consensus on labels for existing examples, it does not directly define a consensus model that can be used to predict consensus labels for future examples; although one may use the labels obtained from majority voting to train a model in a separate step. Improvements and refinements of learning a consensus label or model take into account and explicitly model some of the sources of annotator disagreements. Sheng et al. [17] and Snow et al. [18] showed the benefits of obtaining labels from multiple non-experts and unreliable annotators. Dawid and Skene [8] proposed a learning framework in which biases and skills of annotators were modeled using a confusion matrix. This work was later generalized and extended in [25,24,26] by modeling difficulty of examples. Finally, Raykar et al. [14] used an expectation\u2013maximization (EM) algorithm to iteratively learn the reliability of annotators. The initial reliability estimates were obtained using the majority vote. The current state-of-the-art learning methods with multiple human annotators are the works of Raykar et al. [14], Welinder et al. [24], and Yan et al. [26]. Among these, only Raykar et al. [14] uses a framework similar to the one we use in this paper; that is, it assumes (1) not all examples are labeled by all experts and (2) the objective is to construct a good classification model. However, the model differs from our approach in how it models the skills and biases of the human annotators. Also the authors in [14] show that their approach improves over simple baselines only when the number of annotators is large (more than 40). This is practical when the labeling task is easy so crowd-sourcing services like Amazon Mechanical Turk can be utilized. However, it is not practical in domains in which the annotation is time consuming. In real world or scientific domains that involve uncertainty, including medicine, it is infeasible to assume the same patient case is labeled in parallel by many different experts. Indeed the most common cases is when every patient instance is labeled by just one expert. The remaining state-of-the-art learning from crowds methods, i.e. the works of Welinder et al. [24] and Yan et al. [26], are optimized for different settings than ours. Welinder et al. [24] assumes that there is no feature vector available for the cases; it only learns expert specific models g k s, and it does not attempt to learn a consensus model f. On the other hand, Yan et al. [26] assumes that each example is labeled by all experts in parallel. As noted earlier, this is unrealistic, and most of the time each example is labeled only by one expert. The approach we propose in this paper overcomes these limitations and is flexible in that it can learn the models when there is one or more labels per example. In addition, our approach differs from the work of Yan et al. [26] in how we parameterize and optimize our model. 3 Methodology We aim to combine data labeled by multiple experts and build (1) a unified consensus classification model f for these experts and (2) expert-specific models g k , for all k =1,\u2026, m that can be applied to future data. Fig. 2 illustrates the idea of our framework with linear classification models. Briefly, let us assume a linear consensus model f with parameters (weights) u and b from which linear expert-specific models g k s with parameters w k and b k are generated. Given the consensus model, the consensus label on example x is positive if u T x + b \u2a7e0, otherwise it is negative. Similarly, the expert model g k for expert k assigns a positive label to example x if w k T x + b k \u2a7e 0 , otherwise the label is negative. To simplify the notation in the rest of the paper, we include the bias term b for the consensus model in the weights vector u, the biases b k in w k s, and extend the input vector x with constant 1. The consensus and expert models in our framework and their labels are linked together using two reliability parameters: 1. \u03b1 k : the self-consistency parameter that characterizes how reliable the labeling of expert k is; it is the amount of consistency of expert k within his/her own model w k . 2. \u03b2 k : the consensus-consistency parameter that models how consistent the model of expert k is with respect to the underlying consensus model u. This parameter models the differences in the knowledge or expertise of the experts. We assume, all deviations of the expert specific models from the consensus model are adequately modeled by these expert-specific reliability parameters. In the following we present the details of the overall model and how reliability parameters are incorporated into the objective function. 3.1 Multiple Experts Support Vector Machines (ME-SVM) Our objective is to learn the parameters u of the consensus model and parameters w k for all expert-specific models from the data. We combine this objective with the objective of learning the expert specific reliability parameters \u03b1 k and \u03b2 k . We have expressed the learning problem in terms of the objective function based on the max-margin classification framework [16,19] which is used, for example, by support vector machines (SVMs). However, due to its complexity we motivate and explain its components using an auxiliary probabilistic graphical model that we later modify to obtain the final max-margin objective function. Fig. 3 shows the probabilistic graphical model representation [5,13] that refines the high level description presented in Fig. 2. Briefly, the consensus model u is defined by a Gaussian distribution with zero mean and precision parameter \u03b7 as: (1) p ( u | 0 d , \u03b7 ) = N ( 0 d , \u03b7 - 1 I d ) where I d is the identity matrix of size d, and 0 d is a vector of size d with all elements equal to 0. The expert-specific models are generated from a consensus model u. Every expert k has his/her own specific model w k that is a noise corrupted version of the consensus model u; that is, we assume that expert k, w k , is generated from a Gaussian distribution with mean u and an expert-specific precision \u03b2 k : p ( w k | u , \u03b2 k ) = N u , \u03b2 k - 1 I d The precision parameter \u03b2 k for the expert k determines how much w k differs from the consensus model. Briefly, for a small \u03b2 k , the model w k tends to be very different from the consensus model u, while for a large \u03b2 k the models will be very similar. Hence, \u03b2 k represents the consistency of the reviewer specific model w k with the consensus model u, or, in short, consensus-consistency. The parameters of the expert model w k relate examples (and their features) x to labels. We assume this relation is captured by the regression model: p y i k | x i k , w k , \u03b1 k = N w k T x i k , \u03b1 k - 1 where \u03b1 k is the precision (inverse variance) and models the noise that may corrupt expert\u2019s label. Hence \u03b1 k defines the self-consistency of expert k. Please also note that although y i k is binary, similarly to [9,27], we model the label prediction and related noise using the Gaussian distribution. This is equivalent to using the squared error loss as the classification loss. We treat the self-consistency and consensus-consistency parameters \u03b1 k and \u03b2 k as random variables, and model their priors using Gamma distributions. More specifically, we define: (2) p ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) = G ( \u03b8 \u03b2 , \u03c4 \u03b2 ) p ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) = G ( \u03b8 \u03b1 , \u03c4 \u03b1 ) where hyperparameters \u03b8 \u03b2 k and \u03c4 \u03b2 k represent the shape and the inverse scale parameter of the Gamma distribution representing \u03b2 k . Similarly, \u03b8 \u03b1 k and \u03c4 \u03b1 k are the shape and the inverse scale parameter of the distribution representing \u03b1 k . Using the above probabilistic model we seek to learn the parameters of the consensus u and expert-specific models W from data. Similarly to Raykar et al. [14] we optimize the parameters of the model by maximizing the posterior probability p(u, W, \u03b1, \u03b2\u2223X, y, \u03be), where \u03be is the collection of hyperparameters \u03b7 , \u03b8 \u03b2 k , \u03c4 \u03b2 k , \u03b8 \u03b1 k , \u03c4 \u03b1 k . The posterior probability can be rewritten as follows: (3) p ( u , W , \u03b1 , \u03b2 | X , y , \u03be ) \u221d p ( u | 0 d , \u03b7 ) \u220f k = 1 m p ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) p ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) p ( w k | u , \u03b2 k ) \u220f i = 1 n k p y i k | x i k , \u03b1 k , w k where X = x 1 1 ; \u2026 ; x n 1 1 ; \u2026 ; x 1 m ; \u2026 ; x n m m is the matrix of examples labeled by all the experts, and y = y 1 1 ; \u2026 ; y n 1 1 ; \u2026 ; y m 1 ; \u2026 ; y n m m are their corresponding labels. Similarly, X k and y k are the examples and their labels from expert k. Direct optimization (maximization) of the above function is difficult due to the complexities caused by the multiplication of many terms. A common optimization trick to simplify the objective function is to replace the original complex objective function with the logarithm of that function. This conversion reduces the multiplication to summation [5]. Logarithm function is a monotonic function and leads to the same optimization solution as the original problem. Negative logarithm is usually used to cancel many negative signs produced by the logarithm of exponential distributions. This changes the maximization to minimization. We follow the same practice and take the negative logarithm of the above expression to obtain the following problem (see Appendix A for the details of the derivation): (4) min u , w , \u03b1 , \u03b2 \u03b7 2 \u2016 u \u2016 2 + 1 2 \u2211 k = 1 m \u03b1 k \u2211 i = 1 n k y i k - w k T x i k 2 + 1 2 \u2211 k = 1 m \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m ( - ln ( \u03b2 k ) - n k ln ( \u03b1 k ) ) + \u2211 k = 1 m ( - ( \u03b8 \u03b2 k - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 k \u03b2 k ) + \u2211 k = 1 m ( - ( \u03b8 \u03b1 k - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 k \u03b1 k ) Although we can solve the objective function in Eq. (4) directly, we replace the squared error function in Eq. (4) with the hinge loss 1 Hinge loss is a loss function originally designed for training large margin classifiers such as support vector machines. The minimization of this loss leads to a classification decision boundary that has the maximum distance to the nearest training example. Such a decision boundary has interesting properties, including good generalization ability [15,21]. 1 for two reasons: (1) the hinge loss function is a tighter surrogate for the zero-one (error) loss used for classification than the squared error loss[15] and (2) the hinge loss function leads to the sparse kernel solution [5]. Sparse solution means that the decision boundary depends on a smaller number of training examples. Sparse solutions are more desirable specially when the models are extended to non-linear case where the similarity of the unseen examples needs to be evaluated with respect to the training examples on which the decision boundary is dependent. By replacing the squared errors with the hinge loss we obtain the following objective function: (5) min u , w , \u03b1 , \u03b2 \u03b7 2 \u2016 u \u2016 2 + 1 2 \u2211 k = 1 m \u03b1 k \u2211 i = 1 n k max 0 , 1 - y i k w k T x i k ) + 1 2 \u2211 k = 1 m \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m ( - ln ( \u03b2 k ) - n k ln ( \u03b1 k ) ) + \u2211 k = 1 m ( - ( \u03b8 \u03b2 k - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 k \u03b2 k ) + \u2211 k = 1 m ( - ( \u03b8 \u03b1 k - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 k \u03b1 k ) We minimize the above objective function with respect to the consensus model u, the expert specific model w k , and expert specific reliability parameters \u03b1 k and \u03b2 k . 3.2 Optimization We need to optimize the objective function in Eq. (5) with regard to parameters of the consensus model u, the expert-specific models w k , and expert-specific parameters \u03b1 k and \u03b2 k . Similarly to the SVM, the hinge loss term: max 0 , 1 - y i k w k T x i k in Eq. (5) can be replaced by a constrained optimization problem with a new parameter \u220a i k . Briefly, from the optimization theory, the following two equations are equivalent [6]: min w k max 0 , 1 - y i k w k T x i k and min \u220a i k , w k \u220a i k s.t. y i k w k T x i k > 1 - \u220a i k Now replacing the hinge loss terms in Eq. (5), we obtain the equivalent optimization problem: (6) min u , w , \u220a , \u03b1 , \u03b2 \u03b7 2 \u2016 u \u2016 2 + 1 2 \u2211 k = 1 m \u03b1 k \u2211 i = 1 n k \u220a i k + 1 2 \u2211 k = 1 m \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m ( - ln ( \u03b2 k ) - n k ln ( \u03b1 k ) ) + \u2211 k = 1 m ( - ( \u03b8 \u03b2 k - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 k \u03b2 k + \u2211 k = 1 m ( - ( \u03b8 \u03b1 k ) - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 k \u03b1 k ) s . t . y i k w k T x i k \u2a7e 1 - \u220a i k , k = 1 \u22ef m , i = 1 \u22ef n k \u220a i k \u2a7e 0 , k = 1 \u22ef m , i = 1 \u22ef n k where \u220a denote the new set of \u220a i k parameters. We optimize the above objective function using the alternating optimization approach [4]. Alternating optimization splits the objective function into two (or more) easier subproblems, each depends only on a subset of (hidden/learning) variables. After initializing the variables, it iterates over optimizing each set by fixing the other set until there is no change of values of all the variables. For our problem, diving the learning variables into two subsets, {\u03b1, \u03b2} and {u, w} makes each subproblem easier, as we describe below. After initializing the first set of variables, i.e. \u03b1 k =1 and \u03b2 k =1, we iterate by performing the following two steps in our alternating optimization apparoach: \u2022 Learning u and w k : In order to learn the consensus model u and expert specific model w k , we consider the reliability parameters \u03b1 k and \u03b2 k as constants. This will lead to an SVM form optimization to obtain u and w k . Notice that \u220a i k is also learned as part of SVM optimization. \u2022 Learning \u03b1 k and \u03b2 k : By fixing u, w k for all experts, and \u220a , we can minimize the objective function in Eq. (6) by computing the derivative with respect to \u03b1 and \u03b2 . This results in the following closed form solutions for \u03b1 k and \u03b2 k : (7) \u03b1 k = 2 ( n k + \u03b8 \u03b1 k - 1 ) \u2211 y i k = 1 \u220a i k + 2 \u03c4 \u03b1 k (8) \u03b2 k = 2 \u03b8 \u03b2 k \u2016 w k - u \u2016 2 + 2 \u03c4 \u03b2 k Notice that \u220a i k is the amount of violation of label constraint for example x i k (i.e. the ith example labeled by expert k) thus \u2211 i = 1 \u220a i k is the summation of all labeling violations for model of expert k. This implies that \u03b1 k is inversely proportional to the amount of misclassification of examples by expert k according to its specific model w k . As a result, \u03b1 k represents the consistency of the labels provided by expert k with his/her own model. \u03b2 k is inversely related to the difference of the model of expert k (i.e. w k ) with the consensus model u. Thus it is the consistency of the model learned for expert k from the consensus model u. 4 Experimental evaluation We test the performance of our methods on clinical data obtained from EHRs for post-surgical cardiac patients and the problem of monitoring and detection of the Heparin Induced Thrombocytopenia (HIT) [23,22]. HIT is an adverse immune reaction that may develop if the patient is treated for a longer time with heparin, the most common anticoagulation treatment. If the condition is not detected and treated promptly it may lead to further complications, such as thrombosis, and even to patient\u2019s death. An important clinical problem is the monitoring and detection of patients who are at risk of developing the condition. Alerting when this condition becomes likely prevents the aggravation of the condition and appropriate countermeasures (discontinuation of the heparin treatment or switch to an alternative anticoagulation treatment) may be taken. In this work, we investigate the possibility of building a detector from patient data and human expert assessment of patient cases with respect to HIT and the need to raise the HIT alert. This corresponds to the problem of learning a classification model from data where expert\u2019s alert or no-alert assessments define class labels. 4.1 Data The data used in the experiments were extracted from over 4486 electronic health records (EHRs) in Post-surgical Cardiac Patient (PCP) database [11,20,12]. The initial data consisted of over 51,000 unlabeled patient-state instances obtained by segmenting each EHR record in time with 24-h period. Out of these we have selected 377 patient instances using a stratified sampling approach that were labeled by clinical pharmacists who attend and manage patients with HIT. Since the chance of observing HIT is relatively low, the stratified sampling was used to increase the chance of observing patients with positive labels. Briefly, a subset of strata covered expert-defined patterns in the EHR associated with the HIT or its management, such as, the order of the HPF4 lab test used to confirm the condition [22]. We asked three clinical pharmacists to provide us with labels showing if the patient is at the risk of HIT and if they would agree to raise an alert on HIT if the patient was encountered prospectively. The assessments were conducted using a web-based graphical interface (called PATRIA) we have developed to review EHRs of patients in the PCP database and their instances. All three pharmacists worked independently and labeled all 377 instances. After the first round of expert labeling (with three experts) we asked a (senior) expert on HIT condition to label the data, but this time, the expert in addition to information in the EHR also had access to the labels of the other three experts. This process led to 88 positive and 289 negative labels. We used the judgement and labels provided by this expert as consensus labels. We note that alternative ways of defining consensus labels in the study would be possible. For example, one could ask the senior expert to label the cases independent of labels of other reviewers and consider expert\u2019s labels as surrogates for the consensus labels. Similarly one can ask all three experts to meet and resolve the cases they disagree on. However, these alternative designs come with the different limitations. First, not seeing the labels of other reviewers the senior expert would make a judgment on the labels on her own and hence it would be hard to speak about consensus labels. Second, the meeting of the experts and the resolution of the differences on every case in the study in person would be hard to arrange and time consuming to undertake. Hence, we see the option of using senior expert\u2019s opinion to break the ties as a reasonable alternative that (1) takes into account labels from all experts and (2) resolves them without arranging a special meeting of all experts involved. In addition, we would like to emphasize that the labels provided by the (senior) expert were only used to evaluate the quality of the different consensus models. That is, we did not use the labels provided by that expert when training the different consensus models, and only applied them in the evaluation phase. 4.2 Temporal feature extraction The EHR consists of complex multivariate time series data that reflect sequences of lab values, medication administrations, procedures performed, etc. In order to use these for building HIT prediction models, a small set of temporal features representing well the patient state with respect to HIT for any time t is needed. However, finding a good set of temporal features is an extremely challenging task [10,2,7,3,1]. Briefly, the clinical time series, are sampled at irregular times, have missing values, and their length may vary depending on the time elapsed since the patient was admitted to the hospital. All these make the problem of summarizing the information in the time series hard. In this work, we address the above issues by representing the patient state at any (segmentation) time t using a subset of pre-defined temporal feature mappings proposed by Hauskrecht et al. [11,20,12] that let us convert patient\u2019s information known at time t to a fixed length feature vector. The feature mappings define temporal features such as last observed platelet count value, most recent platelet count trend, or, the length of time the patient is on medication. Fig. 4 illustrates a subset of 10 feature mappings (out of 14) that we applied to summarize time series for numeric lab tests. We used feature mappings for five clinical variables useful for the detection of HIT: Platelet counts, Hemoglobin levels, White Blood Cell Counts, Heparin administration record, Major heart procedure. The full list of features generated for these variables is listed in Appendix B. Briefly, temporal features for numeric lab tests: Platelet counts, Hemoglobin levels and White Blood Cell Counts used feature mappings illustrated in Fig. 4 plus additional features representing the presence of last two values, and pending test. The heparin features summarize if the patient is currently on the heparin or not, and the timing of the administration, such as the time elapsed since the medication was started, and the time since last change in its administration. The heart procedure features summarize whether the procedure was performed or not and the time elapsed since the last and first procedure. The feature mappings when applied to EHR data let us map each patient instance to a vector of 50 features. These features were then used to learn the models in all subsequent experiments. The alert labels assigned to patient instances by experts were used as class labels. 4.3 Experimental set-up To demonstrate the benefits of our multi-expert learning framework we used patient instances labeled by four experts as outlined above. The labeled data were randomly split into the training and test sets, such that 2/3 of examples were used for training examples and 1/3 for testing. We trained all models in the experimental section on the training set and evaluated on the test set. We used the Area Under the ROC Curve (AUC) on the test set as the main statistic for all comparisons. We repeated train/test split 100 times and report the average and 95% confidence interval. We compare the following algorithms: \u2022 SVM-baseline: This is a model obtained by training a linear SVM classifier that considers examples and their labels and ignores any expert information. We use the model as a baseline. \u2022 Majority: This model selects the label in the training data using the majority vote and learns a linear SVM classifier on examples with the majority label. This model is useful only when multiple experts label the same patient instance. Notice that SVM and Majority performs exactly the same if each example is labeled by one and only one expert. \u2022 Raykar: This is the algorithm and model developed by Raykar et al. [14]. We used the same setting as discussed in [14]. \u2022 ME-SVM: This is the new method we propose in this paper. We set the parameters \u03b7 = \u03c4 \u03b1 = \u03c4 \u03b2 =1, \u03b8 \u03b1 = \u03b8 \u03b2 =1. \u2022 SE-SVM: Senior-Expert-SVM (SE-SVM) is the SVM model trained using the consensus labels provided by our senior pharmacist. Note that this method does not derive a consensus model from labels given by multiple experts; instead, it \u2018cheats\u2019 and learns consensus model directly from consensus labels. This model and its results are used for comparison purposes only and serve as the reference point. We investigate two aspects of the proposed ME-SVM method: 1. The performance of the consensus model on the test data when it is evaluated on the labels provided by the senior expert on HIT. 2. The performance of the expert-specific model w k for expert k when it is evaluated on the examples labeled by that expert. 4.4 Results and discussion 4.4.1 Learning consensus model The cost of labeling examples in medical domain is typically very high, so in practice we may have a very limited number of training data. Therefore, it is important to have a model that can efficiently learn from a small number of training examples. We investigate how different methods perform when the size of training data varies. For this experiment we randomly sample examples from the training set to feed the models and evaluate them on the test set. We simulated and tested two different ways of labeling the examples used for learning the model: (1) every example was given to just one expert, and every expert labeled the same number of examples and (2) every example was given to all experts, that is, every example was labeled three times. The results are shown in Fig. 5 . The x-axis shows the total number of cases labeled by the experts. The left and right plots respectively show the results when labeling options 1 and 2 are used. First notice that our method that explicitly models experts\u2019 differences and their reliabilities consistently outperforms other consensus methods in both strategies, especially when the number of training examples is small. This is particularly important when labels are not recorded in the EHRs and must be obtained via a separate post-processing step, which can turn out to be rather time-consuming and requires additional expert effort. In contrast to our method the majority voting does not model the reliability of different experts and blindly considers the consensus label as the majority vote of labels provided by different experts. The SVM method is a simple average of reviewer specific models and does not consider the reliability of different experts in the combination. The Raykar method, although modeling the reliabilities of different experts, assumes that the experts have access to the label generated by the consensus model and report a perturbed version of the consensus label. This is not realistic because it is not clear why the expert perturb the labels if they have access to consensus model. In contrary, our method assumes that different experts aim to use a model similar to consensus model to label the cases however their model differs from the label of the consensus model because of their differences in the domain knowledge, expertise and utility functions. Thus, our method uses a more intuitive way and realistic approach to model the label generating process. Second, by comparing the two strategies for labeling patient instances we see that option 1, where each reviewer labels different patient instances, is better (in terms of the total labeling effort) than option 2 where all reviewers label the same instances. This shows that the diversity in patient examples seen by the framework helps and our consensus model is improving faster, which is what we intuitively expect. Finally, note that our method performs very similarly to the SE-SVM \u2013 the model that \u2018cheats\u2019 and is trained directly on the consensus labels given by the senior pharmacist. This verifies that our framework is effective in finding a good consensus model without having access to the consensus labels. 4.4.2 Modeling individual experts One important and unique feature of our framework when compared to other multi-expert learning frameworks is that it models explicitly the individual experts\u2019 models w k , not just the consensus model u. In this section, we study the benefit of the framework for learning the expert specific models by analyzing how the model for any of the experts can benefit from labels provided by other experts. In other words we investigate the question: Can we learn an expert model better by borrowing the knowledge and labels from other experts? We compared the expert specific models learned by our framework with the following baselines: \u2022 SVM: We trained a separate SVM model for each expert using patient instances labeled only by that expert. We use this model as a baseline. \u2022 Majority \u2217: This is the Majority model described in the previous section. However, since Majority model does not give expert specific models, we use the consensus model learned by the Majority method in order to predict the labels of each expert. \u2022 Raykar \u2217: This is the model developed by Raykar et al. [14], as described in the previous section. Similarly to Majority, Raykar\u2019s model does not learn expert specific models. Hence, we use the consensus model it learns to predict labels of individual experts. \u2022 ME-SVM: This is the new method we propose in this paper, that generates expert specific models as part of its framework. Similarly to Section 4.4.1, we assume two different ways of labeling the examples: (1) every example was given to just one expert, and every expert labeled the same number of examples and (2) every example was given to all experts, that is every example was labeled three times. We are interested in learning individual prediction models for three different experts. If we have a budget to label some number of patient instances, say, 240, and give 80 instances to each expert, then we have can an individual expert model from: (1) all 240 examples by borrowing from the instances labeled by the other experts or (2) only its own 80 examples. The hypothesis is that learning from data and labels given by all three experts collectively is better than learning each of them individually. The hypothesis is also closely related to the goal of multi-task learning, where the idea is to use knowledge, models or data available for one task to help learning of models for related domains. The results for this experiment are summarized in Fig. 6 , where x-axis is the number of training examples fed to the models and y-axis shows how well the models can predict individual experts\u2019 labels in terms of the AUC score. The first (upper) line of sub-figures shows results when each expert labels a different set of patient instances, whereas the second (lower) line of sub-figures shows results when instances are always labeled by all three experts. The results show that our ME-SVM method outperforms the SVM trained on experts\u2019 own labels only. This confirms that learning from three experts collectively helps to learn expert-specific models better than learning from each expert individually and that our framework enables such learning. In addition, the results of Majority\u2217 and Raykar\u2217 methods show that using their consensus models to predict expert specific labels is not as effective and that their performance is worse than our framework that relies on expert specific models. 4.4.3 Self-consistency and consensus-consistency As we described in Section 3, we model self-consistency and consensus-consistency with parameters \u03b1 k and \u03b2 k . \u03b1 k measures how consistent the labeling of expert k is with his/her own model and \u03b2 k measures how consistent the model of expert k is with respect to the consensus model. The optimization problem we proposed in Eq. (6) aims to learn not just the parameters u and w k of the consensus and experts\u2019 models, but also the parameters \u03b1 k and \u03b2 k , and this without having access to the labels from the senior expert. In this section, we attempt to study and interpret the values of the reliability parameters as they are learned by our framework and compare them to empirical agreements in between the senior (defining the consensus) and other experts. Fig. 7 a shows the agreements of labels provided by the three experts with labels given by the senior expert, which we assumed gives the consensus labels. From this figure we see that Expert 2 agrees with the consensus labels the most, followed by Expert 3 and then Expert 1. The agreement is measured in terms of the absolute agreement, and reflects the proportion of instances for which the two labels agree. Fig. 7b and c show the values of the reliability parameters \u03b1 and \u03b2, respectively. The x-axis in these figures shows how many training patient instances per reviewer are fed to the model. Normalized self-consistency in Fig. 7b is the normalized value of \u03b1 k in Eq. (6). Normalized consensus-consistency in Fig. 7c is the normalized inverse value of Euclidean distance between an expert specific model and consensus model: 1/\u2225w k \u2212 u\u2225, which is proportional to \u03b2 k in Eq. (6). In Fig. 7d we add the two consistency measures in an attempt to measure the overall consistency in between the senior expert (consensus) and other experts. As we can see, at the beginning when there is no training data all experts are assumed to be the same (much like the majority voting approach). However, as the learning progresses with more training examples available, the consistency measures are updated and their values define the contribution of each expert to the learning of consensus model: the higher the value the larger the contribution. Fig. 7b shows that expert 3 is the best in terms of self-consistency given the linear model, followed by expert 2 and then expert 1. This means expert 3 is very consistent with his model, that is, he likely gives the same labels to similar examples. Fig. 7c shows that expert 2 is the best in terms of consensus-consistency, followed by expert 3 and then expert 1. This means that although expert 2 is not very consistent with respect to his own linear model his model appears to converge closer to the consensus model. In other words, expert 2 is the closest to the expected consensus in terms of the expertise but deviates with some labels from his own linear model than expert 3 does. 2 We would like to note that the self-consistency and consensus-consistency parameters learned by our framework are learned together and hence it is possible one consistency measure may offset or compensate for the value of the other measure during the optimization. In that case the interpretation of the parameters as presented may not be as straightforward. 2 Fig. 7d shows the summation of the two consistency measures. By comparing Fig. 7a and d we observe that the overall consistency mimics well the agreements in between the expert defining the consensus and other experts, especially when the number of patient instances labeled and used to train our model increases. This is encouraging, since the parameters defining the consistency measures are learned by our framework only from the labels of the three experts and hence the framework never sees the consensus labels. 5 Conclusion The construction of predictive classification models from clinical data often relies on labels reflecting subjective human assessment of the condition of interest. In such a case, differences among experts may arise leading to potential disagreements on the class label that is assigned to the same patient case. In this work, we have developed and investigated a new approach to combine class-label information obtained from multiple experts and learn a common (consensus) classification model. We have shown empirically that our method outperforms other state-of-the-art methods when building such a model. In addition to learning a common classification model, our method also learns expert specific models. This addition provides us with an opportunity to understand the human experts\u2019 differences and their causes which can be helpful, for example, in education and training, or in resolving disagreements in the patient assessment and patient care. Acknowledgements This research work was supported by Grants R01LM010019 and R01GM088224 from the National Institutes of Health. Its content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. Appendix A Derivation of Eq. (4) from Eq. (3) In this appendix, we give a more detailed derivation of Eq. (4) from (3): p ( u , W , \u03b7 , \u03b1 , \u03b2 | X , y , \u03be ) \u221d p ( u | 0 d , \u03b7 ) \u220f k = 1 m p ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) p ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) p ( w k | u , \u03b2 k ) \u220f i = 1 n k p y i k | x i k , \u03b1 k , w k = N u | 0 , \u03b2 k - 1 I d \u220f k = 1 m G ( \u03b2 k | \u03b8 \u03b2 , \u03c4 \u03b2 ) G ( \u03b1 k | \u03b8 \u03b1 , \u03c4 \u03b1 ) N ( w k | u , \u03b2 k - 1 I d ) \u220f i = 1 n k N y i k | w k \u22a4 x i k , \u03b1 k = \u03b7 k 2 \u03c0 e - \u03b7 \u2016 u \u2016 2 2 \u00d7 \u220f k = 1 m 1 \u0393 ( \u03b8 \u03b2 ) \u03c4 \u03b2 \u03b8 \u03b2 \u03b2 k \u03b8 \u03b2 - 1 e - \u03c4 \u03b2 \u03b2 k 1 \u0393 ( \u03b8 \u03b1 ) \u03c4 \u03b1 \u03b8 \u03b1 \u03b1 k \u03b8 \u03b1 - 1 e - \u03c4 \u03b1 \u03b1 k \u03b2 k 2 \u03c0 e - \u03b2 k \u2016 w k - u \u2016 2 2 \u220f i = 1 n k \u03b1 k 2 \u03c0 e - \u03b1 k y i k - w k \u22a4 x i k 2 2 Taking the negative logarithm of p ( u , W , \u03b7 , \u03b1 , \u03b2 \u2223 X , y , \u03be ) that lets us to convert the maximization problem to minimization, we get: - ln p ( u , W , \u03b7 , \u03b1 , \u03b2 \u2223 X , y , \u03be ) = - ln ( \u03b7 ) - log ( 2 \u03c0 ) + 1 2 \u03b7 \u2016 u \u2016 2 + \u2211 k = 1 m ( ln ( \u0393 ( \u03b8 \u03b2 ) ) - \u03b8 \u03b2 ln ( \u03c4 \u03b2 ) - ( \u03b8 \u03b2 - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 \u03b2 k ) + \u2211 k = 1 m ( ln ( \u0393 ( \u03b8 \u03b1 ) ) - \u03b8 \u03b1 ln ( \u03c4 \u03b1 ) - ( \u03b8 \u03b1 - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 \u03b1 k ) + \u2211 k = 1 m - ln ( \u03b2 k ) + ln ( 2 \u03c0 ) + 1 2 \u03b2 k \u2016 w k - u \u2016 2 ) + \u2211 k = 1 m \u2211 i = 1 n k - ln ( \u03b1 k ) + ln ( 2 \u03c0 ) + 1 2 \u03b1 k \u2016 y i k - w k \u22ba x i k \u2016 2 Rewriting the above equation we get: - ln p ( u , W , \u03b7 , \u03b1 , \u03b2 \u2223 X , y , \u03be ) = 1 2 \u03b7 \u2016 u \u2016 2 + \u2211 k = 1 m ( - ( \u03b8 \u03b2 - 1 ) ln ( \u03b2 k ) + \u03c4 \u03b2 \u03b2 k ) + \u2211 k = 1 m ( - ( \u03b8 \u03b1 - 1 ) ln ( \u03b1 k ) + \u03c4 \u03b1 \u03b1 k ) + \u2211 k = 1 m - ln ( \u03b2 k ) + 1 2 \u03b2 k \u2016 w k - u \u2016 2 + \u2211 k = 1 m \u2211 i = 1 n k - ln ( \u03b1 k ) + 1 2 \u03b1 k \u2016 y i k - w k \u22ba x i k \u2016 2 + A where A sums all constant terms that can be ignored during the optimization step, and that include terms involving hyperparameters \u03b7 , \u03b8 \u03b1 , \u03c4 \u03b1 , \u03b8 \u03b2 that are constants. By ignoring A and rearranging the remaining terms we get Eq. 4. Removing the constants terms (i.e. those related to \u03b7, \u03b8 \u03b1 , \u03c4 \u03b1 , \u03b8 \u03b2 and \u03c4 \u03b2 , we will have: 1 2 \u03b7 \u2016 u \u2016 2 + \u2211 k = 1 m - ( \u03b8 \u03b2 - 1 ) log ( \u03b2 k ) + \u03c4 \u03b2 \u03b2 k - ( \u03b8 \u03b1 - 1 ) log ( \u03b1 k ) + \u03c4 \u03b1 \u03b1 k - log ( \u03b2 k ) + 1 2 \u03b2 k \u2016 w k - u \u2016 2 + \u2211 i = 1 n k - log ( \u03b1 k ) + 1 2 \u03b1 k y i k - w k \u22a4 x i k 2 Rearranging the terms in the above equation, we obtain Eq. (4). Appendix B Features used for constructing the predictive models See Table 1 . References [1] Iyad Batal Dmitriy Fradkin James Harrison Fabian Moerchen Milos Hauskrecht Mining recent temporal patterns for event detection in multivariate time series data Proceedings of the international conference on Knowledge discovery and data mining 2012 ACM 280 288 [2] Batal Iyad, Sacchi Lucia, Bellazzi Riccardo, Hauskrecht Milos. Multivariate time series classification with temporal abstractions. In: Proceedings of Florida Artificial intelligence research society conference; 2009. [3] Iyad Batal Hamed Valizadegan Gregory F. Cooper Milos Hauskrecht A pattern mining approach for classifying multivariate temporal data IEEE international conference on bioinformatics and biomedicine (BIBM) 2011 IEEE 358 365 [4] James C. Bezdek Richard J. Hathaway Some notes on alternating optimization Proceedings of the 2002 AFSS international conference on fuzzy systems Calcutta: advances in soft computing, AFSS \u201902 2002 Springer-Verlag London, UK, UK 288 300 [5] Christopher M. Bishop Pattern recognition and machine learning 2006 Springer [6] Stephen Boyd Lieven Vandenberghe Convex optimization 2004 Cambridge University Press New York, NY, USA [7] Carlo Combi Elpida Keravnou-Papailiou Yuval Shahar Temporal information systems in medicine 2010 Springer Publishing Company, Incorporated [8] A.P. Dawid A.M. Skene Maximum likelihood estimation of observer error-rates using the em algorithm Appl Stat 28 1 1979 20 28 [9] Theodoros Evgeniou Massimiliano Pontil Regularized multi-task learning Proceedings of the international conference on Knowledge discovery and data mining 2004 ACM New York, NY, USA 109 117 [10] Hauskrecht M, Fraser H. Modeling treatment of ischemic heart disease with partially observable markov decision processes. In: Proceedings of the AMIA annual symposium; 1998. p. 538\u201342. [11] Hauskrecht M, Valko M, Batal I, Clermont G, Visweswaran S, Cooper GF. Conditional outlier detection for clinical alerting. In: Proceedings of the AMIA annual symposium; 2010. p. 286\u2013890. [12] Milos Hauskrecht Iyad Batal Michal Valko Shyam Visweswaran Gregory F. Cooper Gilles Clermont Outlier detection for patient monitoring and alerting J Biomed Inform 46 1 2013 47 55 [13] Daphne Koller Nir Friedman Probabilistic graphical models: principles and techniques 2009 MIT Press [14] V.C. Raykar S. Yu L.H. Zhao G.H. Valadez C. Florin L. Bogoni Learning from crowds Journal of Machine Learning Research 11 2010 1297 1322 [15] Bernhard Scholkopf Alexander J. Smola Learning with kernels: support vector machines, regularization, optimization, and beyond 2001 MIT Press Cambridge, MA, USA [16] Bernhard Scholkopf Alexander J. Smola Learning with kernels: support vector machines, regularization, optimization, and beyond 2002 MIT Press Cambridge, MA, USA [17] Victor S. Sheng Foster Provost Panagiotis G. Ipeirotis Get another label? Improving data quality and data mining using multiple, noisy labelers Proceedings of the international conference on Knowledge discovery and data mining 2008 ACM 614 622 [18] Rion Snow Brendan O\u2019Connor Daniel Jurafsky Andrew Y. Ng Cheap and fast\u2014but is it good?: Evaluating non-expert annotations for natural language tasks Conference on Empirical Methods on Natural Language Processing 2008 Association for Computational Linguistics Stroudsburg, PA, USA 254 263 [19] Hamed Valizadegan Rong Jin Generalized maximum margin clustering and unsupervised kernel learning B. Sch\u00f6lkopf J. Platt T. Hoffman Advances in neural information processing systems vol. 19 2007 MIT Press Cambridge, MA 1417 1424 [20] Valko Michal, Hauskrecht Milos. Feature importance analysis for patient management decisions. In: Proceedings of the 13th international congress on medical informatics; 2010. p. 861\u20135. [21] Vladimir N. Vapnik The nature of statistical learning theory 1995 Springer-Verlag New York, Inc. New York, NY, USA [22] TE. Warkentin Heparin-induced thrombocytopenia: pathogenesis and management Br J Haematol 2003 535 555 [23] TE. Warkentin JI. Sheppard P. Horsewood Impact of the patient population on the risk for heparin-induced thrombocytopenia Blood 2000 1703 1708 [24] Welinder Peter, Branson Steve, Belongie Serge, Perona Pietro. The multidimensional wisdom of crowds. In: Advances in neural information processing systems; 2010, 2424\u20132432. [25] Whitehill Jacob, Ruvolo Paul, fan Wu Ting, Bergsma Jacob, Movellan Javier. Whose vote should count more: optimal integration of labels from labelers of unknown expertise. In: Advances in neural information processing systems; 2009. p. 2035\u201343. [26] Yan Yan, Fung Glenn, Dy Jennifer, Rosales Romer. Modeling annotator expertise: learning when everybody knows a bit of something. In: Proceedings of the international conference on Artificial Intelligence and Statistics; April 2010. [27] Zhang Yu, Yeung Dit-Yan. A convex formulation for learning task relationships in multi-task learning. In: Proceedings of the international conference on the Uncertainty in Artificial Intelligence; 2010.", "scopus-id": "84888198561", "pubmed-id": "24035760", "coredata": {"eid": "1-s2.0-S1532046413001226", "dc:description": "Abstract Building classification models from clinical data using machine learning methods often relies on labeling of patient examples by human experts. Standard machine learning framework assumes the labels are assigned by a homogeneous process. However, in reality the labels may come from multiple experts and it may be difficult to obtain a set of class labels everybody agrees on; it is not uncommon that different experts have different subjective opinions on how a specific patient example should be classified. In this work we propose and study a new multi-expert learning framework that assumes the class labels are provided by multiple experts and that these experts may differ in their class label assessments. The framework explicitly models different sources of disagreements and lets us naturally combine labels from different human experts to obtain: (1) a consensus classification model representing the model the group of experts converge to, as well as, and (2) individual expert models. We test the proposed framework by building a model for the problem of detection of the Heparin Induced Thrombocytopenia (HIT) where examples are labeled by three experts. We show that our framework is superior to multiple baselines (including standard machine learning framework in which expert differences are ignored) and that our framework leads to both improved consensus and individual expert models.", "openArchiveArticle": "true", "prism:coverDate": "2013-12-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046413001226", "dc:creator": [{"@_fa": "true", "$": "Valizadegan, Hamed"}, {"@_fa": "true", "$": "Nguyen, Quang"}, {"@_fa": "true", "$": "Hauskrecht, Milos"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046413001226"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046413001226"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(13)00122-6", "prism:volume": "46", "prism:publisher": "Elsevier Inc.", "dc:title": "Learning classification models from multiple experts", "prism:copyright": "Copyright \u00a9 2013 Elsevier Inc. All rights reserved.", "prism:issueName": "Special Section: Social Media Environments", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "6", "dcterms:subject": [{"@_fa": "true", "$": "Classification learning with multiple experts"}, {"@_fa": "true", "$": "Consensus models"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "6", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "1125-1135", "prism:endingPage": "1135", "prism:coverDisplayDate": "December 2013", "prism:doi": "10.1016/j.jbi.2013.08.007", "prism:startingPage": "1125", "dc:identifier": "doi:10.1016/j.jbi.2013.08.007", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "20", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "260", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "240", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1308", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "193", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1093", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "187", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1013", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "102", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "591", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "260", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "153", "@width": "425", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si38.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "4607", "@ref": "si38", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "96", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si37.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "500", "@ref": "si37", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "301", "@width": "296", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si36.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "6437", "@ref": "si36", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "277", "@width": "393", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si35.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "8967", "@ref": "si35", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "162", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si34.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "873", "@ref": "si34", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "293", "@width": "497", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si33.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "10708", "@ref": "si33", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "50", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si32.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "371", "@ref": "si32", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si31.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "249", "@ref": "si31", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si30.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "235", "@ref": "si30", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "249", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "46", "@width": "168", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si29.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1007", "@ref": "si29", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "48", "@width": "151", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si28.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1143", "@ref": "si28", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si27.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "235", "@ref": "si27", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si26.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "235", "@ref": "si26", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "327", "@width": "397", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si25.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "7202", "@ref": "si25", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "65", "@width": "171", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si24.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1222", "@ref": "si24", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "30", "@width": "191", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si23.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1139", "@ref": "si23", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si22.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "235", "@ref": "si22", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "148", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "858", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "158", "@width": "569", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "5975", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "128", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "773", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "158", "@width": "529", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "5586", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "30", "@width": "229", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "936", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "30", "@width": "234", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "911", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "52", "@width": "662", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3926", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "120", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "616", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "21", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "231", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "249", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "21", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "236", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "254", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "44", "@width": "169", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1641", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "111", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "620", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "1892", "@width": "2624", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr7_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "617281", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1884", "@width": "3369", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr6_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "810544", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1020", "@width": "2529", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "309781", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "728", "@width": "2382", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "195072", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "536", "@width": "1562", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "76045", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1307", "@width": "1597", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "163099", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "446", "@width": "1423", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "62585", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "886", "@width": "1450", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "185828", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "428", "@width": "593", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "82629", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "426", "@width": "761", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "99644", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "230", "@width": "571", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "37512", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "170", "@width": "556", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "31759", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "121", "@width": "353", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "16784", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "305", "@width": "373", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "32398", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "103", "@width": "329", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "13878", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "200", "@width": "327", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "30438", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "158", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8379", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "122", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6646", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "88", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4730", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "67", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3814", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "75", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3607", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "200", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5079", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "69", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2059", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "134", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413001226-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8004", "@ref": "fx1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84888198561"}}
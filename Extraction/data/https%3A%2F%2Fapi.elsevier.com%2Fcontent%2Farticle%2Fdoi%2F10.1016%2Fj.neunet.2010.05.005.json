{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608010000985", "dc:identifier": "doi:10.1016/j.neunet.2010.05.005", "eid": "1-s2.0-S0893608010000985", "prism:doi": "10.1016/j.neunet.2010.05.005", "pii": "S0893-6080(10)00098-5", "dc:title": "Feedback associative memory based on a new hybrid model of generalized regression and self-feedback neural networks ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "23", "prism:issueIdentifier": "7", "prism:startingPage": "892", "prism:endingPage": "904", "prism:pageRange": "892-904", "prism:number": "7", "dc:format": "application/json", "prism:coverDate": "2010-09-30", "prism:coverDisplayDate": "September 2010", "prism:copyright": "Copyright \u00a9 2010 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Amiri, Mahmood"}, {"@_fa": "true", "$": "Davande, Hamed"}, {"@_fa": "true", "$": "Sadeghian, Alireza"}, {"@_fa": "true", "$": "Chartier, Sylvain"}], "dc:description": "\n               Abstract\n               \n                  The focus of this paper is to propose a hybrid neural network model for associative recall of analog and digital patterns. This hybrid model consists of self-feedback neural network structures (SFNN) in parallel with generalized regression neural networks (GRNN). Using a new one-shot learning algorithm developed in the paper, pattern representations are first stored as the asymptotically stable fixed points of the SFNN. Then in the retrieving process, each pattern is applied to the GRNN to make the corresponding initial condition and to initiate the dynamical equations of the SFNN that should in turn output the corresponding representation. In this way, the corresponding stored patterns are retrieved even under high noise degradation. Moreover, contrary to many associative memories, the proposed hybrid model is without any spurious attractors and can store both binary and real-value patterns without any preprocessing. Several simulations confirm the theoretical analyses of the model. Results indicate that the performance of the hybrid model is better than that of recurrent associative memory and competitive with other classes of networks.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Associative memory"}, {"@_fa": "true", "$": "Self-feedback neural network"}, {"@_fa": "true", "$": "Generalized regression neural network"}, {"@_fa": "true", "$": "Pattern recognition"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608010000985", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608010000985", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "77955057320", "scopus-eid": "2-s2.0-77955057320", "pubmed-id": "20627454", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/77955057320", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20100531", "$": "2010-05-31"}}}}}
{"scopus-eid": "2-s2.0-84924495386", "originalText": "serial JL 272371 291210 291682 291870 291901 31 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2014-12-12 2014-12-12 2015-03-05T07:05:15 1-s2.0-S1532046414002676 S1532-0464(14)00267-6 S1532046414002676 10.1016/j.jbi.2014.11.015 S300 S300.1 FULL-TEXT 1-s2.0-S1532046415X00025 2016-01-31T20:18:00.510837-05:00 0 0 20150201 20150228 2015 2014-12-12T17:04:20.32136Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes grantsponsor highlightsabst primabst ref specialabst 1532-0464 15320464 true 53 53 C Volume 53 34 300 307 300 307 201502 February 2015 2015-02-01 2015-02-28 2015 Regular articles article fla Copyright \u00a9 2014 Elsevier Inc. KNOWLEDGEBASEDWORDCONCEPTMODELESTIMATIONREFINEMENTFORBIOMEDICALTEXTMINING JIMENOYEPES A 1 Introduction 2 Related work 3 Methods 3.1 Word-concept probability estimation 3.2 Using the model in disambiguation 3.3 Model adjustment 3.4 Model refinement 3.5 Using the proposed model in document ranking 3.6 Experimental setup 3.6.1 Biomedical knowledge base 3.6.2 Biomedical corpora 4 Results 4.1 Disambiguation performance 4.2 Document ranking 4.3 Discussion 5 Conclusion and future work Acknowledgments References AGIRRE 2010 2889 2896 E ALEXOPOULOU 2009 28 D ARONSON 2010 229 236 A ASHBURNER 2000 25 29 M BAHL 1983 179 190 L BLAIR 2014 e1003799 D BLEI 2003 993 1022 D BODENREIDER 2004 D267 D270 O CAMON 2004 D262 D266 E CAO 2005 298 305 G PROCEEDINGS28THANNUALINTERNATIONALACMSIGIRCONFERENCERESEARCHDEVELOPMENTININFORMATIONRETRIEVAL INTEGRATINGWORDRELATIONSHIPSLANGUAGEMODELS CHENG 2012 231 239 W PROCEEDINGS2012WORKSHOPBIOMEDICALNATURALLANGUAGEPROCESSING SCALINGUPWSDAUTOMATICALLYGENERATEDEXAMPLES COHEN 1995 P EMPIRICALMETHODSFORARTIFICIALINTELLIGENCE GALE 1992 233 237 W PROCEEDINGSWORKSHOPSPEECHNATURALLANGUAGE ONESENSEPERDISCOURSE HUMPHREY 2006 96 113 S JIMENOYEPES 2010 11:565 A JIMENOYEPES 2012 733 736 A PROCEEDINGS2NDACMSIGHITINTERNATIONALHEALTHINFORMATICSSYMPOSIUM KNOWLEDGEBASEDKNOWLEDGELEANMETHODSCOMBINEDINUNSUPERVISEDWORDSENSEDISAMBIGUATION JIMENOYEPES 2010 261 283 A JIMENOYEPES 2009 6 14 A PROCEEDINGSWSDM09WORKSHOPEXPLOITINGSEMANTICANNOTATIONSININFORMATIONRETRIEVAL TERMINOLOGICALCLEANSINGFORIMPROVEDINFORMATIONRETRIEVALBASEDONTOLOGICALTERMS JIMENOYEPES 2010 426 435 A JIMENOYEPES 2011 223 A LEACOCK 1998 147 165 C NAVIGLI 2005 1075 1086 R NEBOT 2014 365 389 V PESQUITA 2009 e1000443 C PLAZA 2011 355 L PORTER 1980 130 137 M REITER 2000 E BUILDINGNATURALLANGUAGEGENERATIONSYSTEMS SCHUEMIE 2005 554 565 M SINGH 2013 B SMITH 2007 1251 1255 B SPASIC 2005 239 251 I STEVENSON 2011 235 240 M TAO 2006 162 169 T PROCEEDINGS29THANNUALINTERNATIONALACMSIGIRCONFERENCERESEARCHDEVELOPMENTININFORMATIONRETRIEVAL REGULARIZEDESTIMATIONMIXTUREMODELSFORROBUSTPSEUDORELEVANCEFEEDBACK UEDA 1998 271 282 N WEEBER 2001 746 M PROCEEDINGSAMIASYMPOSIUM DEVELOPINGATESTCOLLECTIONFORBIOMEDICALWORDSENSEDISAMBIGUATION YAROWSKY 1993 266 271 D PROCEEDINGSWORKSHOPHUMANLANGUAGETECHNOLOGY ONESENSEPERCOLLOCATION ZHAI 2004 179 214 C ZHONG 2012 273 282 Z PROCEEDINGS50THANNUALMEETINGASSOCIATIONFORCOMPUTATIONALLINGUISTICSLONGPAPERS WORDSENSEDISAMBIGUATIONIMPROVESINFORMATIONRETRIEVAL JIMENOYEPESX2015X300 JIMENOYEPESX2015X300X307 JIMENOYEPESX2015X300XA JIMENOYEPESX2015X300X307XA Full 2016-02-01T00:20:52Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(14)00267-6 S1532046414002676 1-s2.0-S1532046414002676 10.1016/j.jbi.2014.11.015 272371 2015-03-05T03:49:34.179777-05:00 2015-02-01 2015-02-28 1-s2.0-S1532046414002676-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/MAIN/application/pdf/fb023f36bed9715606c6c9c033cd9b5e/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/MAIN/application/pdf/fb023f36bed9715606c6c9c033cd9b5e/main.pdf main.pdf pdf true 593188 MAIN 8 1-s2.0-S1532046414002676-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/PREVIEW/image/png/1e6a744102b68cee00b2a07436cbf6e0/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/PREVIEW/image/png/1e6a744102b68cee00b2a07436cbf6e0/main_1.png main_1.png png 56156 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046414002676-si72.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/6a22118f4769d5b9b3dd053ad1278865/si72.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/6a22118f4769d5b9b3dd053ad1278865/si72.gif si72 si72.gif gif 2021 42 329 ALTIMG 1-s2.0-S1532046414002676-si70.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2ff8d22a652e076195601c63af5fb881/si70.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2ff8d22a652e076195601c63af5fb881/si70.gif si70 si70.gif gif 1525 38 254 ALTIMG 1-s2.0-S1532046414002676-si67.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/4782dbc0d86dc5ac145f3039672f425c/si67.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/4782dbc0d86dc5ac145f3039672f425c/si67.gif si67 si67.gif gif 3088 58 340 ALTIMG 1-s2.0-S1532046414002676-si61.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/1d47fbc1453afa5e5ad6d6fcc0269315/si61.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/1d47fbc1453afa5e5ad6d6fcc0269315/si61.gif si61 si61.gif gif 1078 29 177 ALTIMG 1-s2.0-S1532046414002676-si59.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/be5bd877fb3865627ba96dd287b73883/si59.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/be5bd877fb3865627ba96dd287b73883/si59.gif si59 si59.gif gif 2037 46 337 ALTIMG 1-s2.0-S1532046414002676-si58.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/711cf78446438102b0bb66c80eba4161/si58.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/711cf78446438102b0bb66c80eba4161/si58.gif si58 si58.gif gif 1422 44 233 ALTIMG 1-s2.0-S1532046414002676-si57.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/cc68ff960d074921d2bebcf1e6b4c9bf/si57.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/cc68ff960d074921d2bebcf1e6b4c9bf/si57.gif si57 si57.gif gif 1337 18 281 ALTIMG 1-s2.0-S1532046414002676-si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/4c44f0801195763324015b12f0846961/si50.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/4c44f0801195763324015b12f0846961/si50.gif si50 si50.gif gif 1402 41 205 ALTIMG 1-s2.0-S1532046414002676-si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/b3aa64b83d9a88fd8debeccfc72b9bfd/si42.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/b3aa64b83d9a88fd8debeccfc72b9bfd/si42.gif si42 si42.gif gif 1489 39 227 ALTIMG 1-s2.0-S1532046414002676-si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/52a5d761bc7a5f7e9aa21f7837ea6491/si41.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/52a5d761bc7a5f7e9aa21f7837ea6491/si41.gif si41 si41.gif gif 1798 45 318 ALTIMG 1-s2.0-S1532046414002676-si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/3736ed294a6f305c7417aa11cbfbaa74/si40.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/3736ed294a6f305c7417aa11cbfbaa74/si40.gif si40 si40.gif gif 1233 45 206 ALTIMG 1-s2.0-S1532046414002676-si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/b1d3b01967d567e24a77e01906091c62/si39.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/b1d3b01967d567e24a77e01906091c62/si39.gif si39 si39.gif gif 1143 39 206 ALTIMG 1-s2.0-S1532046414002676-si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a425dd54e502c43f8dd15e40623f5485/si38.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a425dd54e502c43f8dd15e40623f5485/si38.gif si38 si38.gif gif 548 19 85 ALTIMG 1-s2.0-S1532046414002676-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/be5eb1712a215e1d0d19a3649b597885/si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/be5eb1712a215e1d0d19a3649b597885/si18.gif si18 si18.gif gif 1838 46 248 ALTIMG 1-s2.0-S1532046414002676-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/29eed1104525197aafef4c0e45b83887/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/29eed1104525197aafef4c0e45b83887/si13.gif si13 si13.gif gif 916 36 179 ALTIMG 1-s2.0-S1532046414002676-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/98c6a9c4ced4e3db4a1adb58614f0fb1/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/98c6a9c4ced4e3db4a1adb58614f0fb1/si12.gif si12 si12.gif gif 1205 35 190 ALTIMG 1-s2.0-S1532046414002676-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif si9 si9.gif gif 197 11 12 ALTIMG 1-s2.0-S1532046414002676-si82.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/18c85bc517d0d4be3205260064fa9d5c/si77.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/18c85bc517d0d4be3205260064fa9d5c/si77.gif si82 si82.gif gif 241 16 17 ALTIMG 1-s2.0-S1532046414002676-si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/7bb66d927bed88b49e8978b158ddd189/si81.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/7bb66d927bed88b49e8978b158ddd189/si81.gif si81 si81.gif gif 229 16 16 ALTIMG 1-s2.0-S1532046414002676-si80.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/88aa138f6088036210bf1e7ba16486f5/si75.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/88aa138f6088036210bf1e7ba16486f5/si75.gif si80 si80.gif gif 243 16 17 ALTIMG 1-s2.0-S1532046414002676-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif si8 si8.gif gif 239 14 18 ALTIMG 1-s2.0-S1532046414002676-si79.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif si79 si79.gif gif 211 16 11 ALTIMG 1-s2.0-S1532046414002676-si78.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/83c190918868037aed0fae355b180003/si78.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/83c190918868037aed0fae355b180003/si78.gif si78 si78.gif gif 367 17 40 ALTIMG 1-s2.0-S1532046414002676-si77.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/18c85bc517d0d4be3205260064fa9d5c/si77.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/18c85bc517d0d4be3205260064fa9d5c/si77.gif si77 si77.gif gif 241 16 17 ALTIMG 1-s2.0-S1532046414002676-si76.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/7bb66d927bed88b49e8978b158ddd189/si81.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/7bb66d927bed88b49e8978b158ddd189/si81.gif si76 si76.gif gif 229 16 16 ALTIMG 1-s2.0-S1532046414002676-si75.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/88aa138f6088036210bf1e7ba16486f5/si75.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/88aa138f6088036210bf1e7ba16486f5/si75.gif si75 si75.gif gif 243 16 17 ALTIMG 1-s2.0-S1532046414002676-si74.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2cdfc5726210b0ba4f3e181a62d0e838/si74.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2cdfc5726210b0ba4f3e181a62d0e838/si74.gif si74 si74.gif gif 263 17 26 ALTIMG 1-s2.0-S1532046414002676-si73.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/284d88456777375d3c6ac567f17ee086/si73.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/284d88456777375d3c6ac567f17ee086/si73.gif si73 si73.gif gif 285 17 27 ALTIMG 1-s2.0-S1532046414002676-si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/7b493365eeb4deca322168896f0163ac/si71.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/7b493365eeb4deca322168896f0163ac/si71.gif si71 si71.gif gif 183 13 10 ALTIMG 1-s2.0-S1532046414002676-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/234340657fd2a75cf7d926f28425036c/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/234340657fd2a75cf7d926f28425036c/si7.gif si7 si7.gif gif 444 18 55 ALTIMG 1-s2.0-S1532046414002676-si69.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/249ee7fae56e335484f644705fca669c/si69.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/249ee7fae56e335484f644705fca669c/si69.gif si69 si69.gif gif 438 17 55 ALTIMG 1-s2.0-S1532046414002676-si68.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/e246c68a474748a61488f422178f3c0f/si68.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/e246c68a474748a61488f422178f3c0f/si68.gif si68 si68.gif gif 410 17 51 ALTIMG 1-s2.0-S1532046414002676-si66.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif si66 si66.gif gif 211 16 11 ALTIMG 1-s2.0-S1532046414002676-si65.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2a94b4904d3db852ebe07e23c3f71bbd/si65.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2a94b4904d3db852ebe07e23c3f71bbd/si65.gif si65 si65.gif gif 195 10 11 ALTIMG 1-s2.0-S1532046414002676-si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/d65320a8fcda4164e0bc707d7635dc25/si64.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/d65320a8fcda4164e0bc707d7635dc25/si64.gif si64 si64.gif gif 199 13 9 ALTIMG 1-s2.0-S1532046414002676-si63.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif si63 si63.gif gif 211 16 11 ALTIMG 1-s2.0-S1532046414002676-si62.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif si62 si62.gif gif 211 16 11 ALTIMG 1-s2.0-S1532046414002676-si60.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/eb407eb826b99b40af652c68f8c35e9c/si60.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/eb407eb826b99b40af652c68f8c35e9c/si60.gif si60 si60.gif gif 338 16 49 ALTIMG 1-s2.0-S1532046414002676-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/25fe84cfbf5050af7697dbb48a0cad1c/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/25fe84cfbf5050af7697dbb48a0cad1c/si6.gif si6 si6.gif gif 344 17 46 ALTIMG 1-s2.0-S1532046414002676-si56.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/bf1fcbbd653592bd64dd667cb9b260c3/si56.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/bf1fcbbd653592bd64dd667cb9b260c3/si56.gif si56 si56.gif gif 264 17 24 ALTIMG 1-s2.0-S1532046414002676-si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/6332f9c2b6adfe7cc0538f71ec44aaf0/si55.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/6332f9c2b6adfe7cc0538f71ec44aaf0/si55.gif si55 si55.gif gif 242 17 19 ALTIMG 1-s2.0-S1532046414002676-si54.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a255cc655a34b9d25c4e98d1010de476/si54.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a255cc655a34b9d25c4e98d1010de476/si54.gif si54 si54.gif gif 511 19 63 ALTIMG 1-s2.0-S1532046414002676-si53.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/7b493365eeb4deca322168896f0163ac/si71.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/7b493365eeb4deca322168896f0163ac/si71.gif si53 si53.gif gif 183 13 10 ALTIMG 1-s2.0-S1532046414002676-si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/69a017fb0cc0350caeaa0b074b464a15/si52.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/69a017fb0cc0350caeaa0b074b464a15/si52.gif si52 si52.gif gif 379 17 63 ALTIMG 1-s2.0-S1532046414002676-si51.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/072259c7d1623a2b0cfcaf0800a64eb7/si63.gif si51 si51.gif gif 211 16 11 ALTIMG 1-s2.0-S1532046414002676-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/83c190918868037aed0fae355b180003/si78.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/83c190918868037aed0fae355b180003/si78.gif si5 si5.gif gif 367 17 40 ALTIMG 1-s2.0-S1532046414002676-si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/43da1a45b574b74aa9e5a670cd0b5c21/si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/43da1a45b574b74aa9e5a670cd0b5c21/si49.gif si49 si49.gif gif 197 11 12 ALTIMG 1-s2.0-S1532046414002676-si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/43da1a45b574b74aa9e5a670cd0b5c21/si49.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/43da1a45b574b74aa9e5a670cd0b5c21/si49.gif si48 si48.gif gif 197 11 12 ALTIMG 1-s2.0-S1532046414002676-si47.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/1ee2e5521be58f8143b36dff41bd6035/si47.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/1ee2e5521be58f8143b36dff41bd6035/si47.gif si47 si47.gif gif 232 12 25 ALTIMG 1-s2.0-S1532046414002676-si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/e45a91a99f96d4b4324f1cfbccb4f4bd/si46.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/e45a91a99f96d4b4324f1cfbccb4f4bd/si46.gif si46 si46.gif gif 206 11 15 ALTIMG 1-s2.0-S1532046414002676-si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/327f3eb8ff9455368b25dbce3507c769/si45.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/327f3eb8ff9455368b25dbce3507c769/si45.gif si45 si45.gif gif 195 11 14 ALTIMG 1-s2.0-S1532046414002676-si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/4e56758c0baa58e281f584eb3ed8c86a/si44.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/4e56758c0baa58e281f584eb3ed8c86a/si44.gif si44 si44.gif gif 380 17 56 ALTIMG 1-s2.0-S1532046414002676-si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/e113d3a53d96990d5518536cb62a2952/si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/e113d3a53d96990d5518536cb62a2952/si43.gif si43 si43.gif gif 430 17 64 ALTIMG 1-s2.0-S1532046414002676-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2feb0548b04cd421c43bbd841d7fbe48/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2feb0548b04cd421c43bbd841d7fbe48/si4.gif si4 si4.gif gif 280 13 38 ALTIMG 1-s2.0-S1532046414002676-si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/ed9a6ef6d0936f2869cfda64a035deb3/si37.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/ed9a6ef6d0936f2869cfda64a035deb3/si37.gif si37 si37.gif gif 489 18 65 ALTIMG 1-s2.0-S1532046414002676-si36.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2bae2d684a6961477f6387a56856a25a/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2bae2d684a6961477f6387a56856a25a/si36.gif si36 si36.gif gif 209 12 15 ALTIMG 1-s2.0-S1532046414002676-si35.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif si35 si35.gif gif 239 14 18 ALTIMG 1-s2.0-S1532046414002676-si34.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2bae2d684a6961477f6387a56856a25a/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2bae2d684a6961477f6387a56856a25a/si36.gif si34 si34.gif gif 209 12 15 ALTIMG 1-s2.0-S1532046414002676-si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif si33 si33.gif gif 212 11 15 ALTIMG 1-s2.0-S1532046414002676-si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif si32 si32.gif gif 212 11 15 ALTIMG 1-s2.0-S1532046414002676-si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif si31 si31.gif gif 239 14 18 ALTIMG 1-s2.0-S1532046414002676-si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a6818957c15268c21bf7a15601ee8117/si30.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a6818957c15268c21bf7a15601ee8117/si30.gif si30 si30.gif gif 491 18 65 ALTIMG 1-s2.0-S1532046414002676-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/253d965ba6e10904a32a7ddf2dc819ac/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/253d965ba6e10904a32a7ddf2dc819ac/si3.gif si3 si3.gif gif 195 13 11 ALTIMG 1-s2.0-S1532046414002676-si29.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif si29 si29.gif gif 212 11 15 ALTIMG 1-s2.0-S1532046414002676-si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/e113d3a53d96990d5518536cb62a2952/si43.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/e113d3a53d96990d5518536cb62a2952/si43.gif si28 si28.gif gif 430 17 64 ALTIMG 1-s2.0-S1532046414002676-si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif si27 si27.gif gif 212 11 15 ALTIMG 1-s2.0-S1532046414002676-si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c9b58f02eba6a609e6d23f0f35b39a8b/si26.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c9b58f02eba6a609e6d23f0f35b39a8b/si26.gif si26 si26.gif gif 383 17 43 ALTIMG 1-s2.0-S1532046414002676-si25.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif si25 si25.gif gif 212 11 15 ALTIMG 1-s2.0-S1532046414002676-si24.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif si24 si24.gif gif 239 14 18 ALTIMG 1-s2.0-S1532046414002676-si23.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2bae2d684a6961477f6387a56856a25a/si36.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2bae2d684a6961477f6387a56856a25a/si36.gif si23 si23.gif gif 209 12 15 ALTIMG 1-s2.0-S1532046414002676-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/a071e528b0a1720833b27c0150edee95/si25.gif si22 si22.gif gif 212 11 15 ALTIMG 1-s2.0-S1532046414002676-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif si21 si21.gif gif 197 11 12 ALTIMG 1-s2.0-S1532046414002676-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif si20 si20.gif gif 197 11 12 ALTIMG 1-s2.0-S1532046414002676-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/851b0eb8883c11995cc9355abe51d24d/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/851b0eb8883c11995cc9355abe51d24d/si2.gif si2 si2.gif gif 439 18 55 ALTIMG 1-s2.0-S1532046414002676-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif si19 si19.gif gif 239 14 18 ALTIMG 1-s2.0-S1532046414002676-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/8e2bbb3ae0b9ad99e6d147d1e4fd7664/si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/8e2bbb3ae0b9ad99e6d147d1e4fd7664/si17.gif si17 si17.gif gif 204 14 12 ALTIMG 1-s2.0-S1532046414002676-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif si16 si16.gif gif 239 14 18 ALTIMG 1-s2.0-S1532046414002676-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif si15 si15.gif gif 197 11 12 ALTIMG 1-s2.0-S1532046414002676-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/c00a68ece0832c8fc8438f4e12ac695d/si31.gif si14 si14.gif gif 239 14 18 ALTIMG 1-s2.0-S1532046414002676-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/2d1facdc273b1f33e722d6ff2e9d4886/si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/2d1facdc273b1f33e722d6ff2e9d4886/si11.gif si11 si11.gif gif 230 24 12 ALTIMG 1-s2.0-S1532046414002676-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/b77987d5159887292b04993d4d38f699/si10.gif si10 si10.gif gif 197 11 12 ALTIMG 1-s2.0-S1532046414002676-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/STRIPIN/image/gif/851b0eb8883c11995cc9355abe51d24d/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/STRIPIN/image/gif/851b0eb8883c11995cc9355abe51d24d/si2.gif si1 si1.gif gif 439 18 55 ALTIMG 1-s2.0-S1532046414002676-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/gr1/HIGHRES/image/jpeg/7c28334f807cb09fe6dfe77bcf36908f/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/gr1/HIGHRES/image/jpeg/7c28334f807cb09fe6dfe77bcf36908f/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 130758 843 1902 IMAGE-HIGH-RES 1-s2.0-S1532046414002676-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/fx1/HIGHRES/image/jpeg/458013869fe675b6ea2ee3b0d659bc27/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/fx1/HIGHRES/image/jpeg/458013869fe675b6ea2ee3b0d659bc27/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 118658 886 1379 IMAGE-HIGH-RES 1-s2.0-S1532046414002676-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/gr2/HIGHRES/image/jpeg/91faf0358477b05ab7ecec0e06dd2db0/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/gr2/HIGHRES/image/jpeg/91faf0358477b05ab7ecec0e06dd2db0/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 174345 1044 1902 IMAGE-HIGH-RES 1-s2.0-S1532046414002676-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/gr1/DOWNSAMPLED/image/jpeg/2f85346457801751246259e5b14066b0/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/gr1/DOWNSAMPLED/image/jpeg/2f85346457801751246259e5b14066b0/gr1.jpg gr1 gr1.jpg jpg 29414 207 467 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414002676-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/fx1/DOWNSAMPLED/image/jpeg/e404b141cca275e4ff88fee9dc659376/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/fx1/DOWNSAMPLED/image/jpeg/e404b141cca275e4ff88fee9dc659376/fx1.jpg fx1 true fx1.jpg jpg 24236 200 311 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414002676-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/gr2/DOWNSAMPLED/image/jpeg/72d448d765dd6a4dbe14661db18aa5df/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/gr2/DOWNSAMPLED/image/jpeg/72d448d765dd6a4dbe14661db18aa5df/gr2.jpg gr2 gr2.jpg jpg 38662 256 467 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414002676-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/gr1/THUMBNAIL/image/gif/205c0825302f57d8162409901f153ef9/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/gr1/THUMBNAIL/image/gif/205c0825302f57d8162409901f153ef9/gr1.sml gr1 gr1.sml sml 3208 97 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414002676-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/fx1/THUMBNAIL/image/gif/9c91b37ccb3cdf85e12cfcc7b9d6b3f8/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/fx1/THUMBNAIL/image/gif/9c91b37ccb3cdf85e12cfcc7b9d6b3f8/fx1.sml fx1 true fx1.sml sml 5161 141 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414002676-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414002676/gr2/THUMBNAIL/image/gif/68e1542224b7ae6113d90a0256f6ebd0/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414002676/gr2/THUMBNAIL/image/gif/68e1542224b7ae6113d90a0256f6ebd0/gr2.sml gr2 gr2.sml sml 4328 120 219 IMAGE-THUMBNAIL YJBIN 2263 S1532-0464(14)00267-6 10.1016/j.jbi.2014.11.015 Elsevier Inc. Fig. 1 Simplified version of how the UMLS concept C0009264 (cold temperature) is considered by the model in a 1-step model. Fig. 2 Simplified version of how the UMLS concept C0009264 (cold temperature) is considered by the model in a 1-step model after an example refinement. Table 1 Probabilities for words (stemmed using Porter stemmer (stemmed form ended with \u2217)) related to UMLS concepts C0009264 (cold temperature), C0024117 (chronic obstructive airway disease) and C0009443 (common cold) ( P ( w i | c j ) ) related to the term cold after tuning the model. CUI:C0009264 CUI:C0024117 CUI:C0009443 Word Probability Word Probability Word Probability cold 0.364455 chronic 0.154269 cold 0.162294 temperatur\u2217 0.296702 obstruct\u2217 0.153241 common 0.135191 low 0.035278 diseas\u2217 0.132414 acut\u2217 0.101557 frostbit\u2217 0.004125 pulmonari\u2217 0.069153 coryza 0.064442 refriger\u2217 0.004123 copd 0.056498 nasopharyng\u2217 0.056429 cryoscienc\u2217 0.004120 lung 0.051505 rhiniti\u2217 0.038304 shiver 0.004111 airwai\u2217 0.025152 infect\u2217 0.036675 hypothermia 0.003935 di\u2217 0.019244 respiratori\u2217 0.014978 freez\u2217 0.002973 no 0.010173 diseas\u2217 0.012207 cryosurgeri\u2217 0.002852 pulm\u2217 0.009851 viral 0.012051 Table 2 Probabilities for words (stemmed using Porter stemmer (stemmed form ended with \u2217)) related to concepts C0009264 (cold temperature), C0024117 (chronic obstructive airway disease) and C0009443 (common cold) ( P ( w i | c j ) ) related to the term cold after tuning the refined model. CUI:C0009264 CUI:C0024117 CUI:C0009443 Word Probability Word Probability Word Probability cold 0.511172 chronic 0.191317 cold 0.479154 temperatur\u2217 0.172350 obstruct\u2217 0.190142 common 0.274660 low 0.149683 diseas\u2217 0.189146 acut\u2217 0.017842 exposur\u2217 0.000891 pulmonari\u2217 0.138241 coryza 0.015999 studi\u2217 0.000613 lung 0.048191 nasopharyng\u2217 0.009669 gene 0.000605 copd 0.045529 infect\u2217 0.007214 activ\u2217 0.000592 cold 0.023634 rhiniti\u2217 0.006479 stress 0.000568 airwai\u2217 0.004760 respiratori\u2217 0.003581 protein 0.000563 patient\u2217 0.003714 upper 0.003322 rat 0.000475 di\u2217 0.002211 viral 0.003287 Table 3 Disambiguation results on the MSH WSD data set. Baseline WSD methods results are shown with the reference to the article reporting the result. Method Accuracy MRD [26] 0.807 2-MRD [26] 0.780 AEC [26] 0.838 SSI [38] 0.743 SSI+IC [38] 0.860 PageRank [16] 0.786 MRD+KMeans [22] 0.874 AEC+KMeans [22] 0.865 CPIDF [21] 0.877 Na\u00efve Bayes [26] 0.930 0-step model 0.829 2-step model 0.863 Refined model 0.891 Table 4 Document ranking results in terms of mean average precision (MAP), precision @ 10 (P@10) and the number of Relevant Retrieved (Rretr). Method MAP P@10 Rretr pr.simple_kl_dir 0.2944 0.6146 7339 pr.mixfb_kl_dir 0.2985 0.6366 7435 kl_divergence 0.2955 0.5866 7399 kl_feedback [42] 0.3055 0.5902 7776 SVM 0.3544 0.6537 8317 2-step model 0.3025 0.6341 7372 Refined model 0.3176 0.6463 7799 Knowledge based word-concept model estimation and refinement for biomedical text mining Antonio Jimeno Yepes a \u204e antonio.jimeno@gmail.com Rafael Berlanga b a Department of Computing and Information Systems, The University of Melbourne, VIC 3010, Australia Department of Computing and Information Systems The University of Melbourne VIC 3010 Australia b Departamento de Lenguages y Sistemas Inform\u00e1ticos, Universitat Jaume I, Castell\u00f3n de la Plana, 12071, Spain Departamento de Lenguages y Sistemas Inform\u00e1ticos Universitat Jaume I Castell\u00f3n de la Plana 12071 Spain \u204e Corresponding author. Graphical abstract Highlights \u2022 We describe a method to generate word-concept statistical models from a knowledge base \u2022 This method integrates knowledge base descriptions and corpora information \u2022 Word sense disambiguation with this method is better than state-of-the-art approaches \u2022 Ranking of citation with the model improves the performance of baseline approaches Abstract Text mining of scientific literature has been essential for setting up large public biomedical databases, which are being widely used by the research community. In the biomedical domain, the existence of a large number of terminological resources and knowledge bases (KB) has enabled a myriad of machine learning methods for different text mining related tasks. Unfortunately, KBs have not been devised for text mining tasks but for human interpretation, thus performance of KB-based methods is usually lower when compared to supervised machine learning methods. The disadvantage of supervised methods though is they require labeled training data and therefore not useful for large scale biomedical text mining systems. KB-based methods do not have this limitation. In this paper, we describe a novel method to generate word-concept probabilities from a KB, which can serve as a basis for several text mining tasks. This method not only takes into account the underlying patterns within the descriptions contained in the KB but also those in texts available from large unlabeled corpora such as MEDLINE. The parameters of the model have been estimated without training data. Patterns from MEDLINE have been built using MetaMap for entity recognition and related using co-occurrences. The word-concept probabilities were evaluated on the task of word sense disambiguation (WSD). The results showed that our method obtained a higher degree of accuracy than other state-of-the-art approaches when evaluated on the MSH WSD data set. We also evaluated our method on the task of document ranking using MEDLINE citations. These results also showed an increase in performance over existing baseline retrieval approaches. Keywords Word-concept probability Text mining Word sense disambiguation Information retrieval Biomedical literature 1 Introduction Text mining of biomedical literature has supported the development of biomedical knowledge bases (KB), which are actively used by the research community [23]. These databases have contributed as well in the development of methods to perform text mining related tasks like entity recognition and relation extraction. There are a large number of KBs available for biomedical text mining purposes. Some of these resources are integrated into the Unified Medical Language System\u00ae (UMLS\u00ae) [12] and many resources are available from the Open Biological and Biomedical Ontologies (OBO) foundry [39]. 1 OBO foundry: http://www.obofoundry.org. 1 Unfortunately, since these resources were not developed to perform text mining tasks, knowledge based methods usually exhibit lower performance compared to ad hoc supervised methods (e.g., supervised classifiers) [20]. Despite this limitation, knowledge based approaches become crucial when either there is a scarcity of labeled data to train supervised methods. Due to the heterogeneity and large scale of biomedical resources, knowledge based methods are becoming more popular. Estimating word-concept probabilities from KBs provides an effective way to support a large range of text mining tasks in the biomedical domain [40]. Unlike supervised methods, the absence of manually labeled data can be alleviated by defining statistical approximations from either the existing data in the KBs (e.g., names, relations and descriptions) or external data such as MEDLINE\u00ae abstracts [20]. Other approaches are aimed at building statistical models directly from corpora, like Latent Dirichlet Allocation (LDA) [11], but it is not clear how to interpret or integrate these models within the KB structures [15]. Word sense disambiguation (WSD) and information retrieval (IR) are two tasks that benefit from word-concept probability models. Given an ambiguous word with its context, WSD attempts to select the proper sense given a set of candidate senses. An example of ambiguity is the word cold which could either refer to low temperature or the viral infection. The context in which cold appears is used to disambiguate it. WSD is an intermediate task that supports other tasks such as: information extraction [5], information retrieval and summarization [33]. WSD in the biomedical domain is mostly based on either supervised learning or knowledge based approaches [37]. As previously mentioned, the scarcity of training data makes knowledge based methods preferable to supervised ones. In IR, KB based methods have been proposed for either expanding queries or for performing semantic searches [14,25]. However, these methods do not provide a proper way to combine the expanded words, and just use the KB for defining improved IR queries as we have shown in [25]. This work proposes a novel method for generating word-concept statistical models from KBs that can be used directly for both IR and WSD. As mentioned earlier, this method is also able to take advantage of existing data in MEDLINE to produce a model with improved performance. These models can be integrated into IR language models to resolve ambiguity. An implementation of the presented method is available from https://bitbucket.org/ajjimeno/wkpropability. 2 Related work In the biomedical domain, there have been several big projects and initiatives to build comprehensive knowledge resources such as OBO and UMLS. At the same time, during the last decade researchers have devised automatic text mining techniques to find new knowledge from the scientific literature [9]. In this paper, we are interested in developing a general purpose probabilistic model that can be used in several text mining tasks, such as WSD and document ranking. WSD methods are based on supervised learning or KB-based approaches [37]. Supervised methods are trained on examples for each one of the senses of an ambiguous word. A trained model is used to disambiguate previously unseen examples. This approach requires a large set of training examples, which is usually not available. For example, the 2009AB version of the UMLS contains approximately 24 thousand ambiguous words, based on the exact match of the words in the UMLS Metathesaurus. Preparing such training examples would be very expensive to build and maintain [44]. In the biomedical domain, KB-based methods for WSD either build a concept profile [29,28,20], develop a graph-based model [2,3] or rely on the semantic types assigned to each concept for disambiguation [19]. These derived models are compared to the context of the ambiguous word being disambiguated to select the most likely sense. In these approaches, candidate senses of the ambiguous word are UMLS concepts. KB-based methods have been complemented with information available from existing resources like MEDLINE. An example is the use of MeSH indexing\u00ae 2 NLM\u2019s controlled vocabulary used to index MEDLINE: https://www.nlm.nih.gov/mesh. 2 as additional information [41]; although this approach is dependent on the availability of MeSH indexing. In previous work, we collected training data from MEDLINE citations for each sense of an ambiguous word [20]. PubMed queries used to retrieve these citations were generated using English monosemous relations [27] of the candidate concepts which, potentially, have an unambiguous use in MEDLINE. This approach has shown good performance compared to other KB-based methods. In a subsequent study, we extended the work in [20] by considering all of MEDLINE instead of the top 100 recovered citations by PubMed and by generating concept profiles that can be easily estimated on large number of examples [21]. Using a large number of examples showed an improvement over previous methods. Semi-supervised algorithms could be used to obtain additional examples of contexts for ambiguous words. We explored this in [22], where the initial disambiguation predictions provided by an unsupervised method were used as a seed to identify better concept profiles. This method showed a significant improvement. There are several approaches in WSD that utilize the graph structure of the resources [30,1], e.g., by applying adaptations of the page rank algorithm. Unfortunately, these methods cannot be re-used for other tasks like IR, because the generated models are only able to rank senses for given contexts, and not documents for given concepts. Conversely, approaches for IR that take into account the KB (e.g., [25]) are aimed at generating IR queries but not statistical models for other purposes. In this paper, we claim that the generation of statistical models from both the KB and existing external corpora can provide a very valuable resource for effectively performing various text mining tasks. Furthermore, we show that the presented model generates word-concept probabilities that produce good results on these tasks. 3 Methods In this section, we present the word-concept statistical model. The estimation of the model based on the knowledge base is presented in Section 3.1. The model estimates weights to combine probabilities from concepts at different traversal steps. In this work, the model is adjusted using it for disambiguation, which is introduced in Section 3.2. The adjustment is based on Expectation\u2013Maximization as explained in Section 3.3. Once the model is trained, it can be refined based on existing corpora in an unsupervised way as explained in Section 3.4. The word-concept probabilities obtained from this model can be used in other tasks such as IR as explained in Section 3.5. Lastly, experimental set up and data sets used in this work are presented in Section 3.6. In this work, a KB is defined as an inventory of concepts C , where each concept c \u2208 C is associated to a list of lexical forms lex ( c ) (i.e., strings of text that are synonyms, variants, and so on), and a set of relations to other concepts, denoted with r ( c , c \u2032 ) . These relations can be of any kind, from taxonomic is-a relations to other specific biomedical domain relationships (e.g., treats). Resources like the UMLS Metathesaurus fit this KB definition (see Section 3.6). Strings of text consist of tokens, that are their model primitives. Tokens may be punctuation or words, which are the minimal semantic tokens in the text. Terms are words or multi-word expressions denoting a concept (e.g., the synonyms and lexical variants linked to concepts in the UMLS). 3.1 Word-concept probability estimation We propose estimating the probability P ( w j | c i ) by selecting a word w j given a concept c i in a KB. This is done by selecting a word from the concept c i , step 0, or from any of the related concepts at any specific step k while traversing the KB relations. The method described below provides a way to estimate this probability at different traversal steps. The models obtained at different steps are combined using a linear combination. The weights of the linear combination are defined in the vector \u03b2 \u2192 (from Eq. (2)), whose dimension is the number of traversal steps as shown in Eq. (1). (1) P ( w j | c i ) = \u2211 k = 0 \u2026 l \u03b2 k P k ( w j | c i ) (2) \u03b2 0 \u2026 \u03b2 l > 0 , \u2211 k = 0 \u2026 l \u03b2 k = 1 At step 0, the probability of a word w j given a concept of interest c i is given in Eq. (3). The equation considers the relative frequency of the word in the context of the lexical forms of the concept. The function count returns the number of times the word w j is linked to concept c j by any of the synonyms associated to the concept. (3) P 0 ( w j | c i ) = count ( w j , c i ) \u2211 w j \u2208 lex ( c i ) count ( w j , c i ) When estimating the probability for a step k larger than 0, the probability of the word w j for the concept c i is derived from Eq. (4)\u2013(8), considering all the concepts at k steps from c i . The concept of interest is at step 0 and referred as c 0 . The final concept of a path is denoted as c k . The probabilities are summed for all possible paths with length k linking word w j and concept c 0 . In these equations, R k ( c 0 ) returns the concepts reached after k steps from concept c 0 . P ( c l + 1 | c l ) is the traversal probability estimated using Eq. (9). The concepts in the paths of length k can be obtained by traversing the KB relations using breadth-first search starting at concept c 0 . Eq. (8), shows how to estimate the probability P k ( w j | c 0 ) for word w j and concepts at step k from c 0 . The final equation depends on traversal probabilities from c 0 to concept at step k ( c k ) and the conditional probability of the word w j with the concept c k ( P 0 ( w j | c k ) ), which can be estimated as shown in Eq. (3). (4) P k ( w j | c 0 ) = (5) \u2211 c k \u2208 R k ( c 0 ) P k ( w j , c k , \u2026 , c 1 | c 0 ) = (6) \u2211 c k \u2208 R k ( c 0 ) P k ( w j , c k , \u2026 , c 0 ) P ( c 0 ) = (7) \u2211 c k \u2208 R k ( c 0 ) P 0 ( w j | c k ) \u220f l = 0 \u2026 k - 1 P ( c l + 1 | c l ) P ( c 0 ) P ( c 0 ) = (8) \u2211 c k \u2208 R k ( c 0 ) P 0 ( w j | c k ) \u220f l = 0 \u2026 k - 1 P ( c l + 1 | c l ) When estimating P ( c l + 1 | c l ) , as shown below, the function r ( c 1 , c 2 ) returns the relations in which concepts c 1 and c 2 are related in the knowledge base. The numerator is the count of relations in which concepts c l + 1 and c l are related. The denominator is the count of relations in which concept c l is in. (9) P ( c l + 1 | c l ) = | r ( c l + 1 , c l ) \u2208 KB | | r ( \u00b7 , c l ) \u2208 KB | We have set the initial \u03b2 weights to \u03b2 i = 1 / n where n is the number of steps considered. Log probabilities are used to obtain better accuracy in the probability estimation, which is not shown here for simplicity but it is available from the source code in bitbucket. Fig. 1 shows a simplified version of how the UMLS concept C0009264 (cold temperature) is considered by the model in a 1-step model. The terms linked to the concept are decomposed into words and counts for the stemmed words (that appear ended with the \u2217 character) can be estimated in relation to the concept. In this case, the count for the stem temperatur \u2217 is 2, the count for low and cold is 1 respectively. Fig. 1 shows as well the related concept C0016736 (frostbite). Frequency of the related concept is used to estimate the relation probability. The final model is smoothed based on Jelinek\u2013Mercer smoothing [7] as shown in Eq. (10), where \u03bb has been set to 0.75 based on previous work by Zhai and Lafferty [46]. The background of each word P ( w j | KB ) has been estimated over the KB occurrences by applying an add-one smoothing as shown in Eq. (11). | N | is the count of unique words in the KB, while | w i | is the count of the ith word in the KB. (10) P ( w j | c i ) = ( 1 - \u03bb ) P ( w j | c i ) + \u03bb P ( w j | KB ) (11) P ( w i | KB ) = \u03b1 + | w i | \u03b1 \u00b7 | N | + \u2211 j = 1 \u2026 N | w j | 3.2 Using the model in disambiguation Disambiguation consists of selecting the sense that best fits the context D of an ambiguous word. The context typically consists of the set of words surrounding the ambiguous word. In this work, the context is the MEDLINE abstract containing the ambiguous word. Disambiguation is performed similarly to Na\u00efve Bayes classification, using the following equation, which assumes the independence of words. (12) P ( c j | D ) = P ( D | c j ) P ( c j ) P ( D ) \u221d P ( D | c j ) = \u220f w i \u2208 D P ( w i | c j ) A candidate concept for an ambiguous word is selected according to maximum a posteriori (MAP) of the above expression given the context D of an ambiguous word w and the candidate concepts C w \u2286 C . (13) c \u2217 ( w ) = arg max c \u2208 C w P ( D | c ) 3.3 Model adjustment In order to establish the \u03b2 parameters of the traversals, we apply an Expectation\u2013Maximization (EM) method over the set of contexts, D, where ambiguous words occur. This set of documents can be taken from either the KB (e.g., concept descriptions or definitions) or from an external corpus (e.g., MEDLINE abstracts). In any case, the algorithm does not know a priori the right concept associated to each context, so the method is fully unsupervised. In the implementation presented in this work, during the expectation step, the concept with the highest probability is assigned to each context D using Eq. (13), introduced in the previous section. During the maximization step, we use the concept assignment to estimate the \u03b2 weights. A regularization parameter based on an estimated \u03b8 prior (probability of selecting a word from a given step) is used to avoid overfitting. The weight associated to this prior ( \u03b1 ) is set to 0.3. More complex regularization methods could be applied [43], but their evaluation is beyond the scope of this paper. A modified version of the log-likelihood including the prior of each \u03b2 parameter is used. After each iteration t, the log probability of the model is estimated, and the EM method stops when the log probability is not smaller than the previous iteration\u2019s log probability. The estimation of parameters at each iteration is defined in Eq. (14). \u03b4 is set to 1 when the ambiguous word w has been disambiguated with concept c in context d. (14) \u03b2 i t + 1 = \u2211 d \u2211 w \u03b2 i t P i ( w | c ) \u03b4 ( c , d ) + \u03b1 P \u03b8 i t ( w ) \u2211 d \u2211 w \u2211 j \u03b2 j t P j ( w | c ) \u03b4 ( c , d ) + \u03b1 P \u03b8 j t ( w ) 3.4 Model refinement As previously mentioned, the initial word-concept model is estimated from the KB data only. We propose exploiting the information available in an external corpora relying on two heuristics. The first heuristic is one sense per discourse [18], namely: all the occurrences of an ambiguous word in a document refer to the same sense. The second heuristic is one sense per collocation [45]. The idea is to identify the terms that tend to happen with each possible sense of the ambiguous word. We propose refining the estimates iteratively using statistics from the target corpus, which is done in two steps. In the first step, the corpus is annotated with KB concepts, resolving the ambiguities with the word-concept model of the current iteration. In the second step, a new word-concept model is obtained based on the KB statistics and the annotated corpus statistics. The word-concept count in Eq. (3) also considers counts from the KB and the annotated corpus. The counts from the corpus indicate which terms tend to be used in the same context as the concept. This is different to the approach used in [24,25], where terms were removed from the resource. The concept-concept count in Eq. (9) also considers counts from the KB and the corpus. In contrast to previous work, this allows adding information by assigning a weight to the relations. In the current implementation, the concept-concept counts are based on co-occurrences of concepts at sentence level, even though higher precision information extraction methods can be considered (e.g., syntactic dependencies and relation extraction [31]). The two steps are repeated until the Log Likelihood derived from Eq. (1) does not increase. Fig. 2 shows a simplified version of the state of the UMLS concept C0009264 (cold temperature) in a 1-step model after a refinement. In contrast to the example in Fig. 1, the term low temperature appears more frequently in the corpus in comparison to cold temperature. In this case, the count for the word temperatur \u2217 is 20, the count for low is 18 and the count for cold is 2. Similarly, frequencies are updated for the other concepts. Fig. 2 shows as well the related concept C0016736 (frostbite) and the newly related concept C0016736 (cold exposure). Frequencies to the related concepts are updated according to the refinement method. In this example, just one occurrence with concept C0016736 was found in the corpus, which is added with the mention from the KB, so its (e.g., MEDLINE abstracts) new frequency is 2. No relation to concept C0016736 (cold exposure) appeared in the KB but this concept was found to appear 15 times with the concept C0009264, thus the frequency is 15. 3.5 Using the proposed model in document ranking In addition to disambiguation, we propose using the model in document ranking. The ranking of the documents D for a given concept c can be derived from cross-entropy (CE) [25] between the word-concept P ( w i | c ) and word-document P ( w i | D ) models as follows: (15) CE ( c , D ) = \u2211 w i \u2208 D P ( w i | c ) \u00b7 log P ( w i | D ) Word-document probability can be estimated as shown in Eq. (16), which combines the maximum likelihood estimation (MLE) with a background probability G using Jelinek\u2013Mercer smoothing. As before, \u03bb is initially set to 0.75. (16) P ( w i | D ) = ( 1 - \u03bb ) count ( w i ) \u2211 w \u2208 D count ( w ) + \u03bb P ( w i | G ) 3.6 Experimental setup 3.6.1 Biomedical knowledge base The biomedical KB used in our experiments is the UMLS. The UMLS is a compendium of a large number of biomedical terminologies and ontologies, and is the largest biomedical terminological resource. We used the 2012 UMLS version AA with the default installation. We estimated the model using two UMLS Metathesaurus tables available in Rich Release Format (RRF). The MRCONSO table was used to estimate the word-concept probabilities in Eq. (9). The terms linked to the concepts are lowercased, tokenized into individual words, stemmed with the Porter stemmer [34] and filtered using a standard stop word list. 3 Stopword list from the SMART system: ftp://ftp.cs.cornell.edu/pub/smart. 3 The MRREL table was used to calculate the traversal probabilities in Eq. (9). Since synonym information is already obtained from MRCONSO and it is not clear how to interpret a synonym relation in MRREL, this information from MRREL is ignored. More details about these tables can be found from the UMLS web site. 4 UMLS site: http://www.nlm.nih.gov/research/umls. 4 3.6.2 Biomedical corpora We used two data sets, one for model refinement and disambiguation evaluation, and another one for evaluating the retrieval performance. Both sets are derived from MEDLINE. The first set is the WSD corpus called MSH (MeSH) WSD [26]. 5 MSH WSD: http://wsd.nlm.nih.gov/collaboration.shtml. 5 This corpus has been generated using MeSH indexing of MEDLINE to determine the correct UMLS concept assigned to an ambiguous word. Using MeSH as reference allows us to automatically build a a large disambiguation corpora which is typically a time intensive processAlthough, the corpus is limited to MeSH headings that can be mapped to UMLS concepts, it contains a more comprehensive set of possible ambiguities than other biomedical WSD corpora (e.g., [44]). MSH WSD contains 203 ambiguous terms, with an average of 2.3 senses per term and a maximum of 100 examples per sense. The context of the ambiguous word is composed of the words in the citation in which the ambiguous word appears. As in the processing of the MRCONSO file, the text is lowercased, tokenized, processed with the Porter stemmer and filtered using the same stopword list. The ranking set is based on a corpus developed for the evaluation and comparison of algorithms for MeSH indexing. 6 http://ii.nlm.nih.gov/DataSets/index.shtml#2013_MTI_ML. 6 Citations belong to a subset from the 2013 MEDLINE and have been split into 2 / 3 (94,942 citations) for training and 1 / 3 (48,911 citations) for testing purposes. MEDLINE is indexed manually using terms from the MeSH controlled vocabulary, thus this indexing was used to build the retrieval data set. As in the disambiguation task, the text is lowercased, tokenized, processed with the Porter stemmer and filtered using the same stopword list. For retrieval evaluation, we have reused the ambiguous terms from the MSH data set as queries, since they can be mapped to MeSH terms. Then, we selected the ones with at least 100 citations in the training set, determined by the MeSH indexing. This totaled 82 terms used as queries. 4 Results The generated model and its refinement based on the UMLS as KB and a corpus derived from MEDLINE for the refinement have been evaluated in the ranking and disambiguation tasks. We determine statistical significance with a randomization version of the two sample t-test [17], which avoids making assumptions on the distribution of the data and allows for a better estimation of significance between the difference of the methods performance. As mentioned before, we have limited the model to 2-step paths due to computation time and memory requirements. After estimating the beta values for the probabilities in each step k using the EM method, we obtained the beta values: \u03b2 0 =0.6654, \u03b2 1 =0.0678, \u03b2 2 =0.2668. That is, the 0-step model (i.e., considering only words in lex ( c ) ) holds the highest weight, followed by the 2-step model. The estimation of the model, which includes the traversal of the KB, took around 2h on an Intel Xeon @ 2.40GHz with 5GB of RAM. The target corpus was processed with MetaMap [5] to map spans of text to UMLS Metathesaurus concepts. No disambiguation provided by MetaMap has been used (default option) so all possible concepts identified by MetaMap are available for model refinement. This is because the disambiguation has to be done by the proposed model that will provide different disambiguation results at each iteration. Candidate senses for ambiguous mappings are based on the result of the EM algorithm. Once the EM algorithm has converged, the most likely concept for each ambiguous word is selected. Once the MetaMap annotations are disambiguated, it is possible to identify which words tend to be used to denote a concept and which concepts are related to each other in the corpus used for refinement. Then, the statistics on term to concept and concept to concept relations are calculated and the EM algorithm is run with these models. The counts in Eqs. (3) and (9) are updated adding these frequencies. After the refinement of the word-concept model with the target corpus, we obtained a new set of \u03b2 values: \u03b2 0 =0.8315, \u03b2 1 =0.0711, \u03b2 2 =0.0975. In this case, much more weight is given to the 0-step model. This is because the refinement produces profiles that are considerably larger since more words are linked to the concepts derived from the new relations obtained from co-occurrences found in the corpus. The refinement process took approximately 1day on an Intel Xeon @ 2.40GHz with 5GB of RAM. Tables 1 and 2 show the probabilities of words for concepts linked to the ambiguous word cold. These concepts are C0009264 (cold temperature), C0024117 (chronic obstructive airway disease) and C0009443 (common cold). Table 1 shows the top words ranked by decreasing probability estimated from the KB for each concept. The top words typically come from synonyms of the concepts followed by words from related concepts. In Table 2 probabilities are higher for words linked to common uses of each of the senses of cold. For concept C0009443 (common cold), words associated with the preferred term, common cold, have a higher probability of occurring with the concept than terms acute coryza and acute nasopharyngitis due to their lower occurrence in the corpus. For concept C0009264, we find that even though the top words are the same, the remaining words change, accommodating the words from concepts that tend to co-occur with C0009264. The removed words like frosbite come from related concepts in the KB. These words do not seem to appear in the context of this concept in the corpus. Accuracy for the ambiguous word cold increases from 0.82 with the initial model to almost 0.9 with the refined model. 4.1 Disambiguation performance The disambiguation results are compared to state-of-the-art algorithms already evaluated on the MSH WSD dataset (see Table 3 ), which are briefly described in turn. Machine Readable Dictionary (MRD) and 2-MRD build a concept profile vector assigning weights to words related to concepts [20,26]. Automatic Extracted Corpus (AEC) uses the UMLS Metathesaurus to build queries used to collect training data for each ambiguous concept and then train a Na\u00efve Bayes classifier. Structural Semantic Integration (SSI) and SSI+Information Content (SSI+IC) [38] use a model from the Metathesaurus that is enriched by co-occurrence information available from the UMLS distribution. PageRank [2] uses a graph based approach to perform the selection (we use the results presented in [16]). MRD+KMeans and AEC+KMeans combine MRD and AEC predictions with k-means [22]. CPIDF builds concept profiles for the whole of MEDLINE based on the same queries as the AEC method [21]. Na\u00efve Bayes (NB) has been used as well as baseline, even though it is consider an upper bound of the results since a supervised method is expected to perform better than an unsupervised method on this task. NB results were obtained in 10-fold cross-validation using the MSH WSD data set. More details are available from [26]. We find that the proposed method outperforms existing unsupervised methods, including the AEC algorithm and the SSI+IC that already combine KB data and co-occurrence information from MEDLINE. This improvement is statistically significant (p <0.00001) compared to MRD and AEC, and the refined model significantly outperforms all the methods (p <0.00001). Improvements are significant even when Bonferroni corrections are applied to correct for multiple comparisons. 4.2 Document ranking We have also evaluated the capability of the model to rank documents. The ranking benchmark queries are based on a subset of the MeSH headings available from the MSH WSD set. The queries are built using the words extracted for each one of the relevant concepts from UMLS. MeSH indexing of the citation is used as ground truth, as indicated before. For each retrieval evaluated method, the top 1000 retrieved documents sorted by relevance are selected for each query. Trec_eval 7 http://trec.nist.gov/trec_eval. 7 was used to perform the evaluation with the standard retrieval measures. The baseline is based on a Kullback\u2013Leibler retrieval (pr.simple_kl_dir) using Lemur [4]. We also included using pseudo-relevance feedback with the top 10 documents (pr.mixfb_kl_dir). In addition, we have implemented the pseudo-feedback method by Tao and Zhai [42] (kl_feedback) with the basic version of Kullback\u2013Leibler retrieval (kl_divergence). Another baseline is based on the supervised learning algorithm, Support Vector Machine (SVM). 8 http://ii.nlm.nih.gov/MTI_ML. 8 The model has been trained on a subset of 95 thousand citations, and documents in the evaluation set have been ranked according to the distance to the hyperplane. This method is an upper bound baseline, since it is not expected that any unsupervised method would improve it. Results in Table 4 show that the proposed method significantly performs better than standard IR methods (p <0.001, which is significant even when Bonferroni corrections are applied to correct for multiple comparisons), and that the refinement method outperforms pseudo-relevance feedback approaches. 4.3 Discussion We have proposed an estimation of a word-concept model that improves performance in disambiguation and document ranking by capturing statistical data from a large KB. In addition, we showed that the effectiveness of the proposed model can be further improved by combining corpora co-occurrence statistics. As shown in Table 3, the 2-step model performs better than any unsupervised method built solely on KB information. The refined model, that integrates information as well MEDLINE statistics, performs better than any of the compared KB methods. Regardless of the large number of potentially false positive relations extracted by co-occurrences, the model refinement improves the performance of the initial model only based on the KB. The improvement of the resulting model is global, since the refinement is done on the whole of the KB, and not by a single concept as in [25]. In the document ranking results, we showed significant improvement in ranking over other methods. This may in part be due to the disambiguation performance. The model integrates words from the synonyms and related concepts, which effectively improved baseline performance. Despite the disambiguation performance, the retrieval differences are not equally significant, which indicates that other factors beyond ambiguity are relevant for retrieval. Similar impact of WSD but with a different model and different data sets was observed in [47]. One of the current limitations of the method is the cost of traversing the KB to estimate the probabilities and the cost of the refinement, which is quite expensive with the current implementation. However, all this is only needed to be done once per concept. Once this is done, both disambiguation and document ranking are performed very quickly. Additionally, larger k-step models will not only require more time, but more memory as well, since the chance of relating all vocabulary words and concepts is higher. Notice that the number of words and concepts is over 1million. On the other hand, it is unclear if there will be any positive effect in performance when larger k-step models are considered. The method estimates word-concept probabilities. Higher order n-grams or terms could be considered as well in the model, which would use more precise features than single words (unigrams). A term-concept model could be estimated in the same way as presented in Section 3but instead of words, higher order n-grams or terms should be used. Probabilities from models based on different features (i.e., unigrams and n-grams) could be combined to improve the performance of individual models. On the other hand, while terms are easily identified in the KB, the identification of these terms in text might not be perfect thus adding noise when using a term-concept model. 5 Conclusion and future work Results show that the proposed method improves both word sense disambiguation and document ranking with respect to state-of-the-art methods. The current work considers only two traversal steps, further research is required to replace larger traversal steps efficiently. The current estimation and refinement of the model does not rely on any training data and performance could be further enhanced if some training data is made available. Another possible application of the presented statistical method is text categorization, which could profit from the combination of knowledge based information and information derived from the training data. Another issue to be explored is to identify Gene Ontology [6] concepts, which is difficult to perform with traditional named entity resolution approaches. The Gene Ontology Annotation database [13] could be used to train the model. We plan to extend this preliminary work to more general domains than the biomedical one, by using Wikipedia or more structured data sets like DBpedia. The proposed model has been evaluated in disambiguation and document ranking but we are interested in further evaluating it in other text mining tasks such as knowledge acquisition [35,25], identification of context words for language generation [36], similarity between concepts and semantic distance [32]. The refinement of the model used in this work relies on co-occurrences, which potentially provides a large number of false positives. We would like to integrate additional relation extraction methods, but the difficulty is obtaining training data for all possible relation types. Although, methods based on open information extraction [8] could be considered. The current refinement implementation does not try identifying new synonyms of existing concepts but only tries to quantify how often they are being used with a given concept. Furthermore, it does not try identifying new concepts missing in the KB. It could be worth exploring information extraction methods to identify new synonyms [10] of existing concepts and new concepts. Acknowledgments We thank anonymous reviewers for their very useful comments and suggestions. Special thanks to Bridget McInnes and Maika Vicente Navarro for proofreading the manuscript. The work was supported by the CICYT Project TIN2011\u201324147 from the Spanish Ministry of Economy and Competitiveness (MINECO). References [1] Agirre E, Soroa A. Personalizing pagerank for word sense disambiguation. In: Proceedings of the 12th conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics; 2009. p. 33\u201341. [2] E. Agirre A. Soroa M. Stevenson Graph-based word sense disambiguation of biomedical documents Bioinformatics 26 22 2010 2889 2896 <http://www.ncbi.nlm.nih.gov/pubmed/20934991> [3] D. Alexopoulou B. Andreopoulos H. Dietze A. Doms F. Gandon J. Hakenberg Biomedical word sense disambiguation with ontologies and metadata: automation meets accuracy BMC Bioinform 10 1 2009 28 [4] Allan J, Callan J, Collins-Thompson K, Croft B, Feng F, Fisher D, et al. The lemur toolkit for language modeling and information retrieval. The Lemur Project. <http://lemurproject.org>; 2003 [accessed 25.01.12]. [5] A. Aronson F. Lang An overview of metamap: historical perspective and recent advances J Am Med Inform Assoc 17 3 2010 229 236 [6] M. Ashburner C.A. Ball J.A. Blake D. Botstein H. Butler J.M. Cherry Gene ontology: tool for the unification of biology Nat Genet 25 1 2000 25 29 [7] L.R. Bahl F. Jelinek R. Mercer A maximum likelihood approach to continuous speech recognition IEEE Trans Pattern Anal Mach Intell 2 1983 179 190 [8] Banko M, Cafarella MJ, Soderland S, Broadhead M, Etzioni O. Open information extraction for the web. In: IJCAI, vol. 7; 2007. p. 2670\u201376. [9] Berlanga R, Nebot V, P\u00e9rez M. Tailored semantic annotation for semantic search. Web Semantics: Science, Services and Agents on the World Wide Web; 2014. [18.07.14], http://dx.doi.org/10.1016/j.websem.2014.07.007. [10] D.R. Blair K. Wang S. Nestorov J.A. Evans A. Rzhetsky Quantifying the impact and extent of undocumented biomedical synonymy PLoS Comput Biol 10 9 2014 e1003799 [11] D.M. Blei A.Y. Ng M.I. Jordan Latent dirichlet allocation J Mach Learn Res 3 2003 993 1022 [12] O. Bodenreider The unified medical language system (UMLS): integrating biomedical terminology Nucleic Acids Res 32 Suppl. 1 2004 D267 D270 [13] E. Camon M. Magrane D. Barrell V. Lee E. Dimmer J. Maslen The gene ontology annotation (goa) database: sharing knowledge in uniprot with gene ontology Nucleic Acids Res 32 Suppl. 1 2004 D262 D266 [14] G. Cao J.-Y. Nie J. Bai Integrating word relationships into language models Proceedings of the 28th annual international ACM SIGIR conference on research and development in information retrieval 2005 ACM 298 305 [15] Chang J, Sean G, Chong W, Blei DM. Reading tea leaves: how humans interpret topic models. In: Bengio Y, Schuurmans D, Lafferty J, Williams CKI, Culotta A, editors. Advances in neural information processing systems 22; 2009. p. 288\u201396. [16] W. Cheng J. Preiss M. Stevenson Scaling up wsd with automatically generated examples Proceedings of the 2012 workshop on biomedical natural language processing 2012 Association for Computational Linguistics 231 239 [17] P.R. Cohen Empirical methods for artificial intelligence 1995 MIT Press Cambridge, MA, USA [18] W. Gale K. Church D. Yarowsky One sense per discourse Proceedings of the workshop on speech and natural language 1992 Association for Computational Linguistics 233 237 [19] S. Humphrey W. Rogers H. Kilicoglu D. Demner-Fushman T. Rindflesch Word sense disambiguation by selecting the best semantic type based on Journal Descriptor Indexing: preliminary experiment J Am Soc Inform Sci Technol 57 1 2006 96 113 [Print] [20] A. Jimeno-Yepes A. Aronson Knowledge-based biomedical word sense disambiguation: comparison of approaches BMC Bioinform 2010 11:565 [21] Jimeno-Yepes A, Aronson AR. Integration of umls and medline in unsupervised word sense disambiguation. In: 2012 AAAI fall symposium series; 2012. [22] A. Jimeno Yepes A.R. Aronson Knowledge-based and knowledge-lean methods combined in unsupervised word sense disambiguation Proceedings of the 2nd ACM SIGHIT international health informatics symposium 2012 ACM 733 736 [23] A. Jimeno-Yepes R. Berlanga-Llavori D. Rebholz-Schuchmann Applications of ontologies and text mining in the biomedical domain Ontology Theory Manage Des: Adv Tools Models 2010 261 283 [24] A. Jimeno-Yepes R. Berlanga-Llavori D. Rebholz-Schuhmann Terminological cleansing for improved information retrieval based on ontological terms Proceedings of the WSDM\u201909 workshop on exploiting semantic annotations in information retrieval 2009 ACM 6 14 [25] A. Jimeno-Yepes R. Berlanga-Llavori D. Rebholz-Schuhmann Ontology refinement for improved information retrieval Inform Process Manage 46 4 2010 426 435 [26] A.J. Jimeno-Yepes B.T. McInnes A.R. Aronson Exploiting MeSH indexing in MEDLINE to generate a data set for word sense disambiguation BMC Bioinform 12 1 2011 223 [27] C. Leacock G.A. Miller M. Chodorow Using corpus statistics and wordnet relations for sense identification Comput Linguist 24 1 1998 147 165 [28] McInnes B. An unsupervised vector approach to biomedical term disambiguation: Integrating UMLS and Medline. In: Proceedings of the ACL-08: HLT student research workshop. Association for Computational Linguistics, Columbus, Ohio; June 2008. p. 49\u201354. <http://www.aclweb.org/anthology/P/P08/P08-3009>. [29] McInnes B, Pedersen T, Carlis J. Using UMLS Concept Unique Identifiers (CUIs) for word sense disambiguation in the biomedical domain. In: AMIA annual symposium proceedings, vol. 2007. American Medical Informatics Association; 2007. p. 533\u20137. [30] R. Navigli P. Velardi Structural semantic interconnections: a knowledge-based approach to word sense disambiguation IEEE Trans Pattern Anal Mach Intell 27 7 2005 1075 1086 [31] V. Nebot R. Berlanga Exploiting semantic annotations for open information extraction: an experience in the biomedical domain Knowl Inf Syst 38 2 2014 365 389 http://dx.doi.org/10.1007/s10115-012-0590-x [32] C. Pesquita D. Faria A.O. Falcao P. Lord F.M. Couto Semantic similarity in biomedical ontologies PLoS Comput Biol 5 7 2009 e1000443 [33] L. Plaza A. Jimeno-Yepes A. D\u00edaz A. Aronson Studying the correlation between different word sense disambiguation methods and summarization effectiveness in biomedical texts BMC Bioinform 12 1 2011 355 [34] M.F. Porter An algorithm for suffix stripping Program: Electron Libr Inform Syst 14 3 1980 130 137 [35] Potter S. A survey of knowledge acquisition from natural language. TMA of Knowledge Acquisition from Natural Language; 2003. [36] E. Reiter R. Dale Z. Feng Building natural language generation systems vol. 33 2000 MIT Press [37] M.J. Schuemie J.A. Kors B. Mons Word sense disambiguation in the biomedical domain: an overview J Comput Biol 12 5 2005 554 565 [38] B. Singh E.M. van Mulligen J.A. Kors A scalable knowledge-based method for biomedical term disambiguation JAMIA 2013 [39] B. Smith M. Ashburner C. Rosse J. Bard W. Bug W. Ceusters The obo foundry: coordinated evolution of ontologies to support biomedical data integration Nat Biotechnol 25 11 2007 1251 1255 [40] I. Spasic S. Ananiadou J. McNaught A. Kumar Text mining and ontologies in biomedicine: making sense of raw text Brief Bioinformatics 6 3 2005 239 251 [41] M. Stevenson E. Agirre A. Soroa Exploiting domain information for word sense disambiguation of medical documents J Am Med Inform Assoc 2011 235 240 [42] T. Tao C. Zhai Regularized estimation of mixture models for robust pseudo-relevance feedback Proceedings of the 29th annual international ACM SIGIR conference on research and development in information retrieval 2006 ACM 162 169 [43] N. Ueda R. Nakano Deterministic annealing em algorithm Neural Netw 11 2 1998 271 282 [44] M. Weeber J.G. Mork A.R. Aronson Developing a test collection for biomedical word sense disambiguation Proceedings of the AMIA symposium 2001 American Medical Informatics Association 746 [45] D. Yarowsky One sense per collocation Proceedings of the workshop on human language technology 1993 Association for Computational Linguistics 266 271 [46] C. Zhai J. Lafferty A study of smoothing methods for language models applied to information retrieval ACM Trans Inform Syst (TOIS) 22 2 2004 179 214 [47] Z. Zhong H.T. Ng Word sense disambiguation improves information retrieval Proceedings of the 50th annual meeting of the association for computational linguistics: Long Papers vol. 1 2012 Association for Computational Linguistics 273 282", "scopus-id": "84924495386", "pubmed-id": "25510606", "coredata": {"eid": "1-s2.0-S1532046414002676", "dc:description": "Abstract Text mining of scientific literature has been essential for setting up large public biomedical databases, which are being widely used by the research community. In the biomedical domain, the existence of a large number of terminological resources and knowledge bases (KB) has enabled a myriad of machine learning methods for different text mining related tasks. Unfortunately, KBs have not been devised for text mining tasks but for human interpretation, thus performance of KB-based methods is usually lower when compared to supervised machine learning methods. The disadvantage of supervised methods though is they require labeled training data and therefore not useful for large scale biomedical text mining systems. KB-based methods do not have this limitation. In this paper, we describe a novel method to generate word-concept probabilities from a KB, which can serve as a basis for several text mining tasks. This method not only takes into account the underlying patterns within the descriptions contained in the KB but also those in texts available from large unlabeled corpora such as MEDLINE. The parameters of the model have been estimated without training data. Patterns from MEDLINE have been built using MetaMap for entity recognition and related using co-occurrences. The word-concept probabilities were evaluated on the task of word sense disambiguation (WSD). The results showed that our method obtained a higher degree of accuracy than other state-of-the-art approaches when evaluated on the MSH WSD data set. We also evaluated our method on the task of document ranking using MEDLINE citations. These results also showed an increase in performance over existing baseline retrieval approaches.", "openArchiveArticle": "true", "prism:coverDate": "2015-02-28", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046414002676", "dc:creator": [{"@_fa": "true", "$": "Jimeno Yepes, Antonio"}, {"@_fa": "true", "$": "Berlanga, Rafael"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046414002676"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046414002676"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(14)00267-6", "prism:volume": "53", "prism:publisher": "Elsevier Inc.", "dc:title": "Knowledge based word-concept model estimation and refinement for biomedical text mining", "prism:copyright": "Copyright \u00a9 2014 Elsevier Inc.", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Word-concept probability"}, {"@_fa": "true", "$": "Text mining"}, {"@_fa": "true", "$": "Word sense disambiguation"}, {"@_fa": "true", "$": "Information retrieval"}, {"@_fa": "true", "$": "Biomedical literature"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "300-307", "prism:endingPage": "307", "prism:coverDisplayDate": "February 2015", "prism:doi": "10.1016/j.jbi.2014.11.015", "prism:startingPage": "300", "dc:identifier": "doi:10.1016/j.jbi.2014.11.015", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "42", "@width": "329", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si72.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2021", "@ref": "si72", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "38", "@width": "254", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si70.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1525", "@ref": "si70", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "58", "@width": "340", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si67.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3088", "@ref": "si67", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "29", "@width": "177", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si61.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1078", "@ref": "si61", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "46", "@width": "337", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si59.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2037", "@ref": "si59", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "44", "@width": "233", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si58.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1422", "@ref": "si58", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "281", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si57.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1337", "@ref": "si57", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "41", "@width": "205", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si50.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1402", "@ref": "si50", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "227", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si42.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1489", "@ref": "si42", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "45", "@width": "318", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si41.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1798", "@ref": "si41", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "45", "@width": "206", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si40.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1233", "@ref": "si40", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "206", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si39.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1143", "@ref": "si39", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "85", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si38.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "548", "@ref": "si38", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "46", "@width": "248", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1838", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "36", "@width": "179", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "916", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "35", "@width": "190", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1205", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "197", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si82.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "241", "@ref": "si82", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "16", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si81.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "229", "@ref": "si81", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si80.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "243", "@ref": "si80", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "239", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si79.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si79", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si78.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "367", "@ref": "si78", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si77.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "241", "@ref": "si77", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "16", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si76.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "229", "@ref": "si76", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "17", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si75.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "243", "@ref": "si75", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "26", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si74.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "263", "@ref": "si74", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "27", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si73.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "285", "@ref": "si73", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si71.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "183", "@ref": "si71", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "55", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "444", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "55", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si69.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "438", "@ref": "si69", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "51", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si68.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "410", "@ref": "si68", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si66.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si66", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "10", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si65.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "195", "@ref": "si65", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "9", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si64.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "199", "@ref": "si64", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si63.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si63", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si62.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si62", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "49", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si60.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "338", "@ref": "si60", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "46", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "344", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "24", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si56.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "264", "@ref": "si56", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si55.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "242", "@ref": "si55", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "63", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si54.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "511", "@ref": "si54", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si53.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "183", "@ref": "si53", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "63", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si52.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "379", "@ref": "si52", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si51.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "211", "@ref": "si51", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "367", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si49.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "197", "@ref": "si49", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si48.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "197", "@ref": "si48", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "25", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si47.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "232", "@ref": "si47", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si46.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "206", "@ref": "si46", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si45.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "195", "@ref": "si45", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "56", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si44.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "380", "@ref": "si44", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "64", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si43.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "430", "@ref": "si43", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "38", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "280", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "65", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si37.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "489", "@ref": "si37", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si36.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si36", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si35.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "239", "@ref": "si35", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si34.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si34", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si33.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si33", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si32.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si32", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si31.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "239", "@ref": "si31", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "65", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si30.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "491", "@ref": "si30", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "195", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si29.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si29", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "64", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si28.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "430", "@ref": "si28", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si27.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si27", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "43", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si26.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "383", "@ref": "si26", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si25.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si25", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si24.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "239", "@ref": "si24", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si23.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si23", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si22.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "212", "@ref": "si22", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "197", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "197", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "55", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "439", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "239", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "204", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "239", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "197", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "239", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "24", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "230", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "197", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "55", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "439", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "843", "@width": "1902", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "130758", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "886", "@width": "1379", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "118658", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1044", "@width": "1902", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "174345", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "207", "@width": "467", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "29414", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "200", "@width": "311", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "24236", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "256", "@width": "467", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "38662", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "97", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3208", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "141", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5161", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "120", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414002676-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4328", "@ref": "gr2", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84924495386"}}
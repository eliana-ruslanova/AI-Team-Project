{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608013002323", "dc:identifier": "doi:10.1016/j.neunet.2013.08.005", "eid": "1-s2.0-S0893608013002323", "prism:doi": "10.1016/j.neunet.2013.08.005", "pii": "S0893-6080(13)00232-3", "dc:title": "On the construction of the relevance vector machine based on Bayesian Ying-Yang harmony learning ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "48", "prism:startingPage": "173", "prism:endingPage": "179", "prism:pageRange": "173-179", "dc:format": "application/json", "prism:coverDate": "2013-12-31", "prism:coverDisplayDate": "December 2013", "prism:copyright": "Copyright \u00a9 2013 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Cheng, Dansong"}, {"@_fa": "true", "$": "Nguyen, Minh Nhut"}, {"@_fa": "true", "$": "Gao, Junbin"}, {"@_fa": "true", "$": "Shi, Daming"}], "dc:description": "\n               Abstract\n               \n                  Tipping\u2019s relevance vector machine (RVM) applies kernel methods to construct basis function networks using a least number of relevant basis functions. Compared to the well-known support vector machine (SVM), the RVM provides a better sparsity, and an automatic estimation of hyperparameters. However, the performance of the original RVM purely depends on the smoothness of the presumed prior of the connection weights and parameters. Consequently, the sparsity is actually still controlled by the choice of kernel functions and/or kernel parameters. This may lead to severe underfitting or overfitting in some cases. In this research, we explicitly involve the number of basis functions into the objective of the optimization procedure, and construct the RVM by maximizing the harmony function between \u201chypothetical\u201d probability distribution in the forward training pathway and \u201ctrue\u201d probability distribution in the backward testing pathway, using Xu\u2019s Bayesian Ying-Yang (BYY) harmony learning technique. The experimental results have shown that our proposed methodology can achieve both the least complexity of structure and goodness of fit to data.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Relevance vector machine (RVM)"}, {"@_fa": "true", "$": "Bayesian inference"}, {"@_fa": "true", "$": "Bayesian Ying-Yang (BYY) harmony learning"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608013002323", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608013002323", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84884336149", "scopus-eid": "2-s2.0-84884336149", "pubmed-id": "24055959", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84884336149", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20130904", "$": "2013-09-04"}}}}}
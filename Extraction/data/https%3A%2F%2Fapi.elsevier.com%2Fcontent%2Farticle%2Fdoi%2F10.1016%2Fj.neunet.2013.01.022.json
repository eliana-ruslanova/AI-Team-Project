{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608013000373", "dc:identifier": "doi:10.1016/j.neunet.2013.01.022", "eid": "1-s2.0-S0893608013000373", "prism:doi": "10.1016/j.neunet.2013.01.022", "pii": "S0893-6080(13)00037-3", "dc:title": "First experiments with PowerPlay\n             ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2013 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "41", "prism:startingPage": "130", "prism:endingPage": "136", "prism:pageRange": "130-136", "dc:format": "application/json", "prism:coverDate": "2013-05-31", "prism:coverDisplayDate": "May 2013", "prism:copyright": "Copyright \u00a9 2013 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "Special Issue on Autonomous Learning", "dc:creator": [{"@_fa": "true", "$": "Srivastava, Rupesh Kumar"}, {"@_fa": "true", "$": "Steunebrink, Bas R."}, {"@_fa": "true", "$": "Schmidhuber, J\u00fcrgen"}], "dc:description": "\n               Abstract\n               \n                  Like a scientist or a playing child, PowerPlay (Schmidhuber, 2011) not only learns new skills to solve given problems, but also invents new interesting problems by itself. By design, it continually comes up with the fastest to find, initially novel, but eventually solvable tasks. It also continually simplifies or compresses or speeds up solutions to previous tasks. Here we describe first experiments with PowerPlay. A self-delimiting recurrent neural network SLIM RNN (Schmidhuber, 2012) is used as a general computational problem solving architecture. Its connection weights can encode arbitrary, self-delimiting, halting or non-halting programs affecting both environment (through effectors) and internal states encoding abstractions of event sequences. Our PowerPlay-driven SLIM RNN learns to become an increasingly general solver of self-invented problems, continually adding new problem solving procedures to its growing skill repertoire. Extending a recent conference paper (Srivastava, Steunebrink, Stollenga, & Schmidhuber, 2012), we identify interesting, emerging, developmental stages of our open-ended system. We also show how it automatically self-modularizes, frequently re-using code for previously invented skills, always trying to invent novel tasks that can be quickly validated because they do not require too many weight changes affecting too many previous tasks.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "\n                     PowerPlay\n                  "}, {"@_fa": "true", "$": "Problem invention"}, {"@_fa": "true", "$": "Discovery"}, {"@_fa": "true", "$": "Self-delimiting recurrent neural network"}, {"@_fa": "true", "$": "Skill learning"}, {"@_fa": "true", "$": "Self-modularization"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608013000373", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608013000373", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84875895363", "scopus-eid": "2-s2.0-84875895363", "pubmed-id": "23465562", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84875895363", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20130209", "$": "2013-02-09"}}}}}
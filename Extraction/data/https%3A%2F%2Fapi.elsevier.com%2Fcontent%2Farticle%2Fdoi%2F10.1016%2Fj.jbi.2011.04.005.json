{"scopus-eid": "2-s2.0-79959655291", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2011-04-24 2011-04-24 2011-09-15T23:30:12 1-s2.0-S1532046411000694 S1532-0464(11)00069-4 S1532046411000694 10.1016/j.jbi.2011.04.005 S300 S300.1 FULL-TEXT 1-s2.0-S1532046411X00060 2015-05-15T06:30:58.184067-04:00 0 0 20111001 20111031 2011 2011-04-24T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav absattachment articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes primabst ref specialabst alllist content oa subj ssids 1532-0464 15320464 44 44 5 5 Volume 44, Issue 5 9 789 804 789 804 201110 October 2011 2011-10-01 2011-10-31 2011 article fla Copyright \u00a9 2011 Elsevier Inc. All rights reserved. USINGASHALLOWLINGUISTICKERNELFORDRUGDRUGINTERACTIONEXTRACTION SEGURABEDMAR I 1 Introduction 2 Related work 2.1 Extracting drug information 2.2 Discussion 3 Method 3.1 Dataset 3.2 DDI relation extraction as a classification task 3.3 Shallow linguistic kernel 3.4 Experiments 3.4.1 Kernel selection experiments 3.4.2 Statistical significance tests 3.4.3 Error analysis 3.4.4 Balancing experiments 4 Conclusion and discussion Acknowledgments References RODRIGUEZTEROL 2009 134 A HANSTEN 2003 94 97 P GIULIANO 2007 2 C ZHOU 2008 393 407 D KATRENKO 2007 61 80 S BUNESCU 2005 139 155 R YANG 2010 88 96 Z CORNEY 2004 3206 3213 D SHAWETAYLOR 2004 J KERNELMETHODSFORPATTERNANALYSIS ZELENKO 2003 1083 1106 D BUNESCU 2006 171 R LI 2008 756 769 J PYYSALO 2007 50 S FUNDEL 2007 365 K KRALLINGER 2008 S4 M PYYSALO 2008 S6 S TIKK 2010 e1000837 D YANG 2008 287 291 Z PAFILIS 2009 508 510 E HETTNE 2009 2983 2991 K GURULINGAPPA 2009 1986 1992 H SEGURABEDMAR 2008 816 823 I KOLARIK 2007 i264 C WISHART 2008 D901 D906 D RUBIN 2005 121 129 D DANGER 2010 902 913 R MCCRAY 1994 235 239 A ANNUALSYMPOSIUMCOMPUTERAPPLICATIONINMEDICALCARE LEXICALMETHODSFORMANAGINGVARIATIONINBIOMEDICALTERMINOLOGIES PORTER 1980 130 137 M LAVELLI 2008 361 393 A DAVIS 2006 233 240 J PROCEEDINGS23RDINTERNATIONALCONFERENCEMACHINELEARNING RELATIONSHIPBETWEENPRECISIONRECALLROCCURVES SING 2005 3940 T JIANG 2008 561 595 Y MCNEMAR 1947 153 157 Q DIETTERICH 1998 1895 1923 T HE 2009 1263 H VANHULSE 2009 1513 1542 J FERNER 2006 1435 R ARONSON 2004 473 486 J ARONSON 2007 637 639 J SEGURABEDMARX2011X789 SEGURABEDMARX2011X789X804 SEGURABEDMARX2011X789XI SEGURABEDMARX2011X789X804XI 2013-08-22T00:00:27Z Full http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window ElsevierBranded item S1532-0464(11)00069-4 S1532046411000694 1-s2.0-S1532046411000694 10.1016/j.jbi.2011.04.005 272371 2011-09-15T23:29:34.780312-04:00 2011-10-01 2011-10-31 1-s2.0-S1532046411000694-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/MAIN/application/pdf/e6db524e07b115a468842e71615c0012/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/MAIN/application/pdf/e6db524e07b115a468842e71615c0012/main.pdf main.pdf pdf true 2967861 MAIN 16 1-s2.0-S1532046411000694-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/PREVIEW/image/png/0aaaade8a16116c8eaf5187a1cad230e/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/PREVIEW/image/png/0aaaade8a16116c8eaf5187a1cad230e/main_1.png main_1.png png 87369 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046411000694-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/093a1d223491dfe61e86a2f645f25fed/si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/093a1d223491dfe61e86a2f645f25fed/si15.gif si15 si15.gif gif 1187 38 235 ALTIMG 1-s2.0-S1532046411000694-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/f8eb0dd557db6f53fbe1fe621b6d5930/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/f8eb0dd557db6f53fbe1fe621b6d5930/si13.gif si13 si13.gif gif 883 43 153 ALTIMG 1-s2.0-S1532046411000694-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/faf47364766730c41d1c5b7db0c3647e/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/faf47364766730c41d1c5b7db0c3647e/si12.gif si12 si12.gif gif 2183 58 369 ALTIMG 1-s2.0-S1532046411000694-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/7437b600489dda9f056911396969caab/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/7437b600489dda9f056911396969caab/si10.gif si10 si10.gif gif 1312 19 297 ALTIMG 1-s2.0-S1532046411000694-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/a045b383cca7abc236e405eeabe4d97e/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/a045b383cca7abc236e405eeabe4d97e/si9.gif si9 si9.gif gif 1579 18 380 ALTIMG 1-s2.0-S1532046411000694-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/c7a8f2e5a60f2faa518f4bd2598eeb7f/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/c7a8f2e5a60f2faa518f4bd2598eeb7f/si8.gif si8 si8.gif gif 1229 19 274 ALTIMG 1-s2.0-S1532046411000694-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/ce59eac0ef06635ece3b5aa4102893ae/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/ce59eac0ef06635ece3b5aa4102893ae/si7.gif si7 si7.gif gif 1425 42 188 ALTIMG 1-s2.0-S1532046411000694-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/82583563064dd84206bc3d21d4d16f43/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/82583563064dd84206bc3d21d4d16f43/si6.gif si6 si6.gif gif 1808 43 373 ALTIMG 1-s2.0-S1532046411000694-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/c0c1cd10dc19ad0e7b32f79bdbe5ebb9/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/c0c1cd10dc19ad0e7b32f79bdbe5ebb9/si3.gif si3 si3.gif gif 1106 18 240 ALTIMG 1-s2.0-S1532046411000694-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/c59d430dc1d29d5ace919d8117dc045a/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/c59d430dc1d29d5ace919d8117dc045a/si5.gif si5 si5.gif gif 411 16 77 ALTIMG 1-s2.0-S1532046411000694-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/e3022af7051c3d15e9033db377bef590/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/e3022af7051c3d15e9033db377bef590/si4.gif si4 si4.gif gif 514 16 109 ALTIMG 1-s2.0-S1532046411000694-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/da3d82e9de68defa2d2396579c4fd309/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/da3d82e9de68defa2d2396579c4fd309/si2.gif si2 si2.gif gif 697 40 115 ALTIMG 1-s2.0-S1532046411000694-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/a2585be4988d170f110c91295325eea8/si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/a2585be4988d170f110c91295325eea8/si14.gif si14 si14.gif gif 706 22 123 ALTIMG 1-s2.0-S1532046411000694-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/1a323af61ec256dd2c446469061e96ec/si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/1a323af61ec256dd2c446469061e96ec/si11.gif si11 si11.gif gif 622 18 112 ALTIMG 1-s2.0-S1532046411000694-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/STRIPIN/image/gif/cca22f8f56bc15b0432b6b9b2afeddda/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/STRIPIN/image/gif/cca22f8f56bc15b0432b6b9b2afeddda/si1.gif si1 si1.gif gif 658 40 90 ALTIMG 1-s2.0-S1532046411000694-gr10.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr10/DOWNSAMPLED/image/jpeg/e59807979813f46dd94ba8d37045b0cd/gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr10/DOWNSAMPLED/image/jpeg/e59807979813f46dd94ba8d37045b0cd/gr10.jpg gr10 gr10.jpg jpg 23515 362 489 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr10.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr10/THUMBNAIL/image/gif/619fc428b195e88e32dbcb0f6f7896d1/gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr10/THUMBNAIL/image/gif/619fc428b195e88e32dbcb0f6f7896d1/gr10.sml gr10 gr10.sml sml 2491 162 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr11.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr11/DOWNSAMPLED/image/jpeg/d277f5603c966a70ffeccaebb8ea9b1c/gr11.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr11/DOWNSAMPLED/image/jpeg/d277f5603c966a70ffeccaebb8ea9b1c/gr11.jpg gr11 gr11.jpg jpg 32581 240 464 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr11.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr11/THUMBNAIL/image/gif/5d6dea5267d3d5890ce0ba8f47f31cde/gr11.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr11/THUMBNAIL/image/gif/5d6dea5267d3d5890ce0ba8f47f31cde/gr11.sml gr11 gr11.sml sml 4690 113 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr12.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr12/DOWNSAMPLED/image/jpeg/c50827c6f6126c784e7313a7ddc3715a/gr12.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr12/DOWNSAMPLED/image/jpeg/c50827c6f6126c784e7313a7ddc3715a/gr12.jpg gr12 gr12.jpg jpg 74819 697 733 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr12.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr12/THUMBNAIL/image/gif/b2185cef8bc1bf4474a0ec70dc4e53d5/gr12.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr12/THUMBNAIL/image/gif/b2185cef8bc1bf4474a0ec70dc4e53d5/gr12.sml gr12 gr12.sml sml 4558 163 172 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr13.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr13/DOWNSAMPLED/image/jpeg/bfc3fa926c7630f5f61a217a5e82d901/gr13.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr13/DOWNSAMPLED/image/jpeg/bfc3fa926c7630f5f61a217a5e82d901/gr13.jpg gr13 gr13.jpg jpg 111465 1015 719 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr13.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr13/THUMBNAIL/image/gif/6d6a4e84fa00bab8841d47ba67d4403d/gr13.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr13/THUMBNAIL/image/gif/6d6a4e84fa00bab8841d47ba67d4403d/gr13.sml gr13 gr13.sml sml 3784 164 116 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr2/DOWNSAMPLED/image/jpeg/9a70714a8bbf9cca095aca5ba29c39db/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr2/DOWNSAMPLED/image/jpeg/9a70714a8bbf9cca095aca5ba29c39db/gr2.jpg gr2 gr2.jpg jpg 26125 124 622 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr2/THUMBNAIL/image/gif/9bb93bf6d73ded362d7394bb19e5b902/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr2/THUMBNAIL/image/gif/9bb93bf6d73ded362d7394bb19e5b902/gr2.sml gr2 gr2.sml sml 3530 44 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr3/DOWNSAMPLED/image/jpeg/aaa63b64f892984417247a87ae650bb5/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr3/DOWNSAMPLED/image/jpeg/aaa63b64f892984417247a87ae650bb5/gr3.jpg gr3 gr3.jpg jpg 87592 396 630 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr3/THUMBNAIL/image/gif/d96952f797b07b4ace297fac72d1a647/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr3/THUMBNAIL/image/gif/d96952f797b07b4ace297fac72d1a647/gr3.sml gr3 gr3.sml sml 10119 138 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr4/DOWNSAMPLED/image/jpeg/a10332b6ecb17308f2cf085e5551ed29/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr4/DOWNSAMPLED/image/jpeg/a10332b6ecb17308f2cf085e5551ed29/gr4.jpg gr4 gr4.jpg jpg 102298 293 533 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr4/THUMBNAIL/image/gif/9d954d443822a6e66cc4169f5a645ce6/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr4/THUMBNAIL/image/gif/9d954d443822a6e66cc4169f5a645ce6/gr4.sml gr4 gr4.sml sml 10532 121 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr5/DOWNSAMPLED/image/jpeg/0e983e146df45102cc2c7954621e7ed2/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr5/DOWNSAMPLED/image/jpeg/0e983e146df45102cc2c7954621e7ed2/gr5.jpg gr5 gr5.jpg jpg 33689 218 482 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr5/THUMBNAIL/image/gif/1ede3fc505f92efae9ea50dd58a0e96d/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr5/THUMBNAIL/image/gif/1ede3fc505f92efae9ea50dd58a0e96d/gr5.sml gr5 gr5.sml sml 7108 99 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr6/DOWNSAMPLED/image/jpeg/4f4ce14d89af444e2e21a65be0f42cf7/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr6/DOWNSAMPLED/image/jpeg/4f4ce14d89af444e2e21a65be0f42cf7/gr6.jpg gr6 gr6.jpg jpg 62703 200 534 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr6/THUMBNAIL/image/gif/11ef1468b8e2dc57aa786a7f8cc5d221/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr6/THUMBNAIL/image/gif/11ef1468b8e2dc57aa786a7f8cc5d221/gr6.sml gr6 gr6.sml sml 6771 82 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr7/DOWNSAMPLED/image/jpeg/47951cc3464c600a83773a7e8a30b4f6/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr7/DOWNSAMPLED/image/jpeg/47951cc3464c600a83773a7e8a30b4f6/gr7.jpg gr7 gr7.jpg jpg 42682 218 375 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr7/THUMBNAIL/image/gif/471c581d69937d42100a3862e54024c5/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr7/THUMBNAIL/image/gif/471c581d69937d42100a3862e54024c5/gr7.sml gr7 gr7.sml sml 6730 127 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr8/DOWNSAMPLED/image/jpeg/a8677c0e3c29c0e181b0893312c83d8c/gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr8/DOWNSAMPLED/image/jpeg/a8677c0e3c29c0e181b0893312c83d8c/gr8.jpg gr8 gr8.jpg jpg 19165 140 355 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr8/THUMBNAIL/image/gif/cf57698117769387a3f83307e7e92f14/gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr8/THUMBNAIL/image/gif/cf57698117769387a3f83307e7e92f14/gr8.sml gr8 gr8.sml sml 3763 86 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr9/DOWNSAMPLED/image/jpeg/b969612c07b42590973eac642dd57965/gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr9/DOWNSAMPLED/image/jpeg/b969612c07b42590973eac642dd57965/gr9.jpg gr9 gr9.jpg jpg 25647 158 356 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr9/THUMBNAIL/image/gif/def98a099f06d616d304a768d3ffca3d/gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr9/THUMBNAIL/image/gif/def98a099f06d616d304a768d3ffca3d/gr9.sml gr9 gr9.sml sml 4639 97 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/fx1/DOWNSAMPLED/image/jpeg/059280423a487cd2b1f5a1db21027955/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/fx1/DOWNSAMPLED/image/jpeg/059280423a487cd2b1f5a1db21027955/fx1.jpg fx1 true fx1.jpg jpg 23228 200 264 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/fx1/THUMBNAIL/image/gif/087a3cda42707abd598a81fdfb8b9bb2/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/fx1/THUMBNAIL/image/gif/087a3cda42707abd598a81fdfb8b9bb2/fx1.sml fx1 true fx1.sml sml 8606 164 217 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-fx2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/fx2/DOWNSAMPLED/image/jpeg/4af16f6b7e1229389fb73dce52d48d39/fx2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/fx2/DOWNSAMPLED/image/jpeg/4af16f6b7e1229389fb73dce52d48d39/fx2.jpg fx2 fx2.jpg jpg 19189 137 393 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-fx2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/fx2/THUMBNAIL/image/gif/95f862e36e202bc65b3a4ba733386150/fx2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/fx2/THUMBNAIL/image/gif/95f862e36e202bc65b3a4ba733386150/fx2.sml fx2 fx2.sml sml 4543 76 219 IMAGE-THUMBNAIL 1-s2.0-S1532046411000694-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr1/DOWNSAMPLED/image/jpeg/18c0c75cd3961cc7a6b352f7c2cf3aef/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr1/DOWNSAMPLED/image/jpeg/18c0c75cd3961cc7a6b352f7c2cf3aef/gr1.jpg gr1 gr1.jpg jpg 119696 701 623 IMAGE-DOWNSAMPLED 1-s2.0-S1532046411000694-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046411000694/gr1/THUMBNAIL/image/gif/4eece0b58bc558460551b291ce367218/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046411000694/gr1/THUMBNAIL/image/gif/4eece0b58bc558460551b291ce367218/gr1.sml gr1 gr1.sml sml 8126 164 146 IMAGE-THUMBNAIL YJBIN 1771 S1532-0464(11)00069-4 10.1016/j.jbi.2011.04.005 Elsevier Inc. Fig. 1 DrugBank card for Heparin. Fig. 2 Food and drug interaction fields in Heparin drug card. Fig. 3 Interactions field linked document from Heparin drug card describing DDIs. Fig. 4 Example of document processed by MMTx. Fig. 5 Mapping for the phrase, \u2018Aspirin\u2019. Fig. 6 Example of DDI annotations. Fig. 7 Labeling candidate drugs. Fig. 8 Example of global context kernel for n-gram=1. Fig. 9 Example of global context kernel for n-gram=2. Fig. 10 Average results for shallow linguistic kernel. Fig. 11 Learning curves. Fig. 12 ROC and precision-recall curves. Fig. 13 Precision-recall curves. Table 1 Basic statistics on the DrugDDI corpus. Number Avg. per document Documents 579 Sentences 5806 10.03 Phrases 66,021 114.02 Tokens 127,653 220.47 Sentences with at least one DDI 2044 3.53 Sentences with no DDI 3762 6.50 DDIs 3160 5.46 (0.54 per sentence) Table 2 Distribution of positive and negative examples in training and testing datasets. Set Documents Examples Positives Negatives Train 437 (75.5%) 25,209 2421 (9.6%) 22,788 (90.4%) Final test 142 (24.5%) 5548 739 (13.3%) 4809 (86.7%) Total 579 30,757 3160 (10.27%) 27,597 (89.73%) Table 3 Training and testing datasets. Set Documents Sentences Drugs DDIs Training 437 4578 2560 2421 Final test 142 1228 753 739 Total 579 5806 3313 3160 Table 4 Average results shallow linguistic kernels according to parameters. The highest scores are marked with asterisks (\u2217). Experiment Avg. P Avg. R Avg. F 1 allDDI 0.11 1 0.19 n-gram=1, window-size=1 0.4238 0.7841 0.5490 n-gram=1, window-size=2 0.4397 0.7863\u2217 0.5630 n-gram=1, window-size=3 0.4551 0.7748 0.5727 n-gram=2, window-size=1 0.4693 0.7079 0.5632 n-gram=2, window-size=2 0.4914 0.7115 0.5797 n-gram=2, window-size=3 0.4887 0.7079 0.5779 n-gram=3, window-size=1 0.5040 0.7321 0.5964\u2217 n-gram=3, window-size=2 0.5079 0.6963 0.5861 n-gram=3, window-size=3 0.5207\u2217 0.6996 0.5964\u2217 Table 5 Comparative analysis of global, local and shallow kernels. The highest scores are marked with asterisks (\u2217). Kernel P R F Global context (n-gram=3) 0.5158 0.7114 0.5974\u2217 Local context (window-size=2) 0.4387 0.7843\u2217 0.5618 Shallow (n-gram=3,window-size=3) 0.5207\u2217 0.6996 0.5964 Table 6 Final results obtained by the shallow kernels. The highest scores are marked with asterisks (\u2217). TP FP FN P R F allDDI 739 6270 0 0.11 1 0.19 n-gram=1, window-size=1 569 724 178 0.4401 0.7617\u2217 0.5578 n-gram=1, window-size=2 555 683 192 0.4483 0.7430 0.5592 n-gram=1, window-size=3 552 641 195 0.4627 0.7390 0.5691 n-gram=2, window-size=1 562 579 185 0.4926 0.7523\u2217 0.5953 n-gram=2, window-size=2 557 580 190 0.4899 0.7456 0.5913 n-gram=2, window-size=3 553 557 194 0.4982 0.7403 0.5956 n-gram=3, window-size=1 539 568 208 0.4869 0.7216 0.5814 n-gram=3, window-size=2 542 549 205 0.4968 0.7256 0.5898 n-gram=3, window-size=3 544 522 203 0.5103\u2217 0.7282 0.6001\u2217 Table 7 McNemar\u2019s test contingency table. n 11 n 10 n 01 n 00 Table 8 \u03c7 statistic values using McNemar\u2019s test. The highest scores are marked with asterisks (\u2217). Table 9 Principal causes of false positives generated. Cause % Requiring resolution of coordinate structures and appositions 46 Requiring negation treatment 34 MMTx appositions 14 Corpus error 6 Table 10 Causes of error of false negatives generated. Error in prediction model 41% Detection of appositions and coordinate structures 24% Long DDI descriptions 16% Resolution of complex and compound sentences required 7% Treatment of negation required 7% Resolution of anaphora and cataphora required 5% Table 11 Experimental results for imbalanced and balanced datasets. Experiment P R F 1 Inc. allDDI 0.11 1 0.19 \u2013 Imbalanced 0.5103 0.7282 0.6001 2.1584 TrainingBalanced 0.3469 0.8782 0.4973 1.6173 Table 12 Experimental results for imbalanced and balanced datasets grouped by class. Experiment Class P R F 1 Imbalanced 0 0.97 0.92 0.94 1 0.51 0.72 0.60 TrainingBalanced 0 0.98 0.80 0.88 1 0.35 0.88 0.50 Using a shallow linguistic kernel for drug\u2013drug interaction extraction Isabel Segura-Bedmar \u204e isegura@inf.uc3m.es Paloma Mart\u00ednez pmf@inf.uc3m.es Cesar de Pablo-S\u00e1nchez cdepablo@inf.uc3m.es Computer Science Department, Carlos III University of Madrid, Legan\u00e9s, Spain \u204e Corresponding author. Fax: +34 91 624 91 29. Graphical abstract Our goal is to develop an IE system to extract drug-drug interactions from biomedical texts. We use the DrugBank database as the source of unstructured textual information on drugs and their interactions. These texts are analyzed by the MetaMap tool that provides shallow syntactic and semantic information. Our system is based on a supervised machine learning approach, in particular, a shallow linguistic kernel-based approach that uses Support Vector Machines (SVM). Highlights \u25ba We propose the first full solution for the automatic extraction of drug\u2013drug interactions (DDIs) from biomedical texts. \u25ba We creates the first annotated corpus with DDIs in order to train and evaluate our system. \u25ba Our system is on a shallow linguistic kernel. Abstract A drug\u2013drug interaction (DDI) occurs when one drug influences the level or activity of another drug. Information Extraction (IE) techniques can provide health care professionals with an interesting way to reduce time spent reviewing the literature for potential drug\u2013drug interactions. Nevertheless, no approach has been proposed to the problem of extracting DDIs in biomedical texts. In this article, we study whether a machine learning-based method is appropriate for DDI extraction in biomedical texts and whether the results provided are superior to those obtained from our previously proposed pattern-based approach [1]. The method proposed here for DDI extraction is based on a supervised machine learning technique, more specifically, the shallow linguistic kernel proposed in Giuliano et al. (2006) [2]. Since no benchmark corpus was available to evaluate our approach to DDI extraction, we created the first such corpus, DrugDDI, annotated with 3169 DDIs. We performed several experiments varying the configuration parameters of the shallow linguistic kernel. The model that maximizes the F-measure was evaluated on the test data of the DrugDDI corpus, achieving a precision of 51.03%, a recall of 72.82% and an F-measure of 60.01%. To the best of our knowledge, this work has proposed the first full solution for the automatic extraction of DDIs from biomedical texts. Our study confirms that the shallow linguistic kernel outperforms our previous pattern-based approach. Additionally, it is our hope that the DrugDDI corpus will allow researchers to explore new solutions to the DDI extraction problem. Keywords Biomedical information extraction Drug\u2013drug interactions Patient safety Shallow linguistic kernel Machine learning Unified medical language system MetaMap 1 Introduction A drug\u2013drug interaction (DDI) occurs when one drug influences the level or activity of another, for example, increasing plasma concentration of the drug and potentially intensifying its side effects or decreasing its plasma concentration and thereby reducing its effectiveness. Since negative DDIs can be very dangerous, DDI detection is the subject of an important field of research that is crucial for both patient safety and health care cost control. Although health care professionals are supported in DDI detection by different databases, those being used currently are rarely complete, since their update periods can be as long as three years [3]. Drug interactions are frequently reported in journals of clinical pharmacology and technical reports, making medical literature the most effective source for the detection of DDIs. Every year, 300,000 articles are published within the field of pharmacology alone [4]. The management of DDIs is a critical issue, therefore, due to the overwhelming amount of information available [5]. Information extraction (IE) can be of great benefit for both the pharmaceutical industry by facilitating the identification and extraction of relevant information on DDIs, as well as health care professionals by reducing the time spent reviewing the relevant literature. Moreover, the development of tools for automatically extracting DDIs is essential for improving and updating the drug knowledge databases. Our focus is the detection of sentences carrying information regarding a DDI as well as the specific drugs taking part in the interaction. An additional study goal is to analyze the contribution of current IE methods to DDI extraction and evaluate their performance in select scenarios where technology aiding DDI detection exists and is available. In a previous paper [1], we proposed a hybrid method combining shallow parsing and pattern matching to extract DDIs from texts. Unfortunately, this initial approach yielded poor results (precision=48.89%, recall=24.81%, F-measure=32.92%). In the present article, our approach is based on the use of the shallow linguistic kernel-method [2] which has successfully been applied to the extraction of protein\u2013protein interactions (PPIs) and other relations in newspaper texts [6]. As it will be seen in the following sections, the shallow linguistic kernel is based on two configuration parameters, n-gram and window-size. In this article we evaluate whether kernel performance is robust across different domains and study the effect of the above-mentioned configuration parameters on the results. In order to train and evaluate our system, we have developed the first annotated corpus with DDIs, the DrugDDI corpus. It is our belief that the DrugDDI corpus will help support and evaluate the long-term improvement of technology in drug information management. The paper is organized as follows: Section 2 reviews the principal approaches developed for the extraction of biomedical relations as well as related work on accessing pharmacological information for specific drugs. We describe our proposal in Section 3, detailing from Subsections 3.4.1, 3.4.2, 3.4.3, 3.4.4 the experiments conducted on DDI extraction from biomedical texts and the results obtained. Finally, Section 4 discusses principal conclusions drawn from the experiments as well as proposals for future research. 2 Related work The goal of biomedical relation extraction is to detect occurrences of a predefined type of relationship between a pair of given entity types (e.g., genes, proteins or drugs) in text. These relationships may be very specific such as protein interactions (PPIs), pharmacokinetic interactions between drugs or relationships between genes and diseases. Although relationships can generally involve three or more entities (e.g., drug-gene-disease relationships), most of the existing approaches in relation extraction have focused on the extraction of binary relationships. Typically, resulting data from this task is stored in knowledge bases, which can either be consulted directly by users or exploited by data mining algorithms to infer new knowledge. Relation detection may also help to enhance the presentation and results of specialized search engines for end users. Different techniques have been proposed for the extraction of biomedical relations, particularly PPIs, from texts. Current methods for biomedical relation extraction (and relation extraction, in general) may be classified in three main categories: linguistic-based, pattern-based and machine learning-based approaches. In linguistic-based approaches, linguistic technology is employed to capture syntactic structures or semantic meanings that could be helpful for the discovery of relations in unstructured texts. Pattern-based approaches design a set of domain-specific rules (also called \u2018patterns\u2019) that encode and capture the various forms in which a given relationship is expressed. In general terms, the linguistic-based approaches perform well for capturing relatively simple binary relationships between entities in a sentence, but fail to extract more complex relationships expressed in various coordinate and relational clauses [7]. Pattern-based approaches usually achieve high precision, but low recall. Additionally, they are incapable of handling long and complex sentences that are so common in biomedical texts. As opposed to the previous approaches which require a laborious effort in order to define grammars or a set of rules, machine learning-based approaches enable the learning of meaningful models from annotated corpora. These approaches can be further classified as either feature-based and kernel-based depending on the manner in which instances are represented. In feature-based approaches, relation instances are represented by a set of feature values. Two categories of features are usually selected: (1) properties of single tokens including entity type, Parts-of-Speech tag, lemma and other attributes of the tokens, and (2) relations between tokens represented as the binary presence of certain sequences, parse trees or dependency relations between tokens. In Katrenko and Adriaans [8], dependency parsing and three machine learning algorithms (i.e.,na\u00efve Bayes, BayesNet and K nearest neighbors classifiers) were performed on the AImed [9] and LLL corpora to detect PPIs. Precision ranged between 56% and 81% and recall between 32% and 76% depending on the corpus and classifier used. The highest performance was achieved with the combination of the three classifiers on the AImed corpus (F-measure 72.7%). BioPPISVMExtractor [10] is a system for PPIs extraction based on Support Vector Machines (SVMs) and the link grammar parser [11]. The set of features included surface word, keyword, protein name distance and link path features. The system was trained with the IEAP corpus [12] and tested on the DIP [13] corpus. The system achieved a recall of 70.04%, a precision of 49.28% and an F-measure of 57.85%. In kernel-based approaches, relation instances are encoded as structural representations such as bag-of-words, word-sequence, parse trees or dependency graphs to measure the similarity between them. A word-sequence kernel can be defined as the number of common word subsequences between two relation instances. Kernels do not need to represent each data instance onto a flat set of features, but rather require a similarity measure between instances [14]. Moreover, several representations may be combined by the use of composite kernels by operations like normalization, scaling, linear combination or product. In the last decade, several kernel-based methods have been proposed to solve the problem of relation extraction in journalistic texts. In Zelenko and Aone [15], several tree kernels were adapted for the relation extraction task to calculate the similarity of shallow parse trees including head, PoS and entity tags annotations. A relation instance was represented as the smallest shallow subtree containing both entities in the relation. In Culotta and Sorensen [16], an extension of the previous approach was proposed with a richer sentence representation and through the use of composite kernels to reduce kernel sparsity. Bunescu and Mooney [17] designed a kernel-method using the shortest path between the two entities in a dependency tree. Recent years have seen these kernel-based methods applied to the biomedical relation, as well. In Bunescu and Mooney [18], a generalization of a sequence kernel was proposed using sequences containing words and word classes. Experiments were performed for extracting PPIs from biomedical corpora (AImed and LLL) and top-level relations from newspaper corpora. For PPI extraction, experiments conducted with the AImed corpus yielded an F-measure=59% (precision=60.0%, recall=57.2%) while LLL corpus experiments achieved higher performance with an F-measure of 61.7% (precision=62.1%, recall=61.3%). Later experiments showed that subsequence kernels performed better than the shortest path kernel [19]. Based on the work above, Giuliano et al. [2] proposed a composite sequence kernel, the shallow linguistic kernel, that uses the local context of entities and the global context of their relation to perform the classification. It was evaluated on the AImed (F-measure=63.9%) and LLL (F-measure=58.6%) corpora. We describe this kernel in more detail in Section 3. Li et al. [20] compared different kernels for biomedical relation extraction: a bag-of-words kernel, a subsequence kernel and the tree kernel proposed in Zelenko and Aone [15]. A tree kernel augmented with the trace from the root node of the smallest subtree to the root of the full parse tree was also proposed. To evaluate the kernels, a corpus was built of 2000 cancer-related abstracts from Medline and a total of 8071 relation instances, 2156 of which being identified as true relations. Best results were yielded by the composite kernel combining the sequence kernel and the trace-tree kernel, achieving an F-measure of 67.23% (recall=64.68%, precision=70.11%, accuracy=83.14%). In Airola et al. [21], a dependency-path kernel was proposed to extract PPIs. Each relation instance was represented with a weighted graph consisting of two unconnected subgraphs, one representing the dependency structure of the sentence and the other the linear order of the words. Experiments were performed across five corpora annotated for PPIs (AImed, LLL, IEAP, BioInfer [22], HPRD50 [23], DIP and BioCreAtIvE-PPI [24]) and demonstrated that F-measures varied remarkably across the different corpora. An important variable is the proportion of positive and negative examples in each corpora (i.e., where positive and negative examples involve the respective existence and non-existence of a PPI between proteins in a sentence). The highest F-measure (56.4%) was achieved on the AImed corpus. The above five corpora were unified in a common format in Pyysalo et al. [25]. Recently, Tikk et al. [26] compared some of the above-mentioned convolution kernels (i.e., kernels based on the use of parse trees or dependency graphs of sentences) for PPI extraction. Experiments were performed on the above five gold standard corpora, using different parameters and different evaluation metrics. They showed that even the best kernel is not significantly better than the RelEx system [26], a rule-based method not requiring any training or parameter tuning. 2.1 Extracting drug information The recognition of drug names is an essential prerequisite step for the automatic discovery of DDIs from biomedical texts. While many studies in biomedical named entity recognition have focused on genes and proteins [27\u201333], only a few have addressed drug names [34\u201336]. The DrugNer system [37] is a hybrid method that combines semantic information provided by the Unified Medical Language System (UMLS) MetaMap Transfer (MMTx) tool [38] and a set of affixes recommended by the WHOINN program to identify and classify drug names. The affixes enable the recognition of drugs not detected by MMTx, and establish important information such as drug families. Although experiments showed that affixes alone are not sufficient enough for the detection of drugs, they do help slightly improve coverage. In our previous study [1], we proposed a set of syntactic patterns to split long sentences into clauses from which DDIs were extracted by a pattern matching algorithm. Recently, Garcia-Blasco et al. [41] proposed a method to detect DDI sentences based on maximal frequent sequences. In Kolarik et al. [39], the use of lexico-syntactic patterns was proposed for the identification and extraction of relevant information on pharmacological properties. The goal of the system was to support database content update by providing additional descriptions of pharmacological effects not found in databases like DrugBank [40]. In Duda et al. [4], a corpus of 2000 abstracts of positive and negative drug interaction citations was manually created in order to evaluate the use of an SVM for locating articles about DDIs. Nevertheless, the goal in this particular case was not the extraction of relations, but rather the classification of articles reporting some kind of interaction. A similar purpose was pursued by Rubin et al. [42] in which an automated method was developed for the identification of articles in Medline citations containing gene-drug relationships. In that study, three types of statistical models (i.e., na\u00efve Bayes, logistic regression, and a log-likelihood) and a heuristic method (i.e., a \u2018gene-drug filter\u2019) were implemented to detect pharmacogenetics articles. A sampling of the articles identified from the Medline scans was then reviewed by a pharmacologist to assess the performance of the method. The system achieved an F-measure of 88% with a precision of 80% and a recall of 97%. More recently, several machine learning algorithms were evaluated in Danger et al. [43] in order to obtain a satisfactory classifier for the identification of drug target articles. Best results were achieved by a fuzzy lattice reasoning classifier, reaching 98% of ROC area under curve measurement. 2.2 Discussion Although several works have applied text mining to related problems in the pharmacological domain, none have carried out research specifically on DDI extraction. With regard to the different approaches to relation extraction presented above, while hand-built patterns and linguistic-based approaches achieve strong performance, it is also essential that domain experts get involved in the definition of these patterns and the development of these linguistic tools. Such tasks require labor-intensive manual processing with resulting patterns and tools that are unable to easily adapt to other subdomains. Machine-learning approaches, on the other hand, can be easily extended to new domains or relations when annotated corpora to support their training are created. Certain studies [15,20] have declared that tree kernels not only outperform feature-based methods, but also achieve better results than sequence kernels. It is difficult, however, to reach a conclusion in this case since experiments have been performed on different corpora with different distributions and different experimental conditions. Conversely, in Tikk et al. [26] convolution kernels were shown to provide no significant improvement when compared to rule-based methods. One final issue to consider is the computational complexity of tree kernels [17,20] which may render them inappropriate for practical purposes. Another important issue is that some research on relation extraction has evaluated only the relation detection step (i.e., assuming perfect linguistic analysis and entity identification), while others have presented results of a complete system that may have potentially included cascading errors produce by NERC, PoS taggers and parsers. For example, one of the advantages of the shallow linguistic kernel [6] is that it has been shown to be robust to noise generated through the use of NERC output. In this paper, our ultimate goal is to compare the performance of a machine learning method with that of our previous approach [1] based on the use of patterns and yielding an F-measure in experiments of only 33.64%. Following consideration of the issues described in this section, we have selected sequence kernels and, in particular, the shallow linguistic kernel proposed in Giuliano et al. [2] as the DDI extraction method to be studied. Motivating the selection was our use of the UMLS MetaMap Transfer (MMTx) tool [38] to analyze the DrugDDI corpus (MMTx only provides shallow syntactic and semantic information) and the findings in Tikk et al. [26] that the kernel was nearly as good as the best dependency-based kernels. 3 Method The main goal of this work is the automatic extraction of DDIs from texts. We address the problem using an IE method based on supervised machine learning and kernel-methods. To train and evaluate our approach, we developed and used a corpus of text containing potential DDIs. This corpus is described in Subsection 3.1. Subsection 3.3 briefly describes the details of the kernel that we selected, the shallow linguistic kernel initially proposed in Giuliano et al. [2] and used here. Results and experiments regarding the different models have been outlined in Subsection 3.4. This subsection also includes additional experiments performed in response to the imbalanced nature of the data. 3.1 Dataset In certain studies [44,22,9,24], the biomedical corpora presented focused on the description of several relationships between biological entities. None, however, contained DDIs. While Natural Language Processing(NLP) techniques are relatively domain-portable, corpora are not. For this reason, we created the first annotated corpus, the DrugDDI corpus, studying the phenomenon of interactions among drugs. This corpus allows us to automatically evaluate our approach for extracting DDIs from biomedical texts. Moreover, we believe that the corpus may also serve to encourage the NLP community to conduct further research in the field of pharmacology. We used the DrugBank database [40] as the source of unstructured textual information on drugs and their interactions. DrugBank is a chemical and pharmaceutical database containing information of approximately 4900 pharmacological substances. This database provides information oriented to biochemists and biologists regarding the nomenclature, structure and physical properties of drugs and their drug targets. DrugBank also offers detailed clinical information often used by healthcare professionals about drugs including pharmacology, metabolism and indications. The database has enjoyed wide use in several contexts including drug design, drug target discovery or drug interaction prediction, among many other applications. Furthermore, it is a free, online resource. For each drug, DrugBank contains more than 100 data fields including drug synonyms, brand names, chemical formula and structure, drug categories, ATC and AHFS codes (i.e., codes of standard drug families), mechanism of action, indication, dosage forms and toxicity (see Fig. 1 ). Of particular interest to this study, DrugBank offers a complete collection of DDIs, which was compiled from several resources, checked by an accredited pharmacist and entered manually into the database. This collection consists of 714 food interactions and 13,242 drug\u2013drug interactions contained respectively in the structured information fields, food interactions and drug interactions (see Fig. 2 ). Additional information can be found in the field \u2018interactions\u2019 (see Fig. 3 ), containing a link to a document describing DDIs in unstructured texts. This document not only contains a detailed description of the interactions contained in the above-mentioned fields (i.e., \u2018food interactions\u2019 and \u2018drug interactions\u2019), but also offers information on other interactions not included therein. For the present study, we used the \u2018interactions\u2019 field as a source of unstructured textual information on DDIs. We believe that these texts are a reliable and representative source of data for expressing DDIs since the language used is mostly devoted to descriptions of DDIs. Additionally, the highly specialized pharmacological language is very similar to that found in the Medline pharmacology abstracts. Due to the cost-intensive and time consuming nature of the annotation process, we randomly selected a subset of 579 documents to be annotated for the present study. We used the Kapow\u2019s free RoboMaker screen-scraper 1 http://openkapow.com/. 1 to download the interaction documents. These documents were then analyzed by the UMLS MetaMap Transfer (MMTx) tool performing sentence splitting, tokenization, POS-tagging, shallow syntactic parsing (see Fig. 6) and linking of phrases with UMLS Metathesaurus concepts. Fig. 4 shows part of the output produced by MMTx for a given document. The output of MMTx is transformed into XML format providing maximum flexibility for the use of the DrugDDI corpus. In this transformation process, MMTx first splits the text into sentences. The SPECIALIST minimal commitment parser [45] is then used to produce a shallow syntactic parsing of the texts where phrases in each sentence are identified and classified. The resulting XML document gives the type, number of tokens, text and an identifier for each phrase. The parser then uses the SPECIALIST lexicon to assign POS tags to the tokens, relying on the Xerox part-of-speech tagger [46] in order to determine on the correct tag when a token has several tags in the lexicon. Each token is annotated with its POS tag, word, and a boolean value indicating if it is the head of the phrase (i.e., the attribute \u2018ISHEAD\u2019). In addition, the start and end offsets of each token within the text are stored in the attributes, \u2018start\u2019 and \u2018end\u2019, respectively. These character offsets enable the mapping from the annotation to the raw text. Fig. 4 shows the tokens and their offsets contained in the phrase \u2018with alprazolam,\u2019. For each phrase, a set of variants is generated using the SPECIALIST lexicon and linguistic techniques. These variants are the text of the phrase plus its acronyms, abbreviations and synonyms, as well its derivational, inflectional and spelling variants. These variants are then searched for in the UMLS Metathesaurus, retrieving those concepts containing at least one of them. Each concept is evaluated against the text of the phrase using several linguistic metrics to determine its similarity. Finally, those concepts with the highest similarity are selected as the final mapping. A more detailed description of this process can be found in Aronson [47]. For each concept in the final mapping set, MMTx provides its concept unique identifier (CUI), concept name and semantic types. In this way, drugs are automatically identified by MMTx since the tool allows for the recognition and annotation of biomedical entities occurring in texts according to the UMLS semantic types (e.g., Clinical Drug [clnd], Pharmacological Substance [phsu], Antibiotic [antb]). As an example, Fig. 5 shows that the phrase \u2018Aspirin\u2019 is classified with the semantic type \u2018pharmacological substances (phsu)\u2019. The principal value of the DrugDDI corpus undoubtedly comes from its DDIs annotations. To obtain these annotations, all documents were marked-up by a researcher with pharmaceutical background. DDIs were annotated at the sentence level and, thus, any interactions spanning over several sentences were not annotated here. For the annotation of interactions, then, the annotator needs only select a sentence and indicate the interacting drugs. The annotator should then annotate an interaction for each pair of interacting drugs. Fig. 6 shows an example of an annotated sentence in our XML format containing three interactions. Each interaction is represented as a DDI node in which the names of the interacting drugs are registered in its NAME_DRUG_1 and NAME_DRUG_2 attributes. The identifiers of the phrases (i.e., \u2018DRUG_1\u2019 and \u2018DRUG_2\u2019) containing these interacting drugs were also provided to enable access to the related concepts provided by MMTx. Table 1 shows basic statistics of the DrugDDI corpus. In general, the size of biomedical corpora is quite small and usually does not exceed 1000 sentences. The average number of sentences per MedLine abstract was estimated at 7.2\u00b11.9 [48]. Our corpus contains 5806 sentences with 10.3 sentences per document on average. MMTx identified a total of 66,021 phrases of which 12.5% (8260) are drugs. The average number of drug mentions per document was 24.9, and the average number of drug mentions per sentence was 2.4. The corpus contains a total of 3775 sentences with two or more drug mentions, although only 2044 sentences contain at least one interaction. With the assistance of a pharmacist, a total of 3160 DDIs were with an average of 5.46 DDIs per document and 0.54 per sentence. The DrugDDI corpus is available for research purposes at http://labda.inf.uc3m.es/DrugDDI/. 3.2 DDI relation extraction as a classification task In our approach, DDI extraction is formulated as a supervised learning problem, more particularly, as a drug pair classification task. Therefore, a crucial step is to generate suitable datasets to train and test a classifier from the DrugDDI corpus. The simplest way to generate examples to train a classifier for a specific relation R is to enumerate all possible ordered pairs of sentence entities. In our study, we proceeded in a similar way. Given a sentence S with at least two drugs, we defined D as the set of drugs in S and N as the number of drugs. The set of examples generated for S, therefore, was defined as follows: {(D i , D j ): D i , D j \u03f5 D,1\u2a7d i, j \u2a7d N, i \u2260 j, i < j}. If the interaction existed between the two DDI candidate drugs, then the example was labeled 1. Otherwise, it was labeled 0. Although some DDIs may be asymmetrical, the roles of the interacting drugs were not included in the corpus annotation and are not specifically addressed in this article. As a result, we enumerate candidate pairs here without taking their order into account, such that (D i , D j ) and (D j , D i ) are considered as a single candidate pair. Since the order of the drugs in the sentence was not taken into account, each example is the copy of the original sentence S where the candidates were assigned the tag, \u2018DRUG\u2019, and remaining drugs were assigned the tag, \u2018OTHER\u2019. The set of possible candidate pairs was the set of 2-combinations from the whole set of drugs appearing in S. Thus, the number of examples was C N , 2 = N 2 . The sentence shown in Fig. 7 contains four drugs: \u2018aspirin\u2019, \u2018probenecid\u2019, \u2018sulfinpyrazone\u2019 and \u2018phenylbutazone\u2019. Therefore, the total number of examples generated is C 4 , 2 = 4 2 = 6 . Table 2 shows the total number of relation examples or instances generated from the DrugDDI corpus. In our corpus consisting of a total of 5806 sentences (see Table 1), we considered only those sentences with at least two drugs, obtaining 3775 sentences with 3313 different drug types. Among the 30,757 candidate drug pairs, only 3160 (10.27%) were marked as positive interactions (i.e., DDIs) while 27,597 (89.73%) were marked as negative interactions (i.e., non-DDIs). Once we generated the set of relation instances from the DrugDDI corpus, the set was then split in order to build the datasets for the training and evaluation of the different DDI extraction models. In order to build the training dataset used for development tests, 75.5% of the DrugDDI corpus files (437 files) were randomly selected. The remaining 24.5% (142 files) was used in the final evaluation to determine which model was superior. Table 3 shows the distribution of the documents, sentences, drugs and DDIs in each set. Approximately 90% of the instances in the training dataset were negative examples (i.e., non-DDIs). The distribution between positive and negative examples in the final test dataset was also quite similar (see Table 2). With our modeling, we treated DDI extraction as a classification problem between pairs of entities having been annotated as drugs. Relation extraction was performed using the MMTx annotation including tokenization, POS-tagging, lemmatization and chunking. In addition, it also provides semantic annotation by linking phrase concepts to UMLS concepts. For the present study, we chose the shallow linguistic kernel originally proposed in Giuliano et al. [2] due to its strong performance using only shallow linguistic information and its robustness in the face of annotation errors, such as the incorrect identification of named entities and their boundaries. 3.3 Shallow linguistic kernel Machine-learning classifiers try to find optimal frontiers between classes. When the instances of classes are not linearly separable, kernel methods can transform the problem space to a higher dimensional space, in which the instances might be separable. Formally, a kernel function is a binary function K:X \u00d7 X \u2192[0,\u221e) that maps a pair of instances x, y \u2208 X to their similarity score K(x, y). The kernel function must satisfy the following: (1) \u2200 x , y \u2208 X : K ( x , y ) = \u3008 \u03d5 ( x ) , \u03d5 ( y ) \u3009 , where \u03d5 : X \u2192 F \u2286 R n is a mapping from the input space X to a vector space F. The mapping function \u03d5 transforms each instance x \u2208 X into a feature vector \u03d5(x)=(\u03d5 1(x), \u03d5 2(x),\u2026, \u03d5 m (x)), where \u03d5 i : X \u2192 R , with no need to know the explicit representation of x. Thus, the mapping function \u03d5 allows K(x, y) to be expressed as the dot-product of the features vectors of the input objects x and y. The kernel function allows for the computation of the product of the two embedded vectors without requiring any prior knowledge regarding the features of each vector. Global and local context kernels are normalized using Eq. (3) to integrate information from heterogeneous feature spaces (e.g., combining tokenization, PoS tags or entity tags). (2) \u2200 x , y \u2208 X : K ( x , y ) = \u3008 \u03d5 ( x ) , \u03d5 ( y ) \u3009 = \u2211 i = 1 m \u03d5 i ( x ) \u00b7 \u03d5 i ( y ) . (3) K ( x i , x j ) = \u3008 \u03d5 ( x i ) , \u03d5 ( x j ) \u3009 \u2016 \u03d5 ( x i ) \u2016 \u2016 \u03d5 ( x j ) \u2016 The shallow linguistic kernel (K SL ) is a composite kernel defined in Giuliano et al. [2] as the linear combination of two different sequence kernels, a global context kernel (K GC ) and local context kernel (K LC ). In Eq. (4), R i and R j represent examples of two different candidate DDI between drugs. (4) K SL ( R i , R j ) = K GC ( R i , R j ) + K LC ( R i , R j ) Global context kernel. The global context kernel is designed to discover the presence of a relation between two entities by using information from the whole sentence. Its basis can be explained by the following observation from Bunescu and Mooney [18]: \u201cWhen a sentence asserts a relationship between two entity mentions, it generally does this using one of the following three contexts: fore-between, between, and between-after\u201d. In other words, a relationship between two entities is usually expressed using the words appearing before and between the entities (i.e., fore-between pattern [FB]), only between them (i.e., between pattern [B]) or between and after them (i.e., between-after pattern [BA]). The global context kernel, therefore, is a composite kernel formed by the linear combination of kernels defined for the three contexts relevant for the detection of relations, as shown in following equation. (5) K GC ( R 1 , R 2 ) = K FB ( R 1 , R 2 ) + K B ( R 1 , R 2 ) + K BA ( R 1 , R 2 ) As stated in Giuliano et al. [2], while this kernel uses only lexical tokens or words, it is important to note that its representation nevertheless preserves stop words and punctuation marks since they found to be useful tokens for the relation extraction task. For each of the three patterns described above, the representation uses the term frequency of tokens in the context C, tf(t i , C). To calculate the similarity between two patterns, the authors proposed the use of the n-gram kernel, also known in the literature as the n-spectrum kernel [14]. The n-gram kernel compares two relation instances by counting the common n-grams between the two in each of the three contexts discussed above (i.e., FB, B and BA). Figs. 8 and 9 present examples of a global context kernel calculated with n-gram=1 and n-gram=2, respectively, in order to estimate the similarity between two relation instances. While the 1-g kernel only counts the unigrams in common, the 2-gram kernel scores both unigrams and bigrams. Local context kernel. The local context kernel is based on the hypothesis that the contextual information of candidate entities is particularly useful for the verification of a relationship existing between them. In particular, windows of limited size around entities provide useful clues for the identification of the entities\u2019 roles within a relation. Therefore, Giuliano et al. [2] used the information provided by the two local contexts of the candidate interacting entities, called left and right local context, respectively. Each local context was represented using lexical and morphological features such as tokens, lemmas, PoS tags and stems. Each example was basically represented as an instance of the original sentence with the two candidate entities properly annotated (i.e., with the tag \u2018DRUG\u2019 in the case of the present study). The roles of the candidates are labeled with the tags \u2018A\u2019 (agent) and \u2018T\u2019 (target) which, in the case of the present study, were always the first and second arguments, respectively. Any other entity or tokens that were not candidates were labeled \u2018O\u2019. Since MMTx does not provide lemmatization, our approach here used a \u2018stem\u2019 feature rather than \u2018lemma\u2019. We obtained stems using the Porter Stemming Algorithm [49]. Then, the local context kernel can be defined as the sum of the left and right context kernels, as shown in the following equation: (6) K LC ( R 1 , R 2 ) = K left ( R 1 , R 2 ) + K right ( R 1 , R 2 ) K LC differs substantially from K GC in that it considers the ordering of tokens and enriches the feature space with PoS tags, lemmas, stems and orthographic features. A more detailed description of both kernels can be found in Giuliano et al. A more detailed description of both kernels can be found in Giuliano et al. [2]. In the same study [ibid.], the authors also developed a Java tool for Relation Extraction (jSRE) in order to implement their shallow linguistic kernel. This jSRE implementation used the SVM package LIBSVM [50]. The kernel was represented by a matrix containing the pairwise similarity of all instances. This matrix was then passed over to the LIBSVM, where it was used to learn a classification function (Eq. 7). The SVM classification function takes the form f(x)= wx \u2212 b where w is the weight vector and b is the bias computed by the SVM in the training process. When the training data is not linearly separable, linear SVMs must be extended to nonlinear SVMs through the use of a mapping function \u03d5 transforming the input vectors into high-dimensional feature vectors. Thus, the weight can be reformulated as: w = \u2211 \u03b1 i y i \u03d5 ( x i ) where \u03d5(x i ) are the support vectors. As the SVM computed the dot-product between instances, it can be generalized to kernels since these functions are defined as the dot-product in some expanded feature space. Hence, applying Eq. (2), the classification function becomes: (7) f ( x ) = wx - b = w \u03d5 ( x ) - b = \u2211 \u03b1 i y i \u03d5 ( x i ) \u03d5 ( x ) - b = \u2211 \u03b1 i y i K SL ( x i , x ) - b In both general and biological domains, jSRE has demonstrated strong performance [2,6]. We conducted a set of experiments to study the new problem of DDI extraction from biomedical texts. 3.4 Experiments This subsection describes the experiments run in the present study to evaluate the effectiveness of the shallow linguistic kernel. Since one of our main objectives was to investigate the influence of the configuration parameters of the jSRE tool \u2013 namely, window-size of the local context and n-gram of the global context \u2013 on final performance, we designed a set of experiments in which these parameters were varied. Additionally, due to the greately imbalanced nature of the training and test data (i.e., with regard to negative and positive examples), different experiments were also run in an attempt to compensate for this fact. Starting out, we considered as baseline system, referred to here as allDDI, the case in which every relation instance was classified as a DDI (i.e., a positive example). This baseline yielded the maximum recall, but low precision. Evaluated on the test dataset, the baseline system achieved a baseline precision of 11% and F-measure of 19% (see Table 4 , row 1). 3.4.1 Kernel selection experiments In our experiments, we used 10-fold cross-validation on the training dataset. For each run, nine folds were used to train a model that was evaluated with the remaining fold. The folds were built considering that examples from the same sentence must belong to the same fold. We followed the OAOD (One Answer per Ocurrence in the Document) [51] evaluation methodology, such that, each individual occurrence of a DDI had to be extracted from the document regardless of the number of times it was stated. For the present study, we ran a number of experiments varying configuration parameter values for the local and global kernels in order to contrast performance trade-offs. For the global kernel, the principal parameter is the n-gram size which we varied here between 1 and 3. For the local kernel, the primary parameter is the size of the window delineating the context around the candidate entities. We varied window-size in equal length from \u00b11 to \u00b13. One reason for this selection is that for the two parameters, jSRE implementation does not allow for values superior to 3. The average 10-fold cross-validation results are presented in Table 4 above. Table 4 and Fig. 10 show performance to differ significantly from one configuration to another with average precision ranging from 42.38% (n-gram=1, window-size=1) to 52.07% (n-gram=3, window-size=3) and average recall from 69.63% (n-gram=3, window-size=2) to 78.63% (n-gram=1, window-size=2). Thus, the highest average precision (52.07%) was achieved with an n-gram and window-size of 3 and the highest average recall (78.63%) was achieved with an n-gram of size 1 and window-size of 2. On the contrary, these latter two parameter values (n-gram=1, window-size=2) yielded the second lowest average precision (43.97%). The highest average F-measure (59.64%) was achieved with an n-gram of size 3 and a window-size of either 1 or 3. As parameter values increase, the average precision improved and the average recall declined. Across the experiments generally, a small n-gram size favored the obtainment of a higher recall value while a larger n-gram favored the obtainment of greater precision value. The choice of the parameter window-size, however, does not seem to have significantly affected performance (save for an n-gram of size 3). Such results are coherent with the fact that the window-size parameter is designed to identify the roles of entities within a relation, a consideration not addressed in the context of our current DDI annotation. Among the trained models, we selected the model maximizing both F-measure and precision (n-gram=3, window-size=3) in order to avoid overloading database curators with too many false positives during DDI extraction. Nevertheless, it is important to note that a different choice may have been justified following an exhaustive search in other types of information access applications. In our kernel evaluations, we evaluated each kernel separately in order to analyze the contributions of the global and local kernels to the overall shallow linguistic kernel. Table 5 presents the results yielded with optimal configurations for each kernel type. Results show that global context is more useful than local context for DDI detection since highest F-measure (59.74%) was achieved with the former rather than the latter. Although the local kernel was designed to identify the roles of candidate entities within a relation [2], our results show that the local kernel also positively influences DDI detection since the combination of both kernels improved the precision (52.07%), though also causing a slight decrease in the F-measure (59.64%). The model using a global context kernel with n-gram=1 and no local context kernel is very similar to traditional bag-of-words instance representation with an SVM classifier. This configuration showed a precision of 40.18%, a recall of 71.28% and an F-measure of 50.78%. These results confirm the usefulness of the composite kernel and, particularly, the advantage obtained by using larger n-grams. Finally, the shallow kernel (trained with n-gram=3 and window-size=3) was evaluated on the final testing dataset, achieving a precision of 51.03%, a recall of 72.82% and an F-measure of 60.01% (see Table 6 ). With regard to the baseline F-measure recorded, these results represent an improvement of 41%. In addition, we also evaluated the other models from Table 10 using the final test dataset. In general, results for each model were similar to those obtained from the 10-fold cross-validation experiments. Learning curves are useful to show the results achieved in the learning process for different percentages of training documents used. We used the jSRE configuration (n-gram=3 and window-size=3) having yielded the best results in the previous experiments discussed. In Fig. 11 , we calculated the F-measure, precision and recall for different percentages of training documents used. As demonstrated in Fig. 11, performance barely improved when the training size was increased to beyond 60% of the training corpus. Several works have reported that metrics derived from the confusion matrix provide a poor estimate of the performance of a model [52]. Additionally, these metrics are highly sensitive to data anomalies such as class skew. Receiver Operator Characteristic (ROC) curves offer an alternative to traditional metrics since ROC curves describe classifier behavior regardless of class distributions or error costs. Before offering a definition of ROC curves, it is important to briefly review two performance metrics here. The false positive rate (FPR) is the percentage of negative examples misclassified as positive, whereas the true positive rate (TPR), or recall, measures the fraction of positive examples correctly labeled as such. Typically, ROC graphs are constructed by plotting the TPR along y-axis and the FPR along the x-axis. ROC curves are able to depict results information in a more robust and intuitive manner than traditional metrics. At the same time, however, ROC curves may also provide a too optimistic view of classifier performance when dealing with highly skewed datasets. Precision-recall (PR) curves are an alternative to ROC curves when there is a large skew in the class distribution. In PR space, recall (TPR) is plotted along the x-axis and Precision along the y-axis. Precision-recall curves are more suitable for our data since the amount of negative examples (90%) greatly exceeds the amount of positives examples (10%). When a corpus is unbalanced, for example, when the number of negative examples greatly exceeds the number of positives examples, a small change in the number of false positives may be disguised by the large number of true negative in FPR (FP/(FP+TN)). While, in turn, precision (TP/(TP+FP)) is able to reflect the effect of the large number of negative examples on classifier performance because precision compares quantities in a closer order of magnitude (FP to TP rather than TN). Therefore, PR curves are more suitable than ROC curves for comparison in unbalanced datasets. In addition, Davis and Goadrich [53] showed that there is a strong connection between ROC space and PR space, such that a curve dominates in ROC space if and only if it dominates in PR space. We generated both kinds of curves using the ROCR [54] package for visualizing classifier performance (Fig. 12 ). Whereas it is very difficult to distinguish between the different ROC curves produced, PR curves provide for more adequate distinctions between the different models. Moreover, PR curves were recommended by Jiang et al. [55] in cases when ROC curves are not capable of revealing differences in the performance of different classifiers. Scrutiny of the PR curves presented in Fig. 13 shows that an increase of both parameters led to improved performance, though the parameter n-gram exerted a greater influence on performance than window-size. Furthermore, improvement was greater when the n-gram parameter was increased from 1 to 2 than when it was increased from 2 to 3. Fig. 12 shows the ROC and PR curves predicted from all models. It can be observed that the model with n-gram=3 and window-size=3 dominates both ROC and PR spaces. Therefore, this model is at least as good as all other models for all possible error costs and class distributions. This finding is consistent with the results shown in Tables 4 and 6. 3.4.2 Statistical significance tests McNemar\u2019s significance test [56] is a \u03c7 2-based significance test used to compare two groups, such as two classifiers or two population samples. We applied the McNemar\u2019s significance test to compare the performance of the different configurations and determine whether or not they differ significantly. Thus, for each pair of possible configurations C a and C b , their corresponding models were performed on the final test document set. The classification of each example in the test set by each model was recorded, counting the number of examples correctly classified by C a and C b (n 11), the number of examples correctly classified by C a but not by C b (n 10), the number of examples misclassified by C a but not by C b (n 01), and the number of examples misclassified by both C a and C b (n 00). The contingency matrix shown in Table 7 was then built for any pair of configurations. McNemar\u2019s test is based on a \u03c7 2 goodness-of-fit test comparing the distribution of counts expected under the null hypothesis to the counts observed. The null hypothesis H 0 states that the two configurations should have the same error rate (i.e., n 10 = n 01). According to Dietterich [57], under the null hypothesis the following statistic (see Eq. 8) is distributed as an \u03c7 2 distribution with one degree of freedom. (8) \u03c7 = ( | n 01 - n 10 | - 1 ) 2 n 01 + n 10 To test for significance, \u03c7 2 was compared to the appropriate \u03c7 2 table. Results with a probability greater than or equal to 0.05 are generally considered to be significant. Thus, the null hypothesis was correct if \u03c7 2 was lower than \u03c7 1 , 0.05 2 = 3.841459 . In other cases, the null hypothesis could be rejected in favor of the other hypothesis that the two configurations produce different levels of performance. Table 8 summarizes the \u03c7 statistic values for the pairwise comparison of the nine possible configurations using the McNemar\u2019s significance test (i.e., a total of 36 [9*8/2] comparisons). Each cell of this pairwise comparison matrix represents the \u03c7 statistic value for a given pair of configurations. Given the \u03c7 statistic values for the pairwise comparisons, differences in performance for pairs of configurations with n-gram parameters set at 2 are not significant. Similarly, any configuration with an n-gram of 2 does not significantly differ from those configurations with an n-gram equal of 3 and a window-size of less than 3 (see the gray cells in Table 8). Therefore, it may be concluded that those configurations with an n-gram parameter ranging in size from 2 to 3 and window-size parameter of less than 3 have the same rate error. As can be observed in Tables 4 and 6, these configuration pairs demonstrated very similar performance in the experiments run here. On the other hand, the last column in Table 8 shows that values for the configuration with an n-gram and window-size of 3 significantly differs from all others. As these values support the findings from our experiments, we may assert that this configuration (n-gram=3 and window-size=3) achieves the highest performance. 3.4.3 Error analysis Despite the findings above, it is important here to discuss certain limitations in our approach. Evaluated with the final test set (containing a total 739 DDIs), even the model with the highest F-measure (n-gram=3, window-size=3) was observed making a total of 597 errors, 276 of which being false negatives (i.e., interacting pairs that the system failed to detect) and 321 of which being false positives (i.e., pairs wrongly extracted by the system). To better understand these limitations of the system, we selected a random sample of 75% of these false positives and negatives for error analysis. Tables 9 and 10 present the principal causes for the false positives and false negatives generated, respectively. The most frequent cause of false positives was the system\u2019s incapability to distinguish between drugs constituting an apposition or a coordinate structure, and therefore, to recognize that they cannot interact. The following sentences are some examples of these false positives: Bentiromid may interact with acetaminophen (e.g., Tylenol), chloramphenicol (e.g., Chloromycetin ), local anesthetics (e.g., benzocaine and lidocaine), para-aminobenzoic acid (PABA) \u2013 containing preparations (e.g., sunscreens and some multivitamins), procainamide (e.g., Pronestyl), sulfonamides (sulfa medicines), thiazide diuretics (use of these medicines during the test period will affect the test results). A possible approach to improve our system, therefore, could be to introduce a pre-processing step to detect appositions and coordinate structures.. Thus, the pairs of drugs contained within these structures could be removed from the set of possible relation instances. The second most important cause identified was the system\u2019s inability to properly deal with negation. For example, an interaction between azithromycin and warfarin was wrongly detected by the system in the following sentence: \u2018Azithromycin did not affect the prothrombin time response to a single dose of warfarin\u2019. Another frequent cause of false positives were parsing errors made by MMTx. Furthermore, certain erros were caused by the incorrect classification of drug names by MMTx. Approximately 6% of the false positives analyzed were due to corpus annotation errors. In other words, the candidate pair actually represented a DDI and was identified as such by the system; however, the absence of an annotation as such in the corpus led to its classification as a false positive. Regarding false negatives (see Table 10), the most frequent was the need for patterns that could not be extracted from the training corpus. For example, the system was not able to detect the DDI in the following sentence: \u2018Quinolon has also been shown to interfere with the metabolism of caffeine\u2019. Additional training data from different sources such as MedLine may improve these results. In such a case, the resolution of coordinate and appositive structures through a pre-processing step could help improve performance: \u2018Quinolon, including cinoxacin, may enhance the effects of oral anticoagulants, such as warfarin or its derivatives\u2019. Furthermore, some interactions were described with extremely long text at times including additional information about dosages or adverse reactions (see below). Global and local context kernels are not capable of dealing with these types of sentences. For example, the following sentence: The incidence of akathisia in clinical trials of the weekly dosage schedule was greater (8.5%, 4/47 patients) when prochlorperazine was administered on the same day as CAMPTOSAR than when these drugs were given on separate days (1.3%, 1/80 patients). Other interactions were not detected due to the inability of the system to deal with complex and compound sentences: \u2018Urinari alkalinizing agents increase blood levels and decrease excretion of amphetamines\u2019. Another way in which system performance could be improved is through a greater attentiveness to negations. For example: \u2018Therefore, chloroprocaine should not be used in any condition in which a sulfonamide drug is being employed\u2019. Finally, it should be noted that the resolution of cataphora may also improve results. For example, in the following sentence, the term \u2018drugs\u2019 references to the following drugs: Other drugs which may enhance the neuromuscular blocking action of nondepolarizing agents such as NUROMAX include certain antibiotics (e.g., aminoglycosides, tetracyclines, bacitracin, polymyxins, lincomycin, clindamycin, colistin, and sodium colistimethate), magnesium salts, lithium, local anesthetics, procainamide, and quinidine\u2019. 3.4.4 Balancing experiments The textual corpus used for this study was collected from a text field describing DDIs for a given drug in the pharmacological database, DrugBank. Had we instead chosen to build a corpus from Medline abstracts, we imagined that the number of sentences containing DDIs would have been much lower. As discussed earlier, of all pair of drugs occurring in our corpus (30,757), only 10% of them (3160) are drugs that interact. In other words, only a 10% of all relation instances are DDI (positive examples). For this reason, we wanted to study the impact of an imbalanced dataset on the performance of the kernel-based method. A common problem in most of the machine learning algorithms is their inability to accurately learn from imbalanced data. Minority classes are usually underrepresented and rules are fewer and weaker than those of the majority classes [58,59]. Solutions for imbalanced learning include sampling, as well as cost-sensitive and active learning methods. While a detailed description of these solutions can be found in [58], in the present study we focused on undersampling, a simple technique removing examples from the majority class in order to provide a balanced distribution of examples. Undersampling involves a considerable information loss, in which discriminative features to differentiate among classes may be discarded. We therefore performed two experiments with different data distributions: \u2022 Imbalanced: In this experiment, both the training and testing dataset are imbalanced as in our previous experiments. The experiment, therefore, is the closest to the real situation of previous experiments. \u2022 TrainingBalanced: In this experiment, we used undersampling to randomly remove negative examples from the training dataset, while maintaining the test dataset imbalanced. The model trained on the balanced dataset was then applied to the imbalanced test dataset. Our hypothesis was that if the amount of positive and negative examples were the same in the training set, the model can distinguish the minority class (i.e. DDI) better. One drawback of this experiment is that the size of training dataset is reduced notably. In each experiment, results were compared to a baseline allDDI, in which all examples were labeled as DDI (i.e positive examples). This baseline allowed us to estimate the improvement achieved in each experiment. The increment can be defined as follows: (9) Inc ( F baseline , F SL ) = F SL - F baseline F baseline Table 11 shows the results obtained in each experiment. In the first experiment (i.e. Imbalanced), the baseline only achieves a precision of 11%, a perfectly predictable result given that the percentage of positive examples was 11%. The learned model, on the other hand, achieved good performance with an F-measure of 60.01%, an improvement of 41% and an increment of 2.1584 with respect to the baseline. In the second experiment (i.e. TrainingBalanced), a high recall (87.82%) was obtained; however, precision was also quite low (34.69%). Thus, while the balancing of training data helps to improve the recall, precision values are nevertheless adversely affected. The F-measure increment with respect to the baseline was lower in the TrainingBalanced experiment (1.6173) than in the Imbalanced experiment (2.1584). As a result, it can be concluded that balancing positive and negative examples by undersampling mechanism does not lead to results (i.e. a superior F-measure) better than those obtained from the imbalanced data. Regarding the classification task, Table 12 presents experiment performance separated by class (i.e where DDI=1 and non-interaction=0). As evidenced by the table, the experiments demonstrate strong performance with negative examples. In the Imbalanced experiment, these results are due to the fact that theres is a significantly greater amount of negative examples than the number of positive examples, providing strong clues for the description of the majority class (i.e. non-interactions). It must be noted, however, that in the TrainingBalanced experiment in which the number of negatives examples was reduced to equal the number of positive examples, the results for obtained for the negative examples (i.e. the non-interaction class) were nevertheless considerably high. Thus, we are led to believe that the determination of a non-interaction is easier the determination of a DDI. 4 Conclusion and discussion In the present study, our major objective was to evaluate the performance of the shallow linguistic kernel-method introduced in Giuliano et al. [2] in the extraction of DDI from biomedical texts. Several experiments have been conducted on the DrugDDI corpus. In our experiments, we varied n-gram (global context kernel) and window-size (local context kernel) configuration parameters. Greatest precision (52.07%) was achieved when both n-gram size and window-size were equal to 3. The highest recall value (78.63%) was produced with an n-gram size of 1 and window-size of 2. Nevertheless, it is important to note that this configuration also led to the second lowest recorded precision value (43.97%). Among all trained models, we choose that which maximized the F-measure and precision values (i.e. n-gram=3, window-size=3). With the final testing dataset, the model achieved a precision of 51.03%, a recall of 72.82% and an F-measure of 60.01%. In the experiments, a small n-gram size appeared to favor the obtainment of larger recall values while a larger n-gram size favored greater precision values. While the local context kernel was originally designed to identify the roles of the candidate entities within a relation [2] (and no distinguishing between roles of interacting drugs was done here), our results nevertheless show that the local kernel also assists with DDI extraction since the combination of both global and local kernels improved the precision of the shallow linguistic kernel. The DrugDDI corpus presented a large, imbalanced distribution between positive and negative examples,we followed up our principal experiments with others to study the influence of this imbalance on study results. In these latter experiments, we found that efforts to balance the positive and negative examples did not lead to higher performance. From previous studies, the shallow kernel had already shown strong performance in both general and biological domains [2,6]. In particular, [2] performed several experiments on two different biomedical corpora for protein\u2013protein interactions, AImed and LLL. Their experiments were performed using the correct named entities, that is, entities manually annotated in the corpora. Results obtained on the AImed corpus showed a precision of 60.0%, a recall of 57.2%, and F-measure of 59%. Superior performance was nevertheless achieved on the LLL corpus, with a precision of 62.1%, a recall of 61.3%, and an F-measure of 61.7%. Although direct comparisons between these experiments and our own are not possible due to the fact that a different type of relation (i.e. DDIs) was studied here and for which a new corpus was built, the same shallow linguistic kernel applied to the new task of DDI extraction appears to have achieved a similar F-measure (60.01%) and a higher recall (72.82%). Nevertheless a lower precision (51.03%) also resulted. One possible explanation for this lower precision values could be that our performance demonstrated the remarkable impact of automatic entity recognition on the relation extraction task. Had drug names been manually labeled in our corpus, it is highly likely that our results would have been significantly improved. Furthermore, while the LLL corpus is smaller than the DrugDDI corpus, the average number of interactions per sentence is higher in the former corpus (i.e., 2.0 in the LLL corpus) than in the latter (i.e., 0.6 in the DrugDDI corpus). We believe that a higher density of interactions would positively affect performance since sentences in the LLL corpus are focused on interaction description, whereas DrugDDI corpus sentences may be less discriminating. Our pattern-based approach from a previous study [1] was evaluated on the DrugDDI corpus, achieving a precision of 48.89%, a recall of 24.81% and an F-measure of 32.92%. In order to compare the pattern-based approach and shallow linguistic kernel, the latter was tested on the whole DrugDDI corpus using 10-fold cross-validation. It is clear from the study results that the kernel-based method is far superior to our earlier pattern-based approach. The most significant improvement observed in the kernel-based approach was achieved for recall and F-measure values, increasing to 71.19% and 59.52%, respectively. Thus, relative to values obtained from the earlier, pattern-based approach, recall increased by nearly 47% and the F-measure by nearly 27%. A minor improvement was also achieved for precision which increased by 2.36%. As a result, we can conclude that the machine learning-approach is far more efficient than the pattern-based approach for tackling DDI extraction from texts. To conclude, we believe that the solid performance achieved using the shallow linguistic kernel may provide a higher baseline, permitting the measurement of improvements with other methods that use full syntactic or semantic information. We propose several specific ideas for future work: \u2022 Evaluate the performance of the kernel-method when drug names are manually annotated. \u2022 Label the roles of drugs in the DrugDDI corpus in order to evaluate the contribution of the local kernel in their detection. \u2022 Define a semantic kernel using semantic information such as UMLS semantic type or drug families obtained by our DrugNer system [37]. \u2022 Design parse tree or dependency graph kernels for DDI extraction. \u2022 Evaluate other solutions for imbalanced learning such as hybrid sampling or cost-sensitive methods. Finally, in addition to a list of potential DDIs, an ideal description for a particular drug should also include more specific information about each interaction including the interaction mechanism, its relation to the doses of both drugs, its time course, the factors altering an individual\u2019s susceptibility to the DDI, its seriousness and severity, as well as the probability of its occurrence [60,61]. In practice, however, this information is rarely available in DDI knowledge bases [62]. Nevertheless, it may be included using similar techniques. As the detection of this additional information could help healthcare professionals assign real clinical significance to each DDI, it represents an additional, important issue for future study. Acknowledgments This study was funded by the Projects MA2VICMR (S2009/TIC-1542) and MULTIMEDICA (TIN2010-20644-C03-01). The authors are particularly grateful to Mar\u00eda Segura-Bedmar, manager of the Drug Information Center of the Mostoles University Hospital (Spain) for her invaluable support in the creation and evaluation of the DDI corpus. References [1] Segura-Bedmar I, Mart\u00ednez P, De Pablo-S\u00e1nchez C. Combining syntactic information and domain-specific lexical patterns to extract drug\u2013drug interactions from biomedical texts. In: Proceedings of the ACM fourth international workshop on data and text mining in biomedical informatics (DTMBIO\u201910); 2010. p. 49\u201356. [2] Giuliano C, Lavelli A, Romano L. Exploiting shallow linguistic information for relation extraction from biomedical literature. In: Proceedings of the eleventh conference of the European chapter of the association for computational linguistics (EACL-2006); 2006. p. 5\u20137. [3] A. Rodr\u00edguez-Terol C. Camacho Others, calidad estructural de las bases de datos de interacciones Farmacia Hospitalaria 33 03 2009 134 [4] Duda S, Aliferis C, Miller R, Statnikov A, Johnson K. Extracting drug\u2013drug interaction articles from MEDLINE to improve the content of drug databases. In: AMIA annual symposium proceedings, vol. 2005; 2005. p. 216. [5] P.D. Hansten Drug interaction management Pharm World Sci 25 3 2003 94 97 [6] C. Giuliano A. Lavelli L. Romano Relation extraction and the influence of automatic named-entity recognition ACM Trans Speech Lang Process (TSLP) 5 1 2007 2 10.1145/1322391.1322393 [7] D. Zhou Y. He Extracting interactions between proteins from the literature J Biomed Inform 41 2 2008 393 407 [8] S. Katrenko P. Adriaans Learning relations from biomedical corpora using dependency trees Lect Notes Comput Sci 4366 2007 61 80 [9] R. Bunescu R. Ge R.J. Kate E.M. Marcotte R.J. Mooney A.K. Ramani Comparative experiments on learning information extractors for proteins and their interactions Artif Intell Med 33 2 2005 139 155 [10] Z. Yang H. Lin Y. Li BioPPISVMExtractor: a protein\u2013protein interaction extractor for biomedical literature using SVM and rich feature sets J Biomed Inform 43 1 2010 88 96 [11] Grinberg D, Lafferty J, Sleator D. A robust parsing algorithm for link grammars. Arxiv preprint cmp-lg/9508003. [12] Ding J, Berleant D, Nettleton D, Wurtele E. Mining MEDLINE: abstracts, sentences, or phrases? In: Pacific symposium on biocomputing, January 3\u20137, 2002, Kauai, Hawaii; 2002. p. 326. [13] D.P.A. Corney B.F. Buxton W.B. Langdon D.T. Jones BioRAT: extracting biological information from full-length papers Bioinformatics 20 17 2004 3206 3213 [14] J. Shawe-Taylor N. Cristianini Kernel methods for pattern analysis 2004 Cambridge University Press Cambridge [15] D. Zelenko C. Aone A. Richardella Kernel methods for relation extraction J Mach Learn Res 3 2003 1083 1106 [16] Culotta A, Sorensen JS. Dependency tree kernels for relation extraction. In: Proceedings of ACL, vol. 4; 2004. [17] Bunescu R, Mooney RJ. A shortest path dependency kernel for relation extraction. In: Proceedings of the conference on human language technology and empirical methods in natural language processing, October, Association for Computational Linguistics Morristown, NJ, USA; 2005. p. 724\u201331. [18] R. Bunescu R. Mooney Subsequence kernels for relation extraction Adv Neural Inform Process Syst 18 2006 171 [19] Bunescu R, Mooney RJ. Extracting relations from text: from word sequences to dependency paths. In: Natural language processing and text mining; 2007. p. 29\u201344. [20] J. Li Z. Zhang X. Li H. Chen Kernel-based learning for biomedical relation extraction J Am Soc Inform Sci Technol 59 5 2008 756 769 [21] Airola A, Pyysalo S, Bjorne J, Pahikkala T, Ginter F, Salakoski T. A graph kernel for protein-protein interaction extraction. In: Proceedings of BioNLP; 2008. p. 1\u20139. [22] S. Pyysalo F. Ginter J. Heimonen J. Bj\u00f6rne J. Boberg J. J\u00e4rvinen BioInfer: a corpus for information extraction in the biomedical domain BMC Bioinform 8 1 2007 50 [23] K. Fundel R. Kuffner R. Zimmer RelEx-relation extraction using dependency parse trees Bioinformatics 23 3 2007 365 [24] M. Krallinger F. Leitner C. Rodriguez-Penagos A. Valencia Overview of the protein-protein interaction annotation extraction task of BioCreative II Genome Biol 9 Suppl. 2 2008 S4 [25] S. Pyysalo A. Airola J. Heimonen J. Bjorne F. Ginter T. Salakoski Comparative analysis of five protein-protein interaction corpora BMC Bioinform 9 Suppl. 3 2008 S6 [26] D. Tikk P. Thomas P. Palaga J. Hakenberg U. Leser A comprehensive benchmark of kernel methods to extract protein-protein interactions from literature PLoS Comput Biol 6 7 2010 e1000837 [27] Ando R. BioCreative II gene mention tagging system at IBM Watson. In: Proceedings of the second biocreative challenge evaluation workshop, Citeseer; 2007. p. 101\u20133. [28] Kuo C, Chang Y, Huang H, Lin K, Yang B, Lin Y, Hsu C, Chung I. Rich feature set, unification of bidirectional parsing and dictionary filtering for high F-score gene mention tagging. In: Proceedings of the second biocreative challenge evaluation workshop (BioCreative II), Madrid, Spain, Citeseer; 2007. [29] Huang H, Lin Y, Lin K, Kuo C, Chang Y, Yang B, et al. High-recall gene mention recognition by unification of multiple backward parsing models. In: Proceedings of the second biocreative challenge evaluation workshop, Citeseer; 2007. p. 109\u201311. [30] Klinger R, Friedrich C, Fluck J, Hofmann-Apitius M. Named entity recognition with combinations of conditional random fields. In: Proceedings of the second biocreative challenge evaluation workshop, Citeseer; 2007. p. 105\u20137. [31] Z. Yang H. Lin Y. Li Exploiting the performance of dictionary-based bio-entity name recognition in biomedical literature Comput Biol Chem. 32 4 2008 287 291 [32] Leaman R, Gonzalez G. Banner: an executable survey of advances in biomedical named entity recognition. In: Pacific symposium on biocomputing, vol. 13; 2008. p. 652\u201363. [33] E. Pafilis S. O\u2019Donoghue L. Jensen H. Horn M. Kuhn N. Brown Reflect: augmented browsing for the life scientist Nat Biotechnol 27 6 2009 508 510 [34] Sirohi E, Peissig P. Study of effect of drug lexicons on medication extraction from electronic medical records. In: Biocomputing 2005: proceedings of the pacific symposium, Hawaii, USA, 4\u20138 January 2005; 2005. [35] K. Hettne R. Stierum M. Schuemie P. Hendriksen B. Schijvenaars E. van Mulligen A dictionary to identify small molecules and drugs in free text Bioinformatics 25 22 2009 2983 2991 [36] H. Gurulingappa C. Kolarik M. Hofmann-Apitius J. Fluck Concept-based semi-automatic classification of drugs J Chem Inform Model 49 8 2009 1986 1992 [37] I. Segura-Bedmar P. Mart\u00ednez M. Segura-Bedmar Drug name recognition and classification in biomedical texts: a case study outlining approaches underpinning automated systems Drug Discov Today 13 17\u201318 2008 816 823 [38] Aronson AR. Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. In: Annual AMIA symposium; 2001. p. 17\u201321. [39] C. Kolarik M. Hofmann-Apitius M. Zimmermann J. Fluck Identification of new drug classification terms in textual resources Bioinformatics 23 13 2007 i264 [40] D.S. Wishart C. Knox A.C. Guo D. Cheng S. Shrivastava D. Tzur DrugBank: a knowledgebase for drugs, drug actions and drug targets Nucleic Acids Res 36 Database issue 2008 D901 D906 10.1093/nar/gkm958 [41] Garcia-Blasco S, Danger R, Rosso P. Drug\u2013drug interaction detection: a new approach based on maximal frequent sequences. in: SEPLN, vol. 45; 2010. p. 263\u20136. [42] D.L. Rubin C.F. Thorn T.E. Klein R.B. Altman A statistical approach to scanning the biomedical literature for pharmacogenetics knowledge J Am Med Inform Assoc 12 2 2005 121 129 [43] R. Danger I. Segura-Bedmar P. Mart\u00ednez P. Rosso A comparison of machine learning techniques for detection of drug target articles J Biomed Inform 46 6 2010 902 913 [44] Nedellec C. Learning language in logic\u2013genic interaction extraction challenge. In: Proceedings of the ICML05 workshop: learning language in logic (LLL05), vol. 18; 2005. p. 97\u20139. [45] A. McCray S. Srinivasan A. Browne Lexical methods for managing variation in biomedical terminologies Annual symposium on computer application in medical care vol. 18 1994 IEEE Computer Society Press 235 239 [46] Cutting D, Kupiec J, Pedersen J, Sibun P. A practical part-of-speech tagger. In: Proceedings of the third conference on applied natural language processing; 1992. [47] Aronson A. Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. In: Proceedings of the AMIA symposium, American Medical Informatics Association; 2001. p. 17. [48] Yu H. Towards answering biological questions with experimental evidence: automatically identifying text that summarize image content in full-text articles. In: Annual AMIA symposium proceedings; 2006. p. 834\u20138. [49] M.F. Porter An algorithm for suffix stripping Program 14 3 1980 130 137 [50] Chang CC, Lin CJ. LIBSVM: a library for support vector machines; 2001. [51] A. Lavelli M.E. Califf F. Ciravegna D. Freitag C. Giuliano N. Kushmerick Evaluation of machine learning-based information extraction algorithms: criticisms and recommendations Lang Resour Eval 42 2008 361 393 10.1007/s10579-008-9079-3 [52] Provost F, Fawcett T, Kohavi R. The case against accuracy estimation for comparing induction algorithms. In: Proceedings of the fifteenth international conference on machine learning, vol. 445, Citeseer; 1998. [53] J. Davis M. Goadrich The relationship between precision-recall and roc curves Proceedings of the 23rd international conference on machine learning 2006 ACM 233 240 [54] T. Sing O. Sander N. Beerenwinkel T. Lengauer ROCR: visualizing classifier performance in R Bioinformatics 21 20 2005 3940 [55] Y. Jiang B. Cukic Y. Ma Techniques for evaluating fault prediction models Empirical Software Eng 13 5 2008 561 595 [56] Q. McNemar Note on the sampling error of the difference between correlated proportions or percentages Psychometrika 12 2 1947 153 157 [57] T. Dietterich Approximate statistical tests for comparing supervised classification learning algorithms Neural Comput 10 7 1998 1895 1923 [58] H. He E.A. Garcia Learning from imbalanced data IEEE Trans Knowledge Data Eng 21 9 2009 1263 [59] J. Van Hulse T. Khoshgoftaar Knowledge discovery from imbalanced and noisy data Data Knowledge Eng 68 12 2009 1513 1542 [60] R.E. Ferner J.K. Aronson Communicating drug safety JBM 333 2006 1435 [61] J.K. Aronson Drug interactions-information, education, and the British National Formulary Br J Clin Pharmacol 57 4 2004 473 486 [62] J.K. Aronson Communicating information about drug interactions Br J Clin Pharmacol 63 6 2007 637 639 10.1111/j.1365-2125.2007.02948.x", "scopus-id": "79959655291", "pubmed-id": "21545845", "coredata": {"eid": "1-s2.0-S1532046411000694", "dc:description": "Abstract A drug\u2013drug interaction (DDI) occurs when one drug influences the level or activity of another drug. Information Extraction (IE) techniques can provide health care professionals with an interesting way to reduce time spent reviewing the literature for potential drug\u2013drug interactions. Nevertheless, no approach has been proposed to the problem of extracting DDIs in biomedical texts. In this article, we study whether a machine learning-based method is appropriate for DDI extraction in biomedical texts and whether the results provided are superior to those obtained from our previously proposed pattern-based approach [1]. The method proposed here for DDI extraction is based on a supervised machine learning technique, more specifically, the shallow linguistic kernel proposed in Giuliano et al. (2006) [2]. Since no benchmark corpus was available to evaluate our approach to DDI extraction, we created the first such corpus, DrugDDI, annotated with 3169 DDIs. We performed several experiments varying the configuration parameters of the shallow linguistic kernel. The model that maximizes the F-measure was evaluated on the test data of the DrugDDI corpus, achieving a precision of 51.03%, a recall of 72.82% and an F-measure of 60.01%. To the best of our knowledge, this work has proposed the first full solution for the automatic extraction of DDIs from biomedical texts. Our study confirms that the shallow linguistic kernel outperforms our previous pattern-based approach. Additionally, it is our hope that the DrugDDI corpus will allow researchers to explore new solutions to the DDI extraction problem.", "openArchiveArticle": "true", "prism:coverDate": "2011-10-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046411000694", "dc:creator": [{"@_fa": "true", "$": "Segura-Bedmar, Isabel"}, {"@_fa": "true", "$": "Mart\u00ednez, Paloma"}, {"@_fa": "true", "$": "de Pablo-S\u00e1nchez, Cesar"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046411000694"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046411000694"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(11)00069-4", "prism:volume": "44", "prism:publisher": "Elsevier Inc.", "dc:title": "Using a shallow linguistic kernel for drug\u2013drug interaction extraction", "prism:copyright": "Copyright \u00a9 2011 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "5", "dcterms:subject": [{"@_fa": "true", "$": "Biomedical information extraction"}, {"@_fa": "true", "$": "Drug\u2013drug interactions"}, {"@_fa": "true", "$": "Patient safety"}, {"@_fa": "true", "$": "Shallow linguistic kernel"}, {"@_fa": "true", "$": "Machine learning"}, {"@_fa": "true", "$": "Unified medical language system"}, {"@_fa": "true", "$": "MetaMap"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "5", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "789-804", "prism:endingPage": "804", "prism:coverDisplayDate": "October 2011", "prism:doi": "10.1016/j.jbi.2011.04.005", "prism:startingPage": "789", "dc:identifier": "doi:10.1016/j.jbi.2011.04.005", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "38", "@width": "235", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1187", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "43", "@width": "153", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "883", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "58", "@width": "369", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2183", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "297", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1312", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "380", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1579", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "274", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1229", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "42", "@width": "188", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1425", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "43", "@width": "373", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1808", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "240", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1106", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "77", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "411", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "109", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "514", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "40", "@width": "115", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "697", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "22", "@width": "123", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "706", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "112", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "622", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "40", "@width": "90", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "658", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "362", "@width": "489", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr10.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "23515", "@ref": "gr10", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "162", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr10.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2491", "@ref": "gr10", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "240", "@width": "464", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr11.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "32581", "@ref": "gr11", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "113", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr11.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4690", "@ref": "gr11", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "697", "@width": "733", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr12.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "74819", "@ref": "gr12", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "163", "@width": "172", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr12.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4558", "@ref": "gr12", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "1015", "@width": "719", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr13.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "111465", "@ref": "gr13", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "116", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr13.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3784", "@ref": "gr13", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "124", "@width": "622", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "26125", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "44", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3530", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "396", "@width": "630", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "87592", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "138", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10119", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "293", "@width": "533", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "102298", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "121", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10532", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "218", "@width": "482", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "33689", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "99", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7108", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "200", "@width": "534", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62703", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "82", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6771", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "218", "@width": "375", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "42682", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "127", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6730", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "140", "@width": "355", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "19165", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "86", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3763", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "158", "@width": "356", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25647", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "97", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4639", "@ref": "gr9", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "200", "@width": "264", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "23228", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "217", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8606", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "137", "@width": "393", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-fx2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "19189", "@ref": "fx2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "76", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-fx2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4543", "@ref": "fx2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "701", "@width": "623", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "119696", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "146", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046411000694-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8126", "@ref": "gr1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/79959655291"}}
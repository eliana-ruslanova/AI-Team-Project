{"scopus-eid": "2-s2.0-84884569022", "originalText": "serial JL 272099 291210 291735 291838 291840 291848 31 80 Current Biology CURRENTBIOLOGY 2013-09-23 2013-09-23 2016-11-22T12:56:35 1-s2.0-S0960982213011111 S0960-9822(13)01111-1 S0960982213011111 10.1016/j.cub.2013.09.004 S300 S300.2 FULL-TEXT 1-s2.0-S0960982213X00181 2016-11-22T08:02:30.253931-05:00 0 0 20130923 2013 2013-09-23T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure body affil articletitle auth authfirstini authfull authlast primabst pubtype 0960-9822 09609822 false 23 23 18 18 Volume 23, Issue 18 1 R821 R823 R821 R823 20130923 23 September 2013 2013-09-23 2013 Magazine Feature simple-article nws Copyright \u00a9 2013 Published by Elsevier Ltd. All rights reserved. TOWARDSLIVINGMACHINES GROSS M Main Text Thinking and acting machines Hybrid machines Outlook GROSSX2013XR821 GROSSX2013XR821XR823 GROSSX2013XR821XM GROSSX2013XR821XR823XM Full 2014-09-23T00:28:34Z ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window item S0960-9822(13)01111-1 S0960982213011111 1-s2.0-S0960982213011111 10.1016/j.cub.2013.09.004 272099 2016-11-22T08:02:30.253931-05:00 2013-09-23 1-s2.0-S0960982213011111-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/MAIN/application/pdf/59d952dff41fb889538b58c51ce9e9d9/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/MAIN/application/pdf/59d952dff41fb889538b58c51ce9e9d9/main.pdf main.pdf pdf true 663353 MAIN 3 1-s2.0-S0960982213011111-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/PREVIEW/image/png/8ac258db74c848f3993a9536c72ce201/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/PREVIEW/image/png/8ac258db74c848f3993a9536c72ce201/main_1.png main_1.png png 84237 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0960982213011111-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr1/THUMBNAIL/image/gif/9fe2fcbd6d7654c09cd3fa0bda90a6bd/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr1/THUMBNAIL/image/gif/9fe2fcbd6d7654c09cd3fa0bda90a6bd/gr1.sml gr1 gr1.sml sml 33985 164 218 IMAGE-THUMBNAIL 1-s2.0-S0960982213011111-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr2/THUMBNAIL/image/gif/042635bf6bed00acb2834dd236e826cc/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr2/THUMBNAIL/image/gif/042635bf6bed00acb2834dd236e826cc/gr2.sml gr2 gr2.sml sml 26528 164 189 IMAGE-THUMBNAIL 1-s2.0-S0960982213011111-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr3/THUMBNAIL/image/gif/ee104f03aa379cc60bea0f34a695f558/gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr3/THUMBNAIL/image/gif/ee104f03aa379cc60bea0f34a695f558/gr3.sml gr3 gr3.sml sml 24787 146 219 IMAGE-THUMBNAIL 1-s2.0-S0960982213011111-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr1/DOWNSAMPLED/image/jpeg/dfd537421bf4a29480766a96c956bf1c/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr1/DOWNSAMPLED/image/jpeg/dfd537421bf4a29480766a96c956bf1c/gr1.jpg gr1 gr1.jpg jpg 53207 380 506 IMAGE-DOWNSAMPLED 1-s2.0-S0960982213011111-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr2/DOWNSAMPLED/image/jpeg/544b3afdf40887c081175c7966225df5/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr2/DOWNSAMPLED/image/jpeg/544b3afdf40887c081175c7966225df5/gr2.jpg gr2 gr2.jpg jpg 49985 439 506 IMAGE-DOWNSAMPLED 1-s2.0-S0960982213011111-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr3/DOWNSAMPLED/image/jpeg/365c7371813c4a9d66cdc598e0015401/gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr3/DOWNSAMPLED/image/jpeg/365c7371813c4a9d66cdc598e0015401/gr3.jpg gr3 gr3.jpg jpg 52951 338 506 IMAGE-DOWNSAMPLED 1-s2.0-S0960982213011111-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr1/HIGHRES/image/jpeg/23b0d4898f68b57ef589d226bad95f8e/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr1/HIGHRES/image/jpeg/23b0d4898f68b57ef589d226bad95f8e/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 148241 1009 1345 IMAGE-HIGH-RES 1-s2.0-S0960982213011111-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr2/HIGHRES/image/jpeg/1905edf5c27db8b829ead69c3239ce8f/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr2/HIGHRES/image/jpeg/1905edf5c27db8b829ead69c3239ce8f/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 443912 1946 2241 IMAGE-HIGH-RES 1-s2.0-S0960982213011111-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0960982213011111/gr3/HIGHRES/image/jpeg/ed1aa73a5074b5f69d5748fcdbf8ca20/gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0960982213011111/gr3/HIGHRES/image/jpeg/ed1aa73a5074b5f69d5748fcdbf8ca20/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 395021 1497 2241 IMAGE-HIGH-RES CURBIO 10612 S0960-9822(13)01111-1 10.1016/j.cub.2013.09.004 Feature Towards living machines Michael Gross Michael Gross is a science writer based at Oxford. He can be contacted via his web page at www.michaelgross.co.uk Summary Progress in biomimetic technology and the production of biohybrid techniques converges towards autonomous, more convincingly life-like systems and novel medical applications. Michael Gross reports. Main Text W. Grey Walter (1910\u20131977), a US-born neurophysiologist and EEG specialist at Bristol, UK, made important contributions to the neurosciences, but he is best remembered for a sideline activity, building robots. In an effort to show that extremely simple artificial brains can generate complex behaviour, Walter built two mechanical tortoises known as Elmer and Elsie in 1948\u20131949. The three-wheeled machines, which Walter called Machina Speculatrix, initially only had two \u2018neurons\u2019, enabling them to display phototactic behaviour. In later versions, Walter added a memory and a microphone and conducted Pavlovian experiments in which the machine was conditioned to associate specific sounds with rewards. As historian Andrew Pickering from the University of Exeter explained in the opening lecture of the recent Living Machines conference at the Natural History Museum in London, Walter\u2019s tortoises hold an important position in the history of cybernetics, as they show the brain as an acting machine, not just a thinking machine. Efforts to imitate nature, Pickering elaborated, can produce very different results depending on which role of a biological system one decides to focus on. Mimicking only the thinking role of the brain, one can get artificial intelligence (AI) or chess-playing algorithms. Copying only mechanics gives us production-line robots and autonomous vacuum cleaners. However, if researchers can make artificial brains that actively engage with their environment, perceiving, thinking, and acting, then the result could be convincingly life-like, a true \u2018living machine\u2019. Thinking and acting machines The Convergent Science Network of biomimetic and biohybrid systems organises the Living Machines conferences, and the proceedings of the London meeting are available in book form (N. Lepora et al., eds., Biomimetic and Biohybrid Systems, Springer, 2013). The key idea behind the network and the meetings is to combine approaches from the biomimetic field, including machines that think, act, or do both, with hybrid approaches merging biological and artificial elements to novel functional units. In short, to make all boundaries between biology and technology disappear. At one extreme, these developments will produce androids of a sophistication hitherto only seen in science fiction. Researchers, such as Vasiliki Vouloutsi from the Universitat Pompeu Fabra in Barcelona, are already working on optimising the social behaviour of humanoid robots to enable them to fit in when it comes to the stage where they become part of our everyday lives. Vouloutsi and her colleagues are members of the European EFAA (Experimental Functional Android Assistant) project, which has developed a model of social behaviour for robots based on emotions and drives. The main goals they set for the robot\u2019s behaviour were survival, security, play, exploration and interaction with people. Its drives are designed to optimise these goals, and each drive has a regulation mechanism aiming to return it to the optimal level. There is also a higher level of control to select a course of action in case different drives have competing interests. Vouloutsi and colleagues implemented this concept with the established humanoid robot iCub, using an interactive table known as Reactable allowing the robot to play games with human companions. Typically, the robot might look around for humans to interact with, then communicate with them or play games. It can demonstrate negative emotions like fear or disgust, for instance when it is grabbed unexpectedly or when there is a confusing multitude of objects on the Reactable. The iCub robot displays emotions with the help of its facial features, making its social interactions appear almost human. Given our tendency to recognise human-like features and behaviours in non-human agents from cartoon characters to pets, it is not difficult to imagine such \u2018social robots\u2019 getting a job at a customer helpdesk quite soon. Mechanical tortoise: A replica of W. Grey Walter\u2019s 1951 robot Machina Speculatrix, incorporating several original parts, but without the perspex shell responsible for the tortoise nickname, built by Ian Horsfield and Owen Holland in the Bristol Robotics Lab. (Photo: Alan Winfield.) I Robot: Vasiliki Vouloutsi delivering a talk at the Living Machines meeting at the Natural History Museum, London, with a slide showing the iCub robot used in her research. (Photo: Michael Gross.) Using the same iCub robot system, and also as part of the EFAA project, Gregoire Pointeau and colleagues at INSERM\u2019s Robot Cognition Laboratory at Bron, near Lyon, France, have studied how humanoid robots can use mental models of the world. Specifically, the authors showed that a forward model, in which the robot mentally plays out the action it takes, enables it to check whether the planned action, e.g. moving an object to a different location, was successful by comparing the anticipated change in its mental model to the reality it observes. Any mismatch would suggest that the action failed and the robot could try again. The researchers also used this mechanism to show that a robot can take into account the state of mind of other agents, as exemplified in the Sally\u2013Anne task, often used to test theory of mind in children. (Sally puts her ball in a basket, leaves the room, Anne moves ball to a box. Child is asked where Sally would look for her ball on her return.) By redefining the robot\u2019s forward model to register only events that Sally witnessed in the room, they enabled the robot to take a different person\u2019s perspective. Of course, the robot only takes this perspective because it has been specifically instructed to do so. The harder part is to recognise when perspective-taking is required, and to activate it autonomously. \u201cWe are currently working to automatically attribute to each recognized agent its beliefs, using only a single \u2018extra\u2019 mental world that we adapt to take any of these perspectives,\u201d Pointeau explains. \u201cThe first step is to identify different individual agents. For now, we can do this based on their names, and the underlying principal of our work on mental models will apply.\u201d In the meantime, biomimetic research aiming to mimic mainly sensorimotor functions of living beings is alive and kicking, crawling, climbing, swimming\u2026 Several groups have developed a range of climbing robots inspired by the mechanics of animals including spiders. Jian Chen and colleagues from the University of Hamburg, Germany, have added a mechanical caterpillar to this bestiary. Their modular robot built of seven segments measures just under eight centimetres when fully extended. It follows a very simple set of instructions: 1) lift the tail; 2) propagate the hump; 3) stretch out the front. Using passive suckers to attach its feet to a substrate, the caterpillar robot can even climb up vertical windowpanes. A deceptively simple-looking natural motion that still poses challenges for biomimetic research is the swimming of fish. Marc Ziegler and Rolf Pfeifer from the University of Zurich, Switzerland, have built a fish robot that has only one degree of freedom, namely the flapping of its tail fin. Nevertheless, they can show that by adjusting the elasticity of the fin, the fish can perform all movements required to swim in any direction. Hybrid machines While biomimetic research just takes its inspiration from nature, the biohybrid approach involves borrowing functional elements, from proteins up to entire organisms, and incorporating them into an artificial context. The approach isn\u2019t fundamentally different from historical machinery using horses or oxen as energy source, but nowadays the merging of biology and technology is more likely to operate on much smaller scales, down to the nanometre scale. Turning the idea around, implants that function in a biological context can also be described as biohybrids. A long-established and highly successful bio-electronic device of the latter kind is the cochlear implant used to treat hearing loss. Pacemakers and the emerging prospect of an artificial retina are other medical implants that fall in this category. As for the application of biological functions in a man-made context, the use of biomolecules in devices such as biosensors has already become commonplace. Challenges remain for the incorporation of larger biological units, from cells to organisms, into interactive devices. Some research groups have used mammalian muscle fibres as microscale actuators in hybrid devices. However, the mammalian cells are quite demanding in terms of the environmental conditions they need to function. Even at physiological temperature and with frequent replacements of the medium, rat muscle can only be kept functional for around two weeks. Therefore, Keisuke Morishima and colleagues from Osaka University, Japan, are advocating the use of insect muscle instead. They developed a biohybrid microrobot driven by the dorsal vessel muscle from the inchworm Ctenoplusia agnata. Their experimental results show that this tissue remains functional at a wide range of temperatures from 5 to 35\u00b0C for around three months, and there is no need to replace the medium (PLoS One (2012) 7, e38274.). The Osaka researchers attached the tissue to a pantograph-shaped lattice made of polydimethylsiloxane (PDMS) equipped with legs at each corner, 4.2 millimetres long and 3.0 millimetres wide. The basic idea is that contraction of the muscle tissue distorts the parallelograms of this structure and thus shortens its overall length. By adding directionality to the design of the legs, such that the hind legs stick when the structure expands and the front legs stick when it contracts, the microrobot can be made to walk in steps of around 66 micrometres. As yet, the experimental results fall behind what could theoretically be achieved, but the authors are confident that further improvements will enhance the performance of the microrobot, e.g. by optimising the leg design and the attachment of the tissue to the PDMS structure. One of the attractions of this biohybrid system is that its activity can be controlled chemically via the concentration of the arthropod hormone CCAP (crustacean cardio-active peptide). The group has also demonstrated that the activity of the analogous tissue in living flies can be controlled optogenetically via channelrhodopsin, opening up the prospect of light-controlled biohybrid microrobots. An example of a biohybrid interaction at the whole organism level is the recent development of exoskeletons for patients with movement impairments. Several such devices are already available, including one which can be controlled by the user\u2019s thoughts, as it is coupled to detectors picking up the relevant brainwaves. As yet, such devices are mechanically more primitive than healthy human legs, but they are already beginning to become useful for experimental rehabilitation programmes and even for mobility of patients who would otherwise be confined to wheelchairs. Bio tech: The artist Edouard Martinet assembles strikingly natural-looking sculptures of insects and other animals from discarded scraps of metal. Similarly, research in the field of biohybrid systems is now blurring the boundaries between biology and technology. (Photo: Ian Sanderson. Courtesy of Sladmore Contemporary, London http://www.edouardmartinet.net/). Hybridisation can still go one level higher and operate at the level of society. Arguably, this may happen to us one day, when versatile humanoid robots are beginning to take over our jobs, but at the moment, a new research project is looking to explore the workings of \u2018hybridised\u2019 animal societies using the examples of bees and fish. The ASSISI (Animal and robot Societies Self-organise and Integrate by Social Interaction) project is funded under the EU\u2019s FP7 programme and involves research groups from Portugal, France, Germany, Switzerland, Austria and Croatia. Looking at bee society with robotic guests, the project focuses on the complex communication structures within bee society. Because of the hardware necessary for this, the robot bees can\u2019t actually fly, they are just computational nodes sitting on a grid and communicating with the real bees. The situation is different for the fish part of the project, as in fish shoals the movement and positioning of individuals is very important, so the robotic fish will be able to swim with their natural hosts. Another project presented at the conference by Stuart Wilson from the University of Sheffield, UK, involves the introduction of artificial littermates for newborn rats, in order to study their emerging social behaviour. Outlook Life-like robots and sophisticated biohybrids have so far remained a staple of science fiction, a hallmark of a future that has always been beyond the horizon. But maybe the androids imagined so often are now really coming closer to our everyday lives. The impending care crisis for the fast-growing elderly population in the rich world is most likely to be addressed with robotic help at some point. And maybe supermarket customers will eventually prefer a robotic checkout assistant to having no help at all and doing the shop\u2019s work by themselves. More importantly, perhaps, by learning to merge biology and technology, scientists will also come up with new medical devices helping to replace failing organs and tissues, offering real help to patients with problems that are as yet untreatable. What arguably started with one man building toy tortoises may very soon become quite useful for society.", "scopus-id": "84884569022", "pubmed-id": "24199226", "coredata": {"eid": "1-s2.0-S0960982213011111", "dc:description": "Summary Progress in biomimetic technology and the production of biohybrid techniques converges towards autonomous, more convincingly life-like systems and novel medical applications. Michael Gross reports.", "openArchiveArticle": "true", "prism:coverDate": "2013-09-23", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0960982213011111", "dc:creator": {"@_fa": "true", "$": "Gross, Michael"}, "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0960982213011111"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0960982213011111"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0960-9822(13)01111-1", "prism:volume": "23", "prism:publisher": "Published by Elsevier Ltd.", "dc:title": "Towards living machines", "prism:copyright": "Copyright \u00a9 2013 Published by Elsevier Ltd. All rights reserved.", "openaccess": "1", "prism:issn": "09609822", "prism:issueIdentifier": "18", "openaccessArticle": "true", "prism:publicationName": "Current Biology", "prism:number": "18", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "R821-R823", "prism:endingPage": "R823", "pubType": "Feature", "prism:coverDisplayDate": "23 September 2013", "prism:doi": "10.1016/j.cub.2013.09.004", "prism:startingPage": "R821", "dc:identifier": "doi:10.1016/j.cub.2013.09.004", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "164", "@width": "218", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "33985", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "189", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "26528", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "146", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "24787", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "380", "@width": "506", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "53207", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "439", "@width": "506", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "49985", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "338", "@width": "506", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "52951", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1009", "@width": "1345", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "148241", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1946", "@width": "2241", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "443912", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1497", "@width": "2241", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0960982213011111-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "395021", "@ref": "gr3", "@mimetype": "image/jpeg"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84884569022"}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608009000690", "dc:identifier": "doi:10.1016/j.neunet.2009.04.005", "eid": "1-s2.0-S0893608009000690", "prism:doi": "10.1016/j.neunet.2009.04.005", "pii": "S0893-6080(09)00069-0", "dc:title": "Another look at statistical learning theory and regularization ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "22", "prism:issueIdentifier": "7", "prism:startingPage": "958", "prism:endingPage": "969", "prism:pageRange": "958-969", "prism:number": "7", "dc:format": "application/json", "prism:coverDate": "2009-09-30", "prism:coverDisplayDate": "September 2009", "prism:copyright": "Copyright \u00a9 2009 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Cherkassky, Vladimir"}, {"@_fa": "true", "$": "Ma, Yunqian"}], "dc:description": "\n               Abstract\n               \n                  The paper reviews and highlights distinctions between function-approximation (FA) and VC theory and methodology, mainly within the setting of regression problems and a squared-error loss function, and illustrates empirically the differences between the two when data is sparse and/or input distribution is non-uniform. In FA theory, the goal is to estimate an unknown true dependency (or \u2018target\u2019 function) in regression problems, or posterior probability \n                        P\n                        \n                           (\n                           y\n                           /\n                           \n                              x\n                           \n                           )\n                        \n                      in classification problems. In VC theory, the goal is to \u2018imitate\u2019 unknown target function, in the sense of minimization of prediction risk or good \u2018generalization\u2019. That is, the result of VC learning depends on (unknown) input distribution, while that of FA does not. This distinction is important because regularization theory originally introduced under clearly stated FA setting [Tikhonov, N. (1963). On solving ill-posed problem and method of regularization. Doklady Akademii Nauk USSR, 153, 501\u2013504; Tikhonov, N., & V. Y. Arsenin (1977). Solution of ill-posed problems. Washington, DC: W. H. Winston], has been later used under risk-minimization or VC setting. More recently, several authors [Evgeniou, T., Pontil, M., & Poggio, T. (2000). Regularization networks and support vector machines. Advances in Computational Mathematics, 13, 1\u201350; Hastie, T., Tibshirani, R., & Friedman, J. (2001). The elements of statistical learning: Data mining, inference and prediction. Springer; Poggio, T. and Smale, S., (2003). The mathematics of learning: Dealing with data. Notices of the AMS, 50 (5), 537\u2013544] applied constructive methodology based on regularization framework to learning dependencies from data (under VC-theoretical setting). However, such regularization-based learning is usually presented as a purely constructive methodology (with no clearly stated problem setting). This paper compares FA/regularization and VC/risk minimization methodologies in terms of underlying theoretical assumptions. The control of model complexity, using regularization and using the concept of margin in SVMs, is contrasted in the FA and VC formulations.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Function approximation"}, {"@_fa": "true", "$": "Statistical model estimation"}, {"@_fa": "true", "$": "Model identification"}, {"@_fa": "true", "$": "Penalization"}, {"@_fa": "true", "$": "Predictive learning"}, {"@_fa": "true", "$": "Regularization"}, {"@_fa": "true", "$": "Ridge regression"}, {"@_fa": "true", "$": "Structural risk minimization"}, {"@_fa": "true", "$": "SVM regression"}, {"@_fa": "true", "$": "VC-theory"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608009000690", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608009000690", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "69449099786", "scopus-eid": "2-s2.0-69449099786", "pubmed-id": "19443179", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/69449099786", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20090422", "$": "2009-04-22"}}}}}
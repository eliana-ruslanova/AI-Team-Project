{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608012002936", "dc:identifier": "doi:10.1016/j.neunet.2012.11.007", "eid": "1-s2.0-S0893608012002936", "prism:doi": "10.1016/j.neunet.2012.11.007", "pii": "S0893-6080(12)00293-6", "dc:title": "Autonomous reinforcement learning with experience replay ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2013 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "41", "prism:startingPage": "156", "prism:endingPage": "167", "prism:pageRange": "156-167", "dc:format": "application/json", "prism:coverDate": "2013-05-31", "prism:coverDisplayDate": "May 2013", "prism:copyright": "Copyright \u00a9 2012 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "Special Issue on Autonomous Learning", "dc:creator": [{"@_fa": "true", "$": "Wawrzy\u0144ski, Pawe\u0142"}, {"@_fa": "true", "$": "Tanwani, Ajay Kumar"}], "dc:description": "\n               Abstract\n               \n                  This paper considers the issues of efficiency and autonomy that are required to make reinforcement learning suitable for real-life control tasks. A real-time reinforcement learning algorithm is presented that repeatedly adjusts the control policy with the use of previously collected samples, and autonomously estimates the appropriate step-sizes for the learning updates. The algorithm is based on the actor\u2013critic with experience replay whose step-sizes are determined on-line by an enhanced fixed point algorithm for on-line neural network training. An\u00a0experimental study with simulated octopus arm and half-cheetah demonstrates the feasibility of the proposed algorithm to solve difficult learning control problems in an autonomous way within reasonably short time.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Reinforcement learning"}, {"@_fa": "true", "$": "Autonomous learning"}, {"@_fa": "true", "$": "Step-size estimation"}, {"@_fa": "true", "$": "Actor\u2013critic"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608012002936", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608012002936", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84875884428", "scopus-eid": "2-s2.0-84875884428", "pubmed-id": "23237972", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84875884428", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20121128", "$": "2012-11-28"}}}}}
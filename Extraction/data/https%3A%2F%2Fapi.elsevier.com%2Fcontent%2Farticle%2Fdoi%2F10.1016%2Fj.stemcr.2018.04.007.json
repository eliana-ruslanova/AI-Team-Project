{"scopus-eid": "2-s2.0-85046781959", "originalText": "serial JL 286331 291210 291850 291852 291854 291858 31 90 Stem Cell Reports STEMCELLREPORTS 2018-05-10 2018-05-10 2018-06-05 2018-06-05 2020-03-06T20:54:22 1-s2.0-S2213671118301759 S2213-6711(18)30175-9 S2213671118301759 10.1016/j.stemcr.2018.04.007 S300 S300.3 FULL-TEXT 1-s2.0-S2213671117X00040 2020-03-06T21:23:38.378294Z 0 0 20180605 2018 2018-05-10T15:40:26.105169Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure e-component body acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor grantsponsorid highlightsabst misctext primabst pubtype ref specialabst teaserabst 2213-6711 22136711 UNLIMITED NONE true 10 10 6 6 Volume 10, Issue 6 3 1687 1695 1687 1695 20180605 5 June 2018 2018-06-05 2018 Reports article sco \u00a9 2018 The Author(s). AUTOMATEDDEEPLEARNINGBASEDSYSTEMIDENTIFYENDOTHELIALCELLSDERIVEDINDUCEDPLURIPOTENTSTEMCELLS KUSUMOTO D Introduction Results Development of an Automated System to Identify Endothelial Cells Improvement of F1 Score and Accuracy by Optimization Effect of Network Size on Predictive Power K-Fold Cross-Validation Discussion Experimental Procedures iPSC Culture Endothelial Cell Differentiation Flow Cytometry Immunocytochemistry Preparation of Datasets Deep Neural Networks Performance Evaluation Author Contributions Acknowledgments Supplemental Information References ADAMS 2007 464 478 R AVIOR 2016 170 182 Y BENGIO 2006 153 160 Y PROCEEDINGS19THINTERNATIONALCONFERENCENEURALINFORMATIONPROCESSINGSYSTEMS GREEDYLAYERWISETRAININGDEEPNETWORKS BUGGENTHIN 2017 403 406 F CHEN 2016 333 349 I ESTEVA 2017 115 118 A GORODESKI 2011 521 532 E GULSHAN 2016 2402 2410 V HEYLMAN 2015 e0144572 C HINTON 2006 1527 1554 G HSICH 2011 39 45 E HU 2010 4335 4340 B IOFFE 2015 S KRIZHEVSKY 2012 1097 1105 A PROCEEDINGS25THINTERNATIONALCONFERENCENEURALINFORMATIONPROCESSINGSYSTEMS IMAGENETCLASSIFICATIONDEEPCONVOLUTIONALNEURALNETWORKS LECUN 2015 436 444 Y LECUN 1998 2278 2324 Y LINDBLOM 2003 1835 1840 P MCCULLOCH 1943 115 133 W NIIOKA 2018 87 93 H OSAFUNE 2008 313 315 K PATSCH 2015 994 1003 C SIMONYAN 2014 K SZEGEDY 2014 C TAKAHASHI 2006 663 676 K TAKAKURA 2000 199 209 N TANAKA 2014 e001263 A VANVALEN 2016 e1005177 D YUASA 2008 A49 A55 S ZENG 2016 X KUSUMOTOX2018X1687 KUSUMOTOX2018X1687X1695 KUSUMOTOX2018X1687XD KUSUMOTOX2018X1687X1695XD Full 2018-04-16T08:29:45Z Author http://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license. \u00a9 2018 The Author(s). 2019-04-07T00:53:56.820Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp S2213671118301759 JSPS 16K15415 16H05304 Japan Society for the Promotion of Science http://data.elsevier.com/vocabulary/SciValFunders/501100001691 http://sws.geonames.org/1861060/ Keio University Medical Science Fund SENSHIN Medical Research Foundation SENSHIN Medical Research Foundation http://data.elsevier.com/vocabulary/SciValFunders/501100008667 http://sws.geonames.org/1861060/ Suzuken Memorial Foundation Suzuken Memorial Foundation http://data.elsevier.com/vocabulary/SciValFunders/100007434 http://sws.geonames.org/1861060/ We thank all of our laboratory members for assistance. This research was supported by Grants-in-Aid for Scientific Research (JSPS KAKENHI grant numbers 16H05304 and 16K15415 ), by SENSHIN Medical Research Foundation , by Suzuken Memorial Foundation , and by Keio University Medical Science Fund . K.F. is a co-founder of and has equity in Heartseed. T.K. is an employee of Sony Imaging Products & Solutions. item S2213-6711(18)30175-9 S2213671118301759 1-s2.0-S2213671118301759 10.1016/j.stemcr.2018.04.007 286331 2020-03-06T21:23:38.378294Z 2018-06-05 UNLIMITED NONE 1-s2.0-S2213671118301759-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/MAIN/application/pdf/5978756fa6bfd1675d111dc525adc8a7/main.pdf main.pdf pdf true 2052267 MAIN 9 1-s2.0-S2213671118301759-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/PREVIEW/image/png/4346a3db422d932d2c18b3f8a67c71a8/main_1.png main_1.png png 91781 849 656 IMAGE-WEB-PDF 1 1-s2.0-S2213671118301759-fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/fx1/DOWNSAMPLED/image/jpeg/a971b5654bb95b6f3a9cc91093d01267/fx1.jpg fx1 true fx1.jpg jpg 51624 375 375 IMAGE-DOWNSAMPLED 1-s2.0-S2213671118301759-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr1/DOWNSAMPLED/image/jpeg/bbf21fd345cf8ec8be499329af84b079/gr1.jpg gr1 gr1.jpg jpg 133123 751 657 IMAGE-DOWNSAMPLED 1-s2.0-S2213671118301759-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr2/DOWNSAMPLED/image/jpeg/0f5017a59e432c7d83dfed230890c225/gr2.jpg gr2 gr2.jpg jpg 149481 740 657 IMAGE-DOWNSAMPLED 1-s2.0-S2213671118301759-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr3/DOWNSAMPLED/image/jpeg/d71e768f2ae14d6bd6167707bf365b3c/gr3.jpg gr3 gr3.jpg jpg 203705 955 744 IMAGE-DOWNSAMPLED 1-s2.0-S2213671118301759-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr4/DOWNSAMPLED/image/jpeg/1cd7e05cfcda7d027ff5a195fc540bc1/gr4.jpg gr4 gr4.jpg jpg 63422 406 506 IMAGE-DOWNSAMPLED 1-s2.0-S2213671118301759-fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/fx1/THUMBNAIL/image/gif/d74f0d1a62d8643ab7d8176959a48224/fx1.sml fx1 true fx1.sml sml 12450 164 164 IMAGE-THUMBNAIL 1-s2.0-S2213671118301759-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr1/THUMBNAIL/image/gif/9249bdfdc85bf9f7ba96bb9be9d4a207/gr1.sml gr1 gr1.sml sml 9332 163 143 IMAGE-THUMBNAIL 1-s2.0-S2213671118301759-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr2/THUMBNAIL/image/gif/575b388b3fbc41cf989cd0ce21a3eb54/gr2.sml gr2 gr2.sml sml 10043 163 145 IMAGE-THUMBNAIL 1-s2.0-S2213671118301759-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr3/THUMBNAIL/image/gif/b3a9a09ca0922c6508ac5a6120aa20e7/gr3.sml gr3 gr3.sml sml 9785 163 127 IMAGE-THUMBNAIL 1-s2.0-S2213671118301759-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr4/THUMBNAIL/image/gif/09688d028c6338c105030cc6dd7f0456/gr4.sml gr4 gr4.sml sml 10338 164 204 IMAGE-THUMBNAIL 1-s2.0-S2213671118301759-fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/fx1/HIGHRES/image/jpeg/b24795e32fd7f4a8ae136fd54c0ac70d/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 219565 996 996 IMAGE-HIGH-RES 1-s2.0-S2213671118301759-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr1/HIGHRES/image/jpeg/c81f68a19088dea4acf04dbf327adc37/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 1120833 3322 2908 IMAGE-HIGH-RES 1-s2.0-S2213671118301759-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr2/HIGHRES/image/jpeg/168ed6e28aea6c8f78aee57d4cb9162b/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 1142900 3279 2911 IMAGE-HIGH-RES 1-s2.0-S2213671118301759-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr3/HIGHRES/image/jpeg/988989239ff35085322b445145f9272c/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 1993471 4229 3294 IMAGE-HIGH-RES 1-s2.0-S2213671118301759-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/gr4/HIGHRES/image/jpeg/9b104237c944f3ef893a143d08c1cb4d/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 488810 1799 2242 IMAGE-HIGH-RES 1-s2.0-S2213671118301759-mmc1.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/mmc1/MAIN/application/pdf/620f407a69d744ef2509c5747de37213/mmc1.pdf mmc1 mmc1.pdf pdf false 9379304 APPLICATION 1-s2.0-S2213671118301759-mmc2.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2213671118301759/mmc2/MAIN/application/pdf/7a2f470c1704bccd6682ff7edacf8a43/mmc2.pdf mmc2 mmc2.pdf pdf false 11434122 APPLICATION STEMCR 1058 S2213-6711(18)30175-9 10.1016/j.stemcr.2018.04.007 The Author(s) Figure 1 Analysis of Induced Pluripotent Stem Cell-Derived Endothelial Cells Using Convolutional Neural Networks (A) Training protocol. Input blocks were extracted from phase-contrast images and predicted by networks to be unstained (0) or stained (1) for CD31. Target blocks containing single cells were extracted from immunofluorescent images of the same field, binarized based on CD31 staining, and classified as stained or unstained based on the ratio of white pixels to black. Network weights were then automatically and iteratively adjusted to maximize agreement between predicted and observed classification. Scale bars, 400 \u03bcm (upper panels), 5 \u03bcm (middle panels), and 80 \u03bcm (bottom panels). (B) Optimization of experimental parameters to maximize F1 score and accuracy. (C) Two hundred images each were obtained from four independent experiments. Images were randomized at 80:20 ratio into training and evaluation sets, and 200 blocks were randomly extracted from each image. Figure 2 Dataset Adjustment (A) F1 score and accuracy as a function of number of input blocks. Left: network performance using 128 \u00d7 128-pixel (px) input blocks and 128 \u00d7 128-px target blocks. Right: performance using 512 \u00d7 512-px input blocks and 32 \u00d7 32-px target blocks. (B and C) F1 score as a function of input block size and staining threshold. The optimal threshold is boxed in red and the optimal input block size is boxed in blue. (D) Average F1 score for different input block sizes. (E) F1 score for different target block sizes. See also Figure S2 and Tables S1\u2013S3. Figure 3 Network Optimization (A) Comparison of LeNet and AlexNet, which are small and large deep neural networks. (B) F1 score learning curves from the small and large network. (C) Representative true positive, false positive, true negative, and false negative images. Scale bars, 80 \u03bcm. (D) Immunofluorescent images were binarized automatically, or rebinarized by manual comparison of raw fluorescent images to phase-contrast images. Scale bars, 100 \u03bcm. (E) F1 score and accuracy were compared following training of the small and large network on automatically binarized or rebinarized target blocks. See also Figures S3 and S4; Table S4. Figure 4 K-Fold Cross-Validation (A) K-fold cross-validation based on four independent datasets, of which three were used for training and one was used for validation, in all possible combinations. (B) K-fold cross-validation was performed using the small network trained on automatically binarized target blocks, and using the large network trained on rebinarized target blocks. Data are macro averaged F1 score and accuracy. (C) Detailed K-fold cross-validation data. See also Table S4. Report Automated Deep Learning-Based System to Identify Endothelial Cells Derived from Induced Pluripotent Stem Cells Dai Kusumoto 1 2 4 Mark Lachmann 1 4 Takeshi Kunihiro 3 4 Shinsuke Yuasa 1 \u2217 yuasa@keio.jp Yoshikazu Kishino 1 Mai Kimura 1 Toshiomi Katsuki 1 Shogo Itoh 1 Tomohisa Seki 1 2 Keiichi Fukuda 1 1 Department of Cardiology, Keio University School of Medicine, 35 Shinanomachi, Shinjuku-ku, Tokyo 160-8582, Japan Department of Cardiology Keio University School of Medicine 35 Shinanomachi Shinjuku-ku Tokyo 160-8582 Japan 2 Department of Emergency and Critical Care Medicine, Keio University School of Medicine, Tokyo 160-8582, Japan Department of Emergency and Critical Care Medicine Keio University School of Medicine Tokyo 160-8582 Japan 3 LE Development Department, R&D Division, Medical Business Group, Sony Imaging Products & Solutions Inc., 4-14-1 Asahi-cho, Atsugi-shi, Kanagawa 243-0014, Japan LE Development Department R&D Division Medical Business Group Sony Imaging Products & Solutions Inc. 4-14-1 Asahi-cho Atsugi-shi Kanagawa 243-0014 Japan \u2217 Corresponding author 4 Co-first author Published: May 10, 2018 Summary Deep learning technology is rapidly advancing and is now used to solve complex problems. Here, we used deep learning in convolutional neural networks to establish an automated method to identify endothelial cells derived from induced pluripotent stem cells (iPSCs), without the need for immunostaining or lineage tracing. Networks were trained to predict whether phase-contrast images contain endothelial cells based on morphology only. Predictions were validated by comparison to immunofluorescence staining for CD31, a marker of endothelial cells. Method parameters were then automatically and iteratively optimized to increase prediction accuracy. We found that prediction accuracy was correlated with network depth and pixel size of images to be analyzed. Finally, K-fold cross-validation confirmed that optimized convolutional neural networks can identify endothelial cells with high performance, based only on morphology. Graphical Abstract Highlights \u2022 Neural networks were trained to spot endothelial cells on phase-contrast images \u2022 Performance was correlated with network depth and pixel size of training images \u2022 Optimized networks identify endothelial cells with high accuracy Kusumoto et al. developed an automated system to identify endothelial cells derived from induced pluripotent stem cells, based only on morphology. Performance, as assessed by F1 score and accuracy, was correlated with network depth and pixel size of training images. K-fold validation confirmed that endothelial cells are identified automatically with high accuracy using only generalized morphological features. Keywords deep learning induced pluripotent stem cell endothelial cell artificial intelligence machine learning Introduction Machine learning consists of automated algorithms that enable learning from large datasets to resolve complex problems, including those encountered in medical science (Gorodeski et al., 2011; Heylman et al., 2015; Hsich et al., 2011). In deep learning, a form of machine learning, patterns from several types of data are automatically extracted (Lecun et al., 2015) to accomplish complex tasks such as image classification, which in conventional machine learning requires feature extraction by a human expert. Deep learning eliminates this requirement by identifying the most informative features using multiple layers in neural networks, i.e., deep neural networks (Hatipoglu and Bilgin, 2014), which were first conceived in the 1940s to mimic human neural circuits (McCulloch and Pitts, 1943). In such neural networks, each neuron receives weighted data from upstream neurons, which are then processed and transmitted to downstream neurons. Ultimately, terminal neurons calculate a predicted value based on processed data, and weights are then iteratively optimized to increase the agreement between predicted and observed values. This technique is rapidly advancing due to innovative algorithms and improved computing power (Bengio et al., 2006; Hinton et al., 2006). For example, convolutional neural networks have now achieved almost the same accuracy as a clinical specialist in diagnosing diabetic retinopathy and skin cancer (Esteva et al., 2017; Gulshan et al., 2016). Convolutional neural networks have also proved useful in cell biology such as morphological classification of hematopoietic cells, C2C12 myoblasts, and induced pluripotent stem cells (iPSCs) (Buggenthin et al., 2017; Niioka et al., 2018; Yuan-Hsiang et al., 2017). iPSCs, which can be established from somatic cells by expression of defined genes (Takahashi and Yamanaka, 2006), hold great promise in regenerative medicine (Yuasa and Fukuda, 2008), disease modeling (Tanaka et al., 2014), drug screening (Avior et al., 2016), and precision medicine (Chen et al., 2016). iPSCs can differentiate into numerous cell types, although differentiation efficiencies vary among cell lines and are sensitive to experimental conditions (Hu et al., 2010; Osafune et al., 2008). In addition, differentiated cell types are difficult to identify without molecular techniques such as immunostaining and lineage tracing. We hypothesized that phase-contrast images contain discriminative morphological information that can be used by a convolutional neural network to identify endothelial cells. Accordingly, we investigated whether deep learning techniques can be used to identify iPSC-derived endothelial cells automatically based only on morphology. Results Development of an Automated System to Identify Endothelial Cells We differentiated iPSCs as previously described (Patsch et al., 2015), obtaining mesodermal cells at around day 3 and specialized endothelial cells at around day 5 (Figure S1A). At day 6, structures that resemble vascular tubes were formed (Figure S1B). CD31 staining confirmed that endothelial cells were obtained at an efficiency of 20%\u201335%, as assessed by flow cytometry. Differentiation efficiency was strongly variable (Figure S1C), highlighting the need for an automated cell identification system to assess iPSC differentiation or to identify and quantify the cell types formed. The basic strategy to identify endothelial cells by convolutional neural networks is shown in Figure 1 A. In brief, differentiated iPSCs were imaged by phase contrast and by immunofluorescence staining for CD31, a marker of endothelial cells. The latter were then binarized into white and black pixels corresponding to raw pixels above and below a threshold value, respectively. Subsequently, input blocks were extracted randomly from phase-contrast images, and matching target blocks equivalent to or within input blocks were extracted from both phase-contrast and binarized immunofluorescence images. Binarized target blocks were then classified as unstained (0) or stained (1) depending on the ratio of white pixels to black, to generate answers. Finally, input blocks were analyzed in LeNet, a small network (Lecun et al., 1998), and AlexNet, a large network (Krizhevsky et al., 2012), to predict phase-contrast target blocks as unstained or stained. Predictions were compared with answers obtained from binarized target blocks, and weights were automatically and iteratively optimized to train the neural networks and thereby increase accuracy (Figure 1A). Networks were then optimized according to Figure 1B. Number of blocks, input block size, and target block size were first optimized using the small network, along with staining threshold, the ratio of white pixels to black for a target block to be classified as stained. To improve performance, as assessed by F1 score and accuracy, the small network was compared with the large network, observed errors were analyzed, and binarized target blocks were rebinarized by visual comparison of raw fluorescent images with phase-contrast images. Finally, the optimized network was validated by K-fold cross-validation (Figure 1B). To this end, we obtained 200 images from each of four independent experiments, of which 640 were used for training and 160 for validation to collect data shown in Figures 2 and 3 . From each image, 200 blocks were randomly extracted, and 500\u2013128,000 of the blocks were used for training while 32,000 blocks were used for validation (Figure 1C). Improvement of F1 Score and Accuracy by Optimization To train the networks we optimized several experimental conditions, including number of input blocks, target block size, and input block size. Performance was evaluated based on F1 scores, which aggregates recall and precision, and on accuracy, which is the fraction of correct predictions. As noted, we first used 500\u2013128,000 blocks for training (Figure 1C) to determine the number of blocks required to achieved convergence (Table S1). Inflection points in F1 scores and accuracy were observed at 16,000 blocks, and convergence was achieved at 32,000 blocks for an input and target block size of 128 \u00d7 128 pixels, as well as for an input block size of 512 \u00d7 512 pixels and a target block size of 32 \u00d7 32 pixels (Figure 2A). Hence, 32,000 blocks were used for training in subsequent experiments. Next, the optimal combination of block size and staining threshold was determined by input blocks of 32 \u00d7 32, 64 \u00d7 64, 128 \u00d7 128, 256 \u00d7 256, and 512 \u00d7 512 pixels. We note that 32 \u00d7 32-pixel blocks contained only single cells, while 512 \u00d7 512-pixel blocks contained entire colonies and surrounding areas (Figure S2A). Based on F1 scores, performance was best from an input block size of 512 \u00d7 512 pixels combined with a staining threshold of 0.3 (Figures 2B and 2C; Table S2). Both F1 score and accuracy increased with input block size (Figures 2D, S2B, and S2C), indicating that areas surrounding cells should be included to increase accuracy. In contrast, target block size did not affect predictive power (Figure 2E) or the correlation between input block size and F1 scores and accuracy (Figure S2D and Table S3). Effect of Network Size on Predictive Power As network architecture is critical to performance, we compared the predictive power of the small network LeNet (Lecun et al., 1998) after training on 128,000 blocks with that of the large network AlexNet (Krizhevsky et al., 2012) (Figure 3A). F1 scores and accuracy from the latter were higher (Figures 3B and S3A), suggesting that extraction of complex features by a large network improves cell identification by morphology. Performance was further enhanced by analyzing true positives, true negatives, false positives, and false negatives (Figures 3C and S3B). We found that true positives and true negatives were typically obtained in areas with uniformly distributed cells. In contrast, areas with heterogeneous appearance, such as at the border between abundantly and sparsely colonized surfaces, often led to false positives or false negatives. To examine whether F1 scores are influenced by heterogeneous appearance (Figure S4A), we scored the complexity of all 32,000 512 \u00d7 512-pixel validation blocks as the average difference between adjacent pixels, normalized to the dynamic range (Saha and Vemuri, 2000). Blocks with complexity of <0.04 were considered sparsely colonized, while blocks with complexity of 0.04 to 0.08 typically contained uniformly distributed cells with clear boundaries. All other images had complexity >0.08 and contained dense colonies with indistinct cell borders. In both the small and large networks (Figures S4B, S4C, and S4D), F1 scores were highest for blocks with complexity of 0.04 to 0.08 (typically 0.06), implying that variations in cell density and morphology affect network performance, in line with incorrect predictions as shown in Figures 3C and S3B. In light of this result, we speculated that weak staining, non-specific fluorescence, and autofluorescence in dense colonies may also degrade performance. Accordingly, we rebinarized target blocks by visual comparison with raw fluorescent images (Figure 3D). Following this step, 26,861 of 128,000 blocks (21%) were classified as stained, while fully automated binarization scored 40,852 of 128,000 blocks (32%) as stained (Table S4A). Notably, the F1 score and accuracy rose above 0.9 and 0.95, respectively, in the large network (Figure 3E and Table S4A). K-Fold Cross-Validation Finally, we assessed network performance and generalization by K-fold cross-validation, in which k subsets of data are divided into k \u2212 1 training datasets and one validation dataset. Training and validation are then performed k times using different combinations of training and validation datasets. In our case, 800 images were collected in four independent experiments, of which various combinations of 600 images from three experiments were used for training and 200 images from one experiment were used for validation (Figure 4 A). The F1 score and accuracy were approximately 0.7 and higher than 0.7 for the small network with automatically binarized target blocks, but over 0.75 and over 0.9, respectively, for the large network with rebinarized target blocks (Figures 4B and 4C; Table S4B). Discussion In this study, we demonstrated that deep learning techniques are effective in identifying iPSC-derived endothelial cells. Following optimization of parameters such as number of input blocks, target block size, input block size, staining threshold, and network size, we achieved satisfactory F1 scores and accuracy. Notably, we found that a larger input block increases prediction accuracy, indicating that the environment surrounding cells is an essential feature, as was also observed for differentiated C2C12 myoblasts (Niioka et al., 2018). We note that the immediate microenvironment is also an essential determinant of differentiation (Adams and Alitalo, 2007; Lindblom et al., 2003; Takakura et al., 2000), and that the positive correlation between input block size and F1 score or accuracy may prove helpful in future strategies to identify differentiated cells by morphology. In comparison with other machine learning techniques, deep learning is straightforward and achieves high accuracies. Indeed, deep learning algorithms have won the ImageNet Large-Scale Visual Recognition Challenge since 2012 (He et al., 2015; Krizhevsky et al., 2012; Szegedy et al., 2014; Zeng et al., 2016), and have also proved useful in cell biology (Buggenthin et al., 2017; Niioka et al., 2018; Van Valen et al., 2016; Yuan-Hsiang et al., 2017). Although we used the older-generation networks LeNet and AlexNet, newer networks achieve even better accuracy in image classification (Esteva et al., 2017; Gulshan et al., 2016). Several techniques, such as increasing network depth (Simonyan and Zisserman, 2014), residual learning (He et al., 2015), and batch normalization (Ioffe and Szegedy, 2015), may also enhance performance, although these were not implemented in this study, since results were already satisfactory. Inspection revealed some issues in binarizing heterogeneous areas in images with weak staining, non-specific fluorescence, and autofluorescence. To lower the number of false positives and improve performance, we rebinarized these images by comparing raw fluorescent images with phase-contrast images. In addition, cell density significantly affected F1 scores, implying that cells should be cultured carefully to a suitable density, or that networks should be trained to distinguish between true and false positives, especially when images are heterogeneous. Finally, K-fold cross-validation showed that iPSC-derived endothelial cells were identified with accuracy approximately 0.9 and F1 score 0.75, in line with similar attempts (Buggenthin et al., 2017; Niioka et al., 2018; Yuan-Hsiang et al., 2017). Importantly, the data show that iPSC-derived endothelial cells can be identified based on morphology alone, requiring only 100 \u03bcs per block in a small network and 275 \u03bcs per block in a large network (Figure S4E). As morphology-based identification does not depend on labeling, genetic manipulation, or immunostaining, it can be used for various applications requiring native, living cells. Thus, this system may enable analysis of large datasets and advance cardiovascular research and medicine. Experimental Procedures iPSC Culture iPSCs were maintained in mTeSR with 0.5% penicillin/streptomycin on culture dishes coated with growth factor-reduced Matrigel, and routinely passaged every week. Media were changed every other day. Detailed protocols are described in Supplemental Experimental Procedures. Endothelial Cell Differentiation iPSCs cultured on Matrigel-coated 6-well plates were enzymatically detached on day 7, and differentiated into endothelial cells as described in Supplemental Experimental Procedures. Flow Cytometry At day 6 of differentiation, cells were dissociated, stained with APC-conjugated anti-CD31, and sorted on BD FACSAria III. As a negative control, we used unstained cells. Detailed protocols are described in Supplemental Experimental Procedures. Immunocytochemistry At day 6 of differentiation, cells were fixed with 4% paraformaldehyde, blocked with ImmunoBlock, probed with primary antibodies to CD31, and labeled with secondary antibodies as described in Supplemental Experimental Procedures. Preparation of Datasets All phase-contrast and immunofluorescent images were acquired at day 6 of differentiation. Two hundred images were automatically obtained from each of four independent experiments. Of these, 640 were used for training and 160 were used for validation in Figures 2 and 3. For K-fold validation in Figure 4, 600 images from three experiments were used for training and 200 images from one experiment were used for validation, in all possible combinations. Datasets were constructed by randomly extracting 200 input blocks from each phase-contrast image. On the other hand, target blocks were extracted from binarized immunofluorescent images. Detailed procedures are described in Supplemental Experimental Procedures. Deep Neural Networks We used LeNet, a small network that contains two convolution layers, two max pooling layers, and two fully connected layers, as well as AlexNet, a large network that contains five convolution layers, three max pooling layers, and three fully connected layers. Network structures are shown in Figure 3A and Supplemental Experimental Procedures. Performance Evaluation Performance was evaluated based on F1 scores, an aggregate of recall and precision, and on accuracy, the fraction of correct predictions. Detailed information is provided in Supplemental Experimental Procedures. Author Contributions D.K., T. Kunihiro, and S.Y. designed experiments. D.K., M.L., T. Kunihiro, S.Y., Y.K., M.K., T. Katsuki, S.I., T.S., and K.F. collected data. D.K., M.L., and T. Kunihiro analyzed data. K.F. supervised the research. D.K. and S.Y. wrote the article. Acknowledgments We thank all of our laboratory members for assistance. This research was supported by Grants-in-Aid for Scientific Research (JSPS KAKENHI grant numbers 16H05304 and 16K15415), by SENSHIN Medical Research Foundation, by Suzuken Memorial Foundation, and by Keio University Medical Science Fund. K.F. is a co-founder of and has equity in Heartseed. T.K. is an employee of Sony Imaging Products & Solutions. Supplemental Information Supplemental Information includes Supplemental Experimental Procedures, four figures, and four tables and can be found with this article online at https://doi.org/10.1016/j.stemcr.2018.04.007. Supplemental Information Document S1.Supplemental Experimental Procedures, Figures S1\u2013S4, and Tables S1\u2013S4 Document S2. Article plus Supplemental Information References Adams and Alitalo, 2007 R.H. Adams K. Alitalo Molecular regulation of angiogenesis and lymphangiogenesis Nat. Rev. Mol. Cell Biol. 8 2007 464 478 Avior et al., 2016 Y. Avior I. Sagi N. Benvenisty Pluripotent stem cells in disease modelling and drug discovery Nat. Rev. Mol. Cell Biol. 17 2016 170 182 Bengio et al., 2006 Y. Bengio P. Lamblin D. Popovici H. Larochelle Greedy layer-wise training of deep networks B. Sch\u00f6lkopf J.C. Platt T. Hoffman Proceedings of the 19th International Conference on Neural Information Processing Systems 2006 MIT Press 153 160 Buggenthin et al., 2017 F. Buggenthin F. Buettner P.S. Hoppe M. Endele M. Kroiss M. Strasser M. Schwarzfischer D. Loeffler K.D. Kokkaliaris O. Hilsenbeck Prospective identification of hematopoietic lineage choice by deep learning Nat. Methods 14 2017 403 406 Chen et al., 2016 I.Y. Chen E. Matsa J.C. Wu Induced pluripotent stem cells: at the heart of cardiovascular precision medicine Nat. Rev. Cardiol. 13 2016 333 349 Esteva et al., 2017 A. Esteva B. Kuprel R.A. Novoa J. Ko S.M. Swetter H.M. Blau S. Thrun Dermatologist-level classification of skin cancer with deep neural networks Nature 542 2017 115 118 Gorodeski et al., 2011 E.Z. Gorodeski H. Ishwaran U.B. Kogalur E.H. Blackstone E. Hsich Z.M. Zhang M.Z. Vitolins J.E. Manson J.D. Curb L.W. Martin Use of hundreds of electrocardiographic biomarkers for prediction of mortality in postmenopausal women: the Women's Health Initiative Circ. Cardiovasc. Qual. Outcomes 4 2011 521 532 Gulshan et al., 2016 V. Gulshan L. Peng M. Coram M.C. Stumpe D. Wu A. Narayanaswamy S. Venugopalan K. Widner T. Madams J. Cuadros Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs JAMA 316 2016 2402 2410 Hatipoglu and Bilgin, 2014 Hatipoglu, N., and Bilgin, G. (2014). Classification of histopathological images using convolutional neural network. Paper presented at: 2014 4th International Conference on Image Processing Theory, Tools and Applications (IPTA). He et al., 2015 He, K., Zhang, X., Ren, S., and Sun, J. (2015). Deep residual learning for image recognition. https://doi.org/10.1109/CVPR.2016.90. Heylman et al., 2015 C. Heylman R. Datta A. Sobrino S. George E. Gratton Supervised machine learning for classification of the electrophysiological effects of chronotropic drugs on human induced pluripotent stem cell-derived cardiomyocytes PLoS One 10 2015 e0144572 Hinton et al., 2006 G.E. Hinton S. Osindero Y.W. Teh A fast learning algorithm for deep belief nets Neural Comput. 18 2006 1527 1554 Hsich et al., 2011 E. Hsich E.Z. Gorodeski E.H. Blackstone H. Ishwaran M.S. Lauer Identifying important risk factors for survival in patient with systolic heart failure using random survival forests Circ. Cardiovasc. Qual. Outcomes 4 2011 39 45 Hu et al., 2010 B.Y. Hu J.P. Weick J. Yu L.X. Ma X.Q. Zhang J.A. Thomson S.C. Zhang Neural differentiation of human induced pluripotent stem cells follows developmental principles but with variable potency Proc. Natl. Acad. Sci. USA 107 2010 4335 4340 Ioffe and Szegedy, 2015 S. Ioffe C. Szegedy Batch normalization: accelerating deep network training by reducing internal covariate shift ArXiv 2015 https://arxiv.org/pdf/1502.03167.pdf Krizhevsky et al., 2012 A. Krizhevsky I. Sutskever G.E. Hinton ImageNet classification with deep convolutional neural networks F. Pereira C.J.C. Burges L. Bottou K.Q. Weinberger Proceedings of the 25th International Conference on Neural Information Processing Systems 2012 Curran Associates Inc. 1097 1105 Lecun et al., 2015 Y. Lecun Y. Bengio G. Hinton Deep learning Nature 521 2015 436 444 Lecun et al., 1998 Y. Lecun L. Bottou Y. Bengio P. Haffner Gradient-based learning applied to document recognition Proc. IEEE 86 1998 2278 2324 Lindblom et al., 2003 P. Lindblom H. Gerhardt S. Liebner A. Abramsson M. Enge M. Hellstrom G. Backstrom S. Fredriksson U. Landegren H.C. Nystrom Endothelial PDGF-B retention is required for proper investment of pericytes in the microvessel wall Genes Dev. 17 2003 1835 1840 McCulloch and Pitts, 1943 W.S. McCulloch W. Pitts A logical calculus of the ideas immanent in nervous activity Bull. Math. Biol. 5 1943 115 133 Niioka et al., 2018 H. Niioka S. Asatani A. Yoshimura H. Ohigashi S. Tagawa J. Miyake Classification of C2C12 cells at differentiation by convolutional neural network of deep learning using phase contrast images Hum. Cell 31 2018 87 93 Osafune et al., 2008 K. Osafune L. Caron M. Borowiak R.J. Martinez C.S. Fitz-Gerald Y. Sato C.A. Cowan K.R. Chien D.A. Melton Marked differences in differentiation propensity among human embryonic stem cell lines Nat. Biotechnol. 26 2008 313 315 Patsch et al., 2015 C. Patsch L. Challet-Meylan E.C. Thoma E. Urich T. Heckel J.F. O'Sullivan S.J. Grainger F.G. Kapp L. Sun K. Christensen Generation of vascular endothelial and smooth muscle cells from human pluripotent stem cells Nat. Cell Biol. 17 2015 994 1003 Saha and Vemuri, 2000 Saha, S., and Vemuri, R. (2000). An analysis on the effect of image activity on lossy coding performance. Paper presented at: 2000 IEEE International Symposium on Circuits and Systems Emerging Technologies for the 21st Century Proceedings (IEEE Cat No 00CH36353). Simonyan and Zisserman, 2014 K. Simonyan A. Zisserman Very deep convolutional networks for large-scale image recognition ArXiv 2014 https://arxiv.org/pdf/1409.1556.pdf Szegedy et al., 2014 C. Szegedy W. Liu Y. Jia P. Sermanet S. Reed D. Anguelov D. Erhan V. Vanhoucke A. Rabinovich Going deeper with convolutions ArXiv 2014 https://arxiv.org/pdf/1409.4842.pdf Takahashi and Yamanaka, 2006 K. Takahashi S. Yamanaka Induction of pluripotent stem cells from mouse embryonic and adult fibroblast cultures by defined factors Cell 126 2006 663 676 Takakura et al., 2000 N. Takakura T. Watanabe S. Suenobu Y. Yamada T. Noda Y. Ito M. Satake T. Suda A role for hematopoietic stem cells in promoting angiogenesis Cell 102 2000 199 209 Tanaka et al., 2014 A. Tanaka S. Yuasa G. Mearini T. Egashira T. Seki M. Kodaira D. Kusumoto Y. Kuroda S. Okata T. Suzuki Endothelin-1 induces myofibrillar disarray and contractile vector variability in hypertrophic cardiomyopathy-induced pluripotent stem cell-derived cardiomyocytes J. Am. Heart Assoc. 3 2014 e001263 Van Valen et al., 2016 D.A. Van Valen T. Kudo K.M. Lane D.N. Macklin N.T. Quach M.M. DeFelice I. Maayan Y. Tanouchi E.A. Ashley M.W. Covert Deep learning automates the quantitative analysis of individual cells in live-cell imaging experiments PLoS Comput. Biol. 12 2016 e1005177 Yuan-Hsiang et al., 2017 Yuan-Hsiang, C., Abe, K., Yokota, H., Sudo, K., Nakamura, Y., Cheng-Yu, L., and Ming-Dar, T. (2017). Human induced pluripotent stem cell region recognition in microscopy images using convolutional neural networks. Annual International Conference of the IEEE Engineering in Medicine and Biology Society 2017, 4058\u20134061. Yuasa and Fukuda, 2008 S. Yuasa K. Fukuda Cardiac regenerative medicine Circ. J. 72 Suppl A 2008 A49 A55 Zeng et al., 2016 X. Zeng W. Ouyang J. Yan H. Li T. Xiao K. Wang Y. Liu Y. Zhou B. Yang Z. Wang Crafting GBD-Net for object detection ArXiv 2016 https://arxiv.org/pdf/1610.02579.pdf", "scopus-id": "85046781959", "pubmed-id": "29754958", "coredata": {"eid": "1-s2.0-S2213671118301759", "dc:description": "Summary Deep learning technology is rapidly advancing and is now used to solve complex problems. Here, we used deep learning in convolutional neural networks to establish an automated method to identify endothelial cells derived from induced pluripotent stem cells (iPSCs), without the need for immunostaining or lineage tracing. Networks were trained to predict whether phase-contrast images contain endothelial cells based on morphology only. Predictions were validated by comparison to immunofluorescence staining for CD31, a marker of endothelial cells. Method parameters were then automatically and iteratively optimized to increase prediction accuracy. We found that prediction accuracy was correlated with network depth and pixel size of images to be analyzed. Finally, K-fold cross-validation confirmed that optimized convolutional neural networks can identify endothelial cells with high performance, based only on morphology.", "openArchiveArticle": "false", "prism:coverDate": "2018-06-05", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S2213671118301759", "dc:creator": [{"@_fa": "true", "$": "Kusumoto, Dai"}, {"@_fa": "true", "$": "Lachmann, Mark"}, {"@_fa": "true", "$": "Kunihiro, Takeshi"}, {"@_fa": "true", "$": "Yuasa, Shinsuke"}, {"@_fa": "true", "$": "Kishino, Yoshikazu"}, {"@_fa": "true", "$": "Kimura, Mai"}, {"@_fa": "true", "$": "Katsuki, Toshiomi"}, {"@_fa": "true", "$": "Itoh, Shogo"}, {"@_fa": "true", "$": "Seki, Tomohisa"}, {"@_fa": "true", "$": "Fukuda, Keiichi"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S2213671118301759"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S2213671118301759"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S2213-6711(18)30175-9", "prism:volume": "10", "prism:publisher": "The Author(s).", "dc:title": "Automated Deep Learning-Based System to Identify Endothelial Cells Derived from Induced Pluripotent Stem Cells", "prism:copyright": "\u00a9 2018 The Author(s).", "openaccess": "1", "prism:issn": "22136711", "prism:issueIdentifier": "6", "dcterms:subject": [{"@_fa": "true", "$": "deep learning"}, {"@_fa": "true", "$": "induced pluripotent stem cell"}, {"@_fa": "true", "$": "endothelial cell"}, {"@_fa": "true", "$": "artificial intelligence"}, {"@_fa": "true", "$": "machine learning"}], "openaccessArticle": "true", "prism:publicationName": "Stem Cell Reports", "prism:number": "6", "openaccessSponsorType": "Author", "prism:pageRange": "1687-1695", "prism:endingPage": "1695", "pubType": "Report", "prism:coverDisplayDate": "5 June 2018", "prism:doi": "10.1016/j.stemcr.2018.04.007", "prism:startingPage": "1687", "dc:identifier": "doi:10.1016/j.stemcr.2018.04.007", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "standard", "@height": "375", "@width": "375", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "51624", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "751", "@width": "657", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "133123", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "740", "@width": "657", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "149481", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "955", "@width": "744", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "203705", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "406", "@width": "506", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "63422", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "164", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "12450", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "143", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "9332", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "145", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10043", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "127", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "9785", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "204", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10338", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "high", "@height": "996", "@width": "996", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "219565", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "3322", "@width": "2908", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1120833", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "3279", "@width": "2911", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1142900", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "4229", "@width": "3294", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1993471", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1799", "@width": "2242", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "488810", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-mmc1.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "APPLICATION", "@size": "9379304", "@ref": "mmc1", "@mimetype": "application/pdf"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2213671118301759-mmc2.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "APPLICATION", "@size": "11434122", "@ref": "mmc2", "@mimetype": "application/pdf"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046781959"}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608010001188", "dc:identifier": "doi:10.1016/j.neunet.2010.06.005", "eid": "1-s2.0-S0893608010001188", "prism:doi": "10.1016/j.neunet.2010.06.005", "pii": "S0893-6080(10)00118-8", "dc:title": "Communication and knowledge sharing in human\u2013robot interaction and learning from demonstration ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2010 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "23", "prism:issueIdentifier": "8-9", "prism:startingPage": "1104", "prism:endingPage": "1112", "prism:pageRange": "1104-1112", "prism:number": "8-9", "dc:format": "application/json", "prism:coverDate": "2010-11-30", "prism:coverDisplayDate": "October\u2013November 2010", "prism:copyright": "Copyright \u00a9 2010 Published by Elsevier Ltd.", "prism:publisher": "Published by Elsevier Ltd.", "prism:issueName": "Social Cognition: From Babies to Robots", "dc:creator": [{"@_fa": "true", "$": "Koenig, Nathan"}, {"@_fa": "true", "$": "Takayama, Leila"}, {"@_fa": "true", "$": "Matari\u0107, Maja"}], "dc:description": "\n               Abstract\n               \n                  Inexpensive personal robots will soon become available to a large portion of the population. Currently, most consumer robots are relatively simple single-purpose machines or toys. In order to be cost effective and thus widely accepted, robots will need to be able to accomplish a wide range of tasks in diverse conditions. Learning these tasks from demonstrations offers a convenient mechanism to customize and train a robot by transferring task related knowledge from a user to a robot. This avoids the time-consuming and complex process of manual programming. The way in which the user interacts with a robot during a demonstration plays a vital role in terms of how effectively and accurately the user is able to provide a demonstration. Teaching through demonstrations is a social activity, one that requires bidirectional communication between a teacher and a student. The work described in this paper studies how the user\u2019s visual observation of the robot and the robot\u2019s auditory cues affect the user\u2019s ability to teach the robot in a social setting. Results show that auditory cues provide important knowledge about the robot\u2019s internal state, while visual observation of a robot can hinder an instructor due to incorrect mental models of the robot and distractions from the robot\u2019s movements.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Learning from demonstration (LfD)"}, {"@_fa": "true", "$": "Auditory"}, {"@_fa": "true", "$": "Visual"}, {"@_fa": "true", "$": "Teaching"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608010001188", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608010001188", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "77957886853", "scopus-eid": "2-s2.0-77957886853", "pubmed-id": "20598503", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/77957886853", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20100616", "$": "2010-06-16"}}}}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608019302680", "dc:identifier": "doi:10.1016/j.neunet.2019.09.007", "eid": "1-s2.0-S0893608019302680", "prism:doi": "10.1016/j.neunet.2019.09.007", "pii": "S0893-6080(19)30268-0", "dc:title": "A biologically plausible supervised learning method for spiking neural networks using the symmetric STDP rule ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "121", "prism:startingPage": "387", "prism:endingPage": "395", "prism:pageRange": "387-395", "dc:format": "application/json", "prism:coverDate": "2020-01-31", "prism:coverDisplayDate": "January 2020", "prism:copyright": "\u00a9 2019 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Hao, Yunzhe"}, {"@_fa": "true", "$": "Huang, Xuhui"}, {"@_fa": "true", "$": "Dong, Meng"}, {"@_fa": "true", "$": "Xu, Bo"}], "dc:description": "\n               Abstract\n               \n                  Spiking neural networks (SNNs) possess energy-efficient potential due to event-based computation. However, supervised training of SNNs remains a challenge as spike activities are non-differentiable. Previous SNNs training methods can be generally categorized into two basic classes, i.e., backpropagation-like training methods and plasticity-based learning methods. The former methods are dependent on energy-inefficient real-valued computation and non-local transmission, as also required in artificial neural networks (ANNs), whereas the latter are either considered to be biologically implausible or exhibit poor performance. Hence, biologically plausible (bio-plausible) high-performance supervised learning (SL) methods for SNNs remain deficient. In this paper, we proposed a novel bio-plausible SNN model for SL based on the symmetric spike-timing dependent plasticity (sym-STDP) rule found in neuroscience. By combining the sym-STDP rule with bio-plausible synaptic scaling and intrinsic plasticity of the dynamic threshold, our SNN model implemented SL well and achieved good performance in the benchmark recognition task (MNIST dataset). To reveal the underlying mechanism of our SL model, we visualized both layer-based activities and synaptic weights using the t-distributed stochastic neighbor embedding (t-SNE) method after training and found that they were well clustered, thereby demonstrating excellent classification ability. Furthermore, to verify the robustness of our model, we trained it on another more realistic dataset (Fashion-MNIST), which also showed good performance. As the learning rules were bio-plausible and based purely on local spike events, our model could be easily applied to neuromorphic hardware for online training and may be helpful for understanding SL information processing at the synaptic level in biological neural systems.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Spiking neural networks"}, {"@_fa": "true", "$": "Dopamine-modulated spike-timing dependent plasticity"}, {"@_fa": "true", "$": "Pattern recognition"}, {"@_fa": "true", "$": "Supervised learning"}, {"@_fa": "true", "$": "Biologically plausibility"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608019302680", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608019302680", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "85072857617", "scopus-eid": "2-s2.0-85072857617", "pubmed-id": "31593843", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/85072857617", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20190927", "$": "2019-09-27"}}}}}
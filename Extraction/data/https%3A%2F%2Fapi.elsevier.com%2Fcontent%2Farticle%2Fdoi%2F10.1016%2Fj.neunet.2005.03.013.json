{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608005000560", "dc:identifier": "doi:10.1016/j.neunet.2005.03.013", "eid": "1-s2.0-S0893608005000560", "prism:doi": "10.1016/j.neunet.2005.03.013", "pii": "S0893-6080(05)00056-0", "dc:title": "Simultaneous L\n               \n                  p\n               -approximation order for neural networks ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "18", "prism:issueIdentifier": "7", "prism:startingPage": "914", "prism:endingPage": "923", "prism:pageRange": "914-923", "prism:number": "7", "dc:format": "application/json", "prism:coverDate": "2005-09-30", "prism:coverDisplayDate": "September 2005", "prism:copyright": "Copyright \u00a9 2005 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Xu, Zong-Ben"}, {"@_fa": "true", "$": "Cao, Fei-Long"}], "dc:description": "\n               Abstract\n               \n                  Simultaneous approximation of a function and its derivatives are required in many science and engineering applications. There have been many studies on the simultaneous approximation capability of feedforward neural networks (FNNs). Most of the studies are, however, only concerned with density or feasibility of performing simultaneous approximation with FNNs, and no quantitative estimation on approximation accuracy of the simultaneous approximation is given. Moreover, all existing density or feasibility results are established in the uniform metric only, and provide no solution to topology specification of the FNNs used. In this paper, by means of the Bernstein\u2013Durrmeyer operator, a class of FNNs is constructed which realize the simultaneous approximation of any smooth multivariate function and all its existing partial derivatives. We present, by making use of multivariate approximation tools, a quantitative upper bound estimation on approximation accuracy of the simultaneous approximation of the FNNs in terms of the modulus of smoothness of the functions to be approximated. The obtained results reveals that the approximation speed of the constructed FNNs depends not only on the number of hidden units used, but also on the smoothness of functions to be approximated.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Simultaneous approximation"}, {"@_fa": "true", "$": "Neural networks with one hidden layer"}, {"@_fa": "true", "$": "Bernstein\u2013Durrmeyer operator"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608005000560", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608005000560", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "24344486886", "scopus-eid": "2-s2.0-24344486886", "pubmed-id": "15936925", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/24344486886", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20050604", "$": "2005-06-04"}}}}}
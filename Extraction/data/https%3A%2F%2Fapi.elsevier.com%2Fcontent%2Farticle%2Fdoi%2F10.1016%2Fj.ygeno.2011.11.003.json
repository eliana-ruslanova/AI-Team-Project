{"scopus-eid": "2-s2.0-84856426339", "originalText": "serial JL 272501 291210 291856 31 80 Genomics GENOMICS 2011-11-26 2011-11-26 2012-02-01T01:15:56 1-s2.0-S0888754311002606 S0888-7543(11)00260-6 S0888754311002606 10.1016/j.ygeno.2011.11.003 S300 S300.1 FULL-TEXT 1-s2.0-S0888754312X00028 2015-05-15T02:24:22.449914-04:00 0 0 20120201 20120229 2012 2011-11-26T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount figure table body mmlmath affil articletitle auth authfirstini authfull authkeywords authlast primabst ref specialabst alllist content oa subj ssids 0888-7543 08887543 99 99 2 2 Volume 99, Issue 2 5 90 95 90 95 201202 February 2012 2012-02-01 2012-02-29 2012 Regular Articles article fla Published by Elsevier Inc. ROBUSTTWOGENECLASSIFIERSFORCANCERPREDICTION WANG X 1 Introduction 2 Methods 2.1 Construction of two-gene classifiers 2.2 Evaluation of classifier performance 2.3 Materials 3 Results 3.1 Comparison with the TSP classifier 3.2 Comparison with the GP model 3.3 Comparison with the standard classifiers 4 Discussion and conclusions References SIMON 2003 31 36 R SIMON 2003 14 18 R WANG 2009 64 X BAKER 2010 452 S LI 2003 71 78 J WESSELS 2005 3755 3762 L DUDOIT 2003 93 158 S STATISTICALANALYSISGENEEXPRESSIONMICROARRAYDATA CLASSIFICATIONINMICROARRAYEXPERIMENTS GEMAN 2004 D TAN 2005 3896 3904 A EDELMAN 2009 583 L XU 2005 3905 3911 L ZHAO 2010 252 259 H PATNAIK 2010 36 45 S RAPONI 2008 2589 2596 M MA 2004 607 616 X PRICE 2007 3414 3419 N BO 2002 T LAI 2006 235 C FAYYAD 1993 1022 1027 U PROCEEDINGS13THINTERNATIONALJOINTCONFERENCEARTIFICIALINTELLIGENCE MULTIINTERVALDISCRETIZATIONCONTINUOUSVALUEDATTRIBUTESFORCLASSIFICATIONLEARNING ZHAO 2008 9 15 Y WANG 2011 391 X SIMON 2007 11 17 R TALANTOV 2005 7234 7242 D SOTIRIOU 2003 10393 10398 C POMEROY 2002 436 442 S CHEN 2003 3208 3215 X BHATTACHARJEE 2001 13790 13795 A GORDON 2002 4963 4967 G SHIPP 2002 68 74 M TIAN 2003 2483 2494 E ISHIKAWA 2005 387 393 M SINGH 2002 203 209 D WANGX2012X90 WANGX2012X90X95 WANGX2012X90XX WANGX2012X90X95XX http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window Full ElsevierBranded 2013-08-01T00:00:34Z item S0888-7543(11)00260-6 S0888754311002606 1-s2.0-S0888754311002606 10.1016/j.ygeno.2011.11.003 272501 2012-02-01T00:24:40.491533-05:00 2012-02-01 2012-02-29 1-s2.0-S0888754311002606-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/MAIN/application/pdf/56ac8bf8d2b7f60b20feb2fb427cfb41/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/MAIN/application/pdf/56ac8bf8d2b7f60b20feb2fb427cfb41/main.pdf main.pdf pdf true 351955 MAIN 6 1-s2.0-S0888754311002606-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/PREVIEW/image/png/16fc7ac14d368d1dba4477c55e31b49c/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/PREVIEW/image/png/16fc7ac14d368d1dba4477c55e31b49c/main_1.png main_1.png png 59138 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0888754311002606-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/STRIPIN/image/gif/36e3c4e5ec0e16ed8327d85648953c2d/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/STRIPIN/image/gif/36e3c4e5ec0e16ed8327d85648953c2d/si1.gif si1 si1.gif gif 2549 25 432 ALTIMG 1-s2.0-S0888754311002606-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/gr1/DOWNSAMPLED/image/jpeg/3da7eb8d4bb74171db7f82507b2cc87b/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/gr1/DOWNSAMPLED/image/jpeg/3da7eb8d4bb74171db7f82507b2cc87b/gr1.jpg gr1 gr1.jpg jpg 24520 243 489 IMAGE-DOWNSAMPLED 1-s2.0-S0888754311002606-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/gr1/THUMBNAIL/image/gif/a4bbc1930d98d97d8ae48544868d1ac9/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/gr1/THUMBNAIL/image/gif/a4bbc1930d98d97d8ae48544868d1ac9/gr1.sml gr1 gr1.sml sml 2937 109 219 IMAGE-THUMBNAIL 1-s2.0-S0888754311002606-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/gr1/HIGHRES/image/jpeg/18eea46fe380bed8f1b67c2d901f166f/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/gr1/HIGHRES/image/jpeg/18eea46fe380bed8f1b67c2d901f166f/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 212086 1076 2166 IMAGE-HIGH-RES 1-s2.0-S0888754311002606-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/gr2/DOWNSAMPLED/image/jpeg/1b8aad8296e602e10aff0ecd40d27127/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/gr2/DOWNSAMPLED/image/jpeg/1b8aad8296e602e10aff0ecd40d27127/gr2.jpg gr2 gr2.jpg jpg 30537 368 513 IMAGE-DOWNSAMPLED 1-s2.0-S0888754311002606-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/gr2/THUMBNAIL/image/gif/1f9fbf0906a42ad509ec3d0d3d7555b0/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/gr2/THUMBNAIL/image/gif/1f9fbf0906a42ad509ec3d0d3d7555b0/gr2.sml gr2 gr2.sml sml 3520 157 219 IMAGE-THUMBNAIL 1-s2.0-S0888754311002606-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754311002606/gr2/HIGHRES/image/jpeg/1e0d9fc86d5a575ceccbe0d68190f3a7/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754311002606/gr2/HIGHRES/image/jpeg/1e0d9fc86d5a575ceccbe0d68190f3a7/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 260142 1628 2272 IMAGE-HIGH-RES YGENO 8359 S0888-7543(11)00260-6 10.1016/j.ygeno.2011.11.003 Fig. 1 Construction of TGC-1's classification rule. TGC-1's classification rule is built based on a single gene's classification rule by comparison of the number of samples correctly classified with gene g and h. Fig.2 Construction of TGC-2's classification rule. TGC-2's classification rule is built by the weighted consideration of two single genes' classification rules. Table 1 Summary of the eleven gene expression datasets. Dataset # Genes Class # Samples a Melanoma [23] 18256 Malignant/nonmalignant 70 (45/25) Breast Cancer 1 [24] 7650 Relapse/no-relapse 99 (45/54) Brain Cancer [25] 7129 Classic/desmoplastic 60 (46/14) Breast Cancer 2 [15] 17985 Disease-free/cancer recurred 60 (32/28) Gastric Tumor [26] 7195 Normal/tumor 132 (29/103) Lung Cancer 1 [27] 12600 Squamous cell lung carcinoma/pulmonary carcinoid 41 (21/20) Lung Cancer 2 [28] 6321 Mesothelioma/adenocarcinoma 181 (31/150) Lymphoma [29] 7129 Cured/fatal 58 (32/26) Myeloma [30] 6451 Without bone lytic lesion/with bone lytic lesion 173 (36/137) Pancreatic Cancer [31] 22283 Normal/pancreatic ductal carcinoma 49 (25/24) Prostate Cancer [32] 12600 Normal/tumor 102 (50/52) a Note: The sample size of each class is given in parenthesis. Table 2 Comparison of classification accuracy (%) with the TSP classifier. Method TSP TGC-1 TGC-2 Dataset Melanoma 99 97 96 Breast Cancer 1 75 64 64 Brain Cancer 77 77 75 Breast Cancer 2 70 82 78 Gastric Tumor 66 89 88 Lung Cancer 1 95 98 100 Lung Cancer 2 94 93 93 Lymphoma 57 59 60 Myeloma 79 68 54 Pancreatic Cancer 90 71 73 Prostate Cancer 81 89 90 Table 3 Comparison of classification accuracy (%) with the GP model. Method TGC-1 TGC-2 GP Dataset DLDA k-NN SVM Melanoma 97 96 86 90 84 Breast Cancer 1 64 64 74 60 68 Brain Cancer 77 75 67 63 67 Breast Cancer 2 82 78 62 57 60 Gastric Tumor 89 88 80 77 81 Lung Cancer 1 98 100 98 95 95 Lung Cancer 2 93 93 86 89 91 Lymphoma 59 60 69 64 67 Myeloma 68 54 60 69 78 Pancreatic Cancer 71 73 78 76 73 Prostate Cancer 89 90 87 82 85 Table 4 Comparison of classification accuracy (%) with the standard classifiers. Method TGC-1 TGC-2 DLDA k-NN SVM Dataset Melanoma 97 96 97 97 97 Breast Cancer 1 64 64 53 52 43 Brain Cancer 77 75 73 60 70 Breast Cancer 2 82 78 70 72 70 Gastric Tumor 89 88 96 98 92 Lung Cancer 1 98 100 98 98 98 Lung Cancer 2 93 93 99 99 99 Lymphoma 59 60 52 59 57 Myeloma 68 54 80 76 79 Pancreatic Cancer 71 73 61 65 55 Prostate Cancer 89 90 93 93 93 Table 5 Comparison of classification accuracy (%) with the alternative two-gene classifier. Method TGC-Mm TGC-1 TGC-2 Dataset Melanoma 97 97 96 Breast Cancer 1 64 64 64 Brain Cancer 75 77 75 Breast Cancer 2 78 82 78 Gastric Tumor 89 89 88 Lung Cancer 1 98 98 100 Lung Cancer 2 95 93 93 Lymphoma 52 59 60 Myeloma 47 68 54 Pancreatic Cancer 63 71 73 Prostate Cancer 88 89 90 Robust two-gene classifiers for cancer prediction Xiaosheng Wang xiaosheng.wang@nih.gov Biometric Research Branch, National Cancer Institute, National Institutes of Health, Rockville, MD 20852, USA Abstract Two-gene classifiers have attracted a broad interest for their simplicity and practicality. Most existing two-gene classification algorithms were involved in exhaustive search that led to their low time-efficiencies. In this study, we proposed two new two-gene classification algorithms which used simple univariate gene selection strategy and constructed simple classification rules based on optimal cut-points for two genes selected. We detected the optimal cut-point with the information entropy principle. We applied the two-gene classification models to eleven cancer gene expression datasets and compared their classification performance to that of some established two-gene classification models like the top-scoring pairs model and the greedy pairs model, as well as standard methods including Diagonal Linear Discriminant Analysis, k-Nearest Neighbor, Support Vector Machine and Random Forest. These comparisons indicated that the performance of our two-gene classifiers was comparable to or better than that of compared models. Highlights \u25ba We proposed two genuine two-gene classifiers for cancer prediction. \u25ba Our models used simple univariate gene selection strategy. \u25ba Our models used simple classification rules built by information entropy principle. \u25ba Our models had comparable performance to existing methods. \u25ba Simple models have substantial advantages over complicated ones. Keywords Cancer Classification Gene expression profiling Information entropy Computational biology 1 Introduction Many studies have made it a growing consensus that to deal with high-dimensional gene expression data, simple classifiers often have substantial advantages over complicated ones [1\u20137]. One advantage is that simple classifiers often have better classification performance but lower computational cost than complex classifiers. Another advantage is that simple classifiers are more interpretable and applicable compared to complex classifiers because they are often involved in a small number of genes and simple classification rules. As a typical representative of simple classifiers, the two-gene classifier has attracted an increasing interest [8\u201317]. Among them, the top-scoring pair(s) (TSP) classifier classifies phenotypes according to the relative expression of a pair of genes as contributes to its two advantages: first, it avoids over-fitting by eliminating specific parameter tuning; second, it is not affected by normalization issues [8\u20139]. In [17], the authors proposed gene-pair based methods to select gene sets which well distinguished two classes. In [3], the authors screened a small number of informative gene pairs on the basis of their depended degrees proposed in rough sets by which the decision rules were induced to classify phenotypes classes. These two-gene classification algorithms indicated that gene pairs in combination might better discriminate different classes than individual genes due to gene interactions. Although class prediction might be improved by taking advantage of the gene-interaction information, the relevant algorithms were often time-consuming. Moreover, these algorithms were often involved in complex multivariate gene selection approach, which has been proven not to be more effective than simple univariate gene selection approach in most cases [7,18]. In this study, we proposed two new two-gene classification algorithms based on univariate gene selection strategy. We simply selected two genes with the largest absolute t-statistic values, and then constructed classification rules based on their optimal cut-points of expression levels. We detected the optimal cut-point according to the information entropy principle [19]. We compared the performance of the two-gene classification models to that of the TSP [8] and the greedy pairs (GP) based classification models [17]. We also compared the performance of our classifiers with the popularly-used standard models including Diagonal Linear Discriminant Analysis (DLDA), k-Nearest Neighbor (k-NN), Support Vector Machines (SVM) and Random Forest (RF). The materials studied involved eleven publicly available gene expression datasets (http://linus.nci.nih.gov/~brb/DataArchive_New.html) [20]. 2 Methods 2.1 Construction of two-gene classifiers Within each training set, we calculated the value of the t-statistic (t-score) for each gene, and then selected the two genes with the highest absolute values of t-score to build classification rules. Here we obtained the t-score based on the Welch's t-test which supposes two groups of samples have possibly unequal variances. We built the classification rules based on the optimal cut-points for the expression levels of the genes selected. We found the optimal cut-point by using the entropy-based discretization method [19]. In [21], we have given the description of the method for detection of the optimal cut-point. Here we simply repeated the essential procedure. To obtain the optimal cut-point for gene g, we first sorted the training sample set S as s 1 , s 2 , \u2026, s n , based on the expression levels of g, and then constructed the candidate cut-point set P which was composed of the mean values of E(g, s k ) and E(g, s k+1 ) provided that s k and s k+1 were labeled with two different classes. Here E(g, s i ) denotes the expression level of gene g in the sample s i . Each element t of P separated S into two equivalence classes S 1 (t, g) and S 2 (t, g), where S 1 (t, g) = {s\u2208 S | E(g, s)\u2264t} and S 2 (t, g) = {s\u2208 S | E(g, s)>t}. Let C 1 denote the subset of samples whose class label is c 1 , and C 2 the subset of samples whose class label is c 2 . Define the four sets: P 11 , P 12 , P 21 and P 22 , where P 11 =S 1 (t, g)\u2229C 1 , P 12 =S 1 (t, g)\u2229C 2 , P 21 =S 2 (t, g)\u2229C 1 , and P 22 =S 2 (t, g)\u2229C 2 . We calculated the class information entropy of the partition induced by t, denoted E(g, t, S), as follows: E g , t , S = \u2212 S 1 S ( P 11 S 1 log 2 P 11 S 1 + P 12 S 1 log 2 P 12 S 1 ) \u2212 S 2 S ( P 21 S 2 log 2 P 21 S 2 + P 22 S 2 log 2 P 22 S 2 ) . We selected the t which minimized E(g, t, S) as the optimal cut-point T(g) for g. If the candidate cut-point set P was empty (very rare), we took the mean expression level of g in all training samples as the optimal cut-point. Once we obtained the optimal cut-point T(g) for the gene g, we built the single-gene classification rule based on g. Let Q 11 (g) =S 1 (T(g), g)\u2229C 1 , Q 12 (g) =S 1 (T(g), g)\u2229C 2 , Q 21 (g) =S 2 (T(g), g)\u2229C 1 , Q 22 (g) =S 2 (T(g), g)\u2229C 2 , and C(s) denote the class label assigned to the sample s. If |Q 11 (g)|+|Q 22 (g)|>|Q 12 (g)|+|Q 21 (g)|, the classification rule would be \u201cE(g, s)\u2264T(g) =>C(s)=c 1 ; E(g, s)>T(g) =>C(s)=c 2 \u201d; otherwise, the classification rule would be \u201cE(g, s)\u2264T(g) =>C(s)=c 2 ; E(g, s)>T(g) =>C(s)=c 1 \u201d. We have used the above classification rule to construct single-gene classifiers by which we achieved ideal classification effect in most cases [21]. However, the single-gene classifiers' performance would degrade if one noise gene was selected. The present two-gene classifiers were expected to attain more stable performance through combination of the classification rules induced by two genes. Here we constructed two types of two-gene classifiers termed as TGC-1 and TGC-2, respectively. Suppose we selected another gene h with the second largest absolute t-score, apart from the gene g which had the largest absolute t-score. We denoted max(x, y) as the larger one between x and y. We constructed TGC-1's classification rule as follows: if max(|Q 11 (g)|+|Q 22 (g)|, |Q 12 (g)|+|Q 21 (g)|)\u2265 max(|Q 11 (h)|+|Q 22 (h)|, |Q 12 (h)|+|Q 21 (h)|), then the classification rule is the single-gene classification rule based on g; otherwise, the classification rule is the single-gene classification rule based on h. Here max(|Q 11 (g)|+|Q 22 (g)|, |Q 12 (g)|+|Q 21 (g)|) and max(|Q 11 (h)|+|Q 22 (h)|, |Q 12 (h)|+|Q 21 (h)|) indicate the number of samples correctly classified with gene g and h, respectively. Therefore, TGC-1 utilized the classification rule constructed merely based on one of the two selected genes which led to the optimal classification result (Fig. 1 ). In contrast, we constructed TGC-2's classification rule by taking into account the classification rules based on both genes selected simultaneously. As for a single gene x, we will encounter two cases: |Q 11 (x)|+|Q 22 (x)|>|Q 12 (x)|+|Q 21 (x)| and |Q 11 (x)|+|Q 22 (x)| \u2264 |Q 12 (x)|+|Q 21 (x)|, we will have four different combinations for two genes. On the other hand, relative to the optimal cut-point, the expression level of gene x in a sample s can be divided into two cases: E(x, s)\u2264T(x) and E(x, s)>T(x). Thus, the expression levels of two genes in the same sample s will have four different possibilities. Suppose we classify s into class c1 and c2 by the classification rules based on gene x and y, respectively. If c1 is identical to c2, we will certainly classify s into class c1 (or c2); otherwise, we need to consider additional factors to determine the class label of s. One significant factor is the distance between the expression level of one gene and its optimal cut-point. If the distance regarding gene x is greater than that regarding gene y, we think that x has higher weight than y in determining the class attribute of s, and therefore adopt its classification rule to classify s. Because different genes possibly have very different average expression levels across samples, we normalized the distance via dividing it by the average expression level of each gene across all training samples. Fig. 2 illuminates the basic procedure of TGC-2. In detail, we constructed TGC-2's classification rule as follows: (1) if |Q 11 (g)|+|Q 22 (g)|>|Q 12 (g)|+|Q 21 (g)| and |Q 11 (h)|+|Q 22 (h)|>|Q 12 (h)|+|Q 21 (h)|, then 1) E(g, s)\u2264T(g) and E(h, s)\u2264T(h) =>C(s)=c 1 ; 2) E(g, s)>T(g) and E(h, s)>T(h) =>C(s)=c 2 ; 3) if E(g, s)>T(g) and E(h, s)\u2264T(h), then a) (E(g, s) \u2212 T(g))/|mean(g)| < (T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 1 ; b) (E(g, s) \u2212 T(g))/|mean(g)| \u2265 (T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 2 ; 4) if E(g, s)\u2264T(g) and E(h, s)>T(h), then a) (T(g)\u2212 E(g, s))/|mean(g)| \u2265 (E(h, s) \u2212 T(h))/|mean(h)| =>C(s)=c 1 ; b) (T(g)\u2212 E(g, s))/|mean(g)|<(E(h, s) \u2212 T(h))/|mean(h)| =>C(s)=c 2 ; (2) if |Q 11 (g)|+|Q 22 (g)|>|Q 12 (g)|+|Q 21 (g)| and |Q 11 (h)|+|Q 22 (h)| \u2264 |Q 12 (h)|+|Q 21 (h)|, then 1) E(g, s)\u2264T(g) and E(h, s)>T(h) =>C(s)=c 1 ; 2) E(g, s)>T(g) and E(h, s)\u2264T(h) =>C(s)=c 2 ; 3) if E(g, s)>T(g) and E(h, s)>T(h), then a) (E(g, s) \u2212 T(g))/|mean(g)| < (E(h, s) \u2212 T(h) )/|mean(h)| =>C(s)=c 1 ; b) (E(g, s) \u2212 T(g))/|mean(g)| \u2265 (E(h, s) \u2212 T(h) )/|mean(h)| =>C(s)=c 2 ; 4) if E(g, s)\u2264T(g) and E(h, s)\u2264T(h), then a) (T(g)\u2212 E(g, s))/|mean(g)| \u2265 (T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 1 ; b) (T(g)\u2212 E(g, s))/|mean(g)| < (T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 2 ; (3) if |Q 11 (g)|+|Q 22 (g)|\u2264|Q 12 (g)|+|Q 21 (g)| and |Q 11 (h)|+|Q 22 (h)|>|Q 12 (h)|+|Q 21 (h)|, then 1) E(g, s) > T(g) and E(h, s)\u2264T(h) =>C(s)=c 1 ; 2) E(g, s)\u2264T(g) and E(h, s)>T(h) =>C(s)=c 2 ; 3) if E(g, s) > T(g) and E(h, s) > T(h), then a) (E(g, s) \u2212 T(g))/|mean(g)| \u2265 (E(h, s) \u2212 T(h))/|mean(h)| =>C(s)=c 1 ; b) (E(g, s) \u2212 T(g))/|mean(g)| < (E(h, s) \u2212 T(h))/|mean(h)| =>C(s)=c 2 ; 4) if E(g, s)\u2264T(g) and E(h, s)\u2264T(h), then a) (T(g)\u2212 E(g, s))/|mean(g)|<(T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 1 ; b) (T(g)\u2212 E(g, s))/|mean(g)| \u2265 (T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 2 ; (4) if |Q 11 (g)|+|Q 22 (g)| \u2264 |Q 12 (g)|+|Q 21 (g)| and |Q 11 (h)|+|Q 22 (h)| \u2264 |Q 12 (h)|+|Q 21 (h)|, then 1) E(g, s)>T(g) and E(h, s)>T(h) =>C(s)=c 1 ; 2) E(g, s)\u2264T(g) and E(h, s)\u2264T(h) =>C(s)=c 2 ; 3) if E(g, s)>T(g) and E(h, s)\u2264T(h), then a) (E(g, s) \u2212 T(g))/|mean(g)| \u2265 (T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 1 ; b) (E(g, s) \u2212 T(g))/|mean(g)| < (T(h)\u2212 E(h, s))/|mean(h)| =>C(s)=c 2 ; 4) if E(g, s)\u2264T(g) and E(h, s)>T(h), then a) (T(g)\u2212 E(g, s))/|mean(g)| < (E(h, s) \u2212 T(h))/|mean(h)| =>C(s)=c 1 ; b) (T(g)\u2212 E(g, s))/|mean(g)| \u2265 (E(h, s) \u2212 T(h))/|mean(h)| =>C(s)=c 2 ; Here mean(i) indicates the average expression levels of gene i across all training samples. 2.2 Evaluation of classifier performance We evaluated classifier performance by leave-one-out cross validation (LOOCV). In each leave-one-out training set, we selected two genes based on which the classification rule was constructed to classify the omitted sample. We used TGC-1 and TGC-2 to classify each dataset, respectively, and thus we obtained two sets of classification accuracy results. We compared the performance of our models to that of the gene pairs based classification models TSP and GP, as well as four standard classifiers: DLDA, k-NN, SVM and RF. For the TSP classifier, the number of gene pairs selected was set as one. For the GP model, we first selected one pair of genes based on the greedy-pairs approach proposed in [17], and then used DLDA, k-NN and SVM algorithms to perform classification with the two genes selected, respectively. For k-NN, we set the parameter k as 3. The SVM was based on the linear inner product kernel function (cost=1). For RF, we set the number of trees and genes randomly sampled as candidates at each split as 100 and the squared root of the total number of genes, respectively. For the four standard classifiers, the genes significantly different between the classes at 0.001 significance level were used for class prediction. We carried out all the compared classification algorithms in BRB-ArrayTools, an integrated package for the visualization and statistical analysis of DNA microarray gene expression data (http://linus.nci.nih.gov/BRB-ArrayTools.html) [22]. 2.3 Materials We selected eleven gene expression datasets to evaluate classifier performance. These datasets have different scale of sample size and gene number. For the Melanoma, Breast Cancer 2, Gastric Tumor, Lung Cancer 2 and Myeloma datasets, we performed pre-filtering of gene due to computational cost. Thus, the gene numbers presented in the five datasets are post-filtering gene numbers, while the gene numbers shown in the other datasets are the original gene numbers published (Table 1 ). 3 Results 3.1 Comparison with the TSP classifier Table 2 lists the LOOCV results for TSP, TGC-1 and TGC-2. From Table 2, we can see that in the Melanoma, Brain Cancer, Lung Cancer 1, Lung Cancer 2 and Lymphoma datasets, the classification accuracy obtained by our methods matches that obtained by TSP. In the Breast Cancer 1, Myeloma and Pancreatic Cancer datasets, TSP shows higher accuracy than our methods, while in the Breast Cancer 2, Gastric Tumor and Prostate Cancer datasets, our methods exhibit higher accuracy than TSP. Generally speaking, for the datasets examined, our two-gene classifiers show comparable performance with TSP. 3.2 Comparison with the GP model Table 3 compares the classification accuracy by our models to that by DLDA, k-NN, and SVM with the GP gene selection approach. Here we term the classification models based on the GP gene selection approach the GP model regardless of what classification rule is used. From Table 3, we can see that in the Melanoma, Brain Cancer, Breast Cancer 2 and Gastric Tumor datasets, the classification accuracy obtained by our methods are higher than that obtained by GP. In Breast Cancer 1, Lung Cancer 1, Lung Cancer 2, Pancreatic Cancer and Prostate Cancer datasets, our methods and GP achieved close accuracy. In the Lymphoma and Myeloma datasets, our methods exhibit a bit poorer accuracy than GP. Overall, our two-gene classification models surpassed GP in prediction performance for the datasets examined. 3.3 Comparison with the standard classifiers Table 4 compares the classification accuracy between the two-gene classifiers and the standard classifiers. From Table 4, we can see that in the Breast Cancer 1, Brain Cancer, Breast Cancer 2 and Pancreatic Cancer datasets, our methods consistently achieved higher accuracy than all the standard classifiers. In Melanoma, Gastric Tumor, Lung Cancer 1, Lung Cancer 2, Lymphoma and Prostate Cancer datasets, our methods show comparable performance with the standard classifiers. Only in the Myeloma dataset, our methods exhibit poorer accuracy than the standard classifiers. All together, these results indicate that our two-gene classifiers have better performance than the standard classifiers for the datasets examined, lending a support to the notion that simple models outstrip complicated ones in molecular prediction of cancer based on gene expression profiling. Indeed, the average number of genes used for building the standard classifiers ranged from tens to thousands, whereas their performance was not superior to the two-gene classifiers. One sensible explanation is that for the gene expression data involving high-dimensional attributes (p) and low-dimensional instances (n), if too many attributes are selected for construction of classifiers, over-fitting is likely to occur. 4 Discussion and conclusions For the p>n problem such as microarray classification, good performance can often be achieved with a small number of genes, even a pair of genes. Indeed, in some cases, accurate classification can be achieved with one single gene [3,21]. Previously, we developed the single-gene models which were frequently of commensurate accuracy as more complex classifiers, whereas in some cases, the single-gene models performed poorly because of the selection of noise genes [21]. The present two-gene classification models to a large extent overcame the unstability drawback of the single-gene models because it is highly improbable to select two noise genes simultaneously. We can't evaluate the complexity of a classification model simply based on the number of genes in the model. Complexity also depends on gene selection criteria and classification rules employed. Simple models typically involve a simple feature selection scheme and simple classification rule. In contrast, complex models often involve sophisticated feature selection procedures and/or complicated classification rules [21]. Although TSP, GP and our models were all involved in gene pairs, TSP and GP were actually more complex than our models. The TSP algorithm performed gene pair selection by searching for all gene pair combinations that is computationally expensive. The GP algorithm evaluated a subset of all gene pair combinations by first ranking all genes based on individual t-score, which was less computationally expensive than the TSP algorithm but more computationally expensive than our algorithm. Indeed, neither of TSP and GP was a genuine two-gene classification algorithm in that they actually embraced multiple gene pairs in construction of classification rules. Our algorithm selected two genes on the basis of their individual t-score. Therefore, gene interaction information was not considered by our strategy. In fact, the detection of interaction between genes among thousands or tens of thousands candidates is very time-consuming. That was why the TSP and GP algorithms had lower time efficiency than our algorithm. In fact, gene interaction information might not exert a significant influence on classification performance [7,18]. The classification accuracies obtained by TGC-1 and TGC-2 were very close to each other except for in the Myeloma dataset. Both classifiers utilized the identical two genes but different classification rules. Actually, the classification rule used by TGC-1 was the single-gene classification rule. Its excellent performance manifested that the single-gene classification rule was a reasonable choice if the single gene selected was not a noise gene. In contrast, TGC-2 indeed used the two gene selected to construct the classification rule which was more complex than that of TGC-1. Thus, the performance of TGC-2 relied on both genes while the performance of TGC-1 depended upon only one of both genes. That means TGC-1 is a more robust classifier than TGC-2 in that any one noise gene in the gene pair selected will comprise the performance of TGC-2 but not affect that of TGC-1 if the other gene is informative. The great gap between the classification accuracies produced by TGC-1 and TGC-2 in the Myeloma dataset may exemplify this point. Here we selected two genes with the largest absolute values of t-score. An alternative approach is to select two genes with one gene having the largest positive value of t-score and another gene having the smallest negative value of t-score. This approach seems to be a sensible choice in that based on it, we may select one gene with much higher expression levels in one class and another gene with much higher expression levels in another class. In fact, many two-gene classifiers select gene pairs based on similar criteria including the TSP classifier, and our method has 50% chance of meeting this selection. Table 5 compares the performance between TGC-1, TGC-2 and the two-gene classifier constructed based on the alternative gene selection approach and the same classification rule as that used by TGC-2 (TGC-Mm). Apparently, in most cases, the alternative two-gene classifier has comparable performance with TGC-1and TGC-2, whereas in a few cases, it shows poorer performance than TGC-1 and TGC-2 such as in the Lymphoma, Myeloma and Pancreatic Cancer datasets. One possible explanation for the performance gap in these datasets is that there may are much more genes having obviously higher expression levels in one class (class 1) than in another class (class 2) in these datasets so that the selection of two genes with higher expression levels in class 1 is more reasonable than the selection of two genes with higher expression levels in class 1 and class 2, respectively. In this study, we developed genuine two-gene classification models. Through experimental test on several gene expression datasets, we found that although our two-gene classification algorithms were simpler than existing two-gene classification algorithms like TSP and GP, our classifiers' performance was comparable to or better than that of TSP and GP. Moreover, our classifiers exhibited better performance than the standard classifiers DLDA, k-NN, SVM and RF, even though they used much more genes for classification. This study strengthens the consensus that simple classifiers have essential advantages over complicated ones, and therefore should be preferable for cancerous prediction based on gene expression profiling. References [1] R. Simon Supervised analysis when the number of candidate feature (p) greatly exceeds the number of cases (n) ACM SIGKDD Explor. Newsl. 5 2003 31 36 [2] R. Simon M.D. Radmacher K. Dobbin L.M. McShane Pitfalls in the use of DNA microarray data for diagnostic and prognostic classification J. Natl. Cancer Inst. 95 2003 14 18 [3] X. Wang O. Gotoh Accurate molecular classification of cancer using simple rules BMC Med. Genomics 2 2009 64 [4] S.G. Baker Simple and flexible classification of gene expression microarrays via Swirls and Ripples BMC Bioinformatics 11 2010 452 [5] J. Li H. Liu J.R. Downing A.E. Yeoh L. Wong Simple rules underlying gene expression profiles of more than six subtypes of acute lymphoblastic leukemia (ALL) patients Bioinformatics 19 2003 71 78 [6] L.F.A. Wessels M.J.T. Reinders A.A.M. Hart C.J. Veenman H. Dai Y.D. He L.J. van't Veer A protocol for building and evaluating predictors of disease state based on microarray data Bioinform. (Oxf. Engl.) 21 2005 3755 3762 [7] S. Dudoit J. Fridlyand Classification in microarray experiments T. Speed Statistical Analysis of Gene Expression Microarray Data 2003 Chapman & Hall/CRC 93 158 [8] D. Geman C. d'Avignon D.Q. Naiman R.L. Winslow Classifying gene expression profiles from pairwise mRNA comparisons Stat. Appl. Genet. Mol. Biol. 3 2004 Article19 [9] A.C. Tan D.Q. Naiman L. Xu R.L. Winslow D. Geman Simple decision rules for classifying human cancers from gene expression profiles Bioinformatics 21 2005 3896 3904 [10] L.B. Edelman G. Toia D. Geman W. Zhang N.D. Price Two-transcript gene expression classifiers in the diagnosis and prognosis of human diseases BMC Genomics 10 2009 583 [11] L. Xu A.C. Tan D.Q. Naiman D. Geman R.L. Winslow Robust prostate cancer marker genes emerge from direct integration of inter-study microarray data Bioinformatics 21 2005 3905 3911 [12] H. Zhao C.J. Logothetis I.P. Gorlov Usefulness of the top-scoring pairs of genes for prediction of prostate cancer progression Prostate Cancer Prostatic Dis. 13 2010 252 259 [13] S.K. Patnaik E. Kannisto S. Knudsen S. Yendamuri Evaluation of microRNA expression profiles that may predict recurrence of localized stage I non-small cell lung cancer after surgical resection Cancer Res. 70 2010 36 45 [14] M. Raponi J.E. Lancet H. Fan L. Dossey G. Lee I. Gojo E.J. Feldman J. Gotlib L.E. Morris P.L. Greenberg J.J. Wright J.-L. Harousseau B. Lowenberg R.M. Stone P. De Porre Y. Wang J.E. Karp A 2-gene classifier for predicting response to the farnesyltransferase inhibitor tipifarnib in acute myeloid leukemia Blood 111 2008 2589 2596 [15] X.-J. Ma Z. Wang P.D. Ryan S.J. Isakoff A. Barmettler A. Fuller B. Muir G. Mohapatra R. Salunga J.T. Tuggle Y. Tran D. Tran A. Tassin P. Amon W. Wang W. Wang E. Enright K. Stecker E. Estepa-Sabal B. Smith J. Younger U. Balis J. Michaelson A. Bhan K. Habin T.M. Baer J. Brugge D.A. Haber M.G. Erlander D.C. Sgroi A two-gene expression ratio predicts clinical outcome in breast cancer patients treated with tamoxifen Cancer Cell 5 2004 607 616 [16] N.D. Price J. Trent A.K. El-Naggar D. Cogdell E. Taylor K.K. Hunt R.E. Pollock L. Hood I. Shmulevich W. Zhang Highly accurate two-gene classifier for differentiating gastrointestinal stromal tumors and leiomyosarcomas Proc. Natl. Acad. Sci. U.S.A. 104 2007 3414 3419 [17] T. Bo I. Jonassen New feature subset selection procedures for classification of expression profiles Genome Biol. 3 2002 RESEARCH0017 [18] C. Lai M.J.T. Reinders L.J. van't Veer L.F.A. Wessels A comparison of univariate and multivariate gene selection techniques for classification of cancer datasets BMC Bioinformatics 7 2006 235 [19] U.M. Fayyad K.B. Irani Multi-interval discretization of continuous-valued attributes for classification learning Proceedings of the 13th International Joint Conference of Artificial Intelligence 1993 Morgan Kaufmann Chamb\u00e9ry, France 1022 1027 [20] Y. Zhao R. Simon BRB-ArrayTools Data Archive for human cancer gene expression: a unique and efficient data sharing resource Cancer Inf. 6 2008 9 15 [21] X. Wang R. Simon Microarray-based Cancer Prediction Using Single Genes BMC Bioinformatics 12 2011 391 [22] R. Simon A. Lam M.-C. Li M. Ngan S. Menenzes Y. Zhao Analysis of gene expression data using BRB-Array Tools Cancer Inform. 3 2007 11 17 [23] D. Talantov A. Mazumder J.X. Yu T. Briggs Y. Jiang J. Backus D. Atkins Y. Wang Novel genes associated with malignant melanoma but not benign melanocytic lesions Clin. Cancer Res. Off. J Am. Assoc. Cancer Res. 11 2005 7234 7242 [24] C. Sotiriou S.-Y. Neo L.M. McShane E.L. Korn P.M. Long A. Jazaeri P. Martiat S.B. Fox A.L. Harris E.T. Liu Breast cancer classification and prognosis based on gene expression profiles from a population-based study Proc. Natl. Acad. Sci. U.S.A. 100 2003 10393 10398 [25] S.L. Pomeroy P. Tamayo M. Gaasenbeek L.M. Sturla M. Angelo M.E. McLaughlin J.Y.H. Kim L.C. Goumnerova P.M. Black C. Lau J.C. Allen D. Zagzag J.M. Olson T. Curran C. Wetmore J.A. Biegel T. Poggio S. Mukherjee R. Rifkin A. Califano G. Stolovitzky D.N. Louis J.P. Mesirov E.S. Lander T.R. Golub Prediction of central nervous system embryonal tumour outcome based on gene expression Nature 415 2002 436 442 [26] X. Chen S.Y. Leung S.T. Yuen K.-M. Chu J. Ji R. Li A.S.Y. Chan S. Law O.G. Troyanskaya J. Wong S. So D. Botstein P.O. Brown Variation in gene expression patterns in human gastric cancers Mol. Biol. Cell 14 2003 3208 3215 [27] A. Bhattacharjee W.G. Richards J. Staunton C. Li S. Monti P. Vasa C. Ladd J. Beheshti R. Bueno M. Gillette M. Loda G. Weber E.J. Mark E.S. Lander W. Wong B.E. Johnson T.R. Golub D.J. Sugarbaker M. Meyerson Classification of human lung carcinomas by mRNA expression profiling reveals distinct adenocarcinoma subclasses Proc. Natl. Acad. Sci. U.S.A. 98 2001 13790 13795 [28] G.J. Gordon R.V. Jensen L.L. Hsiao S.R. Gullans J.E. Blumenstock S. Ramaswamy W.G. Richards D.J. Sugarbaker R. Bueno Translation of microarray data into clinically relevant cancer diagnostic tests using gene expression ratios in lung cancer and mesothelioma Cancer Res. 62 2002 4963 4967 [29] M.A. Shipp K.N. Ross P. Tamayo A.P. Weng J.L. Kutok R.C.T. Aguiar M. Gaasenbeek M. Angelo M. Reich G.S. Pinkus T.S. Ray M.A. Koval K.W. Last A. Norton T.A. Lister J. Mesirov D.S. Neuberg E.S. Lander J.C. Aster T.R. Golub Diffuse large B-cell lymphoma outcome prediction by gene-expression profiling and supervised machine learning Nat. Med. 8 2002 68 74 [30] E. Tian F. Zhan R. Walker E. Rasmussen Y. Ma B. Barlogie J.D. Shaughnessy The role of the Wnt-signaling antagonist DKK1 in the development of osteolytic lesions in multiple myeloma N. Engl. J. Med. 349 2003 2483 2494 [31] M. Ishikawa K. Yoshida Y. Yamashita J. Ota S. Takada H. Kisanuki K. Koinuma Y.L. Choi R. Kaneda T. Iwao K. Tamada K. Sugano H. Mano Experimental trial for diagnosis of pancreatic ductal carcinoma based on gene expression profiles of pancreatic ductal cells Cancer Sci. 96 2005 387 393 [32] D. Singh P.G. Febbo K. Ross D.G. Jackson J. Manola C. Ladd P. Tamayo A.A. Renshaw A.V. D'Amico J.P. Richie E.S. Lander M. Loda P.W. Kantoff T.R. Golub W.R. Sellers Gene expression correlates of clinical prostate cancer behavior Cancer Cell 1 2002 203 209", "scopus-id": "84856426339", "pubmed-id": "22138042", "coredata": {"eid": "1-s2.0-S0888754311002606", "dc:description": "Abstract Two-gene classifiers have attracted a broad interest for their simplicity and practicality. Most existing two-gene classification algorithms were involved in exhaustive search that led to their low time-efficiencies. In this study, we proposed two new two-gene classification algorithms which used simple univariate gene selection strategy and constructed simple classification rules based on optimal cut-points for two genes selected. We detected the optimal cut-point with the information entropy principle. We applied the two-gene classification models to eleven cancer gene expression datasets and compared their classification performance to that of some established two-gene classification models like the top-scoring pairs model and the greedy pairs model, as well as standard methods including Diagonal Linear Discriminant Analysis, k-Nearest Neighbor, Support Vector Machine and Random Forest. These comparisons indicated that the performance of our two-gene classifiers was comparable to or better than that of compared models.", "openArchiveArticle": "true", "prism:coverDate": "2012-02-29", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0888754311002606", "dc:creator": {"@_fa": "true", "$": "Wang, Xiaosheng"}, "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0888754311002606"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0888754311002606"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0888-7543(11)00260-6", "prism:volume": "99", "dc:title": "Robust two-gene classifiers for cancer prediction", "prism:copyright": "Published by Elsevier Inc.", "openaccess": "1", "prism:issn": "08887543", "prism:issueIdentifier": "2", "dcterms:subject": [{"@_fa": "true", "$": "Cancer"}, {"@_fa": "true", "$": "Classification"}, {"@_fa": "true", "$": "Gene expression profiling"}, {"@_fa": "true", "$": "Information entropy"}, {"@_fa": "true", "$": "Computational biology"}], "openaccessArticle": "true", "prism:publicationName": "Genomics", "prism:number": "2", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "90-95", "prism:endingPage": "95", "prism:coverDisplayDate": "February 2012", "prism:doi": "10.1016/j.ygeno.2011.11.003", "prism:startingPage": "90", "dc:identifier": "doi:10.1016/j.ygeno.2011.11.003", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "25", "@width": "432", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754311002606-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2549", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "243", "@width": "489", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754311002606-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "24520", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "109", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754311002606-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2937", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "1076", "@width": "2166", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754311002606-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "212086", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "368", "@width": "513", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754311002606-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "30537", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "157", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754311002606-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3520", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "high", "@height": "1628", "@width": "2272", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754311002606-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "260142", "@ref": "gr2", "@mimetype": "image/jpeg"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84856426339"}}
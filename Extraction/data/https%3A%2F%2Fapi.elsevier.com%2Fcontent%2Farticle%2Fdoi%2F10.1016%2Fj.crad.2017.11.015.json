{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0009926017305354", "dc:identifier": "doi:10.1016/j.crad.2017.11.015", "eid": "1-s2.0-S0009926017305354", "prism:doi": "10.1016/j.crad.2017.11.015", "pii": "S0009-9260(17)30535-4", "dc:title": "Artificial intelligence in fracture detection: transfer learning from deep convolutional neural networks ", "prism:publicationName": "Clinical Radiology", "prism:aggregationType": "Journal", "prism:issn": "00099260", "prism:volume": "73", "prism:issueIdentifier": "5", "prism:startingPage": "439", "prism:endingPage": "445", "prism:pageRange": "439-445", "prism:number": "5", "dc:format": "application/json", "prism:coverDate": "2018-05-31", "prism:coverDisplayDate": "May 2018", "prism:copyright": "\u00a9 2017 The Royal College of Radiologists. Published by Elsevier Ltd. All rights reserved.", "prism:publisher": "The Royal College of Radiologists. Published by Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Kim, D.H."}, {"@_fa": "true", "$": "MacKinnon, T."}], "dc:description": "\n               \n                  Aim\n                  To identify the extent to which transfer learning from deep convolutional neural networks (CNNs), pre-trained on non-medical images, can be used for automated fracture detection on plain radiographs.\n               \n               \n                  Materials and methods\n                  The top layer of the Inception v3 network was re-trained using lateral wrist radiographs to produce a model for the classification of new studies as either \u201cfracture\u201d or \u201cno fracture\u201d. The model was trained on a total of 11,112 images, after an eightfold data augmentation technique, from an initial set of 1,389 radiographs (695 \u201cfracture\u201d and 694 \u201cno fracture\u201d). The training data set was split 80:10:10 into training, validation, and test groups, respectively. An additional 100 wrist radiographs, comprising 50 \u201cfracture\u201d and 50 \u201cno fracture\u201d images, were used for final testing and statistical analysis.\n               \n               \n                  Results\n                  The area under the receiver operator characteristic curve (AUC) for this test was 0.954. Setting the diagnostic cut-off at a threshold designed to maximise both sensitivity and specificity resulted in values of 0.9 and 0.88, respectively.\n               \n               \n                  Conclusion\n                  The AUC scores for this test were comparable to state-of-the-art providing proof of concept for transfer learning from CNNs in fracture detection on plain radiographs. This was achieved using only a moderate sample size. This technique is largely transferable, and therefore, has many potential applications in medical imaging, which may lead to significant improvements in workflow productivity and in clinical risk reduction.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0009926017305354", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0009926017305354", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "85038394587", "scopus-eid": "2-s2.0-85038394587", "pubmed-id": "29269036", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/85038394587", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20171218", "$": "2017-12-18"}}}}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608005001309", "dc:identifier": "doi:10.1016/j.neunet.2005.06.044", "eid": "1-s2.0-S0893608005001309", "prism:doi": "10.1016/j.neunet.2005.06.044", "pii": "S0893-6080(05)00130-9", "dc:title": "Bayesian approach to feature selection and parameter tuning for support vector machine classifiers ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2005 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "18", "prism:issueIdentifier": "5-6", "prism:startingPage": "693", "prism:endingPage": "701", "prism:pageRange": "693-701", "prism:number": "5-6", "dc:format": "application/json", "prism:coverDate": "2005-08-31", "prism:coverDisplayDate": "July\u2013August 2005", "prism:copyright": "Copyright \u00a9 2005 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "IJCNN 2005", "dc:creator": [{"@_fa": "true", "$": "Gold, Carl"}, {"@_fa": "true", "$": "Holub, Alex"}, {"@_fa": "true", "$": "Sollich, Peter"}], "dc:description": "\n               Abstract\n               \n                  A Bayesian point of view of SVM classifiers allows the definition of a quantity analogous to the evidence in probabilistic models. By maximizing this one can systematically tune hyperparameters and, via automatic relevance determination (ARD), select relevant input features. Evidence gradients are expressed as averages over the associated posterior and can be approximated using Hybrid Monte Carlo (HMC) sampling. We describe how a Nystr\u00f6m approximation of the Gram matrix can be used to speed up sampling times significantly while maintaining almost unchanged classification accuracy. In experiments on classification problems with a significant number of irrelevant features this approach to ARD can give a significant improvement in classification performance over more traditional, non-ARD, SVM systems. The final tuned hyperparameter values provide a useful criterion for pruning irrelevant features, and we define a measure of relevance with which to determine systematically how many features should be removed. This use of ARD for hard feature selection can improve classification accuracy in non-ARD SVMs. In the majority of cases, however, we find that in data sets constructed by human domain experts the performance of non-ARD SVMs is largely insensitive to the presence of some less relevant features. Eliminating such features via ARD then does not improve classification accuracy, but leads to impressive reductions in the number of features required, by up to 75%.\n                        1\n                     \n                     \n                        1\n                        An abbreviated version of some portions of this article appeared in (Gold & Sollich, 2005), published under the IEEE copyright.\n                     \n                  \n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608005001309", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608005001309", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "27744569713", "scopus-eid": "2-s2.0-27744569713", "pubmed-id": "16111861", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/27744569713", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20050818", "$": "2005-08-18"}}}}}
{"scopus-eid": "2-s2.0-84899483858", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2013-12-18 2013-12-18 2015-08-06T04:49:43 1-s2.0-S1532046413002001 S1532-0464(13)00200-1 S1532046413002001 10.1016/j.jbi.2013.12.009 S300 S300.4 FULL-TEXT 1-s2.0-S1532046414X0002X 2015-08-06T04:15:33.718268-04:00 0 0 20140401 20140430 2014 2013-12-18T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor highlightsabst primabst ref specialabst 1532-0464 15320464 true 48 48 C Volume 48 15 114 121 114 121 201404 April 2014 2014-04-01 2014-04-30 2014 Original Research Articles article fla Copyright \u00a9 2013 Elsevier Inc. All rights reserved. ANOVELARTIFICIALNEURALNETWORKMETHODFORBIOMEDICALPREDICTIONBASEDMATRIXPSEUDOINVERSION CAI B 1 Introduction and background 2 Methods 2.1 MPI-ANN 2.2 LASSO 2.3 Data sets 2.4 Experimental method 3 Results 3.1 Results of SNP simulated data 3.2 Results of UCI-BCW real data 4 Discussion 5 Conclusions Acknowledgment References SHORTLIFFE 2006 E BIOMEDICALINFORMATICSCOMPUTERAPPLICATIONSINHEALTHCAREBIOMEDICINE KIM 2012 1191 1198 D GOLUB 1999 531 537 T CESARIO 2011 A CANCERSYSTEMSBIOLOGYBIOINFORMATICSMEDICINERESEARCHCLINICALAPPLICATIONS ZHOU 2004 249 259 X LONG 2011 2003 2023 Q WANG 2005 1530 1537 Y JIANG 2010 462 471 X SARITAS 2012 2901 2907 I HUA 2006 274 J LANCASHIRE 2010 83 93 L STERITI 1993 3074 3077 R ZHANG 2010 Y ARTIFICIALNEURALNETWORKSPROGRESSDEBATEDURINGPUBLISHINGPROCESS RUMELHART 1986 D PARALLELDISTRIBUTEDPROCESSING BELCIUG 2013 243 254 S HUANG 2006 489 501 G HASTIE 2009 T ELEMENTSSTATISTICALLEARNINGDATAMININGINFERENCEPREDICTION HANS 2009 835 845 C CYBENKO 1989 303 314 G TAMURA 1997 251 255 S SERRE 2002 D MATRICESTHEORYAPPLICATIONS CAI 2012 3146 3155 B CAI 2010 213 229 B EFRON 2004 407 499 B VELEZ 2007 306 315 D MANGASARIAN 1990 22 30 O LARGESCALENUMERICALOPTIMIZATION PATTERNRECOGNITIONVIALINEARPROGRAMMINGTHEORYAPPLICATIONMEDICALDIAGNOSIS JIANG 2010 575 581 X JIANG 2011 e22075 X JIANG 2011 X FAN 2008 1871 1874 R CAIX2014X114 CAIX2014X114X121 CAIX2014X114XB CAIX2014X114X121XB Full 2015-04-01T00:18:08Z ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window item S1532-0464(13)00200-1 S1532046413002001 1-s2.0-S1532046413002001 10.1016/j.jbi.2013.12.009 272371 2015-08-06T04:15:33.718268-04:00 2014-04-01 2014-04-30 1-s2.0-S1532046413002001-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/MAIN/application/pdf/3fd3860c25795bc12bef2223dc29864a/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/MAIN/application/pdf/3fd3860c25795bc12bef2223dc29864a/main.pdf main.pdf pdf true 601411 MAIN 8 1-s2.0-S1532046413002001-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/PREVIEW/image/png/9b796db2bdcd958cf94e19bbf6b0ab85/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/PREVIEW/image/png/9b796db2bdcd958cf94e19bbf6b0ab85/main_1.png main_1.png png 60405 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046413002001-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/10e7b442abba29604c119aef32c95fe8/si22.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/10e7b442abba29604c119aef32c95fe8/si22.gif si22 si22.gif gif 4691 70 508 ALTIMG 1-s2.0-S1532046413002001-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/c001efdffb07ef010734942b05904ad1/si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/c001efdffb07ef010734942b05904ad1/si17.gif si17 si17.gif gif 1616 38 303 ALTIMG 1-s2.0-S1532046413002001-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/006b61d5eafc665624da7f718b08ca52/si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/006b61d5eafc665624da7f718b08ca52/si16.gif si16 si16.gif gif 1517 48 243 ALTIMG 1-s2.0-S1532046413002001-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/f2c57b1eefc7a19a8a77a6ef03d5df6d/si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/f2c57b1eefc7a19a8a77a6ef03d5df6d/si15.gif si15 si15.gif gif 1058 20 273 ALTIMG 1-s2.0-S1532046413002001-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/6bd353eea22b0558007036fcbca897ac/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/6bd353eea22b0558007036fcbca897ac/si12.gif si12 si12.gif gif 2236 25 494 ALTIMG 1-s2.0-S1532046413002001-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/6043157af6acf8db113e1b2ef3880f59/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/6043157af6acf8db113e1b2ef3880f59/si10.gif si10 si10.gif gif 461 20 75 ALTIMG 1-s2.0-S1532046413002001-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/e1f6212e0cd956c01797a5479a9e572e/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/e1f6212e0cd956c01797a5479a9e572e/si9.gif si9 si9.gif gif 848 22 215 ALTIMG 1-s2.0-S1532046413002001-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/b3f0180cfa4490e751142ea98cebbcbf/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/b3f0180cfa4490e751142ea98cebbcbf/si8.gif si8 si8.gif gif 5733 221 548 ALTIMG 1-s2.0-S1532046413002001-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/bbdc973991eeeaf8676a9a8eb6ba6356/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/bbdc973991eeeaf8676a9a8eb6ba6356/si7.gif si7 si7.gif gif 422 17 69 ALTIMG 1-s2.0-S1532046413002001-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/24433f8e39719d7d3f0c585914dec40e/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/24433f8e39719d7d3f0c585914dec40e/si6.gif si6 si6.gif gif 1242 52 174 ALTIMG 1-s2.0-S1532046413002001-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/e0b9c0c46466820bd2dcf2b3001622b1/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/e0b9c0c46466820bd2dcf2b3001622b1/si5.gif si5 si5.gif gif 783 46 106 ALTIMG 1-s2.0-S1532046413002001-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/5fba403dc34975e5f8812bbe88e2d6b0/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/5fba403dc34975e5f8812bbe88e2d6b0/si3.gif si3 si3.gif gif 1388 24 369 ALTIMG 1-s2.0-S1532046413002001-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/e1ff758056038653c281c5892b06978f/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/e1ff758056038653c281c5892b06978f/si4.gif si4 si4.gif gif 222 17 14 ALTIMG 1-s2.0-S1532046413002001-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/c0c5bb84209c75206224a7e2c9524474/si21.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/c0c5bb84209c75206224a7e2c9524474/si21.gif si21 si21.gif gif 291 14 41 ALTIMG 1-s2.0-S1532046413002001-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/bc2e68f437f0611030057c23a2ee1615/si20.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/bc2e68f437f0611030057c23a2ee1615/si20.gif si20 si20.gif gif 306 15 43 ALTIMG 1-s2.0-S1532046413002001-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/7e61b347f07cb6d0f32480b97a70dbe9/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/7e61b347f07cb6d0f32480b97a70dbe9/si2.gif si2 si2.gif gif 237 19 16 ALTIMG 1-s2.0-S1532046413002001-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/767c35db2f2285d2ca40624a0bb5f31f/si19.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/767c35db2f2285d2ca40624a0bb5f31f/si19.gif si19 si19.gif gif 268 14 41 ALTIMG 1-s2.0-S1532046413002001-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/50db839bdfdc9916e7f473f2943790d3/si18.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/50db839bdfdc9916e7f473f2943790d3/si18.gif si18 si18.gif gif 312 15 44 ALTIMG 1-s2.0-S1532046413002001-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/a0962a7929dba63add5f7d39e3eb9aed/si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/a0962a7929dba63add5f7d39e3eb9aed/si14.gif si14 si14.gif gif 420 25 50 ALTIMG 1-s2.0-S1532046413002001-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/da878d09b979d73c230f0315858f47af/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/da878d09b979d73c230f0315858f47af/si13.gif si13 si13.gif gif 562 21 83 ALTIMG 1-s2.0-S1532046413002001-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/64237f35ea0a6d7e53daa1c28072cba8/si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/64237f35ea0a6d7e53daa1c28072cba8/si11.gif si11 si11.gif gif 616 33 126 ALTIMG 1-s2.0-S1532046413002001-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/STRIPIN/image/gif/c90b7dd0befc7ae5cca303ce7833c96f/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/STRIPIN/image/gif/c90b7dd0befc7ae5cca303ce7833c96f/si1.gif si1 si1.gif gif 491 21 70 ALTIMG 1-s2.0-S1532046413002001-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr1/HIGHRES/image/jpeg/e36e4be722e3ece43a65a7d6769ab4a2/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr1/HIGHRES/image/jpeg/e36e4be722e3ece43a65a7d6769ab4a2/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 320022 1203 2067 IMAGE-HIGH-RES 1-s2.0-S1532046413002001-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/fx1/HIGHRES/image/jpeg/b0f1d660c2b03f29de20d270e45a89a8/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/fx1/HIGHRES/image/jpeg/b0f1d660c2b03f29de20d270e45a89a8/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 190996 886 1373 IMAGE-HIGH-RES 1-s2.0-S1532046413002001-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr3/HIGHRES/image/jpeg/6d7ef0cad4f3308e470b93b7a720684e/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr3/HIGHRES/image/jpeg/6d7ef0cad4f3308e470b93b7a720684e/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 324720 1369 3305 IMAGE-HIGH-RES 1-s2.0-S1532046413002001-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr2/HIGHRES/image/jpeg/d0b982fcc54e64d2f24f9f80bc08aaa0/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr2/HIGHRES/image/jpeg/d0b982fcc54e64d2f24f9f80bc08aaa0/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 1124510 2613 3356 IMAGE-HIGH-RES 1-s2.0-S1532046413002001-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr1/DOWNSAMPLED/image/jpeg/3c1b9e56ce1c24f23ebaf2618ce36146/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr1/DOWNSAMPLED/image/jpeg/3c1b9e56ce1c24f23ebaf2618ce36146/gr1.jpg gr1 gr1.jpg jpg 42155 272 467 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413002001-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/fx1/DOWNSAMPLED/image/jpeg/372d62aa2783899f0f01f133b9b84d09/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/fx1/DOWNSAMPLED/image/jpeg/372d62aa2783899f0f01f133b9b84d09/fx1.jpg fx1 true fx1.jpg jpg 29213 200 310 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413002001-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr3/DOWNSAMPLED/image/jpeg/62de3258489fb7d8794634d6e1165c0b/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr3/DOWNSAMPLED/image/jpeg/62de3258489fb7d8794634d6e1165c0b/gr3.jpg gr3 gr3.jpg jpg 41475 309 746 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413002001-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr2/DOWNSAMPLED/image/jpeg/0061693acdcd272a50e616e710847b07/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr2/DOWNSAMPLED/image/jpeg/0061693acdcd272a50e616e710847b07/gr2.jpg gr2 gr2.jpg jpg 122626 590 758 IMAGE-DOWNSAMPLED 1-s2.0-S1532046413002001-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr1/THUMBNAIL/image/gif/17f66415d875a93502ef2945b5812542/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr1/THUMBNAIL/image/gif/17f66415d875a93502ef2945b5812542/gr1.sml gr1 gr1.sml sml 6286 127 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413002001-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/fx1/THUMBNAIL/image/gif/0fd5882d49ba3b975bb96f51dbaaec69/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/fx1/THUMBNAIL/image/gif/0fd5882d49ba3b975bb96f51dbaaec69/fx1.sml fx1 true fx1.sml sml 5571 141 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413002001-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr3/THUMBNAIL/image/gif/bee7dea9280fc16065ef1d4b043688b4/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr3/THUMBNAIL/image/gif/bee7dea9280fc16065ef1d4b043688b4/gr3.sml gr3 gr3.sml sml 3515 91 219 IMAGE-THUMBNAIL 1-s2.0-S1532046413002001-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046413002001/gr2/THUMBNAIL/image/gif/4ce45236f922a2d032528fcb93c0f6df/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046413002001/gr2/THUMBNAIL/image/gif/4ce45236f922a2d032528fcb93c0f6df/gr2.sml gr2 gr2.sml sml 8429 164 210 IMAGE-THUMBNAIL YJBIN 2097 S1532-0464(13)00200-1 10.1016/j.jbi.2013.12.009 Elsevier Inc. Fig. 1 Structure diagram for MPI-ANN. Fig. 2 Correct rate comparison of MPI-ANN and LASSO for SNP simulated data. Fig. 3 Correct rate comparison of MPI-ANN and LASSO for UCI-BCW data. Table 1 Experimental results of MPI-ANN and LASSO for SNP simulated data. Feature combination Correct rate Outperformance% MPI-ANN: LASSO p-Value MPI-ANN: LASSO MPI-ANN LASSO Training Testing Training Testing Training (%) Testing (%) Training Testing F 0 0.524998 0.499619 0.517434 0.499686 1.46 \u22120.01 3.03\u00d710\u22123 4.22\u00d710\u221211 F 1 0.524987 0.500023 0.517518 0.499695 1.44 \u22120.07 7.06\u00d710\u22123 5.10\u00d710\u221215 F 0 \u2212 F 1 0.676720 0.661922 0.528117 0.501470 28.09 31.94 2.20\u00d710\u22127 2.04\u00d710\u22126 F 0 \u2212 F 2 0.634639 0.603899 0.533506 0.500638 18.94 20.60 1.10\u00d710\u22124 2.02\u00d710\u22123 F 0 \u2212 F 3 0.606649 0.566907 0.538429 0.500508 12.66 13.25 7.46\u00d710\u22127 1.21\u00d710\u22123 F 0 \u2212 F 4 0.587628 0.542026 0.543084 0.500541 8.20 8.28 5.22\u00d710\u22125 1.90\u00d710\u22122 F 0 \u2212 F 19 0.558203 0.501313 0.584856 0.499962 \u22124.56 0.27 4.41\u00d710\u22122 4.32\u00d710\u22123 Table 2 Comparison of MPI-ANN, SVM and LR for all-feature UCI-BCW data. Methods Correct rate Sensitivity Specificity Computation time (s) Training Testing Training Testing Training Testing Training Testing MPI-ANN 0.902182 0.897344 0.930118 0.927830 0.850430 0.841355 0.012962 0.002720 SVM 0.872625 0.858051 0.889490 0.876864 0.840717 0.818350 0.015600 0.031200 LR 0.872990 0.857986 0.885083 0.865766 0.850403 0.847645 0.046800 0.031200 A novel artificial neural network method for biomedical prediction based on matrix pseudo-inversion Binghuang Cai \u204e bic9@pitt.edu bhcai8@gmail.com Xia Jiang xij6@pitt.edu Department of Biomedical Informatics, School of Medicine, University of Pittsburgh, Pittsburgh, PA 15206-3701, USA Department of Biomedical Informatics School of Medicine University of Pittsburgh Pittsburgh PA 15206-3701 USA \u204e Corresponding author. Address: Department of Biomedical Informatics, School of Medicine, University of Pittsburgh, 5607 Baum Blvd., Pittsburgh, PA 15206-3701, USA. Fax: +1 4126245310. Graphical abstract Highlights \u2022 We develop an effective neural network (MPI-ANN) method for biomedical prediction. \u2022 MPI-ANN directly determines the network weights without lengthy learning iteration. \u2022 Experiments conducted using simulated SNP and real cancer data by cross validation. \u2022 Results show MPI-ANN\u2019s efficacy and significantly better performance than LASSO. \u2022 Results also show that MPI-ANN could be used for bio-marker selection. Abstract Biomedical prediction based on clinical and genome-wide data has become increasingly important in disease diagnosis and classification. To solve the prediction problem in an effective manner for the improvement of clinical care, we develop a novel Artificial Neural Network (ANN) method based on Matrix Pseudo-Inversion (MPI) for use in biomedical applications. The MPI-ANN is constructed as a three-layer (i.e., input, hidden, and output layers) feed-forward neural network, and the weights connecting the hidden and output layers are directly determined based on MPI without a lengthy learning iteration. The LASSO (Least Absolute Shrinkage and Selection Operator) method is also presented for comparative purposes. Single Nucleotide Polymorphism (SNP) simulated data and real breast cancer data are employed to validate the performance of the MPI-ANN method via 5-fold cross validation. Experimental results demonstrate the efficacy of the developed MPI-ANN for disease classification and prediction, in view of the significantly superior accuracy (i.e., the rate of correct predictions), as compared with LASSO. The results based on the real breast cancer data also show that the MPI-ANN has better performance than other machine learning methods (including support vector machine (SVM), logistic regression (LR), and an iterative ANN). In addition, experiments demonstrate that our MPI-ANN could be used for bio-marker selection as well. Keywords Biomedical prediction and classification Neural networks Matrix pseudo-inversion Least Absolute Shrinkage and Selection Operator (LASSO) Single Nucleotide Polymorphism (SNP) Cancer 1 Introduction and background In the biomedical area, predicting clinical outcomes and diagnosing disease from available information, such as clinical and genetic evidence, is an important task for patient care and disease cure, especially for cancer applications [1,2]. Biomedical prediction problems are widely encountered in clinical applications including prognosis, diagnosis, and prediction of response to therapy. As information technology and medical equipment rapidly develop, more and more data, including clinical and genetic information, can be collected for medical utilization, which can increase the accuracy of biomedical prediction. However, as data become very large, especially genome-wide data, the processing of the data and the computation time for biomedical prediction is time-consuming and difficult. The biomedical prediction problem has been increasingly investigated by biomedical and informatics researchers [1\u20134]. This paper will address this challenging problem via developing an effective method and its algorithm. The biomedical prediction problem can be mathematically described as follows. Given an N-sample training data set with elements defined as { X i , Y i } i = 1 N , where X i =[xi 1, xi 2,..., xim ]T \u220a R m (with m being the number of features/attributes) and Y i =[yi 1, yi 2,\u2026, yin ]T \u220a R n (with n being the number of targets), the prediction problem is to discover the relation between X i and Y i and develop a model to describe such a relation, so that the output of the model, Y ^ i , can be as close to the actual targets Y i as possible. The problem can be described as (1) X i \u2192 M \u2192 Y i , s . t . | Y i - Y ^ i | \u2192 0 , i \u2208 { 1 , 2 , \u2026 , N } . The discovered model M can then be used for the outcome prediction of a new observation X \u223c . This is important and useful for genetic prediction, clinical diagnosis, and disease classification. The problem is difficult to solve because biomedical data are often discontinuous, incomplete (values missing) and large-scale. Different models and methods have been developed for the biomedical prediction problem [3,5\u201311]. For instance, a Bayesian approach using the logistic regression model was presented in [5] for cancer classification and prediction. The risk prediction of prostate cancer recurrence was investigated in [6] through regularized rank estimation in partly linear AFT (Accelerated Failure Time) models using high-dimensional gene and clinical data. An automatically derived class predictor was presented in [3] to determine the class of new leukemia cases based on gene expression monitoring by DNA micro-arrays. An effective hybrid approach for selecting marker genes was developed in [7] for phenotype classification using micro-array gene expression data. A Bayesian network model for disease outbreak prediction was developed in [8]. Artificial Neural Networks (ANNs) are widely used in science and information technology due to their notable properties including parallelism, distributed storage, and adaptive self-learning capability [12\u201315]. They have also been utilized to solve biomedical problems, especially in the areas of classification and prediction [9\u201311]. For example, an artificial neural network, which was developed in [9] to determine whether breast cancer is present based on the age of the patient, mass shape, mass border, and mass density, achieved high predictive rates. A noise-injected neural network was designed in [10] for the classification of small-sample expression data for breast cancer patients. It demonstrated superior performance compared to the other methods tested. Another artificial neural network approach was used to reduce the number of gene signatures for the classification of breast cancer patients and the prediction of clinical outcomes, including the capability to accurately predict distant metastases [11]. However, all these ANN methods become very time-consuming as data become bigger, because the traditional learning method based on back-propagation algorithm is employed, and therefore they may not be applicable to practical biomedical prediction. A hybrid neural network and genetic algorithm method was applied to breast cancer detection in [16]; it used a genetic algorithm to determine the weights of the neural network (i.e., a multi-layer perceptron (MLP)). However, time-consuming iterations are still needed to get the weights for this hybrid ANN method. Based on our previous work on weight determination of neural networks [13,14] and related work on ANN learning [17], we develop a Matrix-Pseudo-Inversion based Artificial Neural Network (MPI-ANN) for biomedical prediction. MPI-ANN is a feed-forward neural network with one input layer, one hidden layer and one output layer. Most importantly, MPI-ANN can directly determine the weights of the neural network in one step using pseudo-inversion without a traditional weight-updating iteration. For comparison purposes, LASSO (Least Absolute Shrinkage and Selection Operator) [18,19] is also presented for the biomedical prediction problem. Experimental results based on a set of simulated data sets and a real data set demonstrate the effectiveness and efficiency of the developed MPI-ANN method. Not only does MPI-ANN significantly outperform LASSO in terms of prediction accuracy for the simulated datasets, but it also demonstrates better performance in terms of statistical measurements and efficiency than other machine learning methods including support vector machine (SVM), logistic regression (LR) and an iterative ANN when analyzing a real breast cancer data. The remainder of this paper is organized in four sections. Section 2 presents the MPI-ANN and the LASSO methods, and also introduces the experiment data sets and methods. In Section 3, experimental results are described and analyzed. A discussion appears in Section 4, and Section 5 concludes the paper with final remarks. 2 Methods In this section, the MPI-ANN method is presented and developed for the biomedical prediction problem. The comparative method, LASSO, is also presented. Experimental data sets and the experimental method are finally introduced. 2.1 MPI-ANN To solve the biomedical prediction problem, a feed-forward neural network is constructed according to the structure diagram shown in Fig. 1 . The constructed MPI-ANN has three layers, i.e., the input layer, the hidden layer, and the output layer. The inputs to the neural network are the observed values of the features in the data set, while the outputs are the targets. Specifically, in the input layer of MPI-ANN, the kth (k =1,2,\u2026, m) input of the MPI-ANN is the observed value of the kth feature. Each neuron of the input-layer uses a linear activation function f(x)= x; i.e., the values input into the neural network are directly passed to the hidden layer. Moreover, the hidden layer has p neurons, which employs a group of activation functions fl (l =1,2,\u2026, p); i.e., the lth hidden-layer neuron adopts fl as its activation function. Different kinds of non-regular functions [14,17] can be employed as the activation function of the hidden nodes. In this paper, based on a universal approximation theorem [20], the sigmoid function (i.e., f(x)=1/(1+ e \u2212 x )) is employed for the MPI-ANN, since it is continuous (and thus differentiable), its derivative can be computed quickly, and it has a limited range (from 0 to 1, exclusive) [20]. The connecting weights between the input and hidden layers, ukl \u220a R (k =1,2,\u2026, m; l =1,2,\u2026, p), and the biases of the neurons in the hidden layer, bl \u220a R(l =1,2,\u2026, p), are randomly generated in any intervals of R, since random choice of the input weights and hidden layer biases can exactly learn the training observations, make learning extremely fast, and produce good generalization performance according to [17,21]. Furthermore, the neurons in the output layer also use a linear activation function, and the inputs from the hidden layer are summed as the outputs of the neural network. The MPI-ANN can be considered as a kind of BP (Back Propagation) neural network; so it could use an error back-propagation algorithm [13,15,22] as its training law to determine the weights, wlj \u220a R (l =1,2,\u2026, p; j =1,2,\u2026, n), between the hidden and output layers. To avoid the lengthy learning iteration of the traditional error back-propagation (BP) algorithm based on the gradient-descent method [13,15,22], we develop a matrix pseudo-inversion based weight direct determination method to determine such weights for biomedical prediction. Mathematically, the MPI-ANN model can be formulated as (2) y ij = \u2211 l = 1 p h il w lj , where i =1,2,\u2026, N; j =1,2,\u2026, n and (3) h il = f l \u2211 k = 1 m u kl x ik + b l , is the output of the lth node of the hidden layer for the ith sample. Based on matrix theory [23], the MPI-ANN model (2) can be expressed as the following matrix form. (4) Y = HW , where Y = y 11 y 12 \u22ef y 1 n y 21 y 22 \u22ef y 2 n \u22ee \u22ee \u22f1 \u22ee y N 1 y N 2 \u22ef y Nn \u2208 R N \u00d7 n , H = h 11 h 12 \u22ef h 1 p h 21 h 22 \u22ef h 2 p \u22ee \u22ee \u22f1 \u22ee h N 1 h N 2 \u22ef h Np \u2208 R N \u00d7 p , W = w 11 w 12 \u22ef w 1 n w 21 w 22 \u22ef w 2 n \u22ee \u22ee \u22f1 \u22ee w p 1 w p 2 \u22ef w pn \u2208 R p \u00d7 n . The matrix-form error-function for MPI-ANN is expressed as follows: (5) E = \u2016 Y - Y ^ \u2016 2 = \u2016 Y - HW \u2016 2 , which is equivalent to the traditional element-wise error function for ANN learning. Next, we present a matrix-based weight determination theorem based on previous work [13,14,17]. Theorem Given observation {X, Y}, the weight matrix W of MPI-ANN can be directly determined by (6) W = H \u2020 Y , where H \u2020 = H T H - 1 H T is the pseudo-inverse (Moore-Penrose generalized inverse) [23] of matrix H defined in (4) and (3). Proof Based on the variable definitions of the matrix-form MPI-ANN model (4) and the definition of the matrix-form error function (5), the traditional training BP algorithm [13,15,22] for the neural network can be written in matrix form as follows according to matrix theory [23]: (7) W ( k + 1 ) = W ( k ) - \u03b7 ( \u2202 E / \u2202 W ) | W = W ( k ) = W ( k ) - \u03b7 H T ( HW ( k ) - Y ) . After a sufficient number of iterations, the error function (5) would become small enough, i.e., lim k \u2192\u221e E =0 and the weights can then be obtained. At the same time, the values of the connecting weights would become unchanged; i.e., lim k \u2192\u221e(W(k + 1) \u2212 W(k))=0. Thus, we can let W(k +1)= W(k)= W. Eq. (7) then reduces to H T(HW \u2212 Y)=0 and we have W =(H T H)\u2212 1 H T Y. As the pseudo-inverse (Moore-Penrose generalized inverse) [23] of matrix H can be defined as H \u2020 =(H T H)\u2212 1 H T, we have W = H \u2020 Y. The proof is now complete.\u25a1 In fact, the weight W determined by (9) is the least square solution of linear Eq. (6) based on an error function (5) [17]. We see that the weights can be determined by (6) in one step, which is much more efficient than traditional feed-forward neural network with lengthy training iterations. Preliminary research using simulations has shown that much less computational time (e.g., about 1850 times less time in the example of non-linear system identification in [14] and about 255 times less time in the example of real medical diagnosis in [17]) is required for this type of pseudo-inverse weight-determination ANN than conventional BP neural networks [13,14,17]. In all, we see the significantly superior efficiency of MPI-ANN over traditionally iterative ANN, which has been analyzed above and also mathematically and practically proven in the analysis and results in previous work [13,14,17] (including our previous work [13,14]). Based on the theoretical analysis of the MPI-ANN model above, the procedure of the MPI-ANN algorithm can be described by the following steps. (1) Network construction: construct MPI-ANN based on the network structure shown in Fig. 1. (2) Weight and bias generation: randomly generate weights, ukl (k =1,2,\u2026, m; l=1,2,\u2026, p), between the input and hidden layers, as well as the biases of the hidden neurons, bl (l =1,2,\u2026, p). (3) Weight determination: calculate the weights, wlj (l =1,2,\u2026, p; j =1,2,\u2026, n), between the hidden and output layers based on (6) and the training data sample { ( X i , Y i ) } i = 1 N . (4) Prediction testing: calculate the predicted outcome for the testing data sample { X \u223c i } i = 1 N using (2) based on the determined weights wlj . 2.2 LASSO For comparative purposes, the LASSO (Least Absolute Shrinkage and Selection Operator) method is also presented to solve the prediction problem. LASSO is a shrinkage linear method for regression, which is simple and often provides an adequate and interpretable description of how the inputs affect the output [18,19]. LASSO fits the following linear model for the jth (j =1,2,\u2026, n) target of the biomedical problem (1), (8) y \u02c6 ij = b 0 + b 1 x i 1 + b 2 x i 2 + \u2026 + b m x im , where b 0, b 1,\u2026, bm are the model parameters and can be obtained by (9) min \u2211 i = 1 N ( y ij - y \u02c6 ij ) 2 s . t . \u2211 k = 0 m | b k | \u2a7d s , with s being the bound turning parameter. LASSO could also be expressed as the equivalent Lagrangian form (10) \u03b2 \u02c6 = arg min \u03b2 \u03b3 j - \u03c7 \u03b2 T ( \u03b3 j - \u03c7 \u03b2 ) + \u03bb \u2016 \u03b2 \u2016 1 , where \u03b3j =[y 1 j , y 2 j ,\u2026, yNj ] T \u220a R N \u00d71, \u03b2j =[b 0, b 1,\u2026, bm ] T \u220a R ( m +1)\u00d71, \u03c7 =[\u03c7 1, \u03c7 2,\u2026, \u03c7m ] T \u220a R N \u00d7 m , with \u03c7i =[1, x 1 i , x 2 i ,\u2026, xNi ] T \u220a R N \u00d71, and \u03bb \u2a7e 0 determines the amount of shrinkage. We see that the computation of the LASSO solution is a Quadratic Programming (QP) problem. The QP problem could be solved readily using the MATLAB routine \u201cQUADPROG\u201d [24], or solved preferably by using neural networks [25,26]. Note that when s is large enough (i.e., \u03bb = 0 ), LASSO is multiple linear least squares regression; when s \u2a7e 0 (i.e., \u03bb > 0 ) is a smaller value, LASSO solutions are shrunken versions of the least squares estimates [19]. The computation of the entire path of the LASSO solution can be achieved based on Least Angle Regression (LAR) [27], which is intimately connected with LASSO. That is, LAR provides an extremely efficient algorithm for computing the entire LASSO path, which gives the entire path of LASSO solutions. Different packages have been developed for the computation of LASSO, such as \u201classo4j\u201d [28] in JAVA and \u201cglmnet\u201d [29] in R [30]. In our experiments, \u201classo4j\u201d is used. 2.3 Data sets Two different data sets are employed for the validation of the performance of the developed MPI-ANN algorithm as well as the LASSO method. They are SNP (Single Nucleotide Polymorphism) simulated data sets [31] and the publicly available UCI-BCW [University of California, Irvine (UCI) Breast Cancer Wisconsin] real data set [32]. The SNP simulated data are computer-generated SNP data. They consist of 28,000 simulated data sets generated from 70 different genetic models of 2-SNP strict epistasis. The models were developed based on 70 different penetrance functions that define a probabilistic relationship between genotype and phenotype, which lead to different sensitivities between SNPs and diseases [31]. For example, according to Supplementary Table 1 in [31] and our findings using Bayesian network based methods in our previous studies [33\u201335], Models 55\u201359 have the weakest broad-sense heritability (0.01) and a minor allele frequency (0.2), which would have the lowest detection sensitivity between features and target. In contrast, Models 25\u201329 have the strongest broad-sense heritability (0.4) and a major allele frequency (0.4), which has the highest detection sensitivity. For each model, there are 4 different sample-sizes of data sets, i.e. 200, 400, 800, and 1600. For each sample-size in each model, 100 data sets are generated. Within each data set, there are 20 features (F 0, F 1,\u2026, F 19) with values being 0, 1, or 2 (corresponding to three different states of a SNP), and one disease class indicator with value being 0 or 1 indicating non-disease or having-disease. The numbers of non-disease and having-disease samples are the same in each data set. Note that, for a generated pair of epistatic SNP values (i.e., F 0 and F 1), a set of other 18 SNPs (i.e., F 2 \u2212 F 19) assigned random values was appended to simulate SNPs that are non-informative with respect to the disease status [31\u201335]. The first and the second features (i.e., F 0 and F 1) are the predictors for the disease. The UCI-BCW real data set was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg [32], and is available through the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29). The UCI-BCW data set has 683 samples with complete attribute values. Each sample has 10 features/attributes (i.e., F 0 \u2013 ID Number, F 1 \u2013 Clump Thickness, F 2 \u2013 Uniformity of Cell Size, F 3 \u2013 Uniformity of Cell Shape, F 4 \u2013 Marginal Adhesion, F 5 \u2013 Single Epithelial Cell Size, F 6 \u2013 Bare Nuclei, F 7 \u2013 Bland Chromatin, F 8 \u2013 Normal Nucleoli, F 9 \u2013 Mitoses) and one class feature with value being 2 (for benign tumor) or 4 (for malignant tumor). Note that, there are 444 benign tumor samples and 239 malignant tumor samples in the data set. 2.4 Experimental method The MPI-ANN algorithm and LASSO algorithm were implemented in JAVA [36] with the matrix package \u201cJAMA\u201d [37] employed for matrix calculation in the algorithm, while all experiments of MPI-ANN and LASSO were conducted in the eclipse environment [38]. In the experiments, as a representative example, the weights between the input and hidden layers of MPI-ANN were randomly generated within the range of (\u22121, 1) and the biases of the hidden nodes were randomly generated within the range of (0,1). The number of hidden nodes of MPI-ANN was fixed to 10, i.e., p =10, which is chosen based on experiment testing of different performances of MPI-ANN with different numbers of hidden nodes. The experiments were run on a computer with Intel\u00ae Core\u2122 2 Duo CPU E7600 3.06GHz, 4.00GB RAM. Since the targets of the two data sets include two class types (non-disease and having-disease for SNP data, benign tumor and malignant tumor for UCI-BCW data), the number of outputs of MPI-ANN was set to two. The first output yi 1 would output 1 if the ith sample belongs to the first class, otherwise, it would output \u22121. The same definition holds for yi 2 relative to the second class. Specifically, for SNP simulated data, yi 1 =1 and yi 2 =\u22121 are for class value equal to 1, while yi 1 =\u22121 and yi 2 =1 are for class value equal to 0. For the UCI-BCW data set, yi 1 =1 and yi 2 =\u22121 are for the benign tumor class, while yi 1 =\u22121 and yi 2 =1 are for the malignant tumor class. The correct rate was employed as the accuracy performance evaluation index, which is the proportion of the number of correctly predicted samples. In the SNP simulated data experiments, the average correct rate for all sample-size datasets in each model was calculated and compared for different feature combinations (e.g., F 0, F 1, F 0 \u2212 F 1, F 0 \u2212 F 2, F 0 \u2212 F 3, F 0 \u2212 F 4, and F 0 \u2212 F 19). Feature combinations were selected to test the performance of MPI-ANN for different sizes of feature sets. Predictors F 0 and/or F 1 were included in each combination in order to test the capability of MPI-ANN for predictor discovery. For the UCI-BCW real data set, the average correct rate of each combination of features was computed and compared. This list of feature combinations for testing was selected based on the performance of each feature. Each feature was first input into the MPI-ANN separately and the top-performing features were used to generate new combinations of features. In the UCI-BCW data experiment, each feature combination was tested 100 times to get the average correct rate. In addition, the outperformance percent and the p-value based on the t statistic test were calculated in order to compare the performance of MPI-ANN and LASSO. The 5-fold cross validation method [39] was used for each data set to get the correct rates of training and testing. Each dataset was divided into five parts based on the proportion between case and control of the original dataset, i.e., the proportion in each of the five parts were approximately the same as the one of the original dataset (i.e., 1:1 for SNP simulated data, and 444:239 for UCI-BCW real data). For each fold of cross validation, one part of the five parts of the dataset was selected as the testing data while the remaining four parts were considered as the training data. This was repeated for all five parts and the average value of the correct rate was generated for both training and testing. To demonstrate the efficacy of MPI-ANN further for practical applications, SVM and LR were also compared with MPI-ANN using the UCI-BCW dataset. SVM and LR were implemented using \u201cLIBLINEAR\u201d [40] in MATLAB. We conducted experiments for the prediction with all features (i.e., F 0 \u2212 F 9) of the UCI-BCW dataset as the input of the MPI-ANN and compared the results with SVM and LR. Correct rate, sensitivity, specificity and computing time were used as the evaluation indices for their comparison. Note that, the sensitivity and specificity are statistical measures for the performance of a binary classification. Sensitivity measures the proportion of true positives that are correctly identified, while specificity measures the proportion of true negatives that are correctly identified. Classification should be both sensitive and specific as much as possible [16]. Moreover, to show the superior efficiency of MPI-ANN as compared to iterative ANN methods, we compared the outcome of MPI-ANN with the latest iterative ANN method (i.e., the hybrid genetic algorithm and neural network (hybrid GA-NN) method presented in [16]) using the UCI-BCW dataset. 3 Results In this section, the experimental results are presented, described and compared for the SNP simulated data and the UCI-BCW real data. 3.1 Results of SNP simulated data The experimental results for the SNP simulated data are shown in Fig. 2 and Table 1. Fig. 2 shows that MPI-ANN obtains the best correct rate (red solid curve in Fig. 2(a and b)) for each model when using the data of Features F 0 and F 1 (the predictors in the SNP simulated data sets as mentioned in subsection 2.3) as the inputs of MPI-ANN, as compared with the other feature combinations, both in training and in testing. The simulation results (including the ones using other feature combinations, e.g., F 0 \u2212 F 5, F 0 \u2212 F 6,..., F 0 \u2212 F 18, not shown in Fig. 2) demonstrate that, when non-informative features are combined with the predictors (i.e., F 0 and F 1), a lower correct rate is achieved. Moreover, from Table 1, we see that the best average correct rates (i.e., 0.676720 and 0.661922) is obtained for training and testing when using Features F 0 and F 1. Meanwhile, the results from LASSO in the figure and table show that the best correct rate (less than 0.59) can only be achieved when all features (i.e., F 0 \u2212 F 19) are input for training, while other correct rates are around 0.5, especially for testing. This indicates that MPI-ANN can discover the predictors from the SNP simulated data, while LASSO may not have such capability for the SNP simulated data. This also implies that MPI-ANN can be applied in bio-marker selection in biomedical problems, e.g., via simply calculating the correct rates of different feature combinations and selecting the combination with best correct rate as the bio-marker. Moreover, Fig. 2 also shows that MPI-ANN can perform well for both easy-to-detect models (e.g., Models 25\u201329) and hard-to-detect models (e.g., Models 55\u201359); i.e., it achieves higher correct rates for easy-to-detect models and lower correct rates for hard-to-detect models. This is consistent with our previous findings (e.g., the ones in [34]) of model-related sensitivity using Bayesian networks, which was mentioned in subsection 2.3. We see that MPI-ANN is able to discover how strong the features are related to the targets/diseases, while LASSO does not show this ability since LASSO exhibits no significant difference between correct rates for different models. The experiment results also show that MPI-ANN only needs less than 0.022s to finish the training and less than 0.005s to obtain the output for the testing data. The computational times are slightly larger than the ones for LASSO (around 0.001s), but it is efficient enough for practical applications even in real-time situations. Table 1 also shows that MPI-ANN outperforms LASSO in most of the feature combinations, especially when the combination is the predictors (i.e., F 0 and F 1). For example, MPI-ANN outperforms LASSO by 31.94% in testing and 28.09% in training when the combination is F 0 and F 1. The p-values based on the t-test that appear in Table 1 show that the superior performance of MPI-ANN over LASSO is significant in both training and testing, especially when the combination is F 0 and F 1. This result substantiates the superiority of MPI-ANN for biomedical prediction as compared with LASSO. Above all, the experimental results based on SNP simulated data, show MPI-ANN\u2019s ability to detect biomarkers and discover features and target relationships, as well as MPI-ANN\u2019s significantly superior performance for biomedical prediction as compared with LASSO. 3.2 Results of UCI-BCW real data The experimental results for the UCI-BCW real data are shown in Fig. 3 . From the figure, we see that both MPI-ANN and LASSO can get high correct rates for the UCI-BCW data (from 0.75 to 0.95). However, MPI-ANN performs better (3.23% for training and 2.94% for testing) than LASSO for most combinations of features. The result of MPI-ANN outperforming LASSO is significant at the 9.26\u00d710\u2212 10 level training and at the 2.90\u00d710\u2212 9 level for testing. This again substantiates the effectiveness and superiority of the MPI-ANN method for biomedical prediction, as compared with LASSO. The experiment results also show that MPI-ANN uses less than 0.009s for training and less than 0.003s for testing, which is also efficient for practical applications. Note that the combinations of features are listed as follows: { { F 1 } 1 , { F 2 } 2 , { F 3 } 3 , { F 4 } 4 , { F 5 } 5 , { F 6 } 6 , { F 7 } 7 , { F 8 } 8 , { F 9 } 9 , { F 2 , F 3 } 10 , { F 2 , F 5 } 11 , { F 2 , F 7 } 12 , { F 3 , F 5 } 13 , { F 3 , F 6 } 14 , { F 3 , F 7 } 15 , { F 5 , F 6 } 16 , { F 5 , F 7 } 17 , { F 6 , F 7 } 18 , { F 3 , F 5 , F 6 } 19 , { F 2 , F 3 , F 5 , F 6 , F 7 } 20 } . As mentioned in subsection 2.4, the feature selection for this list is based on the performance of each feature. Specifically, each of the ten features (i.e., F 0 \u2212 F 9) is input into the MPI-ANN separately, and the performances of the outcomes are compared. Top features are used to generate new combinations of features for testing. This shows the potential of using MPI-ANN as a tool for bio-marker selection via comparing the network outputs of different features. The comparative results of MPI-ANN, SVM and LR for the prediction with all features (i.e., F 0 \u2212 F 9) in the UCI-BCW are shown in Table 2 . From the table, we see that the correct rates of the predicted output of MPI-ANN are about 3\u20134% better than the ones of SVM and LR in both training and testing. The sensitivity values of MPI-ANN are about 4\u20135% better than the ones of SVM and LR. The specificity values for MPI-ANN are slightly better than the ones for SVM, and are almost the same as the ones for LR. Moreover, the training time of MPI-ANN is about 3.6 times less than that of LR and slightly less than that of SVM, while the testing time of MPI-ANN is more than 10 times less than those of SVM and LR. This shows the efficiency of MPI-ANN owing it using a one-step weight determination algorithm. In summary, MPI-ANN outperforms SVM and LR for the real UCI-BCW dataset with all 9 features not only in statistical measurements but also in efficiency. In addition, as compared with the latest ANN method (i.e., the hybrid GA-NN method in [16]) for the all-feature UCI-BCW dataset, the performance values of MPI-ANN in Table 2 are similar and comparable to the ones of the hybrid GA-NN method presented in the column \u201cWPBC1\u201d of Tables 3 and 4 of [16] (e.g., 0.9142 as of the best testing correct rate). However, the MPI-ANN takes much less time than the hybrid ANN method. The hybrid ANN takes at least 348s (using a similar-speed computer with Intel\u00ae Core\u2122 2 Extreme CPU X9000, 2.80GHz and 4.00GB RAM for the experiments based on the same implementation language of JAVA) to get the results as shown in the column \u201cWPBC1\u201d of Tables 7 and 8 in [16], while MPI-ANN needs only 0.015682s for both training and testing. That is more than 22,000 times less using similar-speed computer and same programming language. We see that MPI-ANN can achieve similar classification performance with the hybrid ANN method, but it takes much less computing time than the hybrid ANN method. Such superior efficiency is due to MPI-ANN\u2019s one-step weight determination rather than the iterations used by the hybrid GA-NN method. In summary, the experiments based on the simulated data and the real data verify the effectiveness and efficiency of the developed MPI-ANN method for biomedical prediction, as well as the superior performance over LASSO and other machine learning methods. 4 Discussion According to the results described in the previous section, the developed MPI-ANN performed well for both simulated data and real data in terms of accuracy and computation time. The results indicate that MPI-ANN is sufficiently effective and efficient to be applied in practical biomedical prediction applications. It is worth mentioning that MPI-ANN is readily applicable to other data sets with different numbers of features and targets via simply changing the numbers of input and output nodes. It can even handle data with targets including both discrete and continuous values. In addition, MPI-ANN can solve the linear classification problems for the simulated SNP data and the real breast cancer data more effectively than linear classifiers, such as, LASSO, SVM and LR. It is worth mentioning that MPI-ANN can also work well on non-linear classification problems due to its multiple-layer structure and changeable activation functions. In the future, we will apply MPI-ANN to non-linear classification problems. For genome-wide data application, the number of features is huge (in general, more than ten thousands), which is much bigger than the numbers of features in the utilized data sets. Although MPI-ANN has shown its capability of processing a large number of data sets (28000 SNP simulated data sets), the handling of a huge number of features in a genome-wide data set using MPI-ANN is a challenging issue that should be considered in the future. Also, the efficiency of MPI-ANN for large scale biomedical problems compared to traditional methods (e.g., SVM, LASSO, LR, and iterative ANN) is the subject of future research. Fortunately, from the network structure and theory, MPI-ANN could easily scale to a large data set by adding input and output nodes for features and targets as mentioned above. Also, the experimental results demonstrated that MPI-ANN would be able to do feature selection, which would provide an effective way to process a huge number of features. Thus, future work could be the investigation of a feature selection algorithm based on MPI-ANN. We set a fixed number of hidden nodes of the MPI-ANN for each data set in the experiments. From experiments, we have found that the number of hidden nodes may have some impact on the performance of the MPI-ANN. That is, by setting different numbers of hidden nodes, the accuracy performance of MPI-ANN may be different. Is there any relation between the number of hidden nodes and the outcome? Can we get an optimal number of hidden nodes? These are questions that need to be further investigated. Therefore, future research can concern the development of an optimal number determination algorithm for the number of MPI-ANN hidden nodes. In addition, whether multiple-hidden-layer ANN would improve the performance of MPI-ANN for biomedical prediction problem and how MPI-based weight determination method could be applied to the multiple-hidden-layer ANN are interesting topics that we will further investigate in the future. 5 Conclusions We presented and developed an MPI-ANN (Artificial Neural Network based on Matrix Pseudo-Inversion) to solve the biomedical prediction problem based on clinical and genomic data in this paper. The weights of the MPI-ANN are directly determined without the lengthy learning iteration often used in the traditional neural network method, which is very inefficient for practical application. The LASSO (Least Absolute Shrinkage and Selection Operator) method has also been presented for comparison. We conducted experiments using SNP simulated data set and a breast cancer real data set. The results demonstrated the efficiency and the significantly superior performance of the MPI-ANN method for disease classification and prediction, as compared with LASSO and other machine learning techniques (e.g., SVM and logistic regression). The results also implied that the MPI-ANN could be employed for bio-marker selection. Future research may lie in testing micro-array genetic data, the development of a determination algorithm for the number of hidden nodes in MPI-ANN, and a feature selection algorithm based on MPI-ANN. Acknowledgment This work is funded by National Institutes of Health (NIH) under Grant LM010822. References [1] E.H. Shortliffe J.J. Cimino Biomedical informatics: computer applications in health care and biomedicine 2006 Springer New York [2] D. Kim H. Shin Y.S. Song J.H. Kim Synergistic effect of different levels of genomic data for cancer clinical outcome prediction J Biomed Inform 45 2012 1191 1198 [3] T.R. Golub D.K. Slonim P. Tamayo C. Huard M. Gaasenbeek J.P. Mesirov Molecular classification of cancer: class discovery and class prediction by gene expression monitoring Science 286 1999 531 537 [4] A. Cesario F.B. Marcus Cancer systems biology, bioinformatics and medicine \u2013 research and clinical applications 2011 Springer New York [5] X. Zhou K.Y. Liu S.T.C. Wong Cancer classification and prediction using logistic regression with Bayesian gene selection J Biomed Inform 37 2004 249 259 [6] Q. Long C.S. Moreno B.A. Johnson Risk prediction for prostate cancer recurrence through regularized estimation with simultaneous adjustment for nonlinear clinical effects Ann Appl Stat 5 3 2011 2003 2023 [7] Y. Wang F.S. Makedon J.C. Ford J. Pearlman HykGene: a hybrid approach for selecting marker genes for phenotype classification using microarray gene expression data Bioinformatics 21 8 2005 1530 1537 [8] X. Jiang G.F. Cooper A Bayesian spatio-temporal method for disease outbreak detection J Am Med Inform Assoc 17 4 2010 462 471 [9] I. Saritas Prediction of breast cancer using artificial neural networks J Med Syst 36 2012 2901 2907 [10] J. Hua J. Lowey Z. Xiong E.R. Dougherty Noise-injected neural networks show promise for use on small-sample expression data BMC Bioinformatics 7 2006 274 [11] L.J. Lancashire D.G. Powe J.S. Reis-Filho E. Rakha C. Lemetre B. Weigelt A validated gene expression profile for detecting clinical outcome in breast cancer using artificial neural networks Breast Cancer Res Treat 120 2010 83 93 [12] R.J. Steriti M.A. Fiddy Regularized image reconstruction using SVD and a neural network method for matrix inversion IEEE Trans Signal Process 41 10 1993 3074 3077 [13] Y. Zhang B. Cai Artificial neural networks progress and debate during publishing process 2010 Publishing House of Electronics Industry Beijing [14] Zhang Y, Li W, Yi C, Chen K. A weights-directly-determined simple neural network for nonlinear system identification. In: Proceedings of IEEE international conference on fuzzy systems; 2008. p. 455\u201360. [15] D.E. Rumelhart J.L. McClelland PDP Research Group Parallel distributed processing 1986 MIT Press Cambridge (USA) [16] S. Belciug F. Gorunescu A hybrid neural network/genetic algorithm applied to breast cancer detection and recurrence Expert Syst 30 3 2013 243 254 [17] G.B. Huang Q.Y. Zhu C.K. Siew Extreme learning machine: theory and applications Neurocomputing 70 1\u20133 2006 489 501 [18] T. Hastie R. Tibshirani J. Friedman The elements of statistical learning: data mining, inference, and prediction 2nd ed. 2009 Springer New York [19] C. Hans Bayesian lasso regression Biometrika 96 4 2009 835 845 [20] G. Cybenko Approximations by superpositions of sigmoidal functions Math Control Signals Syst 2 4 1989 303 314 [21] S. Tamura M. Tateishi Capabilities of a four-layered feedforward neural network: four layers versus three IEEE Trans Neural Networks 8 2 1997 251 255 [22] Zhang Y, Li Z, Chen K, Cai B. Common nature of learning exemplified by BP and Hopfield neural networks for solving online a system of linear equations. In: Proceedings of IEEE international conference on networking, sensing and control; 2008. p. 832\u20136. [23] D. Serre Matrices: theory and applications 2002 Springer New York [24] Optimization toolbox user\u2019s guide. Version 3.0.3. Natick (MA): The MathWorks Inc.; 2005. [25] B. Cai Y. Zhang Different-level redundancy-resolution and its equivalent relationship analysis for robot manipulators using gradient-descent and Zhang et al.\u2019s neural-dynamic methods IEEE Trans Ind Electron 59 8 2012 3146 3155 [26] B. Cai Y. Zhang Bi-criteria optimal control of redundant robot manipulators using LVI-based primal-dual neural network Optim Control Appl Methods 31 3 2010 213 229 [27] B. Efron T. Hastie I. Johnstone R. Tibshirani Least angle regression (with discussion) Ann Stat 32 2 2004 407 499 [28] http://code.google.com/p/lasso4j/. [29] http://cran.r-project.org/web/packages/glmnet/index.html. [30] http://www.r-project.org/. [31] D.R. Velez B.C. White A.A. Motsinger A balanced accuracy function for epistasis modeling in imbalanced dataset using multifactor dimensionality reduction Genet Epidemiol 31 2007 306 315 [32] O.L. Mangasarian R. Setiono W.H. Wolberg Pattern recognition via linear programming: theory and application to medical diagnosis T.F. Coleman Y. Li Large-scale numerical optimization 1990 SIAM Publications Philadelphia 22 30 [33] X. Jiang M.M. Barmada S. Visweswaran Identifying genetic interactions in genome-wide data using Bayesian networks Genet Epidemiol 34 6 2010 575 581 [34] X. Jiang M.M. Barmada G.F. Cooper M.J. Becich A Bayesian method for evaluating and discovering disease loci associations PLoS One 6 8 2011 e22075 [35] X. Jiang R.E. Neapolitan M.M. Barmada S. Visweswaran Learning genetic epistasis using Bayesian network scoring criteria BMC Bioinformatics 12 89 2011 [36] http://www.java.com/en/. [37] http://math.nist.gov/javanumerics/jama/. [38] http://www.eclipse.org/. [39] Kohavi R. A study of cross-validation and bootstrap for accuracy estimation and model selection. In: Proceeding of the international joint conference on artificial intelligence; 1995. [40] R.E. Fan K.W. Chang C.J. Hsieh X.R. Wang C.J. Lin LIBLINEAR: a library for large linear classification J Mach Learn Res 9 2008 1871 1874 Software available at <http://www.csie.ntu.edu.tw/~cjlin/liblinear>", "scopus-id": "84899483858", "pubmed-id": "24361387", "coredata": {"eid": "1-s2.0-S1532046413002001", "dc:description": "Abstract Biomedical prediction based on clinical and genome-wide data has become increasingly important in disease diagnosis and classification. To solve the prediction problem in an effective manner for the improvement of clinical care, we develop a novel Artificial Neural Network (ANN) method based on Matrix Pseudo-Inversion (MPI) for use in biomedical applications. The MPI-ANN is constructed as a three-layer (i.e., input, hidden, and output layers) feed-forward neural network, and the weights connecting the hidden and output layers are directly determined based on MPI without a lengthy learning iteration. The LASSO (Least Absolute Shrinkage and Selection Operator) method is also presented for comparative purposes. Single Nucleotide Polymorphism (SNP) simulated data and real breast cancer data are employed to validate the performance of the MPI-ANN method via 5-fold cross validation. Experimental results demonstrate the efficacy of the developed MPI-ANN for disease classification and prediction, in view of the significantly superior accuracy (i.e., the rate of correct predictions), as compared with LASSO. The results based on the real breast cancer data also show that the MPI-ANN has better performance than other machine learning methods (including support vector machine (SVM), logistic regression (LR), and an iterative ANN). In addition, experiments demonstrate that our MPI-ANN could be used for bio-marker selection as well.", "openArchiveArticle": "true", "prism:coverDate": "2014-04-30", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046413002001", "dc:creator": [{"@_fa": "true", "$": "Cai, Binghuang"}, {"@_fa": "true", "$": "Jiang, Xia"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046413002001"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046413002001"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(13)00200-1", "prism:volume": "48", "prism:publisher": "Elsevier Inc.", "dc:title": "A novel artificial neural network method for biomedical prediction based on matrix pseudo-inversion", "prism:copyright": "Copyright \u00a9 2013 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Biomedical prediction and classification"}, {"@_fa": "true", "$": "Neural networks"}, {"@_fa": "true", "$": "Matrix pseudo-inversion"}, {"@_fa": "true", "$": "Least Absolute Shrinkage and Selection Operator (LASSO)"}, {"@_fa": "true", "$": "Single Nucleotide Polymorphism (SNP)"}, {"@_fa": "true", "$": "Cancer"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "114-121", "prism:endingPage": "121", "prism:coverDisplayDate": "April 2014", "prism:doi": "10.1016/j.jbi.2013.12.009", "prism:startingPage": "114", "dc:identifier": "doi:10.1016/j.jbi.2013.12.009", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "70", "@width": "508", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si22.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "4691", "@ref": "si22", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "38", "@width": "303", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1616", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "48", "@width": "243", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1517", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "273", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1058", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "25", "@width": "494", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2236", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "75", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "461", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "22", "@width": "215", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "848", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "221", "@width": "548", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "5733", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "69", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "422", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "52", "@width": "174", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1242", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "46", "@width": "106", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "783", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "24", "@width": "369", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1388", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "222", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "291", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "43", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "306", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "16", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "237", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "268", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "44", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "312", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "25", "@width": "50", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "420", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "83", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "562", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "33", "@width": "126", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "616", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "491", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "1203", "@width": "2067", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "320022", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "886", "@width": "1373", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "190996", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1369", "@width": "3305", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "324720", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2613", "@width": "3356", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1124510", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "272", "@width": "467", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "42155", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "200", "@width": "310", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "29213", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "309", "@width": "746", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "41475", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "590", "@width": "758", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "122626", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "127", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6286", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "141", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5571", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "91", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3515", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "210", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046413002001-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8429", "@ref": "gr2", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899483858"}}
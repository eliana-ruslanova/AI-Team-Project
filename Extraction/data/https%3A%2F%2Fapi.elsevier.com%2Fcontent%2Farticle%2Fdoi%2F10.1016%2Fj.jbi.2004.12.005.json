{"scopus-eid": "2-s2.0-19444378142", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2005-01-19 2005-01-19 2010-10-05T16:27:29 1-s2.0-S1532046404001728 S1532-0464(04)00172-8 S1532046404001728 10.1016/j.jbi.2004.12.005 S300 S300.2 FULL-TEXT 1-s2.0-S1532046405X00235 2015-05-15T06:30:58.184067-04:00 0 0 20050601 20050630 2005 2005-01-19T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings vol vol volfirst volissue webpdf webpdfpagecount body acknowledge affil articletitle auth authfirstini authfull authlast pubtype ref alllist content oa subj ssids 1532-0464 15320464 38 38 3 3 Volume 38, Issue 3 3 173 175 173 175 200506 June 2005 2005-06-01 2005-06-30 2005 Human-Centered Computing in Health Information Systems. Part 2: Evaluation HCI: Evaluation Jiajie Zhang simple-article edi Copyright \u00a9 2005 Elsevier Inc. All rights reserved. HUMANCENTEREDCOMPUTINGINHEALTHINFORMATIONSYSTEMS ZHANG J Acknowledgments References ZHANG 2005 1 3 J ZHANG 2002 42 47 J FRIEDMAN 1997 C EVALUATIONMETHODSINMEDICALINFORMATICS PIZZIFERRI 2005 176 188 L PATTERSON 2005 189 199 E LAXMISAN 2005 200 212 A MALHOTRA 2005 34 50 S GINSBURG 2005 213 219 G FARZANFAR 2005 220 228 R REDDY 2005 229 238 M WACHTER 2005 239 243 B DESPONTGROS 2005 244 255 C ZHANGX2005X173 ZHANGX2005X173X175 ZHANGX2005X173XJ ZHANGX2005X173X175XJ 2013-07-17T11:42:38Z OA-Window Full ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(04)00172-8 S1532046404001728 1-s2.0-S1532046404001728 10.1016/j.jbi.2004.12.005 272371 2010-11-08T01:47:17.99733-05:00 2005-06-01 2005-06-30 1-s2.0-S1532046404001728-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046404001728/MAIN/application/pdf/bbaedcf8324a72ff9d8577ec69d99822/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046404001728/MAIN/application/pdf/bbaedcf8324a72ff9d8577ec69d99822/main.pdf main.pdf pdf true 90343 MAIN 3 1-s2.0-S1532046404001728-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046404001728/PREVIEW/image/png/e38e767d1efff11e90613f5cb8147b64/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046404001728/PREVIEW/image/png/e38e767d1efff11e90613f5cb8147b64/main_1.png main_1.png png 81318 849 656 IMAGE-WEB-PDF 1 YJBIN 1193 S1532-0464(04)00172-8 10.1016/j.jbi.2004.12.005 Elsevier Inc. Guest Editorial Human-centered computing in health information systems Part 2: Evaluation Jiajie Zhang Jiajie.Zhang@uth.tmc.edu School of Health Information Sciences, University of Texas Health Science Center at Houston, Houston, TX 77030, USA This is the second part of two special issues on human-centered computing in health information systems (see [1] for Part 1 Editorial). Human-centered computing is based on four types of analyses for users, functions, representations, and tasks [1,2]. It is also a process that includes work domain analysis, design, and evaluation as three major steps. Part 1 of the special issue focused on the domain analysis and design components of human-centered computing in health information systems. Part 2 focuses on the evaluation component. Evaluation is always an important process for the design and implementation of any health information system [3]. Part 2 of the special issue brings together original research and methodology papers that are concerned primarily with how effective and efficient a system is, along user characteristics, such as ease of use, ease of learning, reduction of medical error, and user satisfaction. The first paper by Pizziferri et al. [4] examines whether an electronic health record (EHR) system decreases or increases physician times on clinical tasks. Time is one of the critical factors that often dictate the success or failure of an EHR system. The authors used a time\u2013motion study method to collect the times primary care physicians spent on clinic tasks before and after the implementation of an EHR system. They also conducted a survey to assess physicians\u2019 perceptions regarding the EHR. The results show that there is no significant difference in times spent on clinic tasks before and after implementation. However, only about a third of the survey respondents reported that the EHR took the same amount or less time than paper records, although the majority of them believed that the EHR resulted in better care quality. Time\u2013motion studies such as the current one are valuable for the assessment of the efficiency and effectiveness of health information systems. With more detailed observations that include times on nonclinical as well as clinical tasks, times on different types of tasks, task steps, and errors, we can gain more insight into human-centered characteristics of EHR systems. The second paper by Patterson et al. [5] is a study of the barriers to the effective use of clinical reminders. Advances in health information systems have made possible many decision support systems such as clinical reminders for recommended actions due for a patient and clinical warnings that immediate actions should be taken to avoid harm to patients. Despite evidence that clinical reminder systems improve adherence to guidelines, there are some challenges in having providers consistently use clinical reminders as intended. This paper describes a study using multiple methods, including ethnographic observations and surveys, to triangulate an understanding of barriers to the effective use of clinical reminders in the Veterans\u2019 Health Administration (VHA). Six barriers were identified from the first study and four more identified from the second study. It is important to note that nearly all of these barriers are caused by user, social, organizational, educational, and other nontechnology factors. The third and fourth papers focus on patient safety considerations in the medical device purchasing process. The paper by Laxmisan and colleagues [6] is the sister paper to Malhotra et al. [7] published in Part 1 of the special issue that focused on analysis and design. Laxmisan et al. used three medical device error cases to create three scenarios for the study of how people with different types of expertise evaluate patient safety and device-related medical errors in the decision process of medical device purchasing. They found that clinicians (nurses and doctors) focused on clinical and human aspects of errors, biomedical engineers focused on device-related errors, and administrators focused on documentation and training. This study raises the question of whether the differences caused by various types of expertise may reflect the broader issues in institutional decision making such as interventions of medical errors, medical device purchasing, and deployment of information technology. The paper by Ginsburg [8] is a clear demonstration of how a human factors evaluation could affect the decision making in hospital procurement processes. In this study three infusion pumps were evaluated for their usability problems in five clinical areas in two phases: heuristics evaluation and user testing. The results were consistent and clearly favored one of the three infusion pumps. Due to the success of this study, the author recommended that a human factors evaluation should be performed to influence all hospital procurement decisions about medical devices to enhance patient safety. The next two papers are concerned with the use of telehealth systems and wireless communication devices. The paper by Farzanfar et al. [9] describes a user evaluation study of an automated telephone-based system for health promotion and behavior interventions. It is generally assumed that adherence to the recommended schedule is related to the impact of the system on users. However, it is not clear what factors influence users\u2019 decisions on using or not using the system. The results of this study show that both user and system factors were responsible for the underutilization or nonuse of the system. Studies such as the current one have great potential for the identification of barriers to the use of and the improvement of usability in telehealth systems, which have been growing in number, usage, and popularity. The paper by Reddy et al. [10] evaluates the impact of the introduction of a wireless alert pager system on collaborative work practices and information flows in a surgical intensive care unit. New technologies are often introduced with good intentions and with optimistic expectations. They can in many ways improve clinical work flows. However, new technologies can also have negative, often unexpected, consequences on information flows. This is the dilemma illustrated by the results of this study, which show that the paging system provided new routes of information to clinical staff but in doing so also disrupted existing work practices and information flows. This study once again shows that implementing a health information system is not a straight information technology project: it involves many nontechnology factors that often determine the success or failure of the system. The next paper by Wachter et al. [11] describes a user evaluation study of a pulmonary graphic display that depicts pulmonary physiological variables for intubated, mechanically ventilated patients in a graphical format. Traditional ICU medical monitors provide discrete data and discrete alarms that alert clinicians to parameters outside a set range, but they do not provide a comprehensive representation of patient physiology by integrating multiple data points. The authors developed an integrated display that was designed to match users\u2019 mental models, increase situation awareness, and help users in assimilating information more rapidly and facilitating efficient and timely medical interventions. This study evaluated how this new technology was integrated and accepted by users. The results, though preliminary, show that the system was monitored, used, and well perceived, and that the integrated display was considered as an accurate representation of respiratory variables. The final paper by Despont-Gros et al. [12] is the methodology review paper for this special issue. The authors reviewed articles that are studies of user evaluation of clinical information systems. From this comprehensive review they identified eight dimensions used in the evaluations, which were then integrated with the dimensions already identified in the human\u2013computer interaction literature. From these integrated dimensions the authors developed an model for evaluation of clinical information systems. This model is a nice bridge that connects the traditional methods used in clinical information system evaluations and the human\u2013computer interaction methods that focus on human dimensions. The current Part 2 of the special issue on evaluation and the earlier Part 1 on analysis and design are two collections of original research and method papers on human-centered computing in health information systems. We hope they will promote and advance human-centered design in health information systems for improving health care quality, increasing patient safety, and reducing health care costs. Acknowledgments I thank all the reviewers for their comprehensive reviews. Without their hard work and professional recommendations it would be an impossible task for me to compile this special issue. Their constructive criticisms also greatly helped the authors in their revisions. I would also like to give special thanks to Vimla Patel for her encouragement and support in producing both part of the special issue. References [1] J. Zhang Human-centered computing in health information systems. Part 1: Analysis and design [Editorial] J Biomed Inform 38 2005 1 3 [2] J. Zhang V.L. Patel K.A. Johnson J. Malin J.W. Smith Designing human-centered distributed information systems IEEE Intell. Syst. 17 5 2002 42 47 [3] C.P. Friedman J.C. Wyatt Evaluation methods in medical informatics 1997 Springer-Verlag Berlin [4] L. Pizziferri A.F. Kittler L.A. Volk M.M. Honour G. Gupta T. Wang Primary care physician time utilization before and after implementation of an electronic health record: a time-motion study J Biomed Inform 38 2005 176 188 [5] E.S. Patterson B.N. Boebbeling C.H. Fung L. Militello S. Anders S.M. Asch Identifying barriers to the effective use of clinical reminders: bootstrapping multiple methods J Biomed Inform 38 2005 189 199 [6] A. Laxmisan S. Malhotra A. Keselman T.R. Johnson V.L. Patel Decisions about critical events in device-related scenarios as a function of expertise J Biomed Inform 38 2005 200 212 [7] S. Malhotra A. Laxmisan A. Keselman J. Zhang V.L. Patel Designing the design phase of critical care devices: a cognitive approach J Biomed Inform 38 2005 34 50 [8] G.E. Ginsburg Human factors engineering: a tool for medical device evaluation in hospital procurement decision-making J Biomed Inform 38 2005 213 219 [9] R. Farzanfar S. Frishkopf J. Migneault R. Friedman Telephone-linked care for physical activity (TLC-PA): a qualitative evaluation of the use patterns of an information technology program for patients J Biomed Inform 38 2005 220 228 [10] M. Reddy D.W. McDonald W. Pratt M.M. Shabot Technology, work, and information flows: lessons from the implementation of a wireless alert pager system J Biomed Inform 38 2005 229 238 [11] B. Wachter B. Markewitz R. Rose D. Westenskow Evaluation of a pulmonary graphical display in the medical intensive care unit: an observational study J Biomed Inform 38 2005 239 243 [12] C. Despont-Gros H. Mueller C. Lovis Evaluating user interactions with clinical information systems: a model based on human\u2013computer interaction models J Biomed Inform 38 2005 244 255", "scopus-id": "19444378142", "pubmed-id": "15896690", "coredata": {"eid": "1-s2.0-S1532046404001728", "dc:description": null, "openArchiveArticle": "true", "prism:coverDate": "2005-06-30", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046404001728", "dc:creator": {"@_fa": "true", "$": "Zhang, Jiajie"}, "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046404001728"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046404001728"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(04)00172-8", "prism:volume": "38", "prism:publisher": "Elsevier Inc.", "dc:title": "Human-centered computing in health information systems Part 2: Evaluation", "prism:copyright": "Copyright \u00a9 2005 Elsevier Inc. All rights reserved.", "prism:issueName": "Human-Centered Computing in Health Information Systems. Part 2: Evaluation", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "3", "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "3", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "173-175", "prism:endingPage": "175", "pubType": "Guest Editorial", "prism:coverDisplayDate": "June 2005", "prism:doi": "10.1016/j.jbi.2004.12.005", "prism:startingPage": "173", "dc:identifier": "doi:10.1016/j.jbi.2004.12.005", "openaccessSponsorName": null}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/19444378142"}}
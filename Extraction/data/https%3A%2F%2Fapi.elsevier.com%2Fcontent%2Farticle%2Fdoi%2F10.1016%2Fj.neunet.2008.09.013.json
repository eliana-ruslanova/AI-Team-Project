{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608008002104", "dc:identifier": "doi:10.1016/j.neunet.2008.09.013", "eid": "1-s2.0-S0893608008002104", "prism:doi": "10.1016/j.neunet.2008.09.013", "pii": "S0893-6080(08)00210-4", "dc:title": "Finding intrinsic rewards by embodied evolution and constrained reinforcement learning ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2008 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "21", "prism:issueIdentifier": "10", "prism:startingPage": "1447", "prism:endingPage": "1455", "prism:pageRange": "1447-1455", "prism:number": "10", "dc:format": "application/json", "prism:coverDate": "2008-12-31", "prism:coverDisplayDate": "December 2008", "prism:copyright": "Copyright \u00a9 2008 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "ICONIP 2007", "dc:creator": [{"@_fa": "true", "$": "Uchibe, Eiji"}, {"@_fa": "true", "$": "Doya, Kenji"}], "dc:description": "\n               Abstract\n               \n                  Understanding the design principle of reward functions is a substantial challenge both in artificial intelligence and neuroscience. Successful acquisition of a task usually requires not only rewards for goals, but also for intermediate states to promote effective exploration. This paper proposes a method for designing \u2018intrinsic\u2019 rewards of autonomous agents by combining constrained policy gradient reinforcement learning and embodied evolution. To validate the method, we use Cyber Rodent robots, in which collision avoidance, recharging from battery packs, and \u2018mating\u2019 by software reproduction are three major \u2018extrinsic\u2019 rewards. We show in hardware experiments that the robots can find appropriate \u2018intrinsic\u2019 rewards for the vision of battery packs and other robots to promote approach behaviors.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Intrinsic and extrinsic rewards"}, {"@_fa": "true", "$": "Reinforcement learning"}, {"@_fa": "true", "$": "Embodied evolution"}, {"@_fa": "true", "$": "Cyber Rodents"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608008002104", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608008002104", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "56949096913", "scopus-eid": "2-s2.0-56949096913", "pubmed-id": "19013054", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/56949096913", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20081009", "$": "2008-10-09"}}}}}
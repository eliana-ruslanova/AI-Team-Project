{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608011001535", "dc:identifier": "doi:10.1016/j.neunet.2011.05.011", "eid": "1-s2.0-S0893608011001535", "prism:doi": "10.1016/j.neunet.2011.05.011", "pii": "S0893-6080(11)00153-5", "dc:title": "A kernel-based framework to tensorial data analysis ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2011 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "24", "prism:issueIdentifier": "8", "prism:startingPage": "861", "prism:endingPage": "874", "prism:pageRange": "861-874", "prism:number": "8", "dc:format": "application/json", "prism:coverDate": "2011-10-31", "prism:coverDisplayDate": "October 2011", "prism:copyright": "Copyright \u00a9 2011 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "Artificial Neural Networks: Selected Papers from ICANN 2010", "dc:creator": [{"@_fa": "true", "$": "Signoretto, Marco"}, {"@_fa": "true", "$": "De Lathauwer, Lieven"}, {"@_fa": "true", "$": "Suykens, Johan A.K."}], "dc:description": "\n               Abstract\n               \n                  Tensor-based techniques for learning allow one to exploit the structure of carefully chosen representations of data. This is a desirable feature in particular when the number of training patterns is small which is often the case in areas such as biosignal processing and chemometrics. However, the class of tensor-based models is somewhat restricted and might suffer from limited discriminative power. On a different track, kernel methods lead to flexible nonlinear models that have been proven successful in many different contexts. Nonetheless, a na\u00efve application of kernel methods does not exploit structural properties possessed by the given tensorial representations. The goal of this work is to go beyond this limitation by introducing non-parametric tensor-based models. The proposed framework aims at improving the discriminative power of supervised tensor-based models while still exploiting the structural information embodied in the data. We begin by introducing a feature space formed by multilinear functionals. The latter can be considered as the infinite dimensional analogue of tensors. Successively we show how to implicitly map input patterns in such a feature space by means of kernels that exploit the algebraic structure of data tensors. The proposed tensorial kernel links to the MLSVD and features an interesting invariance property; the approach leads to convex optimization and fits into the same primal\u2013dual framework underlying SVM-like algorithms.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Multilinear algebra"}, {"@_fa": "true", "$": "Reproducing kernel Hilbert spaces"}, {"@_fa": "true", "$": "Tensorial kernels"}, {"@_fa": "true", "$": "Subspace angles"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608011001535", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608011001535", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "80051813167", "scopus-eid": "2-s2.0-80051813167", "pubmed-id": "21703821", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/80051813167", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20110612", "$": "2011-06-12"}}}}}
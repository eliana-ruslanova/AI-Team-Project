{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608012002134", "dc:identifier": "doi:10.1016/j.neunet.2012.08.003", "eid": "1-s2.0-S0893608012002134", "prism:doi": "10.1016/j.neunet.2012.08.003", "pii": "S0893-6080(12)00213-4", "dc:title": "An incremental neural network with a reduced architecture ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "35", "prism:startingPage": "70", "prism:endingPage": "81", "prism:pageRange": "70-81", "dc:format": "application/json", "prism:coverDate": "2012-11-30", "prism:coverDisplayDate": "November 2012", "prism:copyright": "Copyright \u00a9 2012 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Ciarelli, Patrick Marques"}, {"@_fa": "true", "$": "Oliveira, Elias"}, {"@_fa": "true", "$": "Salles, Evandro O.T."}], "dc:description": "\n               Abstract\n               \n                  This paper proposes a technique, called Evolving Probabilistic Neural Network (\n                        e\n                        \n                           PNN\n                        \n                     ), that presents many interesting features, including incremental learning, evolving architecture, the capacity to learn continually throughout its existence and requiring that each training sample be used only once in the training phase without reprocessing. A series of experiments was performed on data sets in the public domain; the results indicate that \n                        e\n                        \n                           PNN\n                        \n                      is superior or equal to the other incremental neural networks evaluated in this paper. These results also demonstrate the advantage of the small \n                        e\n                        \n                           PNN\n                        \n                      architecture and show that its architecture is more stable than the other incremental neural networks evaluated. \n                        e\n                        \n                           PNN\n                        \n                      thus appears to be a promising alternative for a quick learning system and a fast classifier with a low computational cost.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Incremental learning"}, {"@_fa": "true", "$": "Probabilistic neural network"}, {"@_fa": "true", "$": "Expectation maximization"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608012002134", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608012002134", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84865630075", "scopus-eid": "2-s2.0-84865630075", "pubmed-id": "22954480", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84865630075", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20120822", "$": "2012-08-22"}}}}}
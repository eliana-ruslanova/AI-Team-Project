{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608005000407", "dc:identifier": "doi:10.1016/j.neunet.2005.03.007", "eid": "1-s2.0-S0893608005000407", "prism:doi": "10.1016/j.neunet.2005.03.007", "pii": "S0893-6080(05)00040-7", "dc:title": "Challenges in real-life emotion annotation and machine learning based detection ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2005 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "18", "prism:issueIdentifier": "4", "prism:startingPage": "407", "prism:endingPage": "422", "prism:pageRange": "407-422", "prism:number": "4", "dc:format": "application/json", "prism:coverDate": "2005-05-31", "prism:coverDisplayDate": "May 2005", "prism:copyright": "Copyright \u00a9 2005 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "Emotion and Brain", "dc:creator": [{"@_fa": "true", "$": "Devillers, Laurence"}, {"@_fa": "true", "$": "Vidrascu, Laurence"}, {"@_fa": "true", "$": "Lamel, Lori"}], "dc:description": "\n               Abstract\n               \n                  Since the early studies of human behavior, emotion has attracted the interest of researchers in many disciplines of Neurosciences and Psychology. More recently, it is a growing field of research in computer science and machine learning. We are exploring how the expression of emotion is perceived by listeners and how to represent and automatically detect a subject's emotional state in speech. In contrast with most previous studies, conducted on artificial data with archetypal emotions, this paper addresses some of the challenges faced when studying real-life non-basic emotions. We present a new annotation scheme allowing the annotation of emotion mixtures. Our studies of real-life spoken dialogs from two call center services reveal the presence of many blended emotions, dependent on the dialog context. Several classification methods (SVM, decision trees) are compared to identify relevant emotional states from prosodic, disfluency and lexical cues extracted from the real-life spoken human-human interactions.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Emotion detection"}, {"@_fa": "true", "$": "Emotion annotation"}, {"@_fa": "true", "$": "Blended emotion"}, {"@_fa": "true", "$": "Naturalistic spoken data"}, {"@_fa": "true", "$": "Prosodic, disfluency and lexical features"}, {"@_fa": "true", "$": "Machine learning"}, {"@_fa": "true", "$": "SVM"}, {"@_fa": "true", "$": "Decision trees"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608005000407", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608005000407", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "21544459345", "scopus-eid": "2-s2.0-21544459345", "pubmed-id": "15993746", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/21544459345", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20050701", "$": "2005-07-01"}}}}}
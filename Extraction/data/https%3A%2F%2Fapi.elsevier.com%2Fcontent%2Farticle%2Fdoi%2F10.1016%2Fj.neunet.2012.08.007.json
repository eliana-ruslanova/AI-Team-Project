{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608012002201", "dc:identifier": "doi:10.1016/j.neunet.2012.08.007", "eid": "1-s2.0-S0893608012002201", "prism:doi": "10.1016/j.neunet.2012.08.007", "pii": "S0893-6080(12)00220-1", "dc:title": "Generalized locality preserving Maxi\u2013Min Margin Machine ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "36", "prism:startingPage": "18", "prism:endingPage": "24", "prism:pageRange": "18-24", "dc:format": "application/json", "prism:coverDate": "2012-12-31", "prism:coverDisplayDate": "December 2012", "prism:copyright": "Copyright \u00a9 2012 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Zhang, Zhancheng"}, {"@_fa": "true", "$": "Choi, Kup-Sze"}, {"@_fa": "true", "$": "Luo, Xiaoqing"}, {"@_fa": "true", "$": "Wang, Shitong"}], "dc:description": "\n               Abstract\n               \n                  Research on large margin classifiers from the \u201clocal\u201d and \u201cglobal\u201d view has become an active topic in machine learning and pattern recognition. Inspired from the typical local and global learning machine Maxi\u2013Min Margin Machine (\n                        \n                           \n                              \n                                 M\n                              \n                           \n                           \n                              4\n                           \n                        \n                     ) and the idea of the Locality Preserving Projections (LPP), we propose a novel large margin classifier, the Generalized Locality Preserving Maxi\u2013Min Margin Machine (\n                        \n                           GLPM\n                        \n                     ), where the within-class matrices are constructed using the labeled training points in a supervised way, and then used to build the classifier. The within-class matrices of \n                        \n                           GLPM\n                        \n                      preserve the intra-class manifold in the training sets, as well as the covariance matrices which indicate the global projection direction in the \n                        \n                           \n                              \n                                 M\n                              \n                           \n                           \n                              4\n                           \n                        \n                      model. Moreover, the connections among \n                        \n                           GLPM\n                        \n                     , \n                        \n                           \n                              \n                                 M\n                              \n                           \n                           \n                              4\n                           \n                        \n                      and LFDA are theoretically analyzed, and we show that \n                        \n                           GLPM\n                        \n                      can be considered as a generalized \n                        \n                           \n                              \n                                 M\n                              \n                           \n                           \n                              4\n                           \n                        \n                      machine. The \n                        \n                           GLPM\n                        \n                      is also more robust since it requires no assumption on data distribution while Gaussian data distribution is assumed in the \n                        \n                           \n                              \n                                 M\n                              \n                           \n                           \n                              4\n                           \n                        \n                      machine. Experiments on data sets from the machine learning repository demonstrate its advantage over \n                        \n                           \n                              \n                                 M\n                              \n                           \n                           \n                              4\n                           \n                        \n                      in both local and global learning performance.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Large margin classification"}, {"@_fa": "true", "$": "Maxi\u2013Min Margin Machine"}, {"@_fa": "true", "$": "Locality preserving projections classification"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608012002201", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608012002201", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84870284479", "scopus-eid": "2-s2.0-84870284479", "pubmed-id": "23037772", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84870284479", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20120910", "$": "2012-09-10"}}}}}
{"scopus-eid": "2-s2.0-70349456436", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2009-04-11 2009-04-11 2010-10-09T20:28:24 1-s2.0-S1532046409000525 S1532-0464(09)00052-5 S1532046409000525 10.1016/j.jbi.2009.04.001 S300 S300.1 FULL-TEXT 1-s2.0-S1532046409X00067 2020-03-06T12:32:07.727969Z 0 0 20091001 20091031 2009 2009-04-11T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype subheadings vol volfirst volissue webpdf webpdfpagecount table e-component body mmlmath acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes primabst ref alllist content oa subj ssids 1532-0464 15320464 42 42 5 5 Volume 42, Issue 5 16 887 894 887 894 200910 October 2009 2009-10-01 2009-10-31 2009 Biomedical Natural Language Processing Wendy W. Chapman a K. Bretonnel Cohen b a Department of Biomedical Informatics, University of Pittsburgh, Pittsburgh, PA 15260, USA b Center for Computational Pharmacology, Biomedical Text Mining Group, University of Colorado School of Medicine, Denver, CO 80202 Research Papers article fla Copyright \u00a9 2009 Elsevier Inc. All rights reserved. ASSIGNINGROLESPROTEINMENTIONSCASETRANSCRIPTIONFACTORS YANG H 1 Introduction 2 A brief analysis of TF contexts 3 Methods 3.1 Identification of TF sentences 3.2 Phrase-based Conditional Random Fields 3.3 Word-based Conditional Random Fields 3.4 CRF feature templates 4 Experiments and results 4.1 Comparison to the baseline classifier 4.2 Impact of feature types 5 Discussions and error analysis 6 Comparison to related work 7 Conclusions Acknowledgments Appendix A Supplementary data References GILBERT 2006 S DEVELOPMENTALBIOLOGY WINGENDER 2000 316 319 E MATYS 2003 374 378 V ADRYAN 2006 1532 1533 B PORTALESCASAMAR 2007 R207 E HUERTA 1998 55 59 A MONTGOMERY 2006 637 640 S GRIFFITH 2007 D107 D113 O AERTS 2008 R31 S YANG 2008 S11 H TANABE 2002 1124 1132 L DEGTYARENKO 2008 D344 D350 K KIM 2008 1410 1412 J HAO 2005 3294 3300 Y FRIEDMAN 2001 S74 S82 C YEH 2005 S2 A SETTLES 2005 3191 3192 B KIM 2003 i180 i182 J NENADIC 2003 938 943 G KARAMANIS 2008 193 N BLASCHKE 2002 14 20 C DARASELIA 2004 604 611 N DONALDSON 2003 I MITSUMORI 2006 2464 2466 T MCDONALD 2005 S6 R PAN 2004 W230 W234 H SARIC 2006 645 650 J RODRIGUEZPENAGOS 2007 293 C YANGX2009X887 YANGX2009X887X894 YANGX2009X887XH YANGX2009X887X894XH 2013-07-17T11:42:38Z OA-Window Full ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ 2020-03-01T12:28:58.032Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp S1532046409000525 Biotechnology and Biological Science Research Council BBSRC Biotechnology and Biological Sciences Research Council http://data.elsevier.com/vocabulary/SciValFunders/501100000268 http://sws.geonames.org/2635167/ This work was partially supported by the Bio-MITA project (\u201cMining Term Associations from Literature to Support Knowledge Discovery in Biology\u201d) funded by UK Biotechnology and Biological Science Research Council (BBSRC). We are grateful to ORegAnno, FlyTF and TRANSFAC databases for providing the data. item S1532-0464(09)00052-5 S1532046409000525 1-s2.0-S1532046409000525 10.1016/j.jbi.2009.04.001 272371 2010-11-01T14:20:30.573235-04:00 2009-10-01 2009-10-31 1-s2.0-S1532046409000525-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/MAIN/application/pdf/96bef5974e868b0343340d35eb3b9ec6/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/MAIN/application/pdf/96bef5974e868b0343340d35eb3b9ec6/main.pdf main.pdf pdf true 197260 MAIN 8 1-s2.0-S1532046409000525-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/PREVIEW/image/png/96944362f3b741822c38fe0c41561783/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/PREVIEW/image/png/96944362f3b741822c38fe0c41561783/main_1.png main_1.png png 87222 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046409000525-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/STRIPIN/image/gif/ca79661645172141371378faf696f4e0/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/STRIPIN/image/gif/ca79661645172141371378faf696f4e0/si7.gif si7 si7.gif gif 3959 131 230 ALTIMG 1-s2.0-S1532046409000525-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/STRIPIN/image/gif/257d85d4e66aade4b07ac4234be0847e/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/STRIPIN/image/gif/257d85d4e66aade4b07ac4234be0847e/si6.gif si6 si6.gif gif 1656 38 369 ALTIMG 1-s2.0-S1532046409000525-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/STRIPIN/image/gif/5621b36610eeb754a8e34be292753beb/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/STRIPIN/image/gif/5621b36610eeb754a8e34be292753beb/si5.gif si5 si5.gif gif 577 23 107 ALTIMG 1-s2.0-S1532046409000525-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/STRIPIN/image/gif/99bbec41fc88361240fc58d77a545eaf/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/STRIPIN/image/gif/99bbec41fc88361240fc58d77a545eaf/si4.gif si4 si4.gif gif 717 17 144 ALTIMG 1-s2.0-S1532046409000525-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/STRIPIN/image/gif/bad4c58e0935f8693a9c128ca34e91eb/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/STRIPIN/image/gif/bad4c58e0935f8693a9c128ca34e91eb/si3.gif si3 si3.gif gif 881 41 146 ALTIMG 1-s2.0-S1532046409000525-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/STRIPIN/image/gif/6e51560182ccb796c7b21bafd16eaadf/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/STRIPIN/image/gif/6e51560182ccb796c7b21bafd16eaadf/si2.gif si2 si2.gif gif 527 17 132 ALTIMG 1-s2.0-S1532046409000525-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/STRIPIN/image/gif/55aba4847d264caf26f06e32f49cdadc/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/STRIPIN/image/gif/55aba4847d264caf26f06e32f49cdadc/si1.gif si1 si1.gif gif 525 17 134 ALTIMG 1-s2.0-S1532046409000525-mmc1.doc https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046409000525/mmc1/MAIN/application/msword/9607bb230369ca7fc491bc1f44be17a8/mmc1.doc https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046409000525/mmc1/MAIN/application/msword/9607bb230369ca7fc491bc1f44be17a8/mmc1.doc mmc1 mmc1.doc doc 43008 APPLICATION YJBIN 1542 S1532-0464(09)00052-5 10.1016/j.jbi.2009.04.001 Elsevier Inc. Table 1 Numbers of TFs, supportive evidence sentences and words in TRANSFAC and FlyTF. TRANSFAC FlyTF Curated TFs 1499 234 Supporting sentences 5200 491 Q1 Please check the renumbering of equations. Q2 Please check the author name P. E.D.in Ref. [7]. Q3 Please provide the \u201cyear of publication\u201d for Ref. [8]. Q4 Please provide journal title for Ref. [31]. Table 2 Example TF-patterns, extracted manually from TRANSFAC and FlyTF databases (TF, transcription factor; TG, target gene). Pattern type Pattern examples Example TF contexts Nominalisations DNA-binding by TF \u2026inhibiting DNA-binding by TBP in the absence\u2026 Transcription of TG \u2026is required for transcription of snRNA genes by\u2026 TF heterodimer \u2026mainly p50/p65 heterodimers are induced, whereas \u2026 heterodimerization with TF \u2026heterodimerization with E12 enhances DNA-binding\u2026 activator of TG \u2026activator of olfactory genes Verbal phrases TF bind to DNA site AML1b binds to the PEBP2 site with higher affinity\u2026 TG be regulated by TF The EKLF gene is regulated by GATA-1 TF heterodimerize with Myf-4 heterodimerizes with other myogenic factors TG be activated by TF \u2026Mdm-2 the gene of which is activated by p53 TF repress TG \u2026complex with STE12 that represses the STE2 gene Table 3 Task-specific TF context lexicon classes and examples (NI, negative interaction; PI, positive interaction; G, general). Class Lexicon subtype Keywords Noun NI_N repression; suppression; inhibition; antagonism; counteraction; PI_N accumulation; enrichment; enhancement; increase; promotion; ACTIVATION_N activation; autoactivation; coactivation; inactivation; deactivation; BIOACTOR_N promoter; activator; transcription factor; enhancer; regulator; BIOREGION_N domain; region; motif; site; element; C-terminus; repeat; element BIOFAMILY_N protein; gene; homolog; mutant; peptide; mRNA; complex BIND_N binding; DNA binding; DNA-bound DIMERIZE_N dimerization; heterodimerization; homodimerization INTERACT_N interaction; contact REGULATE_N regulation; auto-regulation; down-regulation; up-regulation PHOSPHORYLATE_N phosphorylation; de-phosphorylation; hyper-phosphorylation TRANSCRIPTION_N transcription G_N association; disruption; recruitment; cooperation Verb NI_V repress; suppress; inhibit; antagonise; counteract; reduce; PI_V enrich; accumulate; augment; increase; promote; support ACTIVATE_V activate; auto-activate; co-activate; in-activate; de-activate BIND_V bind DIMERIZE_V dimerize; heterodimerize; homodimerize; homo-dimerize; ENCODE_V encode INTERACT_V interact REGULATE_V regulate; auto-regulate; down-regulate; up-regulate; PHOSPHORYLATE_V phosphorylate; de-phosphorylate; hyper-phosphorylate; Table 4 A CRF data file sample for sentence \u201cMCM1 forms a ternary complex with STE12 that may also repress the STE2 gene.\u201d Phrase token PN PT PGN B BT TFC TFCT L MCM1 MCM1 NP Y MCM1 Pro_Molecule O O TF forms form VP O form VP form G_V O a ternary complex a ternary complex NP O complex Pro_Complex complex BIOFAMILY_N O with with PP O with PP O O O STE12 STE12 NP Y STE12 Pro_Family O O TF that that NP O O O O O O may also repress repress VP O repress VP repress NI_V O the STE2 genes the STE2 gene NP Y STE2 gene DNA gene BIOFAMILY_N O . . O O O O O O O Table 5 A word-based CRF data file sample for sentence \u201cMCM1 forms a ternary complex with STE12 that may also repress the STE2 gene.\u201d Word token WN POS PGN BT TFC TFCT L MCM1 PGN_1 NN Y B-Pro_Molecule O O TF forms form VBZ O O form G_V O a a DT O O O O O ternary ternary JJ O O O O O complex complex NN O B-Pro_Complex complex BIOFAMILY_N O with with IN O O O O O STE12 PGN_2 NN Y B-Pro_Family O O TF that that WDT O O O O O may may MD O O O O O also also RB O O O O O repress repress VBP O O repress NI_V O the the DT O O O O O STE2 genes PGN_3 NN Y B_DNA O O O . . O O O O O O Table 6 A feature subset (local and context) associated with the TF candidate extraction STE12 in the sentence used in Table 4. For example, Pro-Family is a local feature and complex/with/STE12 is a context feature for token STE12. Template Expended feature Feature type %x[0,1] STE12 Linguistic, local %x[0,3] Y Semantic, local %x[0,5] Pro_Family Semantic, local %x[2,1] repress Linguistic, context %x[\u22122,5] Pro_Complex Semantic, context %x[\u22122,4]/%x[\u22121,4]/%x[0,4] complex/with/ STE12 Semantic, context %x[0,1]/%x[1,1]/%x[2,1]/%x[3,1] STE12/that/ repress/the STE2 gene Semantic, context %x[0,6]/%x[1,6]/%x[2,6]/%x[3,6] O/O/repress/gene Semantic, context %x[0,7]/%x[1,7]/%x[2,7]/%x[3,7] O/O/NI_V/BIOFAMILY_N Semantic, context Table 7 The performance comparison between the CRF classifiers and the baseline classifier. Precision Recall F-measure Random classifier (baseline) 0.2547 0.8991 0.3971 Word-based CRF classifier 0.5641 0.3904 0.4614 Phrase-based CRF classifier 0.6257 0.4380 0.5153 Table 8 The impact of features on performance (PGN=Protein/Gene Name; linguistic features: PN=Phrase Name, PT=Phrase Type; bio-features: B=Bioterm, BT=Bioterm Type, TFC=TF Context, TFCT=TF Context Type). Precision Recall F-measure All features 0.6257 0.4380 0.5153 PN+PT+PGN only 0.6272 0.2925 0.3989 All, but no PN 0.5972 0.4342 0.5028 B+BT+PGN 0.5965 0.3960 0.4760 TFC+TFCT+PGN 0.5083 0.3698 0.4282 All, but no (PN+PT) 0.5980 0.4329 0.5022 Table 9 The impact of various neighbouring phrase window size on performance. Window size Precision Recall F-measure 1 0.6309 0.4348 0.5148 2 0.6257 0.4380 0.5153 3 0.6054 0.4168 0.4937 Assigning roles to protein mentions: The case of transcription factors Hui Yang a 1 John Keane a Casey M. Bergman b Goran Nenadic a \u204e G.Nenadic@manchester.ac.uk a School of Computer Science, University of Manchester, UK b Faculty of Life Sciences, University of Manchester, UK \u204e Corresponding author. Address: Manchester Interdisciplinary BioCentre, University of Manchester, 131 Princess Street, Manchester M1 7DN, UK. Fax: +44 (0) 161 30 61281. 1 Current address: School of Computing, Open University, UK. Abstract Transcription factors (TFs) play a crucial role in gene regulation, and providing structured and curated information about them is important for genome biology. Manual curation of TF related data is time-consuming and always lags behind the actual knowledge available in the biomedical literature. Here we present a machine-learning text mining approach for identification and tagging of protein mentions that play a TF role in a given context to support the curation process. More precisely, the method explicitly identifies those protein mentions in text that refer to their potential TF functions. The prediction features are engineered from the results of shallow parsing and domain-specific processing (recognition of relevant appearing in phrases) and a phrase-based Conditional Random Fields (CRF) model is used to capture the content and context information of candidate entities. The proposed approach for the identification of TF mentions has been tested on a set of evidence sentences from the TRANSFAC and FlyTF databases. It achieved an F-measure of around 51.5% with a precision of 62.5% using 5-fold cross-validation evaluation. The experimental results suggest that the phrase-based CRF model benefits from the flexibility to use correlated domain-specific features that describe the dependencies between TFs and other entities. To the best of our knowledge, this work is one of the first attempts to apply text-mining techniques to the task of assigning semantic roles to protein mentions. Keywords Text mining Information extraction Transcription factor identification Conditional Random Fields 1 Introduction Transcription factors (TFs) are proteins that regulate recruitment of RNA polymerase and initiation of transcription [1], thereby playing a crucial role in regulating gene expression and influencing almost all biological processes in an organism. Because TFs play specific roles in gene expression, they are restricted to specific sub-cellular compartments (i.e. the nucleus), have specific protein structures (e.g. DNA binding domains) and specific functions (activating expression of target genes). These features of TF biology are of critical importance to researchers working on gene expression; yet, the majority of facts about TFs mainly exist in diverse, unstructured formats in the biomedical literature. There are a number of databases that contain manually-curated data on TFs, such as TRANSFAC [2,3], FlyTF [4], PAZAR [5], RegulonDB [6], and ORegAnno [7,8], which store information on TFs in structured formats (including normalised TF and target gene names, DNA binding sites, experimental evidence of interactions, literature references etc.). As with all manual curation tasks, provision of such information is time-consuming and always lags behind the actual knowledge available in the biomedical literature. Recently, the regulatory bioinformatics community has initiated joint efforts to increase the number of curators and coverage of structured TF information by organising a community-driven curation process [7,8]. However, the curation process for each individual curator is only beginning to change. Recent efforts have developed information retrieval and filtering approaches to create a queue of articles to curate [8] and information extraction approaches to identify and map putative TF binding sites [9]. Despite this progress, methods for the identification of TF mentions and textual passages that would support the curation process (or at least improve the ordering within the curation queue) have not yet been implemented. In this paper we present an approach for the identification of TF mentions in documents, which can be consequently used to support TF curation tasks. We build the method on top of a TF sentence recogniser developed earlier, which detects sentences likely to contain information relevant to TF biology [10]. Our formulation of the task is to identify proteins that have a special function in a given context, as opposed to the general protein-protein interaction (PPI) recognition task, which identifies (and potentially characterises) interactions between genes. More precisely, we are focused on a specific role of transcription regulation of a target gene that a protein mention plays in a given context. Consequently, we have construed the task as a text-tagging problem that assigns TF tags to protein mentions. Biomedical text mining research has focused on techniques that allow for automatic extraction of individual entities of a particular class (e.g. protein/gene names [11], chemical entities [12], drugs [13], tissues [14], etc.) and specific relations among them (e.g. PPI [15,16], molecular pathways [17], etc.). Most of approaches (in particular statistical and machine learning methods) assume that occurrences of entities are independent and typically treat each identification/tagging task in isolation. However, in many cases, considering relations between different entities taking part in a biological function or process could potentially improve overall mining accuracy. If a context surrounding an entity mention is associated with a particular (biological) property and is indicative of a function or role, then this should also influence tagging/recognition of occurrences or roles of other (related) entities in a given context. For instance, in the TF identification task studied here, gene regulation involves interactions and relations between target genes, transcription factors (proteins) and other biological entities (e.g. DNA-binding sites), as modelled for example by the Gene Regulation Ontology [18], and therefore occurrences of these entities should be taken into account when recognising TF mentions. Among a large variety of approaches to entity tagging in biomedical text, conditional random fields (CRFs) have been shown as useful for modelling dependences between constituents (e.g. in protein mention detection [19,20]). In this paper, we also investigate a CRF model for the identification of TF mentions. However, unlike CRF methods that generally treat a sentence as a word sequence, our model is based on shallow-parsed phrases, with biological entities nested within them used as phrase properties. Thus, the model not only considers linguistic information (from shallow parsing), but also makes use of semantic types assigned to tokens. Furthermore, we integrate local features of individual phrases (e.g. linguistic and biological properties) with context features describing the relations between phrases in a given sentence (e.g. linguistic and semantic properties of the neighbour phrases around the candidate token). The paper is organised as follows. Section 2 provides a brief analysis of TF contexts available in some relevant databases. The methods designed for phase-based CRF tagging are described in Section 3. Sections 4 and 5 present the results and error analysis, respectively, while Section 6 compares the current method to related work. Finally, Section 7 concludes the paper and gives an outline of topics for future work. 2 A brief analysis of TF contexts We have analysed a sub-collection of TF evidence sentences available in the TRANSFAC [2,3] and FlyTF [4] databases. TRANSFAC curates experimental results from published literature on TFs and regulatory sequences from a variety of eukaryotic organisms, while FlyTF is focused on Drosophila transcription factors. Both resources provide evidence sentences that justify the transcription regulation role of a given protein (in a given context). Compared to FlyTF evidence sentences that are (in most cases) directly extracted from literature, more than a third of TRANSFAC sentences are short descriptions or fragments, sometimes not containing the TF in question (e.g. \u201cmay modulate the expression of the angiotensinogen gene\u201d). Consequently, the average length of the TRANSFAC sentences is smaller than those in the FlyTF database (see Table 1 ). Neither of the resources has the mentions of TFs annotated manually in the evidence sentences, but provides protein identifiers to them. Using a set of synonyms and a simple look-up method, we have reconstructed TF mentions in most of these sentences (note that not all evidence sentences contained direct mentions of investigated/referred TFs \u2013 see the TRANSFAC example above). It is estimated that in \u223c93% of cases the reconstructed TF mentions were correct. We have also recognised other (non-TF curated) mentions of protein/gene names (PGNs) and considered them as occurrences of either target genes (TGs) or other proteins involved in the transcription regulation (not targeted in this work). The PGN mentions have been detected by combining the results from ABNER [21] and LingPipe [22], with an estimated F-score of 78.6% with a precision of 82.3% [10]. Overall, a total of 5384 protein/gene mentions have been recognised in the given sentences, with only 1 in 4 (25.47%) corresponding to TF mentions. The complexity of TF interactions with a variety of entities involved is reflected in complex linguistic expressions used to convey TF information. For example: (a) as indicated above, there are several types of entities appearing in the evidence sentences, belonging to either curated TFs, or interacting entities which physically cooperate in gene regulation, or target genes that transcription factors regulate. (b) in general, an evidence sentence contains a mention of a transcription factor, whose role is expressed using certain patterns and terms (including nominalisations and verbal phrases) that describe interactions of TFs with other biological entities (see Table 2 for examples). In most cases, a window of 2\u20133 phrases was considered sufficient for the identification of the TF role. We have also analysed the main terms and key clue words appearing in TF contexts, and manually compiled a TF context lexicon. The lexicon includes 13 noun subtypes (representing positive and negative interactions, binding events, dimerization, regulation, phosphorylation, biological regions or domains, biological families or groups, etc.) and nine verb subtypes (referring to different regulation events). The terms in the TF context lexicon are considered as important clues for the identification of TF entities, and have been used to indicate the presence of TF-specific semantic features around candidate protein mentions. We note that while some terms, such as dimerization and phosphorylation, describe general biological processes that may not be TF-specific, it is nonetheless the case that these terms appear frequently in TF-related contexts. Table 3 illustrates the classes, while the entire lexicon is available in the Supplementary material (see http://gnode1.mib.man.ac.uk/TF/). The aim of our work described below is to use various domain-specific resources and a set of (noisy) training data from TRANSFAC and FlyTF databases to automatically learn patterns (semantically similar to those in Table 2) that can be used to identify TF mentions in text. 3 Methods Our objective is to develop a system that automatically identifies and tags potential TF mentions in text and extracts relevant evidence sentences to support the annotation of putative transcription factors. We do not aim to tag TFs with molecular functions, but rather to identify proteins that are acting on a target gene in the given context and are therefore likely to be TFs. We approach the problem through two major stages. In the first stage, we use a machine-learning framework to identify TF-related sentences/contexts [10]. In the second stage, potential TFs are tagged in the sentences identified. The tagging approach is based on a Conditional Random Field (CRF) model, which uses shallow-parsed phrases to combine syntactic and semantic features to support identification of TF roles. In this section, we discuss the CRF model and the information that describes the dependencies between different entities involved in the regulation process. We briefly overview the TF sentence identification task first. 3.1 Identification of TF sentences In our previous work [10], we have developed a text-classification system designed to automatically recognise sentences related to TFs. A learning model is based on a set of features (namely protein and gene names, interaction words, other biological terms) that are deemed relevant for the task. The features have been engineered from background knowledge present in existing biological resources (MeSH 2 http://www.nlm.nih.gov/mesh/. 2 and GO 3 http://www.geneontology.org/. 3 ), and indicate presence of protein/gene names and TF-related MeSH or GO terms in a given sentence (more details about the feature types can be found in [10]). Weak and noisy training datasets have been collected from relevant descriptions of TF-related concepts in MeSH and GO. Three machine learning methods have been investigated, along with a vote-based integration of individual approaches and/or different training datasets. The system achieved highly encouraging results, with most classifiers achieving an F-measure above 90%. The experimental results have shown that the proposed model can be used for identification of TF-related sentences with high accuracy, with a significantly reduced set of features when compared to traditional bag-of-words approach. 3.2 Phrase-based Conditional Random Fields Conditional Random Fields (CRFs) [23] are particularly useful for sequence segmentation labelling tasks, such as Named Entity Recognition (NER) [24], Part-of-speech (POS) tagging [23] and shallow parsing [25]. Given an input token sequence X = { x 1 , x 2 , \u2026 , x n } , CRFs provide conditional probability of a possible tag sequence Y = { y 1 , y 2 , \u2026 , y n } , where the conditional probability distribution is defined as P ( y | x ) = 1 Z ( x ) e WF ( y , x ) Here, F ( y , x ) = \u2211 i f ( y , x , i ) is a global feature vector for input token sequence x, y is a tag assigned to the token x, Z = \u2211 y \u2032 e WF ( y \u2032 , x ) is a global normalisation factor, W are learned weights associated with the features, and f is the set of global feature functions. Standard CRF models produce features from the training data and learn a model from it (assigning weights to the features). In our phrase-based CRF model, each TF context sentence is converted into a sequence of shallow-parsed phrase segments generated by GeniaTagger [26]. Each phrase is treated as a token subsequence, which is labelled with a relevant tag. Furthermore, each phrase is \u201cnormalised\u201d using phrase-level morphological and derivational transformation and lemmatization (as provided by GeniaTagger), as well as semantic information. More precisely, in order to generate features, we pre-process TF context sentences to: \u2013 identify PGN mentions, since these should point to potential TF/TG occurrences. PGN mentions are identified by combining outputs from ABNER [21] and LingPipe [22]. In cases where PGN mentions refer to multiple entities (e.g. \u201cda and AS C proteins\u201d), these are replaced with a single multi-entity in order to ensure that it will be assigned to one phrase during shallow parsing (these will be reconstructed when generating the final corresponding CRF phrase sequence data file). \u2013 identify and characterise phrase chunks. We focus on three types of phrases: noun phrases (NP), verb phrases (VP) and preposition phrases (PP). Each phrase is \u201cnormalised\u201d using phrase-level morphological and derivational transformation and lemmatisation. Less \u201cimportant\u201d words such as auxiliaries, modals and adverbs are omitted from VPs (e.g. \u201cmay also directly interact with\u201d is transformed into \u201cinteract with\u201d). Further, in addition to linguistic properties extracted from shallow parsing (i.e. phrase type and normalised form), we also attempt to assign semantic biological properties to the phrases based on terms or clue words that appear within them. We use two biological sources here: a) biological terms and associated types from the Genia ontology [27], as provided by LingPipe, and b) task-specific keywords and classes provided by the TF context lexicon that we have compiled (see Table 3 above). In both cases, phrase properties include keywords contained in a phrase and their type (if there are multiple keywords appearing in a phrase, its properties are based on the right-most biological term/keyword, as this is typically the terminological head). After pre-processing, the following phrase properties are used in CRF data file tables for each phrase token in each TF sentence: \u2013 PhraseNormalised (PN): the normalised phrase; \u2013 PhraseType (PT): the phrase type (NP, VP or PP; O if other type); \u2013 ProteinGeneName (PGN): a binary property, Y if the phrase contains a protein/gene mention or O otherwise; \u2013 Bioterm (B): a bio-term contained in the phrase (as recognised by LingPipe), or O if none appears; \u2013 BiotermType (BT): for NP phrases \u2013 the bio-term type from the Genia ontology as assigned by LingPipe; for other phrases, use their PT (i.e. VP, PP, or O); \u2013 TFContext (TFC): a keyword from the TF context lexicon contained in the phrase, or O if none present; \u2013 TFContextType (TFCT): the corresponding TF context lexicon subtype or O; \u2013 Label (L): TF (transcription factor) or O otherwise, a label assigned to the phrase (in the training or to be assigned in testing phase). Table 4 gives an example of a sentence and the corresponding phrase tokens and their property information. 3.3 Word-based Conditional Random Fields The main reason to use phrase-based approach is that biological entities usually appear within multi-word units. Therefore, we hypothesise that the phrase-based model makes the sentence structure more concise and better captures the dependencies between entities. Still, for comparison, we have also designed a word-based CRF model using the same or comparable linguistic and semantic features. Since we are looking for a specific role that proteins may play in a given context, the only potentially multi-word feature that we have used is a protein/gene name (PGN). Therefore, similarly to the phrase-based model, each PGN mention is replaced with a single PGN unit beforehand in the CRF data file. In the word-based CRF data file, the properties for each word are as follows: \u2013 WordNormalised (WN): the normalised word; \u2013 POSTag (POS): the POS tag obtained by GeniaTagger; \u2013 ProteinGeneName (PGN): a binary property, Y if the word corresponds to a protein/gene mention or O otherwise; \u2013 BiotermType (BT): the bio-term type if the word occurs at the beginning or inside a bio-term recognised by LingPipe (B- and I- tags are added); \u2013 TFContext (TFC): the word itself if it is a keyword from the TF context lexicon, or O otherwise; \u2013 TFContextType (TFCT): the corresponding TF context lexicon subtype, or O; \u2013 Label (L): TF or O otherwise. Table 5 shows the word token information in the word-based CRF model for the same sentence as in Table 4. Using the CRF feature template described below, a set of word-based features were extracted from the CRF data file, and were learned with the word-based CRF model. 3.4 CRF feature templates In this subsection we discuss the features designed for the method, and illustrate how these represent the content and context information of TF candidate extractions. In a CRF template file that specifies features used in training and testing, each line represents one template described with a macro %x[row,col], where row is the relative position from the current tagging focus, and col is the absolute position of the column in the input CRF data file. We have constructed different types of features by making use of phrase properties of an investigated candidate and its contiguous phrase substrings. Overall, 47 templates have been created \u2013 Table 6 gives examples to illustrate a variety of features based on the CRF data file example shown in Table 4. The feature set associated with a particular TF candidate consists of local features describing the focus candidate\u2019s own properties (e.g. linguistic properties of the phrase and biological properties underlying the phrase), and context features that capture relevant linguistic and semantic properties of the neighbour phrases (we have experimented with various context window sizes, ranging from 1 to 3 phrases left and right). As illustrated by Table 6, context features, which combine the properties of a current candidate extraction and its previous or following tokens, could capture information expressed using the context patterns described in Table 2. For example, the (text) expanded feature STE12/that/repress/the STE2 gene exemplifies an interaction relationship between the current TF entity (STE12) and potential target gene (the STE2 gene). Similar examples also include complex/with/STE12 and O/O/repress/gene. 4 Experiments and results For the purpose of evaluation, we used around 5700 plain evidence sentences (no other data assigned to them) appearing in the TRANSFAC and FlyTF databases, and aimed at tagging TF mentions in them. Note that we have not used sentences that are not likely to contain TFs, as these would have been filtered in the initial step of our approach [10]. The CRF model has been built using CRF++ [28]. We have used a standard 5-fold cross validation technique in which, for each iteration, we train on 80% and test on 20% of the rest data. The performance of the task is measured in terms of precision (P), recall (R) and F-measure (F): R = TP TP + FN P = TP TP + FP F-measure = 2 PR P + R where TP (true positives) is the number of correctly tagged TF entities (as indicated by the \u201creconstructed\u201d evidence sentences from TRANSFAC and FlyTF), FN (false negatives) is the number of TF entities not tagged by the system, and FP (false positives) is the number of TF entities that are incorrectly tagged. All results are averaged across five iterations. The overall results (see Tables 7\u20139 ) show that we have achieved precision of 62.5% and recall of 43.8% when the full model was used, giving an F-measure of 51.5% for the TF role tagging task. In order to evaluate the CRF tagger, we have compared it to both a baseline classifier (which performs random TF tagging of protein occurrences) and the word-based CRF tagger (Section 4.1). We also discuss the impact of various feature types on performance (Section 4.2). 4.1 Comparison to the baseline classifier We used a random classifier to compare the performance of the suggested CRF method. Since TFs are proteins that play a special role in gene regulation, we assume that each recognised protein/gene name (PGN) has potential to be a TF, and is counted as a positive match for the baseline tagger. The performance of the random classifier is therefore as follows: P BL = # TFs identifed as PGN total # of PGN R BL = # TFs identified as PGN total # of actual TFs F- measure BL = 2 P BL R BL P BL + R BL The performance comparisons between the CRF classifiers and the baseline classifier are given in Table 7. The phrase-based CRFs classifier achieved almost 2.5 times better precision (62.57% compared to 25.47%), with overall improvement of almost 1/3 in F-measure. The precision of the word-based CRF method was twice better than the random classifier. As expected, the random classifier had significantly better recall (note that it is still not 100%, given the \u201cimperfect\u201d performance of the protein name identification tools we have used). Overall, the results suggest that the CRF classifiers benefit by using additional information represented in our models. As expected, the phrase-based CRF model performed better than the word-based model (with an increase of 5.7 points on precision and 4.8 points on recall), indicating that phrases are more suitable for capturing the information required for role tagging. 4.2 Impact of feature types We have also evaluated the effects of individual phrase properties with that of the full phrase-based CRF model with all features. Obviously, as we are looking for a specific role of proteins, the only feature that we have used in all experiments is whether a phrase contains protein/gene name(s) (PGN). The complete comparison tables are available in the Supplementary material. \u2022 Linguistic features The linguistic information used in the model comprises phrase normalised names (PN) and phrase types (PT). When only these features are used, the system achieved the best precision, but the recall was significantly lower than when task and domain-specific properties were incorporated (see Table 8). Phrase types appeared to have no significant positive influence when added to other features \u2013 however, recall that bio-term type reflects similar properties, which makes the phrase type properties partially redundant in this case. When phrase normalised names are left out, the precision is degraded by around 2.8%, while there is no significant influence on recall. \u2022 Domain-specific features Domain and task-specific features generally improve the performance of the TF tagger. However, when only general domain features are used (B+BT+PGN), the F-measure drops to 0.4760, while with task-specific features (TFC+TFCT+PGN) only, it is even lower (0.4282). The combination of domain features only gives an F-measure of 0.50. \u2022 Context features The model attempts to learn the context between the current focus (TF) phrase and its surrounding phrases as indicated by expression templates. The results presented in Table 9 show that the model based on two-phrase windows achieves the highest overall F-measure, with the one-phrase window model having comparable performance. On the other hand, the model with 3 phrases left and right deteriorates the performance. 5 Discussions and error analysis As indicated above, when only linguistic features are used, precision was high with considerably lower recall, indicating that there exist important domain-specific lexical and syntactic discriminative features that need to be used to identify TF roles. Generally speaking, specific biological terms and TF context terms often lead to improving both precision and recall, while term class information was generally beneficial for recall, since specific term names contributed to more distinguishing features, while term classes resulted in more generic (i.e. normalised) features. For example, the context feature \u201cO/O/NI_V/BIOFAMILY_N\u201d that captures the TF lexicon type information is more generic (normalised) than a specific term feature \u201cO/O/repress/gene\u201d (see Table 6, last two rows), and thus has more abstraction potential that was beneficial for improving recall. Comparing the different tagging approaches, it is obvious that \u2013 compared to the baseline model \u2013 the CRF classifiers improve precision significantly by taking into account linguistic and biological features, both locally and contextually. Similarly to using more generic features as discussed above, it appears that the phrase-based model is more robust in capturing the characteristics of the TF-related contexts compared to the word-based model, which resulted in improved precision and recall. After analysing a random sample containing 200 context sentences of false positive (FP) and false negative (FN) cases in the tagged results, we have identified four major error categories: (a) Long-distance dependences: our CRF model focuses on local contexts between the investigated candidate and its adjacent neighbouring phrases. Obviously, longer dependences cannot be captured (e.g. in sentence \u201casense differs from the other AS C members in its expression pattern, mutant phenotype and some DNA binding properties.\u201d, the distance between the investigated TF \u201casense\u201d and its related discriminative feature information \u201cDNA binding properties\u201d is more than 3 phrases away). This has resulted in numerous FN (estimated 30% of all errors). (b) Weak context evidence: some TF sentences do not contain strong discriminative TF context information that we have used, but still provide TF evidence (e.g. adjective indirect in \u201cinteraction with CRE-BP1 or c-Fos may be indirect\u201d as evidence for \u201cCRE-BP1\u201d). Since these have not been included in the model, it has triggered some false negative cases (estimated 15% of all errors). (c) Feature engineering: the accuracy of biological named entity recognition can produce incorrect or missing biological features used in the model (for example, the ABNER/LingPipe integrated PGN results achieved an estimated F-measure of 78.6%), leading to noisy features (estimated 20% of all errors). (d) Inconsistent and \u201cnoisy\u201d annotation in the resources: since we have performed an automated \u201creconstruction\u201d of TF mentions in evidence sentences, there are a number of errors originated from that process (estimated accuracy is \u223c93%). Also, in some cases, multiple TF mentions have not been annotated in the resources we have used. For example, in sentence \u201c...heterodimers with either c-Myc or Mad exert higher DNA-binding affinity than Max homodimers\u201d, only protein \u201cc-Myc\u201d is annotated as TF, whole the system has recognised Mad as well, which led to a false positive case (although it is a correct TF). We estimate that this \u201cerror\u201d type covers around 20% of cases. The approach that we have followed does not use dictionary look-up, where candidate TFs are recognised using a repository of known TFs. There are two main reasons. Firstly, not all literature mentions of known TFs are related to their TF role, so additional features would be still needed to filter out the unrelated ones. Secondly, while identifying mentions of known TFs, we are also interested in extracting newly reported TFs. Therefore, the phrase-based CRF model recognises protein/gene names as potential TFs of interest, in cases when those mentions have similar behaviour properties to the sample TFs, and is thus more flexible in identifying potential unknown TF entities. Finally, the proposed CRF model is species-independent, as semantic domain features only rely on general biological term properties and TF-specific domain properties. Of course, an extra feature indicating that a given protein is a known TF could further improve precision. 6 Comparison to related work There has been significant work with various text mining approaches applied to biomedical knowledge extraction, retrieval and curation support [13,15\u201317,29\u201331]. Many approaches are based on pre-specified pattern- or rule-based matching [17,32], or more complex template- or frame-based processing [33,34]. Although such approaches achieve rather satisfactory precision, they typically suffer from low recall as in most cases patterns are hand-generated. Several techniques rely on full [35,36] or partial parsing [37]. Much attention in recent years has been focused on machine learning models, such as support vector machines [38,39] or Maximum Entropy models [40]. These models usually use bag-of-features that present linguistic or syntactic information of individual words, and do not consider any dependency or semantic relations between entities or features contained in text. Conditional Random Fields (CRFs) are discriminatively undirected graphic models, a special case of which is a linear chain that corresponds to a condition trained finite-state machine [23]. Unlike other graphical models such as Hidden Markov Models (HMMs) that require stringent conditional independence assumption, one of the most attractive advantages of CRF models is their flexibility in capturing non-independent features, such as capitalisation, suffixes and surrounding words. CRF models have shown success in identification of various biomedical named entity classes (e.g., protein, DNA, RNA, cell-line, cell-type, etc.) [41\u201343]. Still, these models generally work at the word token level and attempt to tag sequences that belong to a certain class. However, in our TF tagging task, TF sentences contain rich but also indispensable biological information reflecting the relationships between potential transcription factors and other biomedical entities, which make proteins acting as TFs in the given context. Such information is hard to capture with flat word sequences, since most of the biomedical entity names are multi-words and appear as parts of phrases. Also, role-specific relations are typically expressed via nominal, verbal and prepositional phrases. We have therefore explored a phrase-based CRF model, which treats a sentence as a sequence of phrase tokens, and takes advantage of a number of context features that combine the properties of a candidate token and its surrounding tokens together. Moreover, we enrich the feature set by using biological knowledge to assign semantic properties to phases. In the area of transcription regulatory networks, one of the first attempts to discover potential functional associations between TFs from literature was presented by Pan et al. [44]. Using controlled vocabularies related to GO terms and disease states, functional associations were extracted based on a set of manually selected abstracts relevant to transcription control. The work by Saric and colleagues [45] reported on the extraction of regulatory relations between entities, especially on gene expression and (de-)phosphorylation relations. Regulatory networks were constructed using a set of rules that capture linguistic structures in gene regulation. Different types of regulation relations were separately identified by incorporating biological constraints and semantic requirements. Rodr\u00edguez-Penagos et al. [46] implemented a rule-based system to generate regulatory networks in Escherichia coli. They used hand-crafted dictionaries and gene name lists along with a syntactic parser to infer grammatical structures that relate two gene/protein noun phrases via a phrase containing verbs from a pre-defined list. Our approach also combines linguistic and domain-specific features on the phrase level, but uses machine-learning (CRFs) to learn discriminative properties to support identification of TF roles in proteins. 7 Conclusions In this paper we have proposed a phrase-based CRF model for the identification of transcription factor mentions, which integrates both linguistic features (e.g. phrase types) and domain properties (e.g. mentions of generic or task-specific biological keywords and types). Since many biomedical entities and events are represented via multi-word expressions, the model is built on a phrase rather than sequence structure, which makes it feasible to capture context information surrounding a current candidate by using a set of context features assigned to both the candidate entity and its neighbours. Moreover, phrase normalisation (e.g. morphological, derivational, lemmatisation) was used to provide most representative features. To the best of our knowledge, this work is one of the first attempts to apply text-mining techniques to the task of assigning TF roles to protein mentions. The approach showed moderate results of an average overall F-measure of 51.5%, with precision of 62.5%. This is a significant improvement compared to the baseline method (F-measure of 39.7%, precision of 25.5%). The experimental results suggest that domain features positively affect both accuracy and coverage of the model. The most useful context information is generally associated with the surrounding tokens within a window size of two to the current candidate. As this is the first attempt, there is still room for improvement on predication accuracy by augmenting phrases with more suitable properties, such as domain-specific terms describing structure features and function properties of transcription factors and adjectives/adverbs referring to interactions (e.g. direct/indirect). Also, more research is needed for the exploitation of longer distance dependences and global relations between candidate transcription factors and other entities. We plan to investigate dependency parsing that would link non-local entities. Finally, we plan to evaluate the proposed method in a real-world scenario for ORegAnno [7] curation, where the overall 3-step process will be used against a set of abstracts (and potentially full text documents) to (a) filter out relevant documents [9], (b) identify potential TFs and TGs (including mapping them to referential databases), and (c) present support sentences to curators. The results will be than compared with the real curation queue (created manually as part of the curation process) for a given period of time. Acknowledgments This work was partially supported by the Bio-MITA project (\u201cMining Term Associations from Literature to Support Knowledge Discovery in Biology\u201d) funded by UK Biotechnology and Biological Science Research Council (BBSRC). We are grateful to ORegAnno, FlyTF and TRANSFAC databases for providing the data. Appendix A Supplementary data Supplementary data associated with this article can be found, in the online version, at doi:10.1016/j.jbi.2009.04.001. Appendix A Supplementary data Supplementary data References [1] S.F. Gilbert Developmental biology 2006 Sinauer Associates Sunderland, Mass [2] E. Wingender X. Chen R. Hehl H. Karas I. Liebich V. Matys TRANSFAC: an integrated system for gene expression regulation Nucleic Acids Res 28 2000 316 319 [3] V. Matys E. Fricke R. Geffers M. Haubrock R. Hehl TRANSFAC: transcriptional regulation, from patterns to profiles Nucleic Acids Res 31 2003 374 378 [4] B. Adryan S.A. Teichmann FlyTF: a systematic review of site-specific transcription factors in the fruit fly Drosophila melanogaster Bioinformatics 22 2006 1532 1533 [5] E. Portales-Casamar S. Kirov J. Lim S. Lithwick M. Swanson A. Ticoll PAZAR: a framework for collection and dissemination of cis-regulatory sequence annotation Genome Biol 8 2007 R207 [6] A.M. Huerta H. Salgado D. Thieffry J. Collado-Vides RegulonDB: a database on transcriptional regulation in Escherichia coli Nucleic Acids Res 26 1 1998 55 59 [7] S.B. Montgomery O.L. Criffith M.C. Sleumer C.M. Bergman M. Bilenky E.D. Pleasance ORegAnno: an open access database and curation system for literature-derived promoters, transcription factor binding sites and regulatory variation Bioinformatics 22 2006 637 640 [8] O.L. Griffith S.B. Montgomery ORegAnno: an open-access community-driven resource for regulatory annotation Nucleic Acids Res 36 2007 D107 D113 [9] S. Aerts M. Haeussler O.L. Griffith S. van Vooren S.J.M. Jones S. Montgomery Text-mining assisted regulatory annotation Genome Biol 9 2008 R31 [10] H. Yang G. Nenadic J.A. Keane Identification of transcription factor contexts in literature using machine learning approaches BMC Bioinform 9 2008 S11 [11] L. Tanabe W. Wilbur Tagging gene and protein names in biomedical text Bioinformatics 18 2002 1124 1132 [12] K. Degtyarenko P. de Matos M. Ennis J. Hastings M. Zbinden A. McNaught ChEBI: a database and ontology for chemical entities of biological interest Nucleic Acids Res 36 2008 D344 D350 [13] J.-j. Kim P. Pezik D. Rebholz-Schuhmann MedEvi: retrieving textual evidence of relations between biomedical concepts from Medline Bioinformatics 24 11 2008 1410 1412 [14] Alex B, Grover C, Haddow B, Kabadjov M, Klein E, Matthews M, et al. The ITI TXM Corpora: tissue expressions and protein\u2013protein interactions. In: Proc. of LREC 2008 workshop on building and evaluating resources for biomedical text mining; 2008. p. 11\u20138. [15] Blaschke C, Andrade MA, Ouzounis C, Valencia A. Automatic extraction of biological information from scientific text: protein\u2013protein interactions. In: Proc. of the 7th ISMB; 1999. p. 60\u20137. [16] Y. Hao X. Zhu M. Huang M. Li Discovering patterns to extract protein\u2013protein interactions from the literature Bioinformatics 21 2005 3294 3300 [17] C. Friedman P. Kra H. Yu M. Krauthammer A. Rzhetsky GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles Bioinformatics 17 2001 S74 S82 [18] Beisswanger E, Lee V, Kim J-J, Rebholz-Schuhmann D, Splendiani A, Dameron O, et al. Gene regulation ontology (GRO): design principles and use cases. In: Proceedings of AMIA annual symposium 2006; 2006. p. 694\u20138. [19] A. Yeh A. Morgan M. Colosimo L. Hirschman BioCreAtIvE Task 1A: gene mention finding evaluation BMC Bioinform 6 Supp1. 2005 S2 [20] Wilbur J, Smith L, Tanabe L. BioCreative 2. Gene mention task. In: Proc. of the second BioCreative challenge evaluation workshop; 2007. [21] B. Settles ABNER: an open source tool for automatically tagging genes Bioinformatics 21 2005 3191 3192 [22] Carpenter B. Phrasal queries with LingPipe and Lucene: Ad Hoc genomics text retrieval. In: Proceedings of the 13th annual text retrieval conference; 2004. [23] Lafferty J, McCallum A, Pereira F. Conditional random fields: probabilistic models for segmenting and labelling sequence data. In: Proc. of the international conference on machine learning (ICML-2001); 2001. p. 282\u20139. [24] McCallum A, Li W. early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons. In: Proceedings of the seventh conference on natural language learning (CoNLL); 2003. [25] Sha F, Pereira F. Shallow parsing with conditional random fields. In: Proceedings of human language technology and the meeting of the North American association for computational linguistics. Edmonton, Canada; 2003. p. 134\u201341. [26] Tsuruoka Y, Tateishi Y, Kim J, Ohta T, McNaught J, Ananiadou S. Developing a robust part-of-speech tagger for biomedical text. In: Advances in Informatics; 2005. p. 382\u201392. [27] J.-D. Kim T. Ohta Y. Teteisi J.i. Tsujii GENIA corpus \u2013 a semantically annotated corpus for bio-text mining Bioinformatics 19 2003 i180 i182 [28] CRF++. Available from: http://crfpp.sourceforge.net/. [29] G. Nenadic I. Spasic S. Ananiadou Terminology-driven mining of biomedical literature Bioinformatics 19 8 2003 938 943 [30] N. Karamanis R. Seal I. Lewin P. McQuilton A. Vlachos C. Gasperin R. Drysdale T. Briscoe Natural language processing in aid of FlyBase curators BMC Bioinform 9 2008 193 [31] Rebholz-Schuhmann D, Kirsch H, Arregui M, Gaudan S, Riethoven M, Stoehr P. EBIMed \u2013 text crunching to gather facts for proteins from Medline. Bioinformatics. 2007; 23:e237\u201344. [32] Park J, Kim H, Kim J. Bidirectional incremental parsing for automatic pathway identification with combinatory categorical grammar. In: Proc. of Pacific symposium on biocomputing; 2001. p. 396\u2013407. [33] C. Blaschke A. Valencia The frame-based module of the Suiseki information extraction system IEEE Intelligent Syst 17 2002 14 20 [34] Thomas J, Milward D, Ouzounis C, Pulman S, Carroll M. Automatic extraction of protein interactions from scientific abstracts. In: Proc. of Pacific symposium on biocomputing; 2000. p. 538\u201349. [35] N. Daraselia A. Yuryev S. Egorov S. Novichkova A. Nikitin I. Mazo Extracting human protein interactions from MEDLINE using a full-sentence parser Bioinformatics 20 2004 604 611 [36] Yakushiji A, Tateisi Y, Miyao Y, Tsujii J. Event extraction from biomedical papers using a full parser. In: Proc. of Pacific symposium on biocomputing; 2001. p. 408\u201319. [37] Pustejovsky J, Castano J, Zhang J, Kotechl M, Doi H. Rubust relational parsing over biomedical literature: extracting inhibit relations In: Proc. of the seventh Pacific symposium on biocomputing; 2002. p. 362\u201373. [38] I. Donaldson J. Martin B.d. Bruijn C. Wolting V. Lay B. Tuekam S. Zhang B. Baskin G.D. Bader K. Michalickova T. Pawson C.W. Hogue PreBIND and Textomy \u2013 mining the biomedical literature for protein-protein interactions using a support vector machine BMC Bioinform 4 2003 [39] T. Mitsumori M. Murata Y. Fukuda K. Doi H. Doi Extracting protein-protein interaction information from biomedical text with SVM IEICE Trans Inform Syst E89-D 2006 2464 2466 [40] Sun C, Lin L, Wang X, Guan Y. Using maximum entropy model to extract protein\u2013protein interaction information from biomedical literature. In: advanced intelligent computing theories and applications. Berlin/Heidelberg: Springer; 2007. p. 730\u20137. [41] R. McDonald F. Pereira Identifying gene and protein mentions in text using conditional random fields BMC Bioinform 6 2005 S6 [42] Settles B. Biomedical named entity recognition using conditional random fields and rich feature sets. In: Proceedings of the international joint workshop on natural language processing in biomedicine and its applications (NLPBA); 2004. p. 104\u20137. [43] Tsai T-H, Wu S-H, Hsu W-L. Exploitation of linguistic features using a CRF-based biomedical named entity recognizer. In: Proceedings of BioLINK 2005; 2005. [44] H. Pan L. Zuo V. Choudhary Z. Zhang Dragon TF association miner: a system for exploring transcription factor associations through text-mining Nucleic Acids Res 32 Jul 1 2004 W230 W234 [45] J. Saric L. Jensen R. Ouzounova I. Rojas P. Bork Extraction of regulatory gene/protein networks from Medline Bioinformatics 22 6 2006 645 650 [46] C. Rodriguez-Penagos H. Salgado I. Martinez-Flores J. Collado-Vides Automatic reconstruction of a bacterial regulatory network using natural language processing BMC Bioinform 8 2007 293", "scopus-id": "70349456436", "pubmed-id": "19364541", "coredata": {"eid": "1-s2.0-S1532046409000525", "dc:description": "Abstract Transcription factors (TFs) play a crucial role in gene regulation, and providing structured and curated information about them is important for genome biology. Manual curation of TF related data is time-consuming and always lags behind the actual knowledge available in the biomedical literature. Here we present a machine-learning text mining approach for identification and tagging of protein mentions that play a TF role in a given context to support the curation process. More precisely, the method explicitly identifies those protein mentions in text that refer to their potential TF functions. The prediction features are engineered from the results of shallow parsing and domain-specific processing (recognition of relevant appearing in phrases) and a phrase-based Conditional Random Fields (CRF) model is used to capture the content and context information of candidate entities. The proposed approach for the identification of TF mentions has been tested on a set of evidence sentences from the TRANSFAC and FlyTF databases. It achieved an F-measure of around 51.5% with a precision of 62.5% using 5-fold cross-validation evaluation. The experimental results suggest that the phrase-based CRF model benefits from the flexibility to use correlated domain-specific features that describe the dependencies between TFs and other entities. To the best of our knowledge, this work is one of the first attempts to apply text-mining techniques to the task of assigning semantic roles to protein mentions.", "openArchiveArticle": "true", "prism:coverDate": "2009-10-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046409000525", "dc:creator": [{"@_fa": "true", "$": "Yang, Hui"}, {"@_fa": "true", "$": "Keane, John"}, {"@_fa": "true", "$": "Bergman, Casey M."}, {"@_fa": "true", "$": "Nenadic, Goran"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046409000525"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046409000525"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(09)00052-5", "prism:volume": "42", "prism:publisher": "Elsevier Inc.", "dc:title": "Assigning roles to protein mentions: The case of transcription factors", "prism:copyright": "Copyright \u00a9 2009 Elsevier Inc. All rights reserved.", "prism:issueName": "Biomedical Natural Language Processing", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "5", "dcterms:subject": [{"@_fa": "true", "$": "Text mining"}, {"@_fa": "true", "$": "Information extraction"}, {"@_fa": "true", "$": "Transcription factor identification"}, {"@_fa": "true", "$": "Conditional Random Fields"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "5", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "887-894", "prism:endingPage": "894", "prism:coverDisplayDate": "October 2009", "prism:doi": "10.1016/j.jbi.2009.04.001", "prism:startingPage": "887", "dc:identifier": "doi:10.1016/j.jbi.2009.04.001", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "131", "@width": "230", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3959", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "38", "@width": "369", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1656", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "107", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "577", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "144", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "717", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "41", "@width": "146", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "881", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "132", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "527", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "134", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "525", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046409000525-mmc1.doc?httpAccept=%2A%2F%2A", "@multimediatype": "Microsoft Word file", "@type": "APPLICATION", "@size": "43008", "@ref": "mmc1", "@mimetype": "application/word"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/70349456436"}}
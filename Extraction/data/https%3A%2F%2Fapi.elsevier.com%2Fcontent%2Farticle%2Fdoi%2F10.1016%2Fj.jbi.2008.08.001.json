{"scopus-eid": "2-s2.0-60049096136", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2008-08-12 2008-08-12 2010-10-09T20:28:24 1-s2.0-S1532046408001019 S1532-0464(08)00101-9 S1532046408001019 10.1016/j.jbi.2008.08.001 S300 S300.1 FULL-TEXT 1-s2.0-S1532046409X0002X 2015-05-15T06:30:58.184067-04:00 0 0 20090201 20090228 2009 2008-08-12T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount figure table body mmlmath affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content oa subj ssids 1532-0464 15320464 42 42 1 1 Volume 42, Issue 1 8 53 58 53 58 200902 February 2009 2009-02-01 2009-02-28 2009 article fla Copyright \u00a9 2008 Elsevier Inc. All rights reserved. IMPROVINGLANGUAGEMODELSFORRADIOLOGYSPEECHRECOGNITION PAULETT J 1 Background 2 Methods 2.1 Setting 2.2 Research database 2.3 Comparing sets of words and trigrams 2.4 Metrics for comparing word and trigram frequencies 3 Results 3.1 Univariate analysis 3.2 Comparison of word frequencies by modality 3.3 Subgroup analysis 3.4 Comparison of word frequency by radiologist 3.5 Trigram frequency analysis 4 Discussion 4.1 Limitations 5 Conclusion References ALAYNATI 2003 721 725 M LIU 2006 98 104 D LANGER 2002 95 104 S LAKHANI 2006 52 68 P KILGARRIFF 2001 97 133 A PAULETTX2009X53 PAULETTX2009X53X58 PAULETTX2009X53XJ PAULETTX2009X53X58XJ 2013-07-17T11:42:38Z OA-Window Full ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(08)00101-9 S1532046408001019 1-s2.0-S1532046408001019 10.1016/j.jbi.2008.08.001 272371 2010-11-01T14:18:15.959871-04:00 2009-02-01 2009-02-28 1-s2.0-S1532046408001019-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/MAIN/application/pdf/52d80fc57b9b4b6a580b43c6513c93e7/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/MAIN/application/pdf/52d80fc57b9b4b6a580b43c6513c93e7/main.pdf main.pdf pdf true 504771 MAIN 6 1-s2.0-S1532046408001019-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/PREVIEW/image/png/f8ac07483813567f516d05ee7a2436e5/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/PREVIEW/image/png/f8ac07483813567f516d05ee7a2436e5/main_1.png main_1.png png 84427 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046408001019-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/STRIPIN/image/gif/e0418db4f8fc680487b56c039b705ad6/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/STRIPIN/image/gif/e0418db4f8fc680487b56c039b705ad6/si2.gif si2 si2.gif gif 1533 38 240 ALTIMG 1-s2.0-S1532046408001019-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/STRIPIN/image/gif/2ad79e51a85af04ddfdda7e887d0e81f/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/STRIPIN/image/gif/2ad79e51a85af04ddfdda7e887d0e81f/si1.gif si1 si1.gif gif 3992 72 482 ALTIMG 1-s2.0-S1532046408001019-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx1/DOWNSAMPLED/image/jpeg/47cf2fcc356dc2d7542128b0965d53dd/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx1/DOWNSAMPLED/image/jpeg/47cf2fcc356dc2d7542128b0965d53dd/fx1.jpg fx1 fx1.jpg jpg 40837 189 819 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408001019-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx1/THUMBNAIL/image/gif/239542d4eec1afe4e1ac62bdff65599b/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx1/THUMBNAIL/image/gif/239542d4eec1afe4e1ac62bdff65599b/fx1.sml fx1 fx1.sml sml 1803 29 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408001019-fx2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx2/DOWNSAMPLED/image/jpeg/a588310496837a6980a306155ff624a1/fx2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx2/DOWNSAMPLED/image/jpeg/a588310496837a6980a306155ff624a1/fx2.jpg fx2 fx2.jpg jpg 19175 122 816 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408001019-fx2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx2/THUMBNAIL/image/gif/3d61cb876b8a0efe866bc976e4b89599/fx2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx2/THUMBNAIL/image/gif/3d61cb876b8a0efe866bc976e4b89599/fx2.sml fx2 fx2.sml sml 1378 19 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408001019-fx4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx4/DOWNSAMPLED/image/jpeg/786d7019de18da03804e8495783b0dbb/fx4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx4/DOWNSAMPLED/image/jpeg/786d7019de18da03804e8495783b0dbb/fx4.jpg fx4 fx4.jpg jpg 39126 189 818 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408001019-fx4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx4/THUMBNAIL/image/gif/a9593f951be17ddabf210913f1e56b41/fx4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx4/THUMBNAIL/image/gif/a9593f951be17ddabf210913f1e56b41/fx4.sml fx4 fx4.sml sml 1746 29 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408001019-fx5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx5/DOWNSAMPLED/image/jpeg/82fa2a022d0fbac17e64fa44473e2825/fx5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx5/DOWNSAMPLED/image/jpeg/82fa2a022d0fbac17e64fa44473e2825/fx5.jpg fx5 fx5.jpg jpg 40431 189 816 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408001019-fx5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx5/THUMBNAIL/image/gif/6f650ab1946dbc6bc997919bdbc00c78/fx5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx5/THUMBNAIL/image/gif/6f650ab1946dbc6bc997919bdbc00c78/fx5.sml fx5 fx5.sml sml 1775 29 125 IMAGE-THUMBNAIL 1-s2.0-S1532046408001019-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/gr1/DOWNSAMPLED/image/jpeg/73ccab51225448558fa780e846c59529/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/gr1/DOWNSAMPLED/image/jpeg/73ccab51225448558fa780e846c59529/gr1.jpg gr1 gr1.jpg jpg 23793 354 378 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408001019-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/gr1/THUMBNAIL/image/gif/866ac452503c1ce41114894a3d90bdce/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/gr1/THUMBNAIL/image/gif/866ac452503c1ce41114894a3d90bdce/gr1.sml gr1 gr1.sml sml 2173 94 100 IMAGE-THUMBNAIL 1-s2.0-S1532046408001019-fx3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx3/DOWNSAMPLED/image/jpeg/82d647f24b94a40b63a8d810bda2d440/fx3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx3/DOWNSAMPLED/image/jpeg/82d647f24b94a40b63a8d810bda2d440/fx3.jpg fx3 fx3.jpg jpg 42013 189 816 IMAGE-DOWNSAMPLED 1-s2.0-S1532046408001019-fx3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408001019/fx3/THUMBNAIL/image/gif/da745a8fc074780f9af4ce8999eb4556/fx3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408001019/fx3/THUMBNAIL/image/gif/da745a8fc074780f9af4ce8999eb4556/fx3.sml fx3 fx3.sml sml 3320 51 219 IMAGE-THUMBNAIL YJBIN 1475 S1532-0464(08)00101-9 10.1016/j.jbi.2008.08.001 Elsevier Inc. Fig. 1 Words per report. The graph is limited to two times the standard deviation\u00b1mean. Table 1 Table for determining the log-likelihood score [9] X Y w a b a+b not w c d c+d a+c b+d a+b+c+d=N Table 2 Report frequency by modality Modality code Modality % Total reports CR Computed radiography 47.9 CT Computed tomography 15.9 MR Magnetic resonance 10.3 US Ultrasound 8.66 NM Nuclear medicine 5.12 MG Mammography 4.85 XA X-ray angiography 3.31 DF Digital fluoroscopy 2.68 DEXA Dual energy X-ray absorptiometry 0.936 PT Positron emission tomography 0.301 MISC 0.0388 MS Magnetic resonance spectroscopy 0.0230 Computed radiography accounted for almost half of reports. CT, MRI, and ultrasound accounted for the bulk of the remainder. Table 3 Reports frequency by body site Body site code Body site % Total reports Chest Chest 36.1 Lwrext Lower extremity 7.56 Head Head 7.30 Abdomen Abdomen 7.00 Pelvis Pelvis 6.86 Breast Breast 6.63 Vertebra Vertebral column 6.04 Cardio Cardiovascular 5.33 Uprext Upper extremity 3.70 GI Gastrointestinal 2.89 Muscskel Musculoskeletal 2.77 GU Genitourinary 2.40 Neck Neck 2.40 Misc Miscellaneous 1.69 Abd\u2013pelvis Abdomen and pelvis 0.886 Neuro Neurological 0.407 A large proportion of reports concerned the thorax. The remainder of reports were widely distributed throughout the body. Table 4 Top 15 most distinctive words between when comparing concordant reports (from the same modality, CR vs. CR) and discordant reports (between different modalities, CR vs. MR) Concordant: CR vs. CR Difference in frequency (CR\u2212CR) Discordant: CR vs. MR Difference in frequency (CR\u2212MR) Compartment \u2212494 Chest +513833 Malleolus +463 Axial \u2212272549 Paratracheal \u2212247 Heart +247858 Asymmetric +231 Lung +213917 Nasal \u2212218 Images \u2212207375 Facial +189 Tube +203790 Fractured +184 MRI \u2212192576 Osteoblastic +164 Atelectasis +185614 Kinked +115 Pneumothorax +178164 Measurement \u221249 Views +175501 Enhancement +47 Sagittal \u2212144446 Myoma \u221237 Signal \u2212140412 Methacrylate +35 Echo \u2212123929 Disarticulation \u221227 Weighted \u2212120174 Cochlear \u221227 T2 \u2212109234 All words listed were classified as distinctive using the log-likelihood test with p <0.01. Approximately 170 million words were in each subset. Table 5 Ratio of distinctive words (SLL metric: p >0.05) by modality Entries highlighted in gray indicate that the modality is the same for both corpora. Concordant comparisons are highlighted in gray. Table 6 Ratio of distinctive words (SLL metric: p >0.05) by subspecialties of the MR modality Table 7 Ratio of distinctive words (SLL metric: p >0.05) by body site of the MR modality Table 8 Ratio of distinctive words (SLL metric: p >0.05) by reading radiologist The column and row headers represent the rank of the radiologist by number of reports dictated. Table 9 Top 25 trigrams use in radiology reports along with number of times each trigram appears in the entire database Trigram No. of occurrences There is no 13120608 There is a 10147824 No evidence of 7892478 Of the chest 6589080 Of the right 6305400 Of the left 5692920 In the right 4937232 Seen in the 4542216 In the left 3804672 Is no evidence 3577140 There are no 3273182 Examination of the 3151104 Normal in size 2908422 Views of the 2827404 Within normal limits 2805176 Comparison is made 2739506 There is mild 2434608 Is normal in 2361870 Is made to 2326368 Is seen in 2315192 Of the abdomen 2300490 Images of the 2294480 The patient is 2258064 View of the 2185600 Available for comparison 1841708 Table 10 Ratio of distinctive trigrams (SLL metric: p >0.05) by modality Table 11 Summary of ratio of n-grams with significant (p <0.05) G 2 values (SLL metric) Parameters Concordant (%) Discordant (%) Modality 0.508%\u00b10.156 39.2%\u00b15.82 Modality, body site 0.805%\u00b10.215 36.0%\u00b16.91 Radiologist 0.515%\u00b10.147 32.5%\u00b18.57 Modality (trigrams) 0.251%\u00b12.23 36.5%\u00b15.60 Comparison of reports with discordant modality and body site had similar rates of distinctive words than comparisons between reports dictated by different radiologists. Discordant reports have much higher rates of distinctive words that concordant reports. Improving language models for radiology speech recognition John M. Paulett a Curtis P. Langlotz b \u204e langlotc@uphs.upenn.edu a School of Engineering and Applied Science, University of Pennsylvania, USA b Department of Radiology, University of Pennsylvania, Radiology Administration, Penn Tower Lobby Level, 399 South 34th Street, Suite 100, Philadelphia, PA 19104, USA \u204e Corresponding author. Fax: +1 215 349 5925. Abstract Speech recognition systems have become increasingly popular as a means to produce radiology reports, for reasons both of efficiency and of cost. However, the suboptimal recognition accuracy of these systems can affect the productivity of the radiologists creating the text reports. We analyzed a database of over two million de-identified radiology reports to determine the strongest determinants of word frequency. Our results showed that body site and imaging modality had a similar influence on the frequency of words and of three-word phrases as did the identity of the speaker. These findings suggest that the accuracy of speech recognition systems could be significantly enhanced by further tailoring their language models to body site and imaging modality, which are readily available at the time of report creation. Keywords Radiology Speech recognition n-Gram Trigram model Word frequency Radiology reports 1 Background As hospitals have sought to tighten their budgets, and referring providers demand rapid turn around time for radiology reports, radiology departments have shifted from using transcription services to the implementation of speech recognition systems. Speech recognition systems replace expensive transcription services and enable much quicker report delivery. However, lower accuracy rates of these systems compared to transcription services have affected the productivity of radiologists by causing them to spend a larger portion of their time correcting the inaccuracies of the computer generated report [1,2]. Over the past several years, speech recognition technology has greatly improved, with some vendors now advertising accuracy rates of up to 99 percent [3]. But the few errors that do occur in radiology reports can have profound effects when clinicians rely on the reports to make life-altering decisions. For example, a speech recognition engine can interpret a radiologist as saying, \u201cThere is now evidence of tuberculosis,\u201d when the radiologist actually said, \u201cThere is no evidence of tuberculosis.\u201d Overall speech recognition error rates can be reduced by several means. For example, most speech recognition engines can be \u201ctrained\u201d or tailored to an individual\u2019s voice and speech pattern. Such training can dramatically improve the accuracy rate of the engine. Additionally, many radiologists utilize macros, which serve as templates for reports that are commonly used. Typically, only a few blanks, called fields, in the macro need to be dictated. Macros thereby reduce the error rate of dictation by limiting the amount of text that is generated by the speech recognition engine. Furthermore, radiologists proofread their reports before signing them. However, even a single error can cause an incorrect diagnosis. Therefore, every additional effort should be made to systematically improve the accuracy of speech recognition. Most modern speech recognition engines rely upon probabilistic measures of word combinations, represented in a language model to translate audio input into words. Typically, statistical language models of speech recognition engines use trigrams, or three-word phrases, to determine which words the speaker used. While products such as Dragon NaturallySpeaking Medical (Nuance, Burlington, MA) include a medical dictionary and a radiology language model, no effort has been made to use the unique properties of radiological examinations to further refine the language model [4,5]. The goal of this study was to demonstrate that certain properties of imaging examinations, such as the body site, modality, and subspecialty, which are known prior to dictation, have an effect on word and trigram frequency that is comparable to the identity of the speaker. Because these former attributes of the report are known in advance, they could be used to dynamically refine the language model used by speech recognition engines, thereby improving accuracy. 2 Methods 2.1 Setting The Radiology department of the Hospital of the University of Pennsylvania has stored reports electronically in a Radiology Information System (GE Healthcare, Waukesha, WI) for about two decades, resulting in over two million digital radiological reports [6]. An automated speech recognition system with macro capabilities [7] (TalkStation, Agfa-Gevaert, Mortsel, Belgium), which incorporated an earlier version of the Dragon speech engine (Nuance, Burlington, MA), was implemented in late 1999. 2.2 Research database The data was loaded into an Oracle 10g Standard Edition database server (Oracle, Redwood Shores, CA), installed on a AMD Athlon desktop running Windows XP SP2. The data set for this study was the same as was used for the study conducted by Lakhani et al. [6]. The study sample consisted of 2,169,967 completed radiology reports from the Hospital of the University of Pennsylvania between January 1, 1998 and November 11, 2005. The authors removed patient identifiers from the database, including name, date of birth, and medical record number. Of the remaining reports, 29,736 contained only patient information with no report text. The authors deleted all 29,736 of these records. There remained 72 reports that contained the patient\u2019s name within the report text. The authors manually edited these to remove the patient information. 2.3 Comparing sets of words and trigrams We opted to develop our own simple tokenizer because to our knowledge no existing tokenizers could be executed directly by the database, which was necessary to reduce processing time. Thus, each report was parsed into a set of tokenized words. Our tokenizer split words based upon a defined list of text delimiters, such as spaces, periods, commas, colons, semicolons, and letter-number interfaces. An exception list was created to list common delimiter characters that do not act as a delimiters but rather add meaning to the word, such as numbers with decimal points, times with colons, and 359 predefined text strings such as \u201cH20\u201d, \u201c2ND\u201d, \u201cGM/CM\u201d, \u201cT9/10\u201d, and \u201cK-WIRE\u201d. We compared the effects of modality, body site, and subspecialty to the effects of radiologist. We conducted four experiments comparing word frequency and one experiment comparing trigram frequency. For each comparison, we randomly divided our database into two subsets of reports of equal number. This enabled comparison of word frequency for both concordant and discordant reports. For the first word comparison experiment, we further subdivided each report subset by modality. We then generated a modality comparison matrix between modality pairs. Each comparison pair had an equal number of reports from each of the two database subsets. For example, we compared 10 modalities, which generated a 100 cell comparison matrix, in which we compared word frequencies between the two halves of the database. The second experiment subdivided each half of the database of reports by both modality and subspecialty and compared the word frequencies in the subgroups. The third experiment subdivided each half of the dictionary by modality and body site and compared word frequency between the halves. The fourth experiment compared word frequencies in sets of reports by radiologist in similar fashion. In addition to the experiments comparing word frequency, we also conducted experiments in which reports and their corresponding trigrams were divided and compared by modality as above. To reduce the huge computational burden, we limited the analysis of trigrams to only those occurring more than once in the database. 2.4 Metrics for comparing word and trigram frequencies The metric used for comparison of word and trigram frequencies was based on the log-likelihood score (G 2). The log-likelihood score assists in finding words or trigrams that are particularly characteristic of a report. This statistic gives an accurate measure of the \u201csurprising\u201d nature of an event and gives a sense of the \u201cdistinctive\u201d nature of a corpus [8]. Kilgarriff [9] defined a framework for using the log-likelihood test to obtain the G 2 statistic for a given word, w, given two texts, X and Y. In our setting, X and Y were the two halves of our dataset. We tabulated a (the number of occurrences of w in X), c (the number of words in X that were not w), b (the number of occurrences of w in Y), and d (the number of words in Y that were not w). Table 1 lays out these calculations in a table. To then find G2 , Eq. (1) is used [9]. This calculation was performed only for words that existed in both halves of the data set. Computation of the G 2 statistic, which is based on the log-likelihood score. (1) G 2 = 2 a log ( a ) + b log ( b ) + c log ( c ) + d log ( d ) - ( a + b ) log ( a + b ) - ( a + c ) log ( a + c ) - ( b + d ) log ( b + d ) - ( c + d ) log ( c + d ) + ( a + b + c + d ) log ( a + b + c + d ) From the G 2 values, the significant log-likelihood (SLL), Eq. (2), expresses the percent of distinct words or trigrams that had significant G 2 values (p <0.05). P-values were calculated from G2 using a reference standard [10]. The significant log-likelihood (SSL) metric measures the percent of significant (p >0.05) n-grams. (2) SLL = n grams G 2 > 3.84 n grams mod el \u222a n grams test For each comparison of corpora, we used the G 2 statistic to compare frequencies of a word or trigram between subsets of reports then used the SSL log-likelihood statistic to determine significance of difference in word frequencies between corpora. 3 Results 3.1 Univariate analysis After de-identifying the data and tokenizing the reports, there were 2,169,967 reports, consisting of 338,435,512 words (tokens). On average, there were 155.9 words per report with a standard deviation of 119.5. The distribution had a positive skew, with a mode of 61 (Fig. 1 ). The longest report contained 2620 words. Table 2 shows the distribution of reports among the 12-modality types defined in this report database. Table 3 shows the distribution of reports across body site. Because we randomly split the data, an equivalent number of reports reside in each subgroup. An analysis of the properties of report length distribution and distributions for modality, body site, and subspecialty for the model set and test set and found no significant differences, indicating that the two sets were properly randomized. 3.2 Comparison of word frequencies by modality To test for distinctive words in each corpus, the log-likelihood test was run for each modality. Table 4 , shows an example of the most significant word frequency differences between corpora. The list on the left shows word frequency between CR corpora, and the list on the right compares word frequency between CR and MR reports. The intra-modality comparison has significantly lower frequency differences than the inter-modality comparison. Table 5 shows the ratio of distinctive words (i.e., words with significant G 2 values) in discordant report sets (different modality) and concordant report sets (same modality). Every concordant comparison (that holds the modality constant), highlight in darker gray, has the smallest ratio of distinct words. The concordant entries (in darker gray) have an average ratio of 0.508% with a standard deviation of 0.156%. The other entries have an average ratio of 39.2% with a standard deviation of 5.82%. Therefore, words contained in a report from a different modality were much more likely to be distinctive than when comparing two words from reports of the same modality. We also examined the differences between the frequency of words that appear in one half of reports but do not appear in the other half. As expected, differences in word frequency in a concordant comparison were much less prevalent, and yielded words that were likely to be typographical or parsing errors. Differences in word frequency between modality in a discordant comparison were frequently used terms that were unique to the modalities in question. 3.3 Subgroup analysis To determine whether partitioning the data into smaller subsets based on body site or subspecialty also showed significant differences based on these variables, we further divided the MR subsets according to body site. The same statistical tests were used. Table 6 displays the results. When the subspecialty was the same, the average ratio of distinctive words (i.e., words with significant G 2 values) was 0.647% with a standard deviation of 0.278%. When the subspecialties were not the same, the ratio was 38.8% (standard deviation=7.26%). The same body site subanalysis was performed on the MR reports. Only the body sites with the 10 highest numbers of reports are shown. As seen in Table 7 , the average SLL for sets with the same body site was 0.805% (std 0.215%), while for sets with different body sites the average SLL was 36.0% (std 6.91%) (Table 5). 3.4 Comparison of word frequency by radiologist The same analysis was conducted by using the dictating radiologist. For this comparison, only reports from the 10 radiologists with the highest number of reports were used. Table 8 shows the percentage of distinctive words (i.e., words with significant G 2 values). When comparing dictionaries from the same radiologist, on average, 0.515% (std 0.147%) of the words are significant (SLL metric), whereas 32.5% (std 8.57%) of the words are significant when comparing dictionaries by different radiologists. 3.5 Trigram frequency analysis We extended our word frequency analysis to examine the frequency of three-word phrases (trigrams) by using the same statistical methods. Table 9 shows the 25 most common trigrams in our database. As shown in Table 10 , the frequency differences for trigrams were more striking than the differences for words alone. When the modality was the same for both sets of trigrams there was an average ratio of 0.251% (std 0.0538%), while when the modality was different there was an average of 36.5% (std 5.60%). Table 11 summarizes the results of the four frequency comparisons. In each case, the word and trigram frequencies were much greater for discordant reports (having different values of the parameter in question) than for concordant reports. 4 Discussion Our analysis of words and trigrams (three-word phrases) in a large corpus of radiology reports shows that modality, body site, and radiologist, can be used to further refine language models. All of these factors are known at the time of dictation, although only the identity of the dictating radiologist is currently used to tailor language models for speech recognition systems. Our data from Table 4 show that words are used at dramatically different frequencies depending on imaging modality. These results, together with those shown in Table 5, show that when using a dictionary on the modality for which it was designed, the word frequencies are relatively constant, while trying to use a dictionary for a different modality results in a markedly different word frequency. Tables 6 and 7 show that differences in word choice and frequency exist even when the data is stratified into smaller subsets. The results show that significant differences between subgroups do exist that could be useful to language model designers. From Table 8, it is evident (as expected) that each radiologist has a unique word choice and unique word frequencies. However, our comparison metrics show that this effect is similar to the effect of modality and body site. Therefore, the use of modality and body site to tailor language models for speech recognition systems may be much more effective than training or tailoring based on the individual radiologist alone. We found that the results obtained for word frequency also applied to the frequency of three-word phrases. When looking at these phrases, there were significant differences between the phrase choice and frequency per modality. While the log-likelihood test typically is used in the case of words not phrases, we believe the test still is applicable for quantifying the distinctness of phrases between two sets of reports. Current speech recognition engines load a language model that is tailored only to the speech pattern of the dictating radiologist. To our knowledge, no available speech recognition engine provides the capability to train or tailor the behavior of the system based on the modality and body site of the imaging exam being dictated. Our results indicate that it might be useful to study the effects of dynamically modifying language models of existing speech recognition software. It is possible that additional gains in accuracy could be obtained by employing models that are specific not only to the reporting radiologist, but also to the modality and body site of the imaging study being reported. 4.1 Limitations The primary limitation of the study is that we could not validate our conclusions by comparing different language models in an actual speech recognition engine. Such language models do not yet exist. We believe that such a study might show that incorporating specialized language models based on modality and body site improves the accuracy of dictation. However, no easy solution is currently available for dynamically changing models in a speech recognition engine. The text of an unknown number of reports in the database was generated in part using macros. Unfortunately, our radiology information system does not record which reports used macros, so we could not study their effects directly. While the use of macros skews the results of the word and phrase frequencies, the effect of this bias likely was similar across the database. Because radiologists have control over their own set of macros, these macros are more likely to reduce variability of word frequency within one radiologists corpus of reports, thereby magnifying the effect of tailoring to the radiologist. However, we found nevertheless that other factors had a similar effect on variability. We believe that macros could improve the accuracy of a speech recognition engine, since the speech engine will have the first two words of a trigram spelled out and thus the engine can refer to the dictionary to fill in the third word. The log-likelihood measure we used had an important limitation. If a word was used frequently in one set of reports, but was never used in the comparison set, that word would not appear in the results of the log-likelihood test. Nevertheless, the measure gave a good sense of frequency with which common words are used in the two corpora. A comparison of word and trigram frequencies that were not in one subset but appeared in another yielded results similar to the log-likelihood comparisons (unpublished data). We limited the analysis to trigrams that occurred more than once. From manual review of the omitted trigrams, we determined that almost all such unique trigrams were phrases with misspellings or numbers. Thus, adding these phrases would provide little benefit to a speech engine. We believe that any bias that may have been introduced by omitting unique trigrams would apply equally to all comparisons, and therefore would not affect our conclusions. Table 11 shows that there are significant word and phrase differences between different types of radiology reports, and that those differences are at least as pronounced between modalities and body sites as they are between speakers. Therefore, custom language models based upon the specific modality, body site, and radiologist could be used by the speech recognition software to improve recognition accuracy. For example, a speech recognition engine could view the exam being dictated (e.g., abdominal CT, knee MR, chest X-ray) and load a language model tailored to the modality and body site for that exam. Most likely, the language models would be cached on a server that periodically would update each model, possibly using the method detailed by Siivola [5]. For the database analyzed in this study, 82 distinct language models would be needed to handle all combinations of modality and body site. However, we were unable to prove definitively that these additional predictors would increase the performance of a speech recognition engine, or to assess how these additional parameters should be weighted. This study focused on radiological exams due to the availability of a large database of reports. A similar approach might be useful in other medical fields that use dictation. For example, word and trigram frequency in operative reports may be strongly affected by the type of surgery. And progress notes from ambulatory clinics might be highly dependent on the chief complaint. 5 Conclusion Our results indicate that the word and phrase frequency during dictation of radiology reports is influenced by the modality and body site of the radiology study. When comparing subsets of reports, there were significantly lower levels of distinctiveness for concordant reports than for discordant reports. While the statistical significance of the differences could not be measured, the magnitudes of the differences were similar to those found between radiologists, indicating they likely have practical significance. This finding held true not only for the frequency of single words, but also for the frequency of three-word phrases. These results suggest that the accuracy of speech recognition products could be improved by tailoring the underlying speech model based on the modality, body site, and other parameters of the radiological study. References [1] M.M. Al-Aynati K.A. Chorneyko Comparison of voice-automated transcription and human transcription in generating pathology reports Arch Pathol Lab Med 127 6 2003 721 725 [2] D. Liu M. Zuckerman W.B. Tulloss Jr. Six characteristics of effective structured reporting and the inevitable integration with speech recognition J Digit Imaging 19 1 2006 98 104 [3] Nuance Dragon NaturallySpeaking 9 Product Page. Available from: <http://www.nuance.com/naturallyspeaking/medical/>. [4] S. Langer Radiology speech recognition: workflow, integration, and productivity issues Curr Probl Diagn Radiol 31 3 2002 95 104 [5] Siivola V, Pellom B. Growing an n-gram language model. Proceedings of 9th European conference on speech communication and technology, 2005. [6] P. Lakhani E.D. Menschik A.F. Goldszal J.P. Murray M.G. Weiner C.P. Langlotz Development and validation of queries using structured query language (SQL) to determine the utilization of comparison imaging in radiology reports stored on PACS J Digit Imaging 19 1 2006 52 68 [7] Agfa TalkStation TeleDictation Product Page. Available from: <http://www.agfa.com/en/he/products_services/all_products/talkstation_teledictation.jsp>; 2007 [accessed 19.08.07]. [8] Adam Kilgarriff Comparing corpora Int J Corpus Linguist 6 2001 97 133 [9] Kilgarriff Adam. Which words are particularly characteristic of a text? a survey of statistical approaches. In: Proceedings of AISB workshop on language engineering for document analysis and recognition; 1996. p. 33\u201340. [10] Rayson P, Berridge D, Francis B. Extending the Cochran rule for the comparison of word frequencies between corpora. In: Proceedings of the seventh international conference on statistical analysis of textual data (JADT 2004). Presses universitaires de Louvain; 2004. p. 926\u201336.", "scopus-id": "60049096136", "pubmed-id": "18761109", "coredata": {"eid": "1-s2.0-S1532046408001019", "dc:description": "Abstract Speech recognition systems have become increasingly popular as a means to produce radiology reports, for reasons both of efficiency and of cost. However, the suboptimal recognition accuracy of these systems can affect the productivity of the radiologists creating the text reports. We analyzed a database of over two million de-identified radiology reports to determine the strongest determinants of word frequency. Our results showed that body site and imaging modality had a similar influence on the frequency of words and of three-word phrases as did the identity of the speaker. These findings suggest that the accuracy of speech recognition systems could be significantly enhanced by further tailoring their language models to body site and imaging modality, which are readily available at the time of report creation.", "openArchiveArticle": "true", "prism:coverDate": "2009-02-28", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046408001019", "dc:creator": [{"@_fa": "true", "$": "Paulett, John M."}, {"@_fa": "true", "$": "Langlotz, Curtis P."}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046408001019"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046408001019"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(08)00101-9", "prism:volume": "42", "prism:publisher": "Elsevier Inc.", "dc:title": "Improving language models for radiology speech recognition", "prism:copyright": "Copyright \u00a9 2008 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "1", "dcterms:subject": [{"@_fa": "true", "$": "Radiology"}, {"@_fa": "true", "$": "Speech recognition"}, {"@_fa": "true", "$": "n-Gram"}, {"@_fa": "true", "$": "Trigram model"}, {"@_fa": "true", "$": "Word frequency"}, {"@_fa": "true", "$": "Radiology reports"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "1", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "53-58", "prism:endingPage": "58", "prism:coverDisplayDate": "February 2009", "prism:doi": "10.1016/j.jbi.2008.08.001", "prism:startingPage": "53", "dc:identifier": "doi:10.1016/j.jbi.2008.08.001", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "38", "@width": "240", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1533", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "72", "@width": "482", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3992", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "189", "@width": "819", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "40837", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "29", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "1803", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "122", "@width": "816", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "19175", "@ref": "fx2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "19", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "1378", "@ref": "fx2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "189", "@width": "818", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "39126", "@ref": "fx4", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "29", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "1746", "@ref": "fx4", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "189", "@width": "816", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "40431", "@ref": "fx5", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "29", "@width": "125", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "1775", "@ref": "fx5", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "354", "@width": "378", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "23793", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "94", "@width": "100", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2173", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "189", "@width": "816", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "42013", "@ref": "fx3", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "51", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408001019-fx3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3320", "@ref": "fx3", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/60049096136"}}
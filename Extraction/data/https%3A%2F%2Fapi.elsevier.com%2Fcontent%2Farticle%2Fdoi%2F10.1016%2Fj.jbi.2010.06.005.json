{"scopus-eid": "2-s2.0-77956263125", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2010-06-23 2010-06-23 2010-10-31T09:02:21 1-s2.0-S1532046410000900 S1532-0464(10)00090-0 S1532046410000900 10.1016/j.jbi.2010.06.005 S300 S300.1 FULL-TEXT 1-s2.0-S1532046410X00065 2020-03-12T21:01:37.430397Z 0 0 20101001 20101031 2010 2010-06-23T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content oa subj ssids 1532-0464 15320464 43 43 5 5 Volume 43, Issue 5 10 725 735 725 735 201010 October 2010 2010-10-01 2010-10-31 2010 article fla Copyright \u00a9 2010 Elsevier Inc. All rights reserved. SEMANTICSPACEMODELSFORCLASSIFICATIONCONSUMERWEBPAGESMETADATAATTRIBUTES CHEN G 1 Introduction 2 Methods 2.1 Data sources 2.2 Hyperspace analogue to language 2.2.1 Semantic Space models 2.2.2 Data pre-processing 2.3 Machine learning algorithms 2.3.1 Decision tree 2.3.2 Round-robin decision forest (RRDF) 2.3.3 Summed similarity measure on HAL (SSMoHal) 2.3.4 Support vector machine (SVM) 2.4 Protocols 2.4.1 Resampling 2.4.2 Natural order 2.4.3 Computational complexity analysis 3 Results 3.1 Accuracy 3.2 Computational complexity analysis of SVM and SSM 4 Discussion Acknowledgments References KIM 2007 12 14 K EYSENBACH 2002 2691 2700 G HAYNES 2006 1801 1808 R MADDEN 2006 A PORTALSPEOPLEPROCESSESTECHNOLOGY PORTALSFILTERSIDENTIFYINGQUALITYINTERNET BURGESS 1998 211 247 C COHEN 2009 390 405 T JOACHIMS 1999 169 184 T ADVANCESINKERNELMETHODSSUPPORTVECTORLEARNING MAKINGLARGESCALESVMLEARNINGPRACTICAL CHEN 2009 e5 G OSUNA 1999 E REDUCINGRUNTIMECOMPLEXITYSUPPORTVECTORMACHINESADVANCESINKERNELMETHODSSUPPORTVECTORLEARNING CHAPMAN 2009 757 759 W CHEN 2005 517 529 J CHENX2010X725 CHENX2010X725X735 CHENX2010X725XG CHENX2010X725X735XG 2013-07-17T11:42:39Z OA-Window Full ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ 2020-03-07T21:01:33.082Z http://vtw.elsevier.com/data/voc/AddOnTypes/50.7/nlp S1532046410000900 University of Auckland University of Auckland http://data.elsevier.com/vocabulary/SciValFunders/501100001537 http://sws.geonames.org/2186224/ Australian Research Council DP0665353 ARC Australian Research Council http://data.elsevier.com/vocabulary/SciValFunders/501100000923 http://sws.geonames.org/2077456/ The authors thank Peter Bruza and Robert McArthur for their advice on use of Semantic Space models; Joanne Evans, Frada Burstein and the other staff of the Smart Information Portals team at Monash University, Australia, for their advice and support with consumer health metadata; and Vojo Kecman for his advice on machine learning methods. This work was supported in part by Australian Research Council Discovery Project DP0665353 and a University of Auckland postgraduate scholarship. item S1532-0464(10)00090-0 S1532046410000900 1-s2.0-S1532046410000900 10.1016/j.jbi.2010.06.005 272371 2010-12-11T03:04:59.015859-05:00 2010-10-01 2010-10-31 1-s2.0-S1532046410000900-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/MAIN/application/pdf/c85c7b1cebf3c1fe4f413a160fdb08bd/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/MAIN/application/pdf/c85c7b1cebf3c1fe4f413a160fdb08bd/main.pdf main.pdf pdf true 2113895 MAIN 11 1-s2.0-S1532046410000900-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/PREVIEW/image/png/d79b4b28333f69b9da53981e32337a3c/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/PREVIEW/image/png/d79b4b28333f69b9da53981e32337a3c/main_1.png main_1.png png 84721 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046410000900-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/58c43b505af9169826e689d81a840cfe/si16.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/58c43b505af9169826e689d81a840cfe/si16.gif si16 si16.gif gif 3860 88 414 ALTIMG 1-s2.0-S1532046410000900-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/fff436195f633c984c7337f2d71836c5/si15.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/fff436195f633c984c7337f2d71836c5/si15.gif si15 si15.gif gif 2331 44 340 ALTIMG 1-s2.0-S1532046410000900-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/18a2398be684aea0b682ea78869c98ea/si11.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/18a2398be684aea0b682ea78869c98ea/si11.gif si11 si11.gif gif 1215 39 196 ALTIMG 1-s2.0-S1532046410000900-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/13981bef80f4c7a01a25569ec276a0a9/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/13981bef80f4c7a01a25569ec276a0a9/si8.gif si8 si8.gif gif 1254 38 196 ALTIMG 1-s2.0-S1532046410000900-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/333e1038896df761684a24220a605c08/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/333e1038896df761684a24220a605c08/si5.gif si5 si5.gif gif 2826 78 314 ALTIMG 1-s2.0-S1532046410000900-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/6cfcfb93eeb339b90ded0d3864196aad/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/6cfcfb93eeb339b90ded0d3864196aad/si3.gif si3 si3.gif gif 742 22 145 ALTIMG 1-s2.0-S1532046410000900-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/b0ffb0d7ac8435517ff690e3c434c976/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/b0ffb0d7ac8435517ff690e3c434c976/si9.gif si9 si9.gif gif 319 21 30 ALTIMG 1-s2.0-S1532046410000900-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/e2bc346cfce9bb2f52581e639e3df363/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/e2bc346cfce9bb2f52581e639e3df363/si4.gif si7 si7.gif gif 262 19 20 ALTIMG 1-s2.0-S1532046410000900-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/4896aab543400d8aca3d2f8944f664fc/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/4896aab543400d8aca3d2f8944f664fc/si6.gif si6 si6.gif gif 373 21 40 ALTIMG 1-s2.0-S1532046410000900-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/e2bc346cfce9bb2f52581e639e3df363/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/e2bc346cfce9bb2f52581e639e3df363/si4.gif si4 si4.gif gif 262 19 20 ALTIMG 1-s2.0-S1532046410000900-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/4896aab543400d8aca3d2f8944f664fc/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/4896aab543400d8aca3d2f8944f664fc/si6.gif si2 si2.gif gif 373 21 40 ALTIMG 1-s2.0-S1532046410000900-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/9aeb9bb8d5adf859eac2b4315e276c1f/si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/9aeb9bb8d5adf859eac2b4315e276c1f/si17.gif si18 si18.gif gif 189 11 10 ALTIMG 1-s2.0-S1532046410000900-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/9aeb9bb8d5adf859eac2b4315e276c1f/si17.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/9aeb9bb8d5adf859eac2b4315e276c1f/si17.gif si17 si17.gif gif 189 11 10 ALTIMG 1-s2.0-S1532046410000900-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/e2bc346cfce9bb2f52581e639e3df363/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/e2bc346cfce9bb2f52581e639e3df363/si4.gif si14 si14.gif gif 262 19 20 ALTIMG 1-s2.0-S1532046410000900-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/74783407360fdd21bad5127924e7306c/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/74783407360fdd21bad5127924e7306c/si13.gif si13 si13.gif gif 298 18 30 ALTIMG 1-s2.0-S1532046410000900-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/26150cb555c2011ff86bb3acccb07517/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/26150cb555c2011ff86bb3acccb07517/si12.gif si12 si12.gif gif 241 15 19 ALTIMG 1-s2.0-S1532046410000900-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/a86801529641dd9818d00504788476c4/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/a86801529641dd9818d00504788476c4/si10.gif si10 si10.gif gif 260 19 19 ALTIMG 1-s2.0-S1532046410000900-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/STRIPIN/image/gif/19380e634cf51eac4f54bcdc8b337862/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/STRIPIN/image/gif/19380e634cf51eac4f54bcdc8b337862/si1.gif si1 si1.gif gif 378 21 44 ALTIMG 1-s2.0-S1532046410000900-gr10.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr10/DOWNSAMPLED/image/jpeg/a84aab6077ade59fb12501abab2327fb/gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr10/DOWNSAMPLED/image/jpeg/a84aab6077ade59fb12501abab2327fb/gr10.jpg gr10 gr10.jpg jpg 61307 568 512 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr10.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr10/THUMBNAIL/image/gif/d82181c045c5bf9fa14b9c15a1400b14/gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr10/THUMBNAIL/image/gif/d82181c045c5bf9fa14b9c15a1400b14/gr10.sml gr10 gr10.sml sml 4702 164 148 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr2/DOWNSAMPLED/image/jpeg/3b56fdb3c58a282d1ee3b1e802a33e85/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr2/DOWNSAMPLED/image/jpeg/3b56fdb3c58a282d1ee3b1e802a33e85/gr2.jpg gr2 gr2.jpg jpg 35149 257 378 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr2/THUMBNAIL/image/gif/aa6aa60dd09449553cc1b6e07511adfc/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr2/THUMBNAIL/image/gif/aa6aa60dd09449553cc1b6e07511adfc/gr2.sml gr2 gr2.sml sml 6816 149 219 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr3/DOWNSAMPLED/image/jpeg/2cd471dcf7d2f796cdbf46dcf370bade/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr3/DOWNSAMPLED/image/jpeg/2cd471dcf7d2f796cdbf46dcf370bade/gr3.jpg gr3 gr3.jpg jpg 57028 393 489 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr3/THUMBNAIL/image/gif/e0f1b10858da0782b770c8b26e29f3ed/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr3/THUMBNAIL/image/gif/e0f1b10858da0782b770c8b26e29f3ed/gr3.sml gr3 gr3.sml sml 8519 164 204 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr4/DOWNSAMPLED/image/jpeg/7b9a34d24a48db0c951bd4530bc63436/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr4/DOWNSAMPLED/image/jpeg/7b9a34d24a48db0c951bd4530bc63436/gr4.jpg gr4 gr4.jpg jpg 44775 357 498 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr4/THUMBNAIL/image/gif/b8ccb9e38b872e529bd54baa5bdc2e30/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr4/THUMBNAIL/image/gif/b8ccb9e38b872e529bd54baa5bdc2e30/gr4.sml gr4 gr4.sml sml 6928 157 219 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr5/DOWNSAMPLED/image/jpeg/4b5ed20c41859c2e2ba24c429c23440f/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr5/DOWNSAMPLED/image/jpeg/4b5ed20c41859c2e2ba24c429c23440f/gr5.jpg gr5 gr5.jpg jpg 50893 289 535 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr5/THUMBNAIL/image/gif/8fdf692dadcb6fe773d570716304d37b/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr5/THUMBNAIL/image/gif/8fdf692dadcb6fe773d570716304d37b/gr5.sml gr5 gr5.sml sml 6871 118 219 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr6/DOWNSAMPLED/image/jpeg/75beb8010b6ef4efade3686ce6d79cb3/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr6/DOWNSAMPLED/image/jpeg/75beb8010b6ef4efade3686ce6d79cb3/gr6.jpg gr6 gr6.jpg jpg 32811 256 489 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr6/THUMBNAIL/image/gif/ef615285660387f07c6096dc40476246/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr6/THUMBNAIL/image/gif/ef615285660387f07c6096dc40476246/gr6.sml gr6 gr6.sml sml 5317 115 219 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr7/DOWNSAMPLED/image/jpeg/5118bcc4472be492a82018d1b4b208f0/gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr7/DOWNSAMPLED/image/jpeg/5118bcc4472be492a82018d1b4b208f0/gr7.jpg gr7 gr7.jpg jpg 62780 552 512 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr7/THUMBNAIL/image/gif/8a1b376d3958418242da31c835f84121/gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr7/THUMBNAIL/image/gif/8a1b376d3958418242da31c835f84121/gr7.sml gr7 gr7.sml sml 4838 164 152 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr8/DOWNSAMPLED/image/jpeg/96bb41cd6292b7ff30485222b2b633cf/gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr8/DOWNSAMPLED/image/jpeg/96bb41cd6292b7ff30485222b2b633cf/gr8.jpg gr8 gr8.jpg jpg 63595 624 510 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr8/THUMBNAIL/image/gif/5e5003459a0628729fc10249bdc1b4e3/gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr8/THUMBNAIL/image/gif/5e5003459a0628729fc10249bdc1b4e3/gr8.sml gr8 gr8.sml sml 4269 164 134 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr9/DOWNSAMPLED/image/jpeg/ffb1c695e16c2ea3a840f080b9c3d2b6/gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr9/DOWNSAMPLED/image/jpeg/ffb1c695e16c2ea3a840f080b9c3d2b6/gr9.jpg gr9 gr9.jpg jpg 62725 528 511 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr9/THUMBNAIL/image/gif/018d286767b0d5b54ba41719d4c5cc53/gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr9/THUMBNAIL/image/gif/018d286767b0d5b54ba41719d4c5cc53/gr9.sml gr9 gr9.sml sml 5299 164 159 IMAGE-THUMBNAIL 1-s2.0-S1532046410000900-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr1/DOWNSAMPLED/image/jpeg/31c31097b2dda52a9aba93dce0452ff7/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr1/DOWNSAMPLED/image/jpeg/31c31097b2dda52a9aba93dce0452ff7/gr1.jpg gr1 gr1.jpg jpg 62674 323 487 IMAGE-DOWNSAMPLED 1-s2.0-S1532046410000900-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046410000900/gr1/THUMBNAIL/image/gif/26c93d10e929149a08affead0cdf5205/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046410000900/gr1/THUMBNAIL/image/gif/26c93d10e929149a08affead0cdf5205/gr1.sml gr1 gr1.sml sml 9091 145 219 IMAGE-THUMBNAIL YJBIN 1675 S1532-0464(10)00090-0 10.1016/j.jbi.2010.06.005 Elsevier Inc. Fig. 1 HAL matrix for window size of 3. Fig. 2 Decision tree showing number of \u2018medical\u2019 and \u2018supportive\u2019 cases, decision word (and its entropy gain in parentheses) annotated with validation path arrows and similarity measures (underlined) for a \u2018medical\u2019 test case. Fig. 3 Classification of the two most popular article categories (\u2018earn\u2019 and \u2018acq\u2019) in Reuters21578. Fig. 4 Classification of \u2018medical\u2019 vs \u2018supportive\u2019 BCKO articles. Fig. 5 Classification of BCKO articles by disease stage (\u2018early\u2019 vs \u2018advanced\u2019). Fig. 6 Classification of BCKO articles by author qualification (\u2018clinician\u2019 vs \u2018lay\u2019). Fig. 7 (a) Accumulated accuracy of \u2018earn\u2019 vs \u2018acq\u2019 in Reuters21578 in Natural Order. (b\u2013d) Each test case is classified using SSM, RRDF and SVM: 1 is correct, 0 is incorrect. Fig. 8 (a) Accumulated accuracy of \u2018medical\u2019 vs \u2018supportive\u2019 in BCKO in Natural Order. (b\u2013d) Each test case is classified using SSM, RRDF and SVM: 1 is correct, 0 is incorrect. Fig. 9 (a) Accumulated accuracy of \u2018early\u2019 vs \u2018advanced\u2019 breast cancer in BCKO in Natural Order. (b\u2013d) Each test case is classified using SSM, RRDF and SVM: 1 is correct, 0 is incorrect. Fig. 10 (a) Accumulated accuracy of \u2018lay author\u2019 vs \u2018clinician\u2019 in BCKO in Natural Order.(b\u2013d) Each test case is classified using SSM, RRDF and SVM: 1 is correct, 0 is incorrect. Table 1 BCKO and Reuters21578 classification accuracy (based on 100 resamples). Data set Reuters21578 Medical vs Supportive Early vs Advanced Lay vs Clinical Training set size 390/class 40/class 70/class 40/class Mean 95% CI Mean 95% CI Mean 95% CI Mean 95% CI SSMoHal 98.00 97.34\u201398.66 92.80 91.94\u201393.66 91.70 91.04\u201392.35 90.75 90.00\u201391.49 RRDFoHal 97.75 97.12\u201398.38 92.40 91.45\u201393.35 90.10 89.27\u201390.93 88.65 87.79\u201389.51 SVMoWfreq 98.25 97.44\u201399.06 92.30 91.53\u201393.07 86.00 85.00\u201387.00 89.45 88.09\u201390.81 rrSVMoWfreq 84.55 83.53\u201385.57 91.35 90.39\u201392.31 80.95 80.08\u201381.82 84.65 83.72\u201385.58 RRDFoWfreq 92.85 92.15\u201393.55 85.45 84.80\u201386.10 79.80 78.97\u201380.64 87.30 85.84\u201388.76 SVMoHal 97.55 96.6\u201398.5 90.20 88.74\u201391.66 89.50 87.46\u201391.54 85.75 84.12\u201387.38 Semantic Space models for classification of consumer webpages on metadata attributes Guocai Chen a \u204e joe.g.chen@hotmail.com Jim Warren a b Patricia Riddle a a Department of Computer Science, The University of Auckland, New Zealand b School of Population Health, The University of Auckland, New Zealand \u204e Corresponding author. Abstract To deal with the quantity and quality issues with online healthcare resources, creating web portals centred on particular health topics and/or communities of users is a strategy to provide access to a reduced corpus of information resources that meet quality and relevance criteria. In this paper we use hyperspace analogue to language (HAL) to model the language use patterns of webpages as Semantic Spaces. We have applied machine learning methods, including support vector machine (SVM), decision forest, and a novel summed similarity measure (SSM) to automatically classify online webpages on their Semantic Space models. We find classification accuracy on metadata attributes to be over 93% for \u2018medical\u2019 versus \u2018supportive\u2019 perspective, over 92% for disease stage of \u2018early\u2019 versus \u2018advanced\u2019, and over 90% for author credentials of \u2018lay\u2019 versus \u2018clinician\u2019 based on webpages of the Breast Cancer Knowledge Online portal. These results indicate that language use patterns can be used to automate such classification with useful levels of accuracy. Keywords Consumer health information Internet Metadata Natural language processing Breast cancer 1 Introduction When confronted with a healthcare situation, people are increasingly turning to the Internet for information to aid in understanding diagnoses, deciding on treatment options and seeking psychosocial support for themselves, their family and their friends [1]. Escalating healthcare costs are one of the key drivers of increasing interest in the provision of health information on the web from a health consumer perspective [2]. Expectations are that informed patients can more actively participate in decisions surrounding treatment choices, better monitor their condition, and have more efficient and effective interactions with medical professionals [3]. The wealth of information on the Internet not only provides abundant choices to users, it also engenders a problem: which source of information is the most appropriate? Vast quantities of health information are being made available online by a number of providers including government agencies, pharmaceutical companies and other commercial enterprises, charity organisations, community groups and individuals to service the information needs of medical professionals and healthcare consumers. As a result, a keyword search using any of the major search engines on most healthcare topics will bring up thousands, hundreds of thousands, and even millions of hits of varying quality and relevance to a person\u2019s particular health and life situation. The resulting \u2018information overload\u2019, where the amount of information exceeds a person\u2019s ability to process it [4], can often add stress to an already stressful situation. Consequently, there is much interest in how the quality, relevance, authority and accuracy of online information can be assessed in a timely manner by both healthcare consumers and medical professionals alike [5,6]. Many projects have been devised to address information overload and investigate ways in which timely, differentiated access to quality online healthcare resources can be provided. One strategy is to create comprehensive repositories of high-quality health information (or links to such information). The US National Library of Medicine\u2019s MedlinePlus (http://medlineplus.gov), Australian HealthInsite (http://www.healthinsite.gov.au) and the Geneva-based Health on the Net (http://www.hon.ch) are examples of such portals. The provision of web portals centred on particular health topics and/or communities of users is another strategy [7,8] which aims to provide access to a reduced corpus of information resources that meet quality and relevance criteria. Portals can be further augmented by capturing and creating descriptive metadata about resources selected for inclusion. This structured, value-added information can then be used by portal users in searching, filtering, ranking, and in making judgements about what information is relevant to their needs and in which they wish to place their trust. Breast cancer knowledge online (BCKO) \u2013 developed through collaboration between Monash University, BreastCare Victoria and the Breast Cancer Action Group \u2013 is an example of a topic-centred portal. The portal provides a gateway to online information about breast cancer of relevance to breast cancer patients, their families, friends and carers. In response to the user studies and needs analysis undertaken in the initial stages of the BCKO project, the portal incorporates metadata that describes relevant resources from a user-centred perspective [9]. Included in the description of resources is metadata about the type and style of information, the stage of breast cancer to which it relates, and the nature of the author. The search interface allows portal users to indicate their information preferences along these lines. While usability studies have shown a high degree of satisfaction with the resultant portal, questions as to its scalability have been raised. Reliance on manual methods of metadata creation are problematic given the volume of information available online and its volatile, dynamic and complex nature [10]. In the case of BCKO, user information needs analysis identified the desire for more access to personal stories of breast cancer experiences, which are often buried deep in the result sets of the major search engines. Better tools to support metadata coders are needed. Thus, the desire to increase the sustainability and quality of such portals motivates investigation into automated support for the generation of metadata describing relevant resources from a user-centred perspective. A high-dimensional Semantic Space model is a method for numerically representing the meanings of words; it is derived from the frequency distributions of the words occurring in the immediate context of a target word, computed over a large language corpus (possibly containing millions of words). Words that occur in the same sorts of contexts are thus contextually similar, and tend to be similar in meaning. Hyperspace analogue to language (HAL) is one specific model/approach for automatic construction of a Semantic Space model from a corpus of text [11]. HAL is just one in a large family of \u2018distributional semantics\u2019 [12], \u2018semantic vector\u2019 [13] or \u2018semantic space\u2019 [14] representations that quantify similarity of meaning of terms or of whole documents. In previous research, Burgess and Lund [15] demonstrated that abstract word categories (e.g., their part of speech \u2013 noun, verb, etc.) and emotional connotation of words could be represented with HAL matrices. By using multi-dimensional scaling (MDS), the distance between two HAL vectors representing two words could be simulated by two lower dimensional points (notably, in 2D). In simulations plotting the clustering of words, they found words were compellingly categorised: nouns close to other nouns, emotionally positive words close to other positive words, negative words close to negative. Given these properties of HAL, we sought to apply HAL as a source of classification features for the problem of identifying metadata values for topic-centred consumer portals such as BCKO. In this paper we describe novel document classifiers tailored to exploitation of HAL\u2019s Semantic Space model, particularly a round-robin decision forest (RRDF) classifier and what we call a summed similarity measurement (SSM) classifier. The chief novelty of our approach is in finding methods to work with the HAL matrix relatively directly, without using computationally expensive dimensional reduction techniques such as singular value decomposition (SVD) and exploiting the HAL matrix structure, as well as simply in our choice of application of Semantic Spaces to requirements derived from experience with consumer health portals. We assess these algorithms based on BCKO\u2019s metadata attributes and, to provide a well-known basis of comparison, the widely-used Reuters21578 data set. In view of its known good performance, widespread application and openly available implementation, we compare our algorithms to a support vector machine (SVM) [16] utilising both HAL attributes and the more traditional word frequencies. Our objective in this research is to determine the feasibility of making such automated classifications, including the relationship of accuracy to amount of training data provided for the various classes of algorithms we consider, with an eye to utilisation of such methods to support consumer health informatics. 2 Methods Since Burgess and Lund [15] had been more interested in linguistics than classification per se, we found that we had a wide space of parameters and methods to consider in adapting HAL as a practical classifier for our problem. Herein we present what we believe are some of the more fruitful and illustrative approaches. In this section we describe our data sources, the specific issues of deriving and managing the data as a HAL model, each of the classification algorithms we apply, and finally the protocol by which we assess their performance as reported in Section 3. In each case, but particularly with respect to the classification algorithms, we provide an overview of the pathway and rationale by which the specific methods reported herein were chosen. 2.1 Data sources A key finding of the initial BCKO user needs analysis was the need to identify quality resources that dealt not only with medical and scientific issues relating to breast cancer, but also with its psychosocial impacts. The metadata schema developed to describe the resources, therefore, incorporates an encoding scheme for categorising the type of resource as medical, supportive and/or personal perspective (an indication of the tone of the article). The BCKO portal database provides metadata to support personalised search for approximately 1000 consumer health websites. To provide an initial test for HAL-based prediction of the BCKO type, we examined the problem of matching the classification of types \u2018medical\u2019 or \u2018supportive\u2019 to that given in the portal\u2019s database (discarding the \u2018personal\u2019 type for the present study because that particular type code was utilised infrequently). To train the classifier, a corpus was extracted from the text of the webpages indexed by the portal. The text is conditioned automatically to remove items outside the main text of the webpage, including sidebars, ads, images and web links. BCKO indexes 135 sites that the coders have typed as \u2018supportive\u2019 and 701 of type \u2018medical\u2019. The two types are not mutually exclusive \u2013 the 127 sites which are classified as both \u2018medical\u2019 and \u2018supportive\u2019 are omitted from further consideration in the present analysis (we return briefly to this issue in Section 4). The sites coded exclusively as \u2018supportive\u2019 are the rarer group, with 51 such sites available for training. Our experiments also cover the attributes of disease stages and authors credential in the BCKO portal. For the disease stages attribute, we can get 213 valid webpages (ones accessible at the URL indicated by the portal at the time of the study) coded exclusively to \u2018Early Breast Cancer\u2019, 17 coded exclusively as \u2018Recurrent Breast Cancer\u2019 and 138 exclusively \u2018Advanced Breast Cancer.\u2019 Due to the limited \u2018Recurrent\u2019 data, we focus on \u2018Early\u2019 versus \u2018Advanced\u2019 stage as a classification problem in the present paper. For the author credentials attribute there are 9 values, of which a website is only assigned one: Cancer Organisation, Clinician, Commercial Body/Group, Consumer Group, Education Institution, Government Organisation, Lay Author, Medical Organisation and Researcher. Clinician and Lay Author have 319 and 52 valid webpages, respectively, and are utilised for the present study. To provide a well-known basis for comparison, we employ the Reuters21578 data set, a sequential set of news articles, mostly concerning business and economy, coded into a number of categories. Reuters21578 has become a long-standing benchmark for text classification algorithms and is freely available for experimentation purposes from http://www.daviddlewis.com/resources/testcollections/~reuters21578/. For the present study we examine the two categories with the highest number of training cases, which are \u2018earn\u2019 and \u2018acq\u2019. There are 3735 cases in class \u2018earn\u2019 and 2125 cases in class \u2018acq\u2019. 2.2 Hyperspace analogue to language 2.2.1 Semantic Space models Hyperspace analogue to language (HAL) is a model/approach for automatic construction of a Semantic Space model from a corpus of text [11]. In the case of HAL, an N \u00d7 N matrix is instantiated with an N-length vector for each unique word occurring in a corpus. A \u2018window\u2019 several words in width is moved across the corpus; wherever, two words occur within the window the value at their intersection in the matrix is incremented. Thus, a corpus is converted to a high-dimensional Semantic Space with minimal consideration to grammar. Other significant Semantic Space models include LSA [17], which is widely used for document indexing, and the more recent COALS model [18]. We were particularly influenced to use HAL because it has some track record in representing emotion in text. Burgess and Lund [15] examined whether HAL could represent abstract concepts, such as love, hate and joy. They found that, in a comparison with human raters in predicting abstract variables for a set of words, \u201cglobal co-occurrence information carried in the word vectors can be used to predict a tangible proportion of the human likert scale ratings\u201d. At an algorithmic level, HAL requires going through the corpus word by word, and for each word assigning a value to other words in its neighbourhood (aka, the \u2018window\u2019, the size of the which is a significant parameter, typically 10 in practice, which we have found to work well in the present application). All words within the window are considered as co-occurring with each other with strengths inversely proportional to the distance between them. For example, Fig. 1 illustrates the appearance of a HAL matrix produced with a window of size 3 passed over the text \u201cEvaluating breast changes or masses usually starts with a mammogram or sonogram (ultrasound) performed by a radiologist\u201d. In keeping with prior studies [19], punctuation, sentence and paragraph boundaries, the order of co-occurrence of words (i.e., before or after), and some extremely common words (e.g., \u201ca\u201d, \u201cthe\u201d, \u201cis\u201d, \u201care\u201d, etc. \u2013 the \u2018stop words\u2019) are not considered useful to the inference of the underlying Semantic Space and are discarded. At the top of Fig. 1 the window and its HAL score contribution is illustrated at the point where the window is applied to the word \u201cmasses\u201d. As the window is moved over the entire text corpus, scores accumulate into an N by N matrix (the \u2018HAL matrix\u2019, H), where N is the number of distinct words in the corpus. This can be accumulated across the text of multiple websites (or multiple articles for the Reuters data); we term a HAL matrix for a set of training data as Ht . 2.2.2 Data pre-processing Since the HAL matrix, H, is very sparse, we first sort the vectors (columns) by the sum of their items in descending order and pick the first n columns (n < N, say n =450), then sort the rows by the sum of the values in the selected columns for each row in descending order and pick the first m number rows (m < N, say m =100). We get a new, sorted, and much smaller, m \u00d7 n matrix (called matrix H\u2032). We can alternatively interpret the elements of H\u2032 as a single vector of length m \u00d7 n. Each webpage can be represented as this m \u00d7 n vector and an associated type (e.g., \u2018medical\u2019 or \u2018supportive\u2019). The vectors for all r webpages (say 100) are assembled into a matrix in which each row represents a webpage (called matrix H\u2217); the corresponding type of each webpage will be put into another single-column matrix. We assume that the most important HAL-based features are among those for which we have a lot of data. Thus, we sort each m \u00d7 n vector in descending order of the sum across the r webpages. Since in our case m \u00d7 n equals 45,000 and is still a large feature set, we often use just some of the p features, p < m \u00d7 n, with the largest sums. 2.3 Machine learning algorithms We started to address the classification problem by adapting an induced decision tree algorithm for classification [20]. While this gave promising results, we then decided to improve the solution by creating multiple decision trees, i.e., a Decision Forest [21], which yielded improved classification accuracy in all cases \u2013 hence we report decision forest rather than single decision tree results herein. Study of the patterns of failure in the individual decision trees and correlations in the HAL matrix revealed that a key weakness in applying decision tree type solutions to our problem is that our webpages are individually often quite brief. This has the effect that a word that is very informative in the corpus as a whole is frequently totally absent from a particular page. This insight led us to enhancements in the way we interpreted induced decision trees, utilising what we call a \u2018validation path\u2019, and ultimately led to a simplified algorithm that yields better (and faster) classification for our problem, which we call summed similarity measurement (SSM). Our objective for this paper is to establish if the HAL-based classifier was suitable for this Health Informatics problem, and not to pursue the Machine Learning question of what method is best per se. However, to assess that we have not made unnecessary (or at least counterproductive) innovations, we: (a) compare our decision forest and SSM to SVM, chosen specifically because of its demonstration as a solid performer on Reuters21578 [22] as well as its widespread availability; and (b) compare our choice to use features from HAL\u2019s Semantic Space model as compared to simpler word frequencies. With respect to the latter comparison, we look at word frequencies with both SVM and decision forests. Moreover, since the notion of creating multiple classifiers for a single data set is not limited to decision trees, we also look at the creation of a \u2018forest\u2019 of SVM classifiers. It should be noted that classification of article tone (\u2018supportive\u2019 versus \u2018medical\u2019) was used for exploration of algorithm parameters (notably, HAL window size, the number of HAL rows and columns to retain for classification, and the number of decision trees per forest) whereas BCKO breast cancer stage and authorship, as well as the Reuters data, were used to confirm performance without undo \u2018data dredging\u2019 in this regard. 2.3.1 Decision tree To create a decision tree based on HAL vectors of words in the corpus, we examine how well each candidate word j splits the training set into estimated membership (e.g., \u2018medical\u2019 vs. \u2018supportive\u2019). The decision word for the root node of our decision tree is taken based on the maximum entropy reduction (i.e., information gain, a la ID3) from the parent to the child. This is repeated recursively, choosing a new best word for each node of the tree, until all training cases are correctly classified or there is no word remaining that provides a further entropy reduction. Since the training matrix is a very large (\u223c7000 by 7000) and sparse, use of the entire matrix in the classifier development process is both computationally cumbersome and also conceptually out-of-keeping with the concept of Semantic Spaces (which assumes the number of relevant semantic dimensions to be less than the total vocabulary size), thus we use a reduced matrix, H\u2032, as described above. In the case of \u2018medical\u2019 versus \u2018supportive\u2019, \u2018medical\u2019 group is denoted as H t [ med ] \u2032 and \u2018supportive\u2019 group is denoted as H t [ sup ] \u2032 , and the union of these two set of vectors is the final base of the training set: (1) H t \u2032 = H t [ med ] \u2032 \u222a H t [ sup ] \u2032 Since cosine is well normalized and amendable to high-dimensional vectors, cosine has been selected as a measure of association. In keeping with the dimensional theory of a HAL matrix, a high cosine on the vector for a particular word between two HAL matrices indicates that the two corpuses use the word in a similar context. Thus, the similarity of the HAL matrix for the ith test website on the jth word (j \u03b5 the words in H t \u2032 ) to the \u2018medical\u2019 corpus is: (2) Sim ( H i \u2032 ( j ) , H t [ med ] \u2032 ( j ) ) = cos ( H i \u2032 ( j ) , H t [ med ] \u2032 ( j ) ) = H i \u2032 ( j ) \u00b7 H t [ med ] \u2032 ( j ) | H i \u2032 ( j ) | \u00d7 | H t [ med ] \u2032 ( j ) | The similarity to the \u2018supportive\u2019 corpus\u2019 use of word j is defined in the same manner with respect to H t [ sup ] \u2032 . Taking word j as a candidate basis for classifying cases as \u2018medical\u2019 or \u2018supportive\u2019, we simply estimate the type of the test case as being that with the highest similarity measure. Ties are taken consistently to arbitrarily go with the right branch as the estimated type (this occurs when the decision word is missing in a specific test case\u2019s corpus; see previous work [20]). A validation path is the path taken in a tree for a given test case. Fig. 2 shows a validation path for a \u2018medical\u2019 test case with case ID #183. In the validation path, the keyword \u2018treatment\u2019 does not occur in case 183, thus both of the similarities of 183 to \u2018medical\u2019 and \u2018supportive\u2019 are 0. Empirically, we find that the remaining entropy reduction after a tie node is relatively small, as for instance in the case in Fig. 2. 2.3.2 Round-robin decision forest (RRDF) A decision tree may yield a reasonable accuracy, but in many cases the absence of a keyword (i.e., one used as a decision node in the tree) in a test webpage will lead to very unstable performance. To eliminate this problem, instead of using one single tree, we use a number of trees (called a decision forest) and take the majority group as the final result. Given the distinctive nature of the decision tree node features in our work (i.e., HAL vectors) we felt that precedent from prior decision forest work may be unreliable, and thus experimented with a range forest sizes. Empirically, for \u2018supportive\u2019 versus \u2018medical\u2019 classification, we find classification accuracy rises with the number of trees in the decision forest until about 20 trees, and is thereafter stable up to 60 trees (the largest number we tried). We chose an odd (tie-breaking) number in the middle of this range and hence use 39 trees per forest throughout this paper. The columns of the training dataset are sorted in descending order by the sum of their element values in H t \u2032 and assigned to the sub-datasets for each tree in a round-robin fashion [21] (i.e., assigning one feature to every tree in turn, then starting over until every feature is allocated to a single tree). The result is what we call a round-robin decision forest (RRDF) on HAL. To further minimize the impact of the lack of particular words in a given test case, and to exploit the fact that the HAL matrix is a highly correlated matrix [23], rather than taking the outcome of each decision tree directly, we create a similarity measure for class c, determined by the sum of the similarity of each node in the validation path, VP: (3) S i = \u2211 j \u2208 VP Sim ( H i \u2032 ( j ) , H t [ c ] \u2032 ( j ) ) Where word j is a node in the validation path of webpage i, H t [ c ] \u2032 is pre-processed training HAL matrix (see Section 2.2.2) for class c, and H i \u2032 is the pre-processed HAL matrix for webpage i. We then take the class i with the highest Si as the decision of the tree. We explore a few other variations of the RRDF concept. We apply SVM (see Section 2.3.4) on word frequency for subsets of the available words and vote for the final result (we label this RRSVMoWfreq). As another method, we follow IBM researchers who used word frequency (0, 1, 2, or >=3) as the basis for nodes of a decision tree [24]. When extending this method to a round-robin decision forest, we call this RRDFoWfreq. 2.3.3 Summed similarity measure on HAL (SSMoHal) SSM on HAL is a variation similar to our use of the validation path for RRDF on HAL. However, instead of summing the similarities of words in the validation path only (as per Eq. (3)), we sum the similarity of every common word as the final similarity measure; thus: (4) S i = \u2211 j \u2200 H i Sim ( H i ( j ) , H t [ c ] ( j ) ) Where word j exists both in test case H i and the sum of the training cases of class c ( H i [ c ] ). The matrices are all full matrices (see Section 2.2.2; i.e., not reduced to H t \u2032 ). 2.3.4 Support vector machine (SVM) In this experiment, we follow the common practice of using normalized term frequency\u2013inverse document frequency (TF*IDF) [22] as the features for SVM, where TF = 1 + log 10 wf ( wf is the frequency of word occurrence in the webpage ) IDF = log 10 R wr ( R is the dimension of the corpus, wr is the total number of webpages in which the word occurs, IDF = 0 if wr is 0 ) We supply SVM with the frequencies of the 1200 most frequent words (which we call SVMoWfreq). We utilise the widely used SVMlight interface in the experiments (see \u201chow to use\u201d in http://svmlight.joachims.org/). The performance of SVMlight on Reuters21578 data has been shown to vary by only about 1% over the three common kernel functions: linear, polynomial and radial basis function [25]. We use the linear-kernel function to avoid the need for parameter tuning and to get greatest speed of performance. We also apply SVM on the 1200 highest value elements of the matrix H\u2217 (which we call SVMoHAL). 2.4 Protocols We apply the algorithms from Section 2.3 using the protocols described below. 2.4.1 Resampling To provide an accurate estimate of the performance of each classification algorithm, for each class, we randomly shuffle the dataset and pick the first ten cases as test cases and the rest as training cases. We do 100 shuffles for the experiment and take the arithmetic mean of the results as the final accuracy of each algorithm. To test performance with limited training data, we train each algorithm and compute its accuracy on the test data for the range from a single training case up to the full training set. In each shuffle, the order of the dataset (i.e., membership of test data and order of cases for introduction as training data) is identical for every algorithm assessed. Our resampling protocol assesses performance with an equal number of cases from each class and thus is limited by the rarer class in the data set. We employ 50 randomly-selected cases from each class for the \u2018supportive\u2019 versus \u2018medical\u2019 and \u2018lay\u2019 versus \u2018clinical\u2019 experiments (as this is the nearest round number to the maximum available in the rarer class in the BCKO data set); we take advantage of the larger available data supply and use 80 randomly-selected cases for \u2018early\u2019 versus \u2018advanced\u2019 stage of breast cancer, and 400 randomly-selected cases for \u2018earn\u2019 versus \u2018acq\u2019 from Reuters21578. 2.4.2 Natural order Realistic scenarios for use of our classifier do not necessarily involve a balanced number of cases from each of two alternative classes. To simulate real use we look at our data sets in their \u2019natural orders\u2019 in which the cases occurred. For Reuters21578 this is date\u2013time order of the news articles. For BCKO, the webpages include a case id indicating the order they were entered into the metadata database as the BCKO project progressed. In the natural order protocols, we use 150 consecutive cases (omitting only those where the metadata coders assigned the case to both of our comparison classes; i.e., both \u2018supportive\u2019 and \u2018medical\u2019 or both \u2018early\u2019 and \u2018advanced\u2019). We report accuracy of the best-performing algorithms from the resampling experiments as a running mean with respect to each case as classified with all chronologically prior cases acting as the training data. That is, the chronologically 2nd case is classified based on just the 1st case in the corpus (and hence the classifier always estimates that the membership is the same) on through to the 150th case which is classified based on the first 149 cases (with a mix of class memberships balanced such as it was in the corpus at the time the 150th case was added). 2.4.3 Computational complexity analysis We will compare SVM and SSM on their computational merits, particularly time complexity and speed, in the next section. 3 Results 3.1 Accuracy Figs. 3\u20136 show how the five algorithms perform on the balanced datasets as assessed with resampling. Table 1 shows the mean performance of each algorithm for each data set with the maximum training data, including a 95% confidence interval (CI) based on the variance over the 100 resamples. SSMoHAL and RRDFoHAL are consistently among the top three performers, and SVMoWfrq is among the top three for three out of the four data sets. In Figs. 7\u201310 we plot the accuracy of these three top-performing algorithms (labeled as SSM, RRDF and SVM, respectively) for the natural order protocol. In Figs. 7\u201310, part (a) plots the accumulated accuracies as training data is added, and parts (b) to (d) show for each case whether it is correctly or incorrectly classified and labels the class of that case. 3.2 Computational complexity analysis of SVM and SSM The amount of time consumed in the training phase is a big consideration for the practicality of a classifier. Conceptually, the size of a HAL matrix is N 2, where N is the vocabulary size of the corpus. However, in practice the matrix is sparse, and by using a hashed structure O(N 2) operations can be avoided. For SSM, the training process has two steps: first creating the HAL matrix of each web, and then adding the HAL matrices of all the webpages in the training dataset together, grouping by class. Each step has time complexity based on the number of additions to be hash-mapped into the HAL matrices and is O(wR n \u00af ), where w is the window size of HAL, R is the total number of webpages in the training dataset, and n \u00af is the mean number of non-stop-words of each webpage. The time complexity of SVM is reported as O(R 2), although it can be optimised to be superior to this in practice [26,27]. Also, we assume the time complexity of SVM has some dependence on the number of features (which is large in our application). As such, the big-O complexity analysis leaves some room for either algorithm to be superior depending on the nature of the data. For our experiments, using a machine with Intel Core 2 Duo E8400 3GHz processor, 4GB RAM and Microsoft Windows Vista Enterprise 64-bit for 50 cases in each class of two classes in which 40 are training cases and 10 are test cases, SSM takes about 16min for 100 resamples; SVM takes 30min for data preparation (notably, TF*IDF computation) and 35min for training (in SVMlight). Thus, our experience is that SSM is substantially faster for our data. 4 Discussion We have demonstrated that Semantic Space models based on HAL can provide features that support classification of consumer health webpages on metadata attributes of relevance to consumer health portals. We have achieved good levels of performance (rising to the low 90% range) using a few different classifiers: a novel method based on HAL vector similarity summation (SSM), an adaptation of decision forests for HAL (RRDF), and application of the well-established SVM method to the cells of the HAL matrix (or alternatively to appropriately conditioned word frequencies). We applied these methods to the well-known Reuters21578 data set for comparison. In addition to simulations that randomise training and testing data with balanced numbers of cases from the classes of interest, we have provided results of classification in the \u2018natural order\u2019. In these experiments we show performance as the classifier learns one case at a time in the order the webpages were actually assigned metadata by the consumer website curator. This simulates the accuracy the curator would have experienced had our algorithm been available as part of their metadata encoding tool suite. While the rate of improvement in accuracy varies depending on the metadata attribute in question, and appears to be slightly less with \u2018natural order\u2019 than an ideal balanced mix of cases from each class, we believe the performance is consistent with useful support within the scale of typical consumer health web portal development projects. A recent issue of Journal of Biomedical Informatics focused on biomedical text processing and illustrated the wide range of methods and applications currently being pursued, as well as the powerful tools that are making it possible to achieve increasingly impressive results in this domain [28]. A number of studies address objectives and employ methods similar to the present work. Deshazo and Turner [29] applied rule based processes and SVM to classify diseases based on discharge summary texts. Focusing specifically on webpage classification, Zhang et al. [30] classified Yahoo web pages in the three categories of health, shopping and education; they used word frequency features selected according to information gain, then employed principal component analysis to those features, and finally used a C4.5 decision tree, yielding classification accuracies slightly over 80%. An alternative source of classification features is exploited by Ypma and Heskes [31] who applied a Markov model to the click-stream log to identify the type of a webpage. Also exploiting the \u2018web\u2019 features of webpages, Attardi et al. [32] based their classifier on context, utilising the hyperlinks to the webpages, and the context in the referring webpage. In a similar vein, Roy et al. [33] attempt to infer the \u2018source\u2019 or \u2018sponsor\u2019 of a webpage by way of analysing its incoming and outgoing links. In another case, Mase [34] automatically derives weights for keywords for webpages, which then allows classification in up to 15 distinct categories with accuracy of 70\u201386%. Perhaps most similar to the present work in terms of feature set, Cohen et al. [14], employ a Semantic Space model with a permutation based word order encoding [35] that allows remarkably insightful results on MEDLINE data, such as correctly inferring asthma treatments based on the association of the unified medical language system (UMLS) \u2018TREATS\u2019 and \u2018Asthma\u2019 concepts. The results support our primary objective of demonstrating the feasibility of classification of relatively subtle attributes of consumer health webpages. That is, beyond determining the topic of a webpage at the level of, say, the disease under discussion, we successfully distinguish the tone of the article, the stage of disease and the nature of the author. The SSM algorithm in particular is an elegant utilisation a Semantic Space model, where classification is made based on the context of use of frequent non-stop words without consideration of sentence structure and with a pure machine learning approach. Conversely, the results do not indicate that either a Semantic Space model or our HAL-specific classifiers (SSM and RRDF) are necessary to achieve good results in this domain. In the context of Reuters21578, SVM has been shown previously to be a good classifier [22]. Our results on consumer health webpages show that SVM (using either HAL features or conditioned word frequencies) is a fast learner in most of the experiments we tried when the number of training cases is small. With more training cases, the results of SVM converge with SSM and RRDF. Careful choice of kernel function and tuning of parameters may yield a small improvement in performance for this method; overall, however, we believe other criteria, such as trade-off of computational space and time for specific applications, may reasonably decide an implementer\u2019s choice among these algorithms for the context we have explored. Empirically, we find SSM to be faster than SVM, but acknowledge the difficulties of comparing performance of a generic third party algorithm to one we have implemented specific to the purposes of this study. According to our computational complexity analysis, SSM should give better performance for large training set sizes, an important and increasingly common case with the continued growth of the web. There are many potential barriers, even with the best possible classifiers, with respect to achieving near-perfect classification on consumer metadata attributes using Semantic Space models. These barriers include quotation, enantiosis and drollness in the text, as well as legitimate difference of opinion as to the class of a specific article with respect to subjective aspects such as \u2018medical\u2019 versus \u2018supportive\u2019 article tone. We have restricted presentation in this paper to 2-class problems. The methods have no inherent limitation in terms of number of distinct classes; however, unsurprisingly, based on results from Reuters-21578 [22] (as well as our own experiences not presented in the results of this article), the larger the number of classes, the harder the problem and the lower the accuracy. It is interesting to note that the difficulty of our consumer health metadata classification problems appears not very different from that of classification in the Reuters data (with the data representations we have chosen). Our data also presents the further issue of non-exclusive class membership, where multiple values of a metadata attribute may apply to the same case. We are investigating the best approach for this, with options that include modelling joint membership (e.g., \u2018supportive\u2019 and \u2018medical\u2019 tone) as a separate class or using ranges of the vote counts in a decision forest to indicate likely joint membership when votes are relatively evenly split. We expect that this problem will be difficult in practice for those consumer health websites where the metadata is defined such that there are a large number of possible overlaps and few available instances of such overlaps. We note that in the natural order experiments most of the misclassifications are with the less frequent classes. Skewed class frequency appears to be a common feature with the consumer health webpages, reflecting the difficulty of finding the \u2018lesser voices\u2019 (e.g., of \u2018supportive\u2019 versus \u2018medical\u2019 tone, or lay versus clinician authors) using conventional search engines. As such, it is desirable to have a classifier which aids identification of these more difficult to find resources. For future development, we plan to explore splitting training data in the bigger class into a few smaller datasets around the size of the smaller class and reusing the smaller class to train multiple classifiers, then taking the majority decision as the final classification result [36,37]. A Java application programming interface (API) for the SSM and RRDF algorithms is available from http://www.cs.auckland.ac.nz/~gchen/api. Please cite this paper and the URL if using the API in research work. Acknowledgments The authors thank Peter Bruza and Robert McArthur for their advice on use of Semantic Space models; Joanne Evans, Frada Burstein and the other staff of the Smart Information Portals team at Monash University, Australia, for their advice and support with consumer health metadata; and Vojo Kecman for his advice on machine learning methods. This work was supported in part by Australian Research Council Discovery Project DP0665353 and a University of Auckland postgraduate scholarship. References [1] Madden M, Fox S. Finding answers online in sickness and in health. Pew Internet and American Life Project, <http://wwwpewinternetorg/pdfs/PIP_Health_Decisions_2006pdf>; 2006 [accessed 26.01.2010]. [2] Eysenbach G. Consumer health informatics. Br Med J 2000/06/23 ed2000. p. 1713\u20136. [3] Bomba D. Evaluating the quality of health web sites: developing a validation method and rating instrument. Proceedings of the 38th annual Hawaii international conference on system sciences (HICSS\u201905) \u2013 Track 6, vol. 06. IEEE Computer Society; 2005. p. 139.1. [4] K. Kim M. Lustria D. Burke N. Kwon Predictors of cancer information overload: findings from a national survey Inf. Res. 12 4 2007 12 14 [5] G. Eysenbach J. Powell O. Kuss E. Sa Empirical studies assessing the quality of health information for consumers on the world wide web a systematic review JAMA: Am Med Assoc 2002 2691 2700 [6] R. Haynes C. Cotoi J. Holland L. Walters N. Wilczynski D. Jedraszewski Second-order peer review of the medical literature for clinical practitioners JAMA 295 15 2006 1801 1808 [7] Moon J, Burstein F. Intelligent Portals for Supporting Medical. Web portals: the new gateways to Internet information and services: IGI Global; 2005. p. 270\u201320. [8] A.D. Madden Portals or filters? Identifying quality on the Internet A. Cox Portals: people, processes and technology 2006 Facet London [9] Burstein F, Fisher J, McKemmish S, Manaszewicz R, Malhotra P. User centred quality health information provision: benefits and challenges. Proceedings of the Proceedings of the 38th annual Hawaii international conference on system sciences (HICSS\u201905) \u2013 Track 6, vol. 06. IEEE Computer Society; 2005. p. 138.3. [10] Hunter J. Next generation tools and services: supporting dynamic knowledge spaces. In: Kapitzke C, Bruce BC, editors. Libr@ ries: changing information space and practice: Lawrence Erlbaum Associates Inc.; 2006. p. 91\u2013122. [11] C. Burgess K. Livesay K. Lund Explorations in context space. Words, sentences, discourse Discourse Process 1998 211 247 [12] T. Cohen D. Widdows Empirical distributional semantics: methods and biomedical applications J Biomed Inform 42 2 2009 390 405 [13] Widdows D, Ferraro K, Semantic vectors: a scalable open source package and online technology management application. Sixth international conference on language resources and evaluation (LREC 2008); 2008. [14] Cohen T, Schvaneveldt R, Rindflesch T, Predication-based semantic indexing: permutations as a means to encode predications in semantic space. Proc AMIA annual symposium; 2009. American Medical Informatics Association. [15] Burgess C, Lund K. Representing abstract words and emotional connotation in a high-dimensional memory space. Cognitive science proceedings, LEA http://halucredu/pdfs/Burgess_Lund(1997b)pdf: Lawrence Erlbaum Associates; p. 61\u20136, 1997 [accessed 26.01.2010]. [16] T. Joachims Making large-scale SVM learning practical B. Scholkopf C. Burges A. Smola Advances in kernel methods \u2013 support vector learning 1999 The MIT Press Cambridge, MA 169 184 [17] Landauer T, Foltz P, Laham D. An introduction to latent semantic analysis. Discourse Process: ABLEX Publishing Co.; 1998. p. 259\u2013284. [18] Rohde D, Gonnerman L, Plaut D. An improved method for deriving word meaning from lexical co-occurrence. Cogn Sci; 2004. [19] McArthur R, Bruza P, Warren J, Kralik D, Projecting computational sense of self: a study of transition in a chronic illness online community. Proceedings of the 39th Hawii international conference on system sciences (HICSS-39); 2006. [20] Chen G, Warren J, Evans J. Automatically generated consumer health metadata using semantic spaces. Proceedings of the second Australasian workshop on Health data and knowledge management, vol. 80. Wollongong, NSW, Australia: Australian Computer Society, Inc.; 2008. p. 9\u201315. [21] G. Chen J. Warren J. Evans \u2018Qualities\u2019 not \u2018Quality\u2019 \u2013 text analysis methods to classify consumer health websites Electron J Health Inform 4 1 2009 e5 [22] Debole F, Sebastiani F. An analysis of the relative hardness of Reuters-21578 subsets. Journal of the american society for information science and technology. Wiley Subscription Services, Inc., A Wiley Company Hoboken; 2005. p. 584\u201313. [23] Chen G, Warren J, McArthur R, Bruza P, Kralik D, Price K. Understanding individual experiences of chronic illness with semantic space models of electronic discussions. Proceedings of the twentieth IEEE international symposium on computer-based medical systems. IEEE Computer Society; 2007. p. 548\u20136. [24] Johnson D, Oles F, Zhang T, Goetz T. A decision-tree-based symbolic rule induction system for text categorization-References. IBM Syst J 2002. [25] Sahlgren M, C\u00f6ster R. Using bag-of-concepts to improve the performance of support vector machines in text categorization. Proceedings of the 20th international conference on computational linguistics (COLING 2004); 2004. Association for Computational Linguistics. [26] E. Osuna F. Girosi Reducing the run-time complexity of support vector machines. Advances in kernel methods: support vector learning 1999 MIT Press Cambridge, MA p. 271\u201384 [27] Lawrence N, Seeger M, Herbrich R. Fast sparse Gaussian process methods: the informative vector machine. Advances in neural information processing systems: Citeseer; 2003. p. 625\u20138. [28] W.W. Chapman K.B. Cohen Current issues in biomedical text mining and natural language processing J Biomed Inform 42 5 2009 757 759 [29] Deshazo JP, Turner AM. An interactive and user-centered computer system to predict physician\u2019s disease judgments in discharge summaries. J Biomed Inform; 2009 Sep 3. [30] Zhang R, Shepherd M, Duffy J, Watters C, Automatic web page categorization using principal component analysis. 40th Hawaii international conference on system sciences; 2007. IEEE. [31] Ypma A, Heskes T. Automatic categorization of web pages and user clustering with mixtures of hidden Markov models. Lecture Notes in Artificial Intelligence 2703: Springer; 2003. p. 35\u201349. [32] Attardi G, Gull\u00ec A, Sebastiani F. Automatic Web page categorization by link and context analysis. Proceedings of THAI\u201999; 1999; Varese, Italy. [33] Roy S, Joshi S, Krishnapuram R. Automatic categorization of web sites based on source types. HT \u201804; 2004; Santa Cruz, CA: ACM. [34] Mase H. Experiments on automatic web page categorization for IR system: Stanford University; 1998. [35] Sahlgren M, Holst A, Kanerva P. Permutations as a means to encode order in word space. Proc 30th annual meeting of the cognitive science society (CogSci\u201908); July 23\u201326, 2008; Washington DC: Citeseer. [36] J. Chen C. Tsai J. Young R. Kodell Classification ensembles for unbalanced class sizes in predictive toxicology SAR QSAR Environ Res: Taylor & Francis 2005 517 529 [37] Frank E, Bouckaert R. Naive bayes for text classification with unbalanced classes. Lecture Notes in Computer Science: Springer; 2006. p. 503.", "scopus-id": "77956263125", "pubmed-id": "20601122", "coredata": {"eid": "1-s2.0-S1532046410000900", "dc:description": "Abstract To deal with the quantity and quality issues with online healthcare resources, creating web portals centred on particular health topics and/or communities of users is a strategy to provide access to a reduced corpus of information resources that meet quality and relevance criteria. In this paper we use hyperspace analogue to language (HAL) to model the language use patterns of webpages as Semantic Spaces. We have applied machine learning methods, including support vector machine (SVM), decision forest, and a novel summed similarity measure (SSM) to automatically classify online webpages on their Semantic Space models. We find classification accuracy on metadata attributes to be over 93% for \u2018medical\u2019 versus \u2018supportive\u2019 perspective, over 92% for disease stage of \u2018early\u2019 versus \u2018advanced\u2019, and over 90% for author credentials of \u2018lay\u2019 versus \u2018clinician\u2019 based on webpages of the Breast Cancer Knowledge Online portal. These results indicate that language use patterns can be used to automate such classification with useful levels of accuracy.", "openArchiveArticle": "true", "prism:coverDate": "2010-10-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046410000900", "dc:creator": [{"@_fa": "true", "$": "Chen, Guocai"}, {"@_fa": "true", "$": "Warren, Jim"}, {"@_fa": "true", "$": "Riddle, Patricia"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046410000900"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046410000900"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(10)00090-0", "prism:volume": "43", "prism:publisher": "Elsevier Inc.", "dc:title": "Semantic Space models for classification of consumer webpages on metadata attributes", "prism:copyright": "Copyright \u00a9 2010 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "5", "dcterms:subject": [{"@_fa": "true", "$": "Consumer health information"}, {"@_fa": "true", "$": "Internet"}, {"@_fa": "true", "$": "Metadata"}, {"@_fa": "true", "$": "Natural language processing"}, {"@_fa": "true", "$": "Breast cancer"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "5", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "725-735", "prism:endingPage": "735", "prism:coverDisplayDate": "October 2010", "prism:doi": "10.1016/j.jbi.2010.06.005", "prism:startingPage": "725", "dc:identifier": "doi:10.1016/j.jbi.2010.06.005", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "88", "@width": "414", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3860", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "44", "@width": "340", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2331", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "196", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1215", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "38", "@width": "196", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1254", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "78", "@width": "314", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2826", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "22", "@width": "145", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "742", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "30", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "319", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "262", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "373", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "262", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "40", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "373", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "189", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "189", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "262", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "30", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "298", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "241", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "260", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "21", "@width": "44", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "378", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "568", "@width": "512", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr10.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "61307", "@ref": "gr10", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "148", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr10.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4702", "@ref": "gr10", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "257", "@width": "378", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "35149", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "149", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6816", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "393", "@width": "489", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "57028", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "204", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8519", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "357", "@width": "498", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "44775", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "157", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6928", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "289", "@width": "535", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "50893", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "118", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6871", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "256", "@width": "489", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "32811", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "115", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5317", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "552", "@width": "512", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62780", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "152", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4838", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "624", "@width": "510", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "63595", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "134", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4269", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "528", "@width": "511", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62725", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "164", "@width": "159", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5299", "@ref": "gr9", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "323", "@width": "487", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62674", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "145", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046410000900-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "9091", "@ref": "gr1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/77956263125"}}
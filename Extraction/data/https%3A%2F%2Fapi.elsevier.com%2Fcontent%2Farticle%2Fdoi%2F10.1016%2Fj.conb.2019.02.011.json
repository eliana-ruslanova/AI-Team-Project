{"scopus-eid": "2-s2.0-85063739404", "originalText": "serial JL 272014 291210 291735 31 90 Current Opinion in Neurobiology CURRENTOPINIONINNEUROBIOLOGY 2019-04-03 2019-04-03 2019-04-03 2019-04-03 2019-06-01T02:59:16 1-s2.0-S0959438818301077 S0959-4388(18)30107-7 S0959438818301077 10.1016/j.conb.2019.02.011 S300 S300.1 FULL-TEXT 1-s2.0-S0959438818X00063 2020-02-17T02:14:55.519254Z 0 0 20190401 20190430 2019 2019-04-03T18:58:00.877955Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure body mmlmath acknowledge affil articletitle auth authfirstini authfull authlast grantnumber grantsponsor grantsponsorid highlightsabst orcid primabst ref 0959-4388 09594388 UNLIMITED NONE true 55 55 C Volume 55 19 133 141 133 141 201904 April 2019 2019-04-01 2019-04-30 2019 Machine Learning, Big Data, and Neuroscience Prof. Maneesh Sahani Prof. Jonathan Pillow article rev \u00a9 2019 The Authors. Published by Elsevier Ltd. NEURALCOGNITIVEARCHITECTUREFORLEARNINGASMALLSAMPLE CORTESE A Introduction Computational advantages of higher cognitive functions in learning Neural implementation of high level cognitive architecture Conclusions Conflict of interest statement References and recommended reading Acknowledgements References HE 2015 1026 1034 K PROCEEDINGSIEEEINTERNATIONALCONFERENCECOMPUTERVISION DELVINGDEEPRECTIFIERSSURPASSINGHUMANLEVELPERFORMANCEIMAGENETCLASSIFICATION LECUN 2015 436 444 Y SILVER 2016 484 489 D ATKESON 2018 667 684 C DARPAROBOTICSCHALLENGEFINALSHUMANOIDROBOTSRESCUE HAPPENEDDARPAROBOTICSCHALLENGEFINALS GHAHRAMANI 2015 452 459 Z LAKE 2015 1332 1338 B GEORGE 2017 eaag2612 D LAKE 2017 e253 B KAWATO 2007 205 212 M BUSCHMAN 2014 T WANG 2018 860 868 J TOKUDA 2017 58 67 I WATANABE 2009 S ALGEBRAICGEOMETRYSTATISTICALLEARNINGTHEORY YAMAZAKI 2014 3541 3562 K XU 2015 K LEE 2013 10625 10633 J FARASHAHI 2017 1768 S YANG 2016 100 108 S LEONG 2017 451 463 Y HUDSON 2018 D LUONG 2015 M LENGYEL 2008 889 896 M ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS20 HIPPOCAMPALCONTRIBUTIONSCONTROLTHIRDWAY SANTORO 2016 12228 12242 A RICHARDS 2017 1071 1084 B GRAVES 2014 A GRAVES 2016 471 476 A WAYNE 2018 G CONSTANTINESCU 2016 1464 1468 A MACK 2016 13203 13208 M HIGGINS 2017 I CORTESE 2016 13669 A POUGET 2016 366 374 A DEHAENE 2017 486 492 S FRISTON 2017 2633 2683 K NASSAR 2010 12366 12378 M MCGUIRE 2014 870 881 J VAGHI 2017 348 354.e4 M GUGGENMOS 2016 M BENGIO 2017 Y INSABATO 2010 539 547 A GOODFELLOW 2014 I ADVANCESINNEURALINFORMATIONPROCESSINGSYSTEMS27 GENERATIVEADVERSARIALNETS JACOBS 1991 79 87 R GROSSBERG 1973 213 257 S GRAYBIEL 1994 A SCHULTZ 1997 1593 1599 W DU 2016 E5501 E5510 H OKEEFE 1971 171 175 J STACHENFELD 2017 1643 1653 K KUMARAN 2016 512 534 D FUNAMIZU 2016 1682 1689 A SCHUCK 2016 1402 1412 N SARMA 2015 A BOWMAN 2018 2605 2614 C WUTZ 2018 716 726 A BASTOS 2015 390 401 A SALEEM 2017 315 322 A BUZSAKI 2004 1926 1929 G ORBAN 2016 530 543 G RUBEN 2014 1410 1417 M KIRKPATRICK 1983 671 680 S GEMAN 1984 721 741 S ATASOY 2016 10340 S LOBIER 2018 222 237 M OEMISCH 2019 176 M STARESINA 2016 e17397 B SAEZ 2018 2889 2899.e3 I HARUNO 2006 1242 1254 M CORTESEX2019X133 CORTESEX2019X133X141 CORTESEX2019X133XA CORTESEX2019X133X141XA Full 2019-03-05T08:10:39Z Author http://creativecommons.org/licenses/by-nc-nd/4.0/ HEFCE 2020-04-03T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license. \u00a9 2019 The Authors. Published by Elsevier Ltd. item S0959-4388(18)30107-7 S0959438818301077 1-s2.0-S0959438818301077 10.1016/j.conb.2019.02.011 272014 2020-02-17T02:14:55.519254Z 2019-04-01 2019-04-30 UNLIMITED NONE 1-s2.0-S0959438818301077-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/MAIN/application/pdf/7e00e7937c5b59430dc872dd57d31b6f/main.pdf main.pdf pdf true 1372969 MAIN 9 1-s2.0-S0959438818301077-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/PREVIEW/image/png/8e805bd60955a26746424a426e3ffee8/main_1.png main_1.png png 76849 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0959438818301077-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr1/THUMBNAIL/image/gif/d84a9274f00f32d737a202c1d0311a2c/gr1.sml gr1 gr1.sml sml 13034 160 219 IMAGE-THUMBNAIL 1-s2.0-S0959438818301077-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr2/THUMBNAIL/image/gif/a24d6f2728fa10c40a7c87d7312af8ba/gr2.sml gr2 gr2.sml sml 13239 164 159 IMAGE-THUMBNAIL 1-s2.0-S0959438818301077-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr3/THUMBNAIL/image/gif/af983e5e6074ce165d38908c46894f16/gr3.sml gr3 gr3.sml sml 10985 122 219 IMAGE-THUMBNAIL 1-s2.0-S0959438818301077-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr1/DOWNSAMPLED/image/jpeg/f9b776f352e54ebee29fc35f1184520c/gr1.jpg gr1 gr1.jpg jpg 72283 489 670 IMAGE-DOWNSAMPLED 1-s2.0-S0959438818301077-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr2/DOWNSAMPLED/image/jpeg/64c7625b10944ea06554cfaa00ab70e2/gr2.jpg gr2 gr2.jpg jpg 89360 529 513 IMAGE-DOWNSAMPLED 1-s2.0-S0959438818301077-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr3/DOWNSAMPLED/image/jpeg/03df6611458c2bb0a0787bafdaf89598/gr3.jpg gr3 gr3.jpg jpg 86567 429 772 IMAGE-DOWNSAMPLED 1-s2.0-S0959438818301077-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr1/HIGHRES/image/jpeg/ae153c8456d4670b84b968e33e15ae9c/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 622544 2168 2969 IMAGE-HIGH-RES 1-s2.0-S0959438818301077-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr2/HIGHRES/image/jpeg/62356a47d16bdc2455882a0da57ac290/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 762210 2344 2274 IMAGE-HIGH-RES 1-s2.0-S0959438818301077-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/gr3/HIGHRES/image/jpeg/9c80d71be8f4c50b21ed4193d56fd758/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 815738 1900 3420 IMAGE-HIGH-RES 1-s2.0-S0959438818301077-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0959438818301077/STRIPIN/image/gif/e690f2af09908cc711f9404365d6d011/si1.gif si1 si1.gif gif 313 16 78 ALTIMG 1-s2.0-S0959438818301077-am.pdf am am.pdf pdf 1015619 AAM-PDF https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/egi:10RT62FDQ84/MAIN/application/pdf/df93b43e4a5fb9f161ad04f6d759f306/am.pdf CONEUR 2139 S0959-4388(18)30107-7 10.1016/j.conb.2019.02.011 The Authors Figure 1 General schematic, solutions to complex problems in artificial intelligence and nature (brains). The key insight discussed here is that higher cognitive functions continuously interact between them and with reinforcement learning to drive generalization and learning from small sample. Figure 1 Figure 2 Winner-take-all parallel computing takes place in loops spanning basal ganglia and neocortex. Excitatory and inhibitory interactions between multiple loops formed by the basal ganglia, thalamus and cerebral cortical regions implement winner-take-all computations. The loop with the best representation for reinforcement learning and minimum reward prediction errors thus wins and all other loops are suppressed. These winner-take-all computations implement dimension reduction and feature selection accelerated by high cognitive functions as follows. Attention executes feature selection rather than dimension reduction, with relatively low abstraction. Episodic memory, among different kinds of memories, represents feature selection in the time domain, and its abstraction level is relatively low. Conceptualization executes dimension reduction rather than feature selection, and its abstraction level is high. Metacognition does both dimension reduction and feature selection and its abstraction level is very high. Consciousness has the highest abstraction level and results in pure dimension reduction. dlPFC, dorsolateral prefrontal cortex; OFC, orbitofrontal cortex; HPC, hippocampal formation; MC, motor cortex; PPC, posterior parietal cortex; ITC, inferior temporal cortex; VC, visual cortex; VTA/SNc, ventral tegmental area/substantia nigra; RL, reinforcement learning. Figure modified from Haruno and Kawato [67]. Figure 2 Figure 3 Different frequency modes in synchronization of neural activity represent broad and fine dimension reduction and feature selection. (a) Neural oscillations are rhythmic repetitions of patterned neural activity. These oscillations can cover frequencies from approximately 0.05 Hz (low spectrum) to 500 Hz (high spectrum). While low-frequency spatio-temporal modes contain many neurons and connections, high frequency modes contain small numbers of neurons and connections. Nonlinear dynamic interactions between low and high-frequency modes provide the computational means for fast parallel search of the optimal metarepresentation, corresponding smallest reward prediction errors (RPE), neurons and connections. When a low frequency mode is selected first, all high frequency modes contained within it are generally activated because low and high frequency modes share common neurons and connections. Among the activated high-frequency modes, those with the highest correlations between meta-representations and RPE are further activated, and an optimal mode is thus selected. Consequently, dimension reduction with low-frequency synchronization and feature selection with high-frequency synchronization proceed together by closely interacting. (b) Illustration of the search implemented by the model. Low frequency mode corresponds to dimension reduction such as principal component analysis (PCA) and high temperature in annealing. High frequency mode corresponds to feature selection such as L1-norm regularization or automatic relevance determination, and low temperature in annealing. Real or simulated annealing takes long time but brains cannot afford that. There exists no external control of temperature in the proposed interaction between different modes; nonlinear brain dynamics directly implements simulated annealing. With low signal to noise ratio, a common issue in most learning problems, first an optimal low-frequency mode is activated because it contains many areas, neurons and connections. This increases the chances of correlation computations surviving high noise conditions. Then, high-frequency modes contained in it are generally activated, and correlations can be more reliably computed by constrained domains and general excitatory inputs to them. The selection of the optimal high-frequency mode can be executed more robustly. This interaction between low and high-frequency modes roughly implements annealing. The key difference with annealing though is that activation and inhibition of all loops start simultaneously in the brain. But convergence starts from large dimension and low abstraction (top left, black dot on top arrow) and proceeds to small dimension and high abstraction (bottom right). This is analogous to simulated annealing (direction of oblique arrow). Figure 3 The neural and cognitive architecture for learning from a small sample Aurelio Cortese 1 Benedetto De Martino 2 3 Mitsuo Kawato 1 4 1 Computational Neuroscience Laboratories, ATR Institute International, Kyoto, Japan Computational Neuroscience Laboratories ATR Institute International Kyoto Japan 2 Institute of Cognitive Neuroscience, University College of London, Alexandra House, 17-19 Queen Square, London WC1N 3AR, United Kingdom Institute of Cognitive Neuroscience University College of London Alexandra House 17-19 Queen Square London WC1N 3AR United Kingdom 3 Wellcome Centre for Human Neuroimaging, University College London, WC1N 3BG London, United Kingdom Wellcome Centre for Human Neuroimaging University College London London WC1N 3BG United Kingdom 4 RIKEN Center for Advanced Intelligence Project, ATR Institute International, Kyoto, Japan RIKEN Center for Advanced Intelligence Project ATR Institute International Kyoto Japan Highlights \u2022 We present how human learners avoid generalization issues found in machine learning. \u2022 We propose a general model explaining how the brain may simplify complex problems. \u2022 Synergy between cognitive functions and reinforcement learning allows simplification. \u2022 Recurrent loops between basal ganglia and cortex form the neuroanatomical substrate. \u2022 Neural oscillatory frequencies provide the computational means to reach convergence. Artificial intelligence algorithms are capable of fantastic exploits, yet they are still grossly inefficient compared with the brain\u2019s ability to learn from few exemplars or solve problems that have not been explicitly defined. What is the secret that the evolution of human intelligence has unlocked? Generalization is one answer, but there is more to it. The brain does not directly solve difficult problems, it is able to recast them into new and more tractable problems. Here, we propose a model whereby higher cognitive functions profoundly interact with reinforcement learning to drastically reduce the degrees of freedom of the search space, simplifying complex problems, and fostering more efficient learning. Current Opinion in Neurobiology 2019, 55:133\u2013141 This review comes from a themed issue on Machine learning, big data, and neuroscience Edited by Jonathan Pillow and Maneesh Sahani For a complete overview see the Issue and the Editorial Available online 3rd April 2019 https://doi.org/10.1016/j.conb.2019.02.011 0959-4388/\u00a9 2019 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Introduction Artificial Intelligence (AI) has come a long way since the summer of 1956, when it was first envisaged at the Dartmouth Summer Research Project on Artificial Intelligence. In the last ten years, we have witnessed how the principles of supervised and reinforcement learning, when embedded in neural networks composed of many hidden layers (\u2018deep neural networks\u2019, or \u2018DNN\u2019), can reach \u2013 and often surpass \u2013 human-level performances in visual object recognition, and in playing video-games and GO [1\u20133]. Despite DNN\u2019s massive computational capabilities, there are two aspects that temper these accomplishments: first, the number of training samples required to reach acceptable performances is huge - tens or hundreds of millions; second, these architectures show a limited ability to generalize to new tasks/settings that were not encountered during training. These limitations become largely evident in motor control as shown by the clumsy behavior of humanoid robots in the DARPA robotic challenge [4]. A second avenue of exciting progress in AI has come from probabilistic machine learning (a.k.a. Bayesian machine learning) [5], where agents can achieve impressive performance on one-shot learning or using a limited amount of examples [6,7]. This probabilistic approach resonates well with intuitive theories of human cognitive development and inductive reasoning [8]. The learning algorithm tries to find among all possible models the one that best explains the data (or, by extension, infer what causes the reality perceived through the sensorium). This approach, while conceptually appealing, is unlikely to provide a realistic model of how the brain operates. The main issue is that fully probabilistic inference might work well in simple and well constrained conditions, but becomes quickly computationally intractable for more complex and unconstrained scenarios. To exacerbate the problem, in order to function efficiently, probabilistic programs have to be endowed with ad-hoc definitions of the necessary representations [5]. Strictly speaking, in Bayesian inference we usually do not have a principled way to select initial priors. Generalization is thus limited to the class of problems, for which the program was designed for [6,7]. A considerable hurdle for artificial agents concerns generalization; how can machine learning algorithms deal with new and never-experienced scenarios? Humans and animals can easily and appropriately respond to new scenarios, mostly transferring knowledge acquired in loosely related contexts. What are the brain mechanisms that enable the human brain with its remarkable generalization capacity? Plain reinforcement learning is too slow, and hierarchical architectures [9], albeit ameliorating the algorithm by subdividing learning among multiple systems and meta-variables [10,11\u2022 ], remain dependent on the need for ad-hoc definitions. Here, we suggest that brains do not simply solve supervised classification problems but transform them into different \u2013 and more tractable \u2013 problems. We propose that an adaptive role of higher cognition is to allow precisely this transformation to take place. More specifically, we propose a model of how higher cognition is able to simultaneously operate the dimensionality reduction and feature selection processes necessary for simplifying complex problems. Adjusting the degree of synchronization between neurons has been suggested as one possible way to control the degrees-of freedom of a neural system [12]. We draw on similarities with simulated annealing, exploring how different frequency modes of brain dynamics serve as inherent implementation channels to reduce degrees-of-freedom and reach optimal solutions. Computational advantages of higher cognitive functions in learning Statistical learning theory of singular problems demonstrates that the generalization error is given by dividing the degrees-of-freedom (d) of the search space by the number of training sample (n): e \u221d d / ( 2 n ) [13,14\u2022 ]. If brains (d \u223c 1011 neurons) need to solve arbitrary classification problems utilizing only a few hundred learning samples (n \u223c 102), the generalization error would become huge, at least 1011/102 = 109. We postulate that brains transform these intractable learning problems into more feasible reinforcement learning problems with small degrees of freedom while being guided by reward and penalty. Higher cognitive functions such as attention, memory, concept formation, and metacognition might find low-dimensional manifolds of meta-representations that are essential for learning from a small sample (Figure 1 ). Here, we will briefly review findings from attention, memory, concept formation, and metacognition, focusing on their role in facilitating learning. We are aware that these are vast and active areas of investigation and that it would be hard to do justice to all the relevant work that has been done. We have, therefore, decided to provide a snapshot of properties, modules and architectures that we believe are particularly relevant to inspire the development of new AI architectures. It is important to recognize that a recent work in the field of machine learning has also started to incorporate some of the intuitions discussed here. Attention is the ability to direct computing resources toward relevant dimensions (stimulus attributes, spatial location, etc.) for focal processing, acting as a filter to amplify relevant information while dampening background clutter [15]. But how does an agent learn what to attend? Rewards and punishments serve to constrain attentional focus [16], and attending to specific features rather than to the whole improves versatility [17]. Essentially, we learn what to attend to at the same time as we are paying attention to what we are learning [18,19\u2022 ]. In machine learning, a useful and efficient way to use attention mechanisms is to decompose tasks or questions into a series of simpler operations [20], or target specific parts of a query (e.g. particular words in a sentence) [21]. An intelligent agent must also be able to remember or even sometime forget past events. Accordingly, episodic memory plays a special role in goal-directed behavior and learning [22]. Reality is statistically structured however, and forms of gist-like memory can enhance reinforcement learning [23\u2022\u2022 ]. Schematic memory still depends on episodes; it is by virtue of statistics over individual traces that summaries can be created. Not surprisingly, both persistence (remembering) and transience (forgetting) are essential ingredients to optimize decision-making [24]. Human-like memory processes are very different from what is usually considered in AI agents, where memory is often deterministic and non-sparse as well as storing all information. Linking neural networks to external buffer memory resources already produces impressive learning capabilities, unattainable by classic neural networks architectures [25,26\u2022 ]. The development of predictive memory architectures, where memory formation itself is guided by a process of predictive inference [27], is one step toward systems storing only relevant information. Concepts are abstractions, closely intertwined with schematic memories. Concepts can be created almost at will, and a key aspect is that they can be connected, creating conceptual maps [28]. Being highly hierarchical and compositional, more abstract concepts can be formed from existing ones. New concepts or conceptual maps can emerge from learning, but can also direct subsequent learning [29]. Concepts share obvious links with memory in their ability to represent schematized information, but work in AI has not yet capitalized on this approach. Conceptual representations in AI are currently restricted to simple visual domain examples that make use of the principles of hierarchy and compositionality [30]. Self-monitoring processes, a more abstract class of cognitive functions, can encompass much richer representations. The ability to monitor one\u2019s thoughts is referred to as metacognition, and is linked to the psychological construct of confidence, that is, how good an agent is at keeping track of the probability of a choice being correct [31,32]. This aspect is very important for AI since it dovetails with a broad range of phenomena such as error monitoring and reality checking [33]. Of particular relevance to AI systems is the ability to explicitly track the evolution of the level of self-knowledge, which might provide biological agents with significant advantages when interacting with their environment [34\u201338]. Although metacognition and consciousness are intimately related, the question of what is the computational advantage of consciousness itself remains currently unanswered. Consciousness could represent the selection of information for global broadcasting within the system, making it flexibly available for local (and distant) computational units [33]. In machine learning consciousness could also be interpreted as a powerful constraint on low-dimensional representations [39\u2022 ]. Earlier efforts suggest that some forms of self-monitoring are computationally simple and can directly arise even in two-layer attractor networks [40]. Generative adversarial networks (GANs) are an exciting development in this direction: a generative model captures the data distribution, and a discriminative model, akin to metacognition, operates a reality check on new samples [41]. Neural implementation of high level cognitive architecture To generate solutions leading to efficient learning and flexible behaviors, nature had to solve a number of physical constraints. The brain cannot be equipped with ad hoc representations for every possible event in the world, since the horizon of possible states is practically infinite; moreover, it does not have unlimited computing resources. Understanding how the brain has overcome these constraints may be inspirational for developing new AI, yet it is important to keep in mind that some biological constraints (e.g. positive neuronal firing rates) may be bypassed by in-silico intelligent systems. In its most basic interpretation, solving complex problems for the brain accounts to finding the relevant (hidden) states for RL. One solution to accelerate the search for hidden states is to capitalize on the brain\u2019s massively parallelized neural circuit architecture. Parallel searches are instantiated in multiple recurrent circuits linking basal ganglia with the cortex (Figure 2 ). These recurrent circuits effectively are information-transmitting loops (bi-directional and closed neural-circuit connections between basal ganglia and cortex): they can carry task-dependent explicit representations (stimuli, goals, etc.), abstract summaries, reward prediction errors (RPEs), and predicted states. Although parallel loops carry heterogeneous information, they do not function independently from each other. Rather, loops formed by sparse neural populations continuously interact at the synaptic level through cooperation and competition. Excitatory interactions (cooperation) appear between loops with similar, inclusive and related representations. In contrast, inhibitory interactions (competition) develop between loops with exclusive, different or unrelated representations. Because of the dynamic nature of the neural networks comprising these excitatory and inhibitory interactions, a winner-take-all scenario emerges [42,43]. That is, only the loop with the \u2018best\u2019 representation survives while other loops are suppressed. Here \u2018best\u2019 means the loop associated with the representation that minimizes RPE. Therefore, the selection of the best loop essentially corresponds to the automatic selection of relevant states for RL. Excitatory and inhibitory interactions can occur virtually anywhere in the brain. However, the basal ganglia, a group of structures located deep within the cerebral hemispheres, should play the most important role in these synaptic interactions for the following reasons: (1) multiple inhibitions and direct, indirect, as well as hyperdirect pathways link basal ganglia to cortex; therefore, winner-take-all computations can best be implemented in basal ganglia [43,44]. (2) RPEs are largely computed in basal ganglia [45], making these nuclei the ideal focal point for the comparison and selection of loops carrying the smallest RPEs. So far, we have discussed a relatively simplified model that is amenable to clearly delineate the theory. The reality of the brain is nevertheless more intricate. Several brain areas are likely interacting to orchestrate an efficient search and ensure convergence to task-relevant low-dimensional manifolds. Prefrontal, sensorimotor, hippocampal cortices, as well as cerebellum, thalamus, and basal ganglia all share recurrent connections. Above this automatic machinery, what is the role of higher cognitive functions? How can they further accelerate learning computations? Metacognition, attention and memory synchronize abstract representations in prefrontal cortex (PFC) or hippocampal formation (HPC) with concrete representations in sensorimotor areas. Recurrent connections between these cortico-striatal regions connect reinforcement learning mechanisms with representational and abstraction engines that makes for an ideal candidate circuitry (Figure 2). Dopamine inputs to the HPC ensure that learned or partially learned rules are conceptualized and stored in memory [46]. But HPC function stretches far beyond memories, and one influential idea is that it plays a key role in building cognitive maps for spatial [47] and conceptual navigation [28]. HPC neurons functionality probably extends so that they take the role of predictive units extracting structure and low-dimensional bases of the world [48,49\u2022 ]. These discoveries are in line with a recent proposal that during decision making, inferable state-to-state transitions represented in the cortex keep track of the evolving hidden space to accelerate learning [50,51]. More specifically, the PFC is thought to hold an exclusive position along the hierarchy of representations as the substrate forging meta-representations [11\u2022 ,31] and abstraction processes [10,52,53]. Furthermore, the PFC oscillatory frequencies act as mediators of abstraction: the synchronization frequency helps shuffle the abstraction level encoded in different regions of the PFC [54\u2022\u2022 ]. In fact, this extends well beyond the PFC; oscillatory frequencies effectively form communication channels throughout the brain [54\u2022\u2022 ,55\u201357]. At the neuronal level, one way to discover correlations between meta-representations and RPEs is to characterize these representations as statistical distributions in neural population activities. The cortex could perform probabilistic inference on such distributions either by sampling over neural populations [58], or by weighting correlations between neurons [59]. Learning new problems should invariably start with a consistent scenario: ignition of myriads of parallel loops resulting in widespread neural activity over extensive cortico-striatal networks. The selection of RL states starts with broad sweeps to evolve in a fine search. Initially, broad brain regions are equally activated and participate in the search. Next, dimension reduction and feature selection begin, in parallel, to drop-out less activated loops, a process accelerated by higher cognition such as attention, memory, metacognition (Figure 2). In the end, only a small number of loops will remain activated and neural activity should be concentrated to the few cortical locations carrying the most relevant representations and the corresponding parts of basal ganglia. A useful analogy for this search from broad to fine neural substrates (and representations) is simulated annealing or Gibbs sampling, optimization techniques to approximate global solutions in large search spaces [60,61]. For example, annealing starts by first using high temperatures causing large changes in the objective function, then iteratively descending to lower temperatures causing ever smaller rearrangements \u2014 until convergence. Furthermore, to extend this analogy, high temperatures are depicted as a form of dimension reduction, while low temperatures as akin to feature selection. We suggest that dimension reduction relates to abstraction, operating at low oscillatory frequency modes with low spatial resolution and using large neural populations, while feature selection relates to specific content utilizing high frequency modes and sparse neural ensembles (Figure 3 a). By frequency modes here we mean specific bands in neural oscillation frequencies \u2013 that is, the frequency at which neuronal populations show synchronized activity. Low frequency synchronization delineates the horizon of relevant dimensions so that high frequency-based feature selection can happen. To note, the direction of search from broad to fine holds in terms of brain areas/neural networks involved; but in terms of abstraction, the search directionality of the model discussed here is unconstrained. The key intuition is that in the brain the processes of dimension reduction and feature selection should take place simultaneously, accelerating interaction and winner-take-all convergence of loop drop-out (Figure 3b). A recent work has elegantly linked the brain\u2019s structural connectivity (particularly the thalamo-cortical system) with neural activity patterns and dynamics, providing a formal basis for harmonic patterns of certain frequencies [62\u2022\u2022 ]. The authors of this work demonstrate that these connectome-specific harmonics patterns self-organize through the interplay of neural excitation and inhibition in coupled dynamical systems. We can now delineate how cognitive functions may affect and expedite learning processes. We have proposed a system composed of massively parallelized modules centered around an RL machinery, where communication frequency determines the abstraction level of representations, and where cognitive functions have the ability to synchronize representations at different abstraction levels. At the very outset the search is characterized by activity over broad areas of the brain, but the system is typified by low abstraction and little synchronization. RPEs may be tied to any aspects of the task, with most RPEs being unspecific and irrelevant. Conceptualization or integration of (task, instruction) rules, together with visuospatial attention [63], can generate the first optimal low-frequency modes, leading an initial dimensionality reduction to define the search horizon where specific features can be selected. Attention and episodic memory also play important roles from the initial stages for the selection of relevant features (i.e. loops) [64\u2022\u2022 ] through synchronization in high spatiotemporal-frequency channels [55,65], nested within low-frequency modes. As learning progresses, high-frequency feature-specific RPEs become predominant [64\u2022\u2022 ,66], and the number of activated loops greatly decreases. The abstraction level is maintained high because feature-specific RPEs can be represented in summarized fashion, hence further reducing the dimensionality and complexity of the problem. Hidden states in reinforcement learning can now be discovered more readily because the search domain has shrunk. Importantly, the degree of certainty or uncertainty on neural meta-representations can provide a fast track to which states are relevant or irrelevant in reinforcement learning, by virtue of metacognition self-monitoring properties [33]. Finally, consciousness itself may lead learning to the highest level of abstraction. Conscious representation of the relevant states or decision policies can be interpreted as a maximally abstract summary, a tensor with very low dimensionality that nevertheless carries all the fundamental information [39\u2022 ]. These meta-representation vectors are extremely useful for generalization because they can be easily applied to new, previously unexperienced, problems. Conclusions Fruitful interactions between neuroscience and AI have opened up a new exciting era beyond DNN, which require huge training samples. Brains utilize higher cognitive functions such as attention, memory, concept formation, and metacognition to transform seemingly intractable supervised learning problems with astronomical degrees-of-freedom state spaces and small samples, into reasonable reinforcement learning problems within a low-dimension meta-representation manifold. We postulated that the neuronal mechanism implementing this transformation of computational problems is likely comprises parallel search of low-dimensional meta-representations via synchronization of multiple loops formed by the cerebral cortex, HPC and basal ganglia. Brain connectivity and nonlinear neural dynamics provide harmonic modes spanning from low to high spatiotemporal frequencies. Interactions between different modes may provide dimension reduction and feature selection analogous to simulated annealing, albeit much faster. That is, low frequency mode could allow for dimension reduction analogous to high temperature in annealing, while high frequency modes could select a small number of features analogous to low temperature. Furthermore, real-time interactions between high and low frequency modes may enable fast parallel searches to quickly determine the reinforcement learning search domain. Attention and episodic memory are presumed mechanisms operating feature selection, while conceptualization mainly takes the form of dimension reduction. Discovery of relevant hidden states may be greatly accelerated by metacognition through synchronization of meta-representations. Taken together these cognitive modules, acquired over millions of years by natural selection, might inspire a new generation of AI architectures that will take us one step closer to human level intelligence. Conflict of interest statement Nothing declared. References and recommended reading Papers of particular interest, published within the period of review, have been highlighted as: \u2022 of special interest \u2022\u2022 of outstanding interest Acknowledgements A.C. and M.K. were supported by the New Energy and Industrial Technology Development Organization (NEDO) and the ImPACT Program of Council for Science, Technology and Innovation, Cabinet Office, Government of Japan; A.C. was supported by JST ERATO (grant number JPMJER1801), and AMED (grant number JP18dm0307008); B.D.M. was supported by the Wellcome Trust and Royal Society (Sir Henry Dale Fellowship 102612/A/13/Z). References 1 K. He X. Zhang S. Ren J. Sun Delving deep into rectifiers: surpassing human-level performance on imagenet classification Proceedings of the IEEE International Conference on Computer Vision 2015 1026 1034 2 Y. LeCun Y. Bengio G. Hinton Deep learning Nature 521 2015 436 444 3 D. Silver A. Huang C. Maddison A. Guez L. Sifre G. Driessche J. Schrittwieser I. Antonoglou V. Panneershelvam M. Lanctot Mastering the game of Go with deep neural networks and tree search Nature 529 2016 484 489 4 C.G. Atkeson P.W.B. Benzun N. Banerjee D. Berenson C.P. Bove X. Cui M. DeDonato R. Du S. Feng P. Franklin What happened at the DARPA robotics challenge finals M. Spenko S. Buerger K. Iagnemma The DARPA Robotics Challenge Finals: Humanoid Robots to the Rescue 2018 Springer International Publishing 667 684 5 Z. Ghahramani Probabilistic machine learning and artificial intelligence Nature 521 2015 452 459 6 B. Lake R. Salakhutdinov J. Tenenbaum Human-level concept learning through probabilistic program induction Science 350 2015 1332 1338 7 D. George W. Lehrach K. Kansky M. L\u00e1zaro-Gredilla C. Laan B. Marthi X. Lou Z. Meng Y. Liu H. Wang A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs Science 358 2017 eaag2612 8 B.M. Lake T.D. Ullman J.B. Tenenbaum S. Gershman Building machines that learn and think like people Behav Brain Sci 40 2017 e253 9 M. Kawato K. Samejima Efficient reinforcement learning: computational theories, neuroscience and robotics Curr Opin Neurobiol 17 2007 205 212 10 T.J. Buschman E.K. Miller Goal-direction and top-down control Philos Trans R Soc Lond B Biol Sci 369 2014 20130471\u201320130471 11\u2022 J.X. Wang Z. Kurth-Nelson D. Kumaran D. Tirumala H. Soyer J.Z. Leibo D. Hassabis M. Botvinick Prefrontal cortex as a meta-reinforcement learning system Nat Neurosci 21 2018 860 868 10.1038/s41593-018-0147-8 Stems from previous intuitions that basal ganglia and prefrontal cortex are two independent learning system. The paper proposes that dopamine from the basal ganglia learning system is used to train an independent, slower but more general and efficient (meta-)learning system in the prefrontal cortex. 12 I.T. Tokuda H. Hoang M. Kawato New insights into olivo-cerebellar circuits for learning from a small training sample Curr Opin Neurobiol 46 2017 58 67 13 S. Watanabe Algebraic Geometry and Statistical Learning Theory 2009 Cambridge University Press 14\u2022 K. Yamazaki Asymptotic accuracy of distribution-based estimation of latent variables J Mach Learn Res 15 2014 3541 3562 This is a theoretical paper that introduces a formal framework for error bounds in statistical learning theory. The author dealt with the generalization error of latent variables in singular cases of machine learning. 15 K. Xu J. Ba R. Kiros K. Cho A. Courville R. Salakhutdinov R. Zemel Y. Bengio Show, attend and tell: neural image caption generation with visual attention arXiv [csLG] 2015 International conference on machine learning, 2048-2057 16 J. Lee S. Shomstein The differential effects of reward on space- and object-based attentional allocation J Neurosci 33 2013 10625 10633 17 S. Farashahi K. Rowe Z. Aslami D. Lee A. Soltani Feature-based learning improves adaptability without compromising precision Nat Commun 8 2017 1768 18 S.C.-H. Yang D.M. Wolpert M. Lengyel Theoretical perspectives on active sensing Curr Opin Behav Sci 11 2016 100 108 19\u2022 Y.C. Leong A. Radulescu R. Daniel V. DeWoskin Y. Niv Dynamic interaction between reinforcement learning and attention in multidimensional environments Neuron 93 2017 451 463 The authors used model-based fMRI and eye tracking to follow trial-by-trial fluctuations in attention while participants performed a decision-making task in a multidimensional environment. Results indicate a bidirectional interaction between attention and learning: attention constraints learning to relevant dimensions, while the question of \u2018what to attend\u2019 is driven by reinforcement learning. 20 D.A. Hudson C.D. Manning Compositional attention networks for machine reasoning arXiv 2018 1803.03067 21 M.-T. Luong H. Pham C.D. Manning Effective approaches to attention-based neural machine translation arXiv 2015 1508.04025 22 M. Lengyel P. Dayan Hippocampal contributions to control: the third way J.C. Platt D. Koller Y. Singer S.T. Roweis Advances in Neural Information Processing Systems 20 2008 Curran Associates, Inc. 889 896 23\u2022\u2022 A. Santoro P. Frankland B. Richards Memory transformation enhances reinforcement learning in dynamic environments J Neurosci 36 2016 12228 12242 This modeling study shows that switching from detailed episodic memory to more generalized and schematic memory is a useful strategy for reinforcement learning in changing environments. Using gist-like memories optimizes behavior over several timescales. 24 B. Richards P. Frankland The persistence and transience of memory Neuron 94 2017 1071 1084 25 A. Graves G. Wayne I. Danihelka Neural turing machines arXiv [csNE] 2014 1410.5401 26\u2022 A. Graves G. Wayne M. Reynolds T. Harley I. Danihelka A. Grabska-Barwi\u0144ska S.G. Colmenarejo E. Grefenstette T. Ramalho J. Agapiou Hybrid computing using a neural network with dynamic external memory Nature 538 2016 471 476 Building directly from neural turing machines, this paper introduces a machine learning model that can read from and write to an external memory buffer (like a standard computer), but learns to do so with data. The proposed architecture shows improved ability to solve complex and structured tasks. 27 G. Wayne C.-C. Hung D. Amos M. Mirza A. Ahuja A. Grabska-Barwinska J. Rae P. Mirowski J.Z. Leibo A. Santoro Unsupervised predictive memory in a goal-directed agent arXiv [csLG] 2018 1803.10760 28 A.O. Constantinescu J.X. O\u2019reilly T.E.J. Behrens Organizing conceptual knowledge in humans with a gridlike code Science 352 2016 1464 1468 29 M.L. Mack B.C. Love A.R. Preston Dynamic updating of hippocampal object representations reflects new conceptual knowledge Proc Natl Acad Sci U S A 113 2016 13203 13208 30 I. Higgins N. Sonnerat L. Matthey A. Pal C.P. Burgess M. Botvinick D. Hassabis A. Lerchner SCAN: learning abstract hierarchical compositional visual concepts arXiv [statML] 2017 1707.03389 31 A. Cortese K. Amano A. Koizumi M. Kawato H. Lau Multivoxel neurofeedback selectively modulates confidence without changing perceptual performance Nat Commun 7 2016 13669 32 A. Pouget J. Drugowitsch A. Kepecs Confidence and certainty: distinct probabilistic quantities for different goals Nat Neurosci 19 2016 366 374 33 S. Dehaene H. Lau S. Kouider What is consciousness, and could machines have it? Science 358 2017 486 492 34 K. Friston M. Lin C. Frith G. Pezzulo J. Hobson S. Ondobaka Active inference, curiosity and insight Neural Comput 29 2017 2633 2683 35 M.R. Nassar R.C. Wilson B. Heasly J.I. Gold An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment J Neurosci 30 2010 12366 12378 36 J.T. McGuire M.R. Nassar J.I. Gold J.W. Kable Functionally dissociable influences on learning rate in a dynamic environment Neuron 84 2014 870 881 37 M.M. Vaghi F. Luyckx A. Sule N.A. Fineberg T.W. Robbins B. De Martino Compulsivity reveals a novel dissociation between action and confidence Neuron 96 2017 348 354.e4 38 M. Guggenmos G. Wilbertz M. Hebart P. Sterzer Mesolimbic confidence signals guide perceptual learning in the absence of external feedback eLife 5 2016 39\u2022 Y. Bengio The consciousness prior arXiv [csLG] 2017 1709.08568 A formal proposal to model consciousness in machine learning. The approach is simple and amenable to current systems, considering consciousness as a vector containing simple statements drawn from summaries of the feature space. 40 A. Insabato M. Pannunzi E.T. Rolls G. Deco Confidence-related decision making J Neurophysiol 104 2010 539 547 41 I.J. Goodfellow J. Pouget-Abadie M. Mirza B. Xu D. Warde-Farley S. Ozair A. Courville Y. Bengio Generative adversarial nets Advances in Neural Information Processing Systems 27 2014 Curran Associates, Inc. 42 R.A. Jacobs M.I. Jordan S.J. Nowlan G.E. Hinton Adaptive mixtures of local experts Neural Comput 3 1991 79 87 43 S. Grossberg Contour enhancement, short term memory, and constancies in reverberating neural networks Stud Appl Math 52 1973 213 257 44 A.M. Graybiel T. Aosaki A.W. Flaherty M. Kimura The basal ganglia and adaptive motor control Science 265 1994 45 W. Schultz P. Dayan P.R. Montague A neural substrate of prediction and reward Science 275 1997 1593 1599 46 H. Du W. Deng J. Aimone M. Ge S. Parylak K. Walch W. Zhang J. Cook H. Song L. Wang Dopaminergic inputs in the dentate gyrus direct the choice of memory encoding Proc Natl Acad Sci U S A 113 2016 E5501 E5510 47 J. O\u2019Keefe J. Dostrovsky The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat Brain Res 34 1971 171 175 48 K. Stachenfeld M. Botvinick S. Gershman The hippocampus as a predictive map Nat Neurosci 20 2017 1643 1653 10.1038/nn.4650 49\u2022 D. Kumaran D. Hassabis J. McClelland What learning systems do intelligent agents need? Complementary learning systems theory updated Trends Cogn Sci 20 2016 512 534 A review of the complementary learning systems theory that integrates recent advances in neuroscience to draw a thorough picture of how hippocampus and neocortex support efficient learning and generalization. Furthermore, core principles of the theory and new findings are discussed in the machine learning context, with the prospect of designing new agents in artificial intelligence. 50 A. Funamizu B. Kuhn K. Doya Neural substrate of dynamic Bayesian inference in the cerebral cortex Nat Neurosci 19 2016 1682 1689 51 N.W. Schuck M.B. Cai R.C. Wilson Y. Niv Human orbitofrontal cortex represents a cognitive map of state space Neuron 91 2016 1402 1412 52 A. Sarma N. Masse X.-J. Wang D. Freedman Task-specific versus generalized mnemonic representations in parietal and prefrontal cortices Nat Neurosci 19 2015 nn.4168 53 C. Bowman D. Zeithamova Abstract memory representations in the ventromedial prefrontal cortex and hippocampus support concept generalization J Neurosci 38 2018 2605 2614 54\u2022\u2022 A. Wutz R. Loonis J. Roy J. Donoghue E. Miller Different levels of category abstraction by different dynamics in different prefrontal areas Neuron 97 2018 716 726 Different levels of category abstraction engage different oscillatory dynamics in different PFC areas. Lower-level categories are first extracted from bottom-up inputs to the ventrolateral PFC reflected in gamma power and spiking. Dorsolateral PFC encode at lower frequencies more abstract levels, depending on top-down processing. 55 A.M. Bastos J. Vezoli C.A. Bosman J.-M. Schoffelen R. Oostenveld J.R. Dowdall P. De Weerd H. Kennedy P. Fries Visual areas exert feedforward and feedback influences through distinct frequency channels Neuron 85 2015 390 401 56 A.B. Saleem A.D. Lien M. Krumin B. Haider M.R. Ros\u00f3n A. Ayaz K. Reinhold L. Busse M. Carandini K.D. Harris Subcortical source and modulation of the narrowband gamma oscillation in mouse visual cortex Neuron 93 2017 315 322 57 G. Buzs\u00e1ki A. Draguhn Neuronal oscillations in cortical networks Science 304 2004 1926 1929 58 G. Orb\u00e1n P. Berkes J. Fiser M. Lengyel Neural variability and sampling-based probabilistic representations in the visual cortex Neuron 92 2016 530 543 59 M.-B. Rub\u00e9n J. Beck I. Kanitscheider X. Pitkow P. Latham A. Pouget Information-limiting correlations Nat Neurosci 17 2014 1410 1417 60 S. Kirkpatrick C.D. Gelatt M.P. Vecchi Optimization by simulated annealing Science 220 1983 671 680 61 S. Geman D. Geman Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images IEEE Trans Pattern Anal Mach Intell 6 1984 721 741 62\u2022\u2022 S. Atasoy I. Donnelly J. Pearson Human brain networks function in connectome-specific harmonic waves Nat Commun 7 2016 10340 Seminal work showing that harmonic frequency modes naturally emerge from the brain\u2019s structural connectivity and excitatory-inhibitory networks dynamics. Different harmonic modes contain either low or high frequency both in space and time. These harmonic modes reproduce resting-state fMRI networks. 63 M. Lobier J.M. Palva S. Palva High-alpha band synchronization across frontal, parietal and visual cortex mediates behavioral and neuronal effects of visuospatial attention Neuroimage 165 2018 222 237 64\u2022\u2022 M. Oemisch S. Westendorff M. Azimi S.A. Hassani S. Ardid P. Tiesinga T. Womelsdorf Feature specific prediction errors and surprise across macaque fronto-striatal circuits during attention and learning Nat Commun 10 2019 176 10.1101/266205 Macaque fronto-striatal loops are the direct neural correlates of feature-specific prediction errors in multidimensional spaces. Learning reduces the number of loops involved, converging to specific traces representing the most important features. 65 B.P. Staresina S. Michelmann M. Bonnefond O. Jensen N. Axmacher J. Fell Hippocampal pattern completion is linked to gamma power increases and alpha power decreases during recollection eLife 5 2016 e17397 66 I. Saez J. Lin A. Stolk E. Chang J. Parvizi G. Schalk R.T. Knight M. Hsu Encoding of multiple reward-related computations in transient and sustained high-frequency activity in human OFC Curr Biol 28 2018 2889 2899.e3 67 M. Haruno M. Kawato Heterarchical reinforcement-learning model for integration of multiple cortico-striatal loops: fMRI examination in stimulus-action-reward association learning Neural Netw 19 2006 1242 1254", "scopus-id": "85063739404", "pubmed-id": "30953964", "coredata": {"eid": "1-s2.0-S0959438818301077", "dc:description": "Artificial intelligence algorithms are capable of fantastic exploits, yet they are still grossly inefficient compared with the brain\u2019s ability to learn from few exemplars or solve problems that have not been explicitly defined. What is the secret that the evolution of human intelligence has unlocked? Generalization is one answer, but there is more to it. The brain does not directly solve difficult problems, it is able to recast them into new and more tractable problems. Here, we propose a model whereby higher cognitive functions profoundly interact with reinforcement learning to drastically reduce the degrees of freedom of the search space, simplifying complex problems, and fostering more efficient learning.", "openArchiveArticle": "false", "prism:coverDate": "2019-04-30", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0959438818301077", "dc:creator": [{"@_fa": "true", "$": "Cortese, Aurelio"}, {"@_fa": "true", "$": "De Martino, Benedetto"}, {"@_fa": "true", "$": "Kawato, Mitsuo"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0959438818301077"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0959438818301077"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0959-4388(18)30107-7", "prism:volume": "55", "prism:publisher": "The Authors. Published by Elsevier Ltd.", "dc:title": "The neural and cognitive architecture for learning from a small sample", "prism:copyright": "\u00a9 2019 The Authors. Published by Elsevier Ltd.", "prism:issueName": "Machine Learning, Big Data, and Neuroscience", "openaccess": "1", "prism:issn": "09594388", "openaccessArticle": "true", "prism:publicationName": "Current Opinion in Neurobiology", "openaccessSponsorType": "Author", "prism:pageRange": "133-141", "prism:endingPage": "141", "prism:coverDisplayDate": "April 2019", "prism:doi": "10.1016/j.conb.2019.02.011", "prism:startingPage": "133", "dc:identifier": "doi:10.1016/j.conb.2019.02.011", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "160", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "13034", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "159", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "13239", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "122", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10985", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "489", "@width": "670", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "72283", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "529", "@width": "513", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "89360", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "429", "@width": "772", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "86567", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2168", "@width": "2969", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "622544", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2344", "@width": "2274", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "762210", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1900", "@width": "3420", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "815738", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "16", "@width": "78", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "313", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0959438818301077-am.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "AAM-PDF", "@size": "1015619", "@ref": "am", "@mimetype": "application/pdf"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85063739404"}}
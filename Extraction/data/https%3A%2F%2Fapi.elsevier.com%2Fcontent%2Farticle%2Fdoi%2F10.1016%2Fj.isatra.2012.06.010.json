{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0019057812000894", "dc:identifier": "doi:10.1016/j.isatra.2012.06.010", "eid": "1-s2.0-S0019057812000894", "prism:doi": "10.1016/j.isatra.2012.06.010", "pii": "S0019-0578(12)00089-4", "dc:title": "Optimal control in microgrid using multi-agent reinforcement learning ", "prism:publicationName": "ISA Transactions", "prism:aggregationType": "Journal", "prism:issn": "00190578", "prism:volume": "51", "prism:issueIdentifier": "6", "prism:startingPage": "743", "prism:endingPage": "751", "prism:pageRange": "743-751", "prism:number": "6", "dc:format": "application/json", "prism:coverDate": "2012-11-30", "prism:coverDisplayDate": "November 2012", "prism:copyright": "Copyright \u00a9 2012 ISA. Published by Elsevier Ltd. All rights reserved.", "prism:publisher": "ISA. Published by Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Li, Fu-Dong"}, {"@_fa": "true", "$": "Wu, Min"}, {"@_fa": "true", "$": "He, Yong"}, {"@_fa": "true", "$": "Chen, Xin"}], "dc:description": "\n               Abstract\n               \n                  This paper presents an improved reinforcement learning method to minimize electricity costs on the premise of satisfying the power balance and generation limit of units in a microgrid with grid-connected mode. Firstly, the microgrid control requirements are analyzed and the objective function of optimal control for microgrid is proposed. Then, a state variable \u201cAverage Electricity Price Trend\u201d which is used to express the most possible transitions of the system is developed so as to reduce the complexity and randomicity of the microgrid, and a multi-agent architecture including agents, state variables, action variables and reward function is formulated. Furthermore, dynamic hierarchical reinforcement learning, based on change rate of key state variable, is established to carry out optimal policy exploration. The analysis shows that the proposed method is beneficial to handle the problem of \u201ccurse of dimensionality\u201d and speed up learning in the unknown large-scale world. Finally, the simulation results under JADE (Java Agent Development Framework) demonstrate the validity of the presented method in optimal control for a microgrid with grid-connected mode.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Distributed generation"}, {"@_fa": "true", "$": "Microgrid"}, {"@_fa": "true", "$": "Multi-agent system"}, {"@_fa": "true", "$": "Reinforcement learning"}, {"@_fa": "true", "$": "MAXQ"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0019057812000894", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0019057812000894", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84866406146", "scopus-eid": "2-s2.0-84866406146", "pubmed-id": "22824135", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84866406146", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20120721", "$": "2012-07-21"}}}}}
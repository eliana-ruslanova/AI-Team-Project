{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608007001682", "dc:identifier": "doi:10.1016/j.neunet.2007.09.016", "eid": "1-s2.0-S0893608007001682", "prism:doi": "10.1016/j.neunet.2007.09.016", "pii": "S0893-6080(07)00168-2", "dc:title": "SOVEREIGN: An autonomous neural system for incrementally learning planned action sequences to navigate towards a rewarded goal ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "21", "prism:issueIdentifier": "5", "prism:startingPage": "699", "prism:endingPage": "758", "prism:pageRange": "699-758", "prism:number": "5", "dc:format": "application/json", "prism:coverDate": "2008-06-30", "prism:coverDisplayDate": "June 2008", "prism:copyright": "Copyright \u00a9 2007 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Gnadt, William"}, {"@_fa": "true", "$": "Grossberg, Stephen"}], "dc:description": "\n               Abstract\n               \n                  How do reactive and planned behaviors interact in real time? How are sequences of such behaviors released at appropriate times during autonomous navigation to realize valued goals? Controllers for both animals and mobile robots, or animats, need reactive mechanisms for exploration, and learned plans to reach goal objects once an environment becomes familiar. The SOVEREIGN (Self-Organizing, Vision, Expectation, Recognition, Emotion, Intelligent, Goal-oriented Navigation) animat model embodies these capabilities, and is tested in a 3D virtual reality environment. SOVEREIGN includes several interacting subsystems which model complementary properties of cortical What and Where processing streams and which clarify similarities between mechanisms for navigation and arm movement control. As the animat explores an environment, visual inputs are processed by networks that are sensitive to visual form and motion in the What and Where streams, respectively. Position-invariant and size-invariant recognition categories are learned by real-time incremental learning in the What stream. Estimates of target position relative to the animat are computed in the Where stream, and can activate approach movements toward the target. Motion cues from animat locomotion can elicit head-orienting movements to bring a new target into view. Approach and orienting movements are alternately performed during animat navigation. Cumulative estimates of each movement are derived from interacting proprioceptive and visual cues. Movement sequences are stored within a motor working memory. Sequences of visual categories are stored in a sensory working memory. These working memories trigger learning of sensory and motor sequence categories, or plans, which together control planned movements. Predictively effective chunk combinations are selectively enhanced via reinforcement learning when the animat is rewarded. Selected planning chunks effect a gradual transition from variable reactive exploratory movements to efficient goal-oriented planned movement sequences. Volitional signals gate interactions between model subsystems and the release of overt behaviors. The model can control different motor sequences under different motivational states and learns more efficient sequences to rewarded goals as exploration proceeds.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Autonomous control"}, {"@_fa": "true", "$": "Pattern recognition"}, {"@_fa": "true", "$": "Categorization"}, {"@_fa": "true", "$": "Navigation"}, {"@_fa": "true", "$": "Attention"}, {"@_fa": "true", "$": "Reinforcement learning"}, {"@_fa": "true", "$": "Working memory"}, {"@_fa": "true", "$": "Planning"}, {"@_fa": "true", "$": "ART. CogEM"}, {"@_fa": "true", "$": "Gated dipole"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608007001682", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608007001682", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "44649089467", "scopus-eid": "2-s2.0-44649089467", "pubmed-id": "17996419", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/44649089467", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20071007", "$": "2007-10-07"}}}}}
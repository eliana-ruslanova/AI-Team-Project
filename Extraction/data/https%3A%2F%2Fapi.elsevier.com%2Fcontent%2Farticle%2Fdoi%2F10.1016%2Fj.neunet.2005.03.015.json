{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608005000833", "dc:identifier": "doi:10.1016/j.neunet.2005.03.015", "eid": "1-s2.0-S0893608005000833", "prism:doi": "10.1016/j.neunet.2005.03.015", "pii": "S0893-6080(05)00083-3", "dc:title": "Global exponential stability of generalized recurrent neural networks with discrete and distributed delays ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "19", "prism:issueIdentifier": "5", "prism:startingPage": "667", "prism:endingPage": "675", "prism:pageRange": "667-675", "prism:number": "5", "dc:format": "application/json", "prism:coverDate": "2006-06-30", "prism:coverDisplayDate": "June 2006", "prism:copyright": "Copyright \u00a9 2005 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Liu, Yurong"}, {"@_fa": "true", "$": "Wang, Zidong"}, {"@_fa": "true", "$": "Liu, Xiaohui"}], "dc:description": "\n               Abstract\n               \n                  This paper is concerned with analysis problem for the global exponential stability of a class of recurrent neural networks (RNNs) with mixed discrete and distributed delays. We first prove the existence and uniqueness of the equilibrium point under mild conditions, assuming neither differentiability nor strict monotonicity for the activation function. Then, by employing a new Lyapunov\u2013Krasovskii functional, a linear matrix inequality (LMI) approach is developed to establish sufficient conditions for the RNNs to be globally exponentially stable. Therefore, the global exponential stability of the delayed RNNs can be easily checked by utilizing the numerically efficient Matlab LMI toolbox, and no tuning of parameters is required. A simulation example is exploited to show the usefulness of the derived LMI-based stability conditions.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Generalized recurrent neural networks"}, {"@_fa": "true", "$": "Discrete and distributed delays"}, {"@_fa": "true", "$": "Lyapunov\u2013Krasovskii functional"}, {"@_fa": "true", "$": "Global exponential stability"}, {"@_fa": "true", "$": "Global asymptotic stability"}, {"@_fa": "true", "$": "Linear matrix inequality"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608005000833", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608005000833", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "33646511197", "scopus-eid": "2-s2.0-33646511197", "pubmed-id": "16046098", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/33646511197", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20050720", "$": "2005-07-20"}}}}}
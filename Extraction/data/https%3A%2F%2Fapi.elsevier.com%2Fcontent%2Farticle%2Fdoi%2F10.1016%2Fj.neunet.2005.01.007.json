{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S089360800500047X", "dc:identifier": "doi:10.1016/j.neunet.2005.01.007", "eid": "1-s2.0-S089360800500047X", "prism:doi": "10.1016/j.neunet.2005.01.007", "pii": "S0893-6080(05)00047-X", "dc:title": "Data-partitioning using the Hilbert space filling curves: Effect on the speed of convergence of Fuzzy ARTMAP for large database problems ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "18", "prism:issueIdentifier": "7", "prism:startingPage": "967", "prism:endingPage": "984", "prism:pageRange": "967-984", "prism:number": "7", "dc:format": "application/json", "prism:coverDate": "2005-09-30", "prism:coverDisplayDate": "September 2005", "prism:copyright": "Copyright \u00a9 2005 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Castro, Jos\u00e9"}, {"@_fa": "true", "$": "Georgiopoulos, Michael"}, {"@_fa": "true", "$": "Demara, Ronald"}, {"@_fa": "true", "$": "Gonzalez, Avelino"}], "dc:description": "\n               Abstract\n               \n                  The Fuzzy ARTMAP algorithm has been proven to be one of the premier neural network architectures for classification problems. One of the properties of Fuzzy ARTMAP, which can be both an asset and a liability, is its capacity to produce new nodes (templates) on demand to represent classification categories. This property allows Fuzzy ARTMAP to automatically adapt to the database without having to a priori specify its network size. On the other hand, it has the undesirable side effect that large databases might produce a large network size (node proliferation) that can dramatically slow down the training speed of the algorithm. To address the slow convergence speed of Fuzzy ARTMAP for large database problems, we propose the use of space-filling curves, specifically the Hilbert space-filling curves (HSFC). Hilbert space-filling curves allow us to divide the problem into smaller sub-problems, each focusing on a smaller than the original dataset. For learning each partition of data, a different Fuzzy ARTMAP network is used. Through this divide-and-conquer approach we are avoiding the node proliferation problem, and consequently we speedup Fuzzy ARTMAP's training. Results have been produced for a two-class, 16-dimensional Gaussian data, and on the Forest database, available at the UCI repository. Our results indicate that the Hilbert space-filling curve approach reduces the time that it takes to train Fuzzy ARTMAP without affecting the generalization performance attained by Fuzzy ARTMAP trained on the original large dataset. Given that the resulting smaller datasets that the HSFC approach produces can independently be learned by different Fuzzy ARTMAP networks, we have also implemented and tested a parallel implementation of this approach on a Beowulf cluster of workstations that further speeds up Fuzzy ARTMAP's convergence to a solution for large database problems.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Fuzzy-ARTMAP"}, {"@_fa": "true", "$": "Hilbert space-filling curve"}, {"@_fa": "true", "$": "Data mining"}, {"@_fa": "true", "$": "Data-partitioning"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S089360800500047X", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S089360800500047X", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "24344450095", "scopus-eid": "2-s2.0-24344450095", "pubmed-id": "15922562", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/24344450095", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20050526", "$": "2005-05-26"}}}}}
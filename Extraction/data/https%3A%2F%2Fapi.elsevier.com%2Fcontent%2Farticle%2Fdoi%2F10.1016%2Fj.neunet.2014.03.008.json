{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608014000719", "dc:identifier": "doi:10.1016/j.neunet.2014.03.008", "eid": "1-s2.0-S0893608014000719", "prism:doi": "10.1016/j.neunet.2014.03.008", "pii": "S0893-6080(14)00071-9", "dc:title": "Discrete-time online learning control for a class of unknown nonaffine nonlinear systems using reinforcement learning ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "55", "prism:startingPage": "30", "prism:endingPage": "41", "prism:pageRange": "30-41", "dc:format": "application/json", "prism:coverDate": "2014-07-31", "prism:coverDisplayDate": "July 2014", "prism:copyright": "Copyright \u00a9 2014 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Yang, Xiong"}, {"@_fa": "true", "$": "Liu, Derong"}, {"@_fa": "true", "$": "Wang, Ding"}, {"@_fa": "true", "$": "Wei, Qinglai"}], "dc:description": "\n               Abstract\n               \n                  In this paper, a reinforcement-learning-based direct adaptive control is developed to deliver a desired tracking performance for a class of discrete-time (DT) nonlinear systems with unknown bounded disturbances. We investigate multi-input\u2013multi-output unknown nonaffine nonlinear DT systems and employ two neural networks (NNs). By using Implicit Function Theorem, an action NN is used to generate the control signal and it is also designed to cancel the nonlinearity of unknown DT systems, for purpose of utilizing feedback linearization methods. On the other hand, a critic NN is applied to estimate the cost function, which satisfies the recursive equations derived from heuristic dynamic programming. The weights of both the action NN and the critic NN are directly updated online instead of offline training. By utilizing Lyapunov\u2019s direct method, the closed-loop tracking errors and the NN estimated weights are demonstrated to be uniformly ultimately bounded. Two numerical examples are provided to show the effectiveness of the present approach.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Adaptive critic design"}, {"@_fa": "true", "$": "Neural network"}, {"@_fa": "true", "$": "Nonaffine nonlinear system"}, {"@_fa": "true", "$": "Online learning"}, {"@_fa": "true", "$": "Reinforcement learning"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608014000719", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608014000719", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84897950099", "scopus-eid": "2-s2.0-84897950099", "pubmed-id": "24721223", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84897950099", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20140328", "$": "2014-03-28"}}}}}
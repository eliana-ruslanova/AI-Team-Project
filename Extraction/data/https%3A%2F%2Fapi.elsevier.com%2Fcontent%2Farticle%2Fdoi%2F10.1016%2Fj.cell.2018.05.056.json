{"scopus-eid": "2-s2.0-85048162030", "originalText": "serial JL 272196 291210 291735 291848 291852 291857 291889 31 Cell CELL 2018-06-14 2018-06-14 2018-06-14 2018-06-14 2019-06-10T21:14:14 1-s2.0-S0092867418307190 S0092-8674(18)30719-0 S0092867418307190 10.1016/j.cell.2018.05.056 S300 S300.2 FULL-TEXT 1-s2.0-S0092867417X00135 2019-06-14T01:08:17.7425Z 0 0 20180614 2018 2018-06-14T15:38:24.428245Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure body acknowledge affil articletitle auth authfirstini authfull authlast footnotes grantnumber grantsponsor primabst pubtype ref teaserabst 0092-8674 00928674 true 173 173 7 7 Volume 173, Issue 7 4 1562 1565 1562 1565 20180614 14 June 2018 2018-06-14 2018 Leading Edge Commentary simple-article dis \u00a9 2018 Published by Elsevier Inc. VISIBLEMACHINELEARNINGFORBIOMEDICINE YU M 10.1016/j.cell.2018.05.015 S0092867418305920 Main Text Dual Challenges of Data Heterogeneity and Lack of Mechanistic Interpretation Toward Visible Engines for Machine Learning Groundwork toward Visible Machine Learning in Biology Understanding Biomedical Data with Visible Machine Learning Goals and Milestones for the Near Future Acknowledgments References ALVAREZ 2016 838 847 M BOYLE 2017 1177 1186 E CHUANG 2007 140 H FISHER 2007 1239 1249 J KARR 2012 389 401 J KOUROU 2014 8 17 K LECUN 2015 436 444 Y LEI T LEISERSON 2013 602 610 M LIN 2017 e156 C MA 2018 290 298 J RIBEIRO 2016 1135 1144 M PROCEEDINGS22NDACMSIGKDDINTERNATIONALCONFERENCEKNOWLEDGEDISCOVERYDATAMININGACM ITRUSTEXPLAININGPREDICTIONSCLASSIFIER SILVER 2016 484 489 D SIMON 1962 467 482 H TORKAMANI 2017 828 843 A YUX2018X1562 YUX2018X1562X1565 YUX2018X1562XM YUX2018X1562X1565XM Full 2019-06-14T00:23:48Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ 2019-06-14T00:00:00.000Z 2019-06-14T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ \u00a9 2018 Published by Elsevier Inc. This article is made available under the Elsevier license. item S0092-8674(18)30719-0 S0092867418307190 1-s2.0-S0092867418307190 10.1016/j.cell.2018.05.056 272196 2019-06-10T20:21:42.819154Z 2018-06-14 1-s2.0-S0092867418307190-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/MAIN/application/pdf/8fdcd320d99c6ac3858016175b8cabf1/main.pdf main.pdf pdf true 763897 MAIN 4 1-s2.0-S0092867418307190-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/PREVIEW/image/png/ac3f00024973970f9d0483d445766483/main_1.png main_1.png png 71260 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0092867418307190-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/gr1/THUMBNAIL/image/gif/c27afdb0d5acd3e5c424743715cebf94/gr1.sml gr1 gr1.sml sml 16873 113 219 IMAGE-THUMBNAIL 1-s2.0-S0092867418307190-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/gr2/THUMBNAIL/image/gif/e1166814467dc2fc0c9f7e2d7721e76a/gr2.sml gr2 gr2.sml sml 20371 102 219 IMAGE-THUMBNAIL 1-s2.0-S0092867418307190-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/gr1/DOWNSAMPLED/image/jpeg/0c4108f9a8ca468df07243ae5df2ed12/gr1.jpg gr1 gr1.jpg jpg 57303 261 504 IMAGE-DOWNSAMPLED 1-s2.0-S0092867418307190-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/gr2/DOWNSAMPLED/image/jpeg/0b695cb75ab3a5edc3bf0cb0fa3eb9b4/gr2.jpg gr2 gr2.jpg jpg 103880 356 761 IMAGE-DOWNSAMPLED 1-s2.0-S0092867418307190-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/gr1/HIGHRES/image/jpeg/c0eaf0c37b74cc6c0f630b0bab9e8b9c/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 356525 1156 2233 IMAGE-HIGH-RES 1-s2.0-S0092867418307190-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0092867418307190/gr2/HIGHRES/image/jpeg/cd9c67ac66287f2084448ca5292e04ad/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 894723 1575 3370 IMAGE-HIGH-RES CELL 10244 S0092-8674(18)30719-0 10.1016/j.cell.2018.05.056 S0092-8674(18)30592-0 10.1016/j.cell.2018.05.015 Figure 1 Current Approaches Relevant to Analysis of Big Biomedical Data First subheading (blue): what each of four approaches (A)\u2013(D) accomplish. Second subheading (orange): limitations and challenges for these approaches. Box: this commentary argues for the synthesis of two approaches in particular\u2014machine learning (B) and experimental cell and tissue biology (C)\u2014resulting in an infrastructure for visible intelligence. Figure 2 Visible Models (A) The Visible V8 was a popular quarter-scale model of an internal combustion engine sold by Renwal Model Company starting in 1958. It conveys the concept and value of visible machine learning. Photo: Trey Ideker. (B) Guiding machine learning systems with visible multi-scale biological structure. Commentary Visible Machine Learning for Biomedicine Michael K. Yu 1 2 3 6 Jianzhu Ma 1 2 6 Jasmin Fisher 4 Jason F. Kreisberg 1 2 Benjamin J. Raphael 5 \u2217 braphael@princeton.edu Trey Ideker 1 2 3 \u2217\u2217 tideker@ucsd.edu 1 Division of Genetics, Department of Medicine, University of California San Diego, La Jolla, CA, USA Division of Genetics Department of Medicine University of California San Diego La Jolla CA USA 2 Cancer Cell Map Initiative, University of California San Diego, La Jolla, CA, USA Cancer Cell Map Initiative University of California San Diego La Jolla CA USA 3 UCSD Program in Bioinformatics and Systems Biology, University of California San Diego, La Jolla, CA, USA UCSD Program in Bioinformatics and Systems Biology University of California San Diego La Jolla CA USA 4 Department of Biochemistry, University of Cambridge, Cambridge, UK Department of Biochemistry University of Cambridge Cambridge UK 5 Department of Computer Science, Princeton University, Princeton, NJ, USA Department of Computer Science Princeton University Princeton NJ USA \u2217 Corresponding author \u2217\u2217 Corresponding author 6 These authors contributed equally A major ambition of artificial intelligence lies in translating patient data to successful therapies. Machine learning models face particular challenges in biomedicine, however, including handling of extreme data heterogeneity and lack of mechanistic insight into predictions. Here, we argue for \u201cvisible\u201d approaches that guide model structure with experimental biology. A major ambition of artificial intelligence lies in translating patient data to successful therapies. Machine learning models face particular challenges in biomedicine, however, including handling of extreme data heterogeneity and lack of mechanistic insight into predictions. Here, we argue for \u201cvisible\u201d approaches that guide model structure with experimental biology. Main Text Like many fields, biomedicine is in the midst of a data revolution. Comprehensive molecular and clinical datasets\u2014including complete human genomes, gene expression profiles, high-resolution imaging, metabolomics, electronic medical records, and so on\u2014are no longer isolated to a few study participants; in a few years, we will have such comprehensive information for millions of patients (Torkamani et al., 2017). Multiple analysis approaches have been advanced to transform patient data into successful therapies, each with their particular benefits and limitations (Figure 1 ). Most prominently, the field of machine learning has seen dramatic advances in the past few years (LeCun et al., 2015) with much excitement around the use of many-layered, \u201cdeep,\u201d artificial neural networks, inspired by actual neural networks and how the brain processes patterns. After training over many examples, artificial neural networks learn to predict the correct answer\u2014or output\u2014that should be returned for the many possible input patterns. Deep learning approaches have been used to recognize objects in images like dogs, people, and faces and to distinguish good from bad moves in games like chess and Go (Silver et al., 2016). Given the parallel advances in biomedical data and computer science, a key question is the extent to which current machine-learning models will be effective at interpreting the massive streams of biomedical information. In particular, will large patient datasets, provided as inputs to deep neural networks or related methods, be sufficient to create the next generation of reliable and precise intelligence infrastructure for understanding and treating disease? Here, we argue that the answer is no\u2014that the very high complexity of biological systems will intrinsically limit applications of current \u201cblack box\u201d machine learning in patient data. As one path forward, we highlight a new generation of \u201cvisible\u201d approaches that aim to guide the structure of machine-learning models with an increasingly extensive knowledge of biological mechanism. That is, machine learning will not replace the need for experimental cell and tissue biology; it will be substantially enabled by such knowledge, given the right visible intelligence infrastructure. Dual Challenges of Data Heterogeneity and Lack of Mechanistic Interpretation Machine-learning systems face two recognized challenges that become particularly acute in biomedical applications. The first is input heterogeneity. Nearly all types of statistical analysis rely on identifying recurrent patterns in data, which provide rules by which future predictions are made. Problems arise, however, when the same outcomes may result from vastly different inputs. Although such input heterogeneity is a property of many and perhaps all complex systems, biological systems are almost certainly more complex than those addressed by machine learning in other areas. For example, cancer can arise as the result of many different combinations of genetic alterations involving many potential genes, any one of which may be mutated only rarely; as a consequence, each new patient presents a distinct constellation of molecular changes never before seen in nature (Alvarez et al., 2016; Kourou et al., 2014). Similar heterogeneity arises in patient data from nearly all common diseases, including cardiovascular, metabolic, and neurodevelopmental disorders, in which recurrent patterns are elusive, making it difficult to make reliable predictions (Boyle et al., 2017). Even rare, presumably Mendelian, disorders can be modified by myriad genetic modifiers elsewhere. Such heterogeneity has long posed a significant challenge to genetic association studies, which tend to be powered to identify single-locus effects (Figure 1A); it is also a significant challenge for machine learning. One might consider a brute-force solution to the problem of heterogeneity by profiling ever more subjects to increase the total volume of data. Certainly, technologies like DNA sequencing are now powerful and inexpensive enough that we may soon have complete genomes for most new patients. The total number of patients is finite, however. Even for common conditions like cancer and heart disease, the number of available datasets will saturate at a few million patient examples. While a million may seem large, this number is modest compared to the amounts of data often needed to train a statistical model, compounded by the as-yet-unknown, but undoubtedly high, complexity of biological systems. As a consequence, even after obtaining the genome sequence of every patient, the genetic patterns driving disease may still remain undiscovered by current statistical methods. In contrast, in many other applications of machine learning such as game playing, if the machine runs out of test games for learning, more examples can readily be generated without bound. A second well-known challenge is that modern machine learning models, including deep neural networks, are black boxes, devices which focus on predicting outputs from inputs without regard for the mechanism or rationale by which a particular outcome is brought about. The game-playing system known as AlphaGo can beat human Go players (Silver et al., 2016), but an examination of its internal structure gives little insight into its moves. Its neural network is subject to extensive mathematical optimization during training, leading to a dense web of neural connections neither tied to an actual system nor based on human reasoning. Similarly, in biomedicine, many machine-learning methods are being developed to predict patient outcomes (Kourou et al., 2014), but these approaches typically do not link predictions to underlying mechanisms (Figure 1B). This is a missed opportunity, as causal mechanistic insights are key to identifying drug targets and advancing basic biological knowledge. Toward Visible Engines for Machine Learning A popular toy in the 1950\u2019s was a working model of an automobile engine called the Visible V8, versions of which are still available today (Figure 2 A). As with many toy models of cars, the engine turned a crankshaft, useful for driving a car forward. However, the main draw of the Visible V8 was not this final engine output, but its faithful simulation of interacting engine components necessary to bring about this result. The engine was correctly subdivided into parts such as the engine block, cylinder heads, distributor, cooling fan, alternator, and both intake and exhaust manifolds. The block and heads, in turn, contained working models of pistons, spark plugs, cams, and camshafts. Importantly, all these aspects were clearly visible because the entire engine case and its hierarchy of constituent parts were transparent. Like man-made engines, biological systems are also complex machines whose outputs emerge from a hierarchy of internal components (Simon, 1962). DNA nucleotides assemble to form sequence domains and genes; linear gene sequences encode 3-dimensional protein structures; proteins assemble to create molecular complexes and pathways; pathways occur within organelles and cells; and cells and cell types assemble to form tissues, organs, and individuals. Mapping such structures has classically been the domain of cell and tissue biology, which has developed a spectrum of experimental measurement techniques to characterize biological machines at each scale (Figure 1C). To name a few of the relevant approaches, protein structures are determined using technologies like cryo-electron microscopy; multimeric protein complexes are cataloged systematically by affinity purification tandem mass spectrometry; larger cell structures are tracked dynamically by advanced light microscopy; and the multicellular architecture of tissues is determined increasingly rapidly by single-cell RNA sequencing. Prior information about cell and tissue biology can also be mined from indirect sources such as literature, although consistent literature curation is a difficult problem and misses the large amount of human biology that we do not yet know (Figure 1D). Unfortunately, basic experimental data types are not usually well connected to analysis of patient data. It is nonetheless easy to see how prior knowledge of biological structure might provide distinct advantages to models capable of incorporating this information\u2014what we here call visible learning\u2014and recent research has begun to prove the concept. Groundwork toward Visible Machine Learning in Biology Visible learning relates to a topic called model interpretation, an active research area in the field of artificial intelligence. Generally, model interpretation tries to explain a model\u2019s internal logic after a model has been trained (Ribeiro et al., 2016) or to force the model to have fewer parameters, which makes it easier to interpret (Lei et al., 2016). In biology, the particular need to understand internal mechanisms, along with the ability to probe these mechanisms, has inspired a class of machine-learning models that is guided by prior mechanistic knowledge. This knowledge is often represented by large molecular network structures, which document known mechanistic aspects of cell biology such as interactions among subunits of a protein complex, between receptors and kinases, or among transcriptional regulatory proteins, enhancers, and genes. One way in which these networks have been used to guide learning is in selection of a minimal set of features for prediction, such as prioritizing candidate disease genes based on network proximity to other genes for which sequence variations are strongly associated with disease (Leiserson et al., 2013). Network connections can also nominate a set of genes whose input data should be aggregated to create a composite feature, such as pooling of rarely altered genes in cancer into a single pathway, which, viewed as a single aggregate, is recurrently altered across a patient population (Alvarez et al., 2016; Chuang et al., 2007). Models with hierarchical (multi-scale) resolution of cell biology are also emerging (Karr et al., 2012), an idea that fits naturally with deep (multi-layered) neural networks. For instance, in formulating a neural network, one might specify the architecture of the intermediate layers\u2014the number of layers, the number of neurons per layer, and which connections between layers are allowed. These neurons, usually hidden inside of the black box, can be made visible by attaching them to actual biological components (Figure 2B). This idea was recently explored by Lin et al. (2017), who predicted cell type and state using a deep neural network for which the structure was determined based on the hierarchical organization of transcriptional regulatory factors in the nucleus. We extended such a strategy to assemble DCell, a model of a basic eukaryotic cell (Ma et al., 2018). DCell uses a deep neural network to translate a list of mutated genes (genotype input) to the resulting cell proliferation rate (phenotype output). Neurons are organized into banks, each of which maps to a distinct biological module within a large hierarchy of known cellular components and processes. A predicted change in cell phenotype can then be interpreted by examining the functional states of underlying cellular components, internal to DCell, whose neuron states are also highly affected. In building these visible systems, care must be taken to learn from the successes and pitfalls of the vast body of work in biological modeling over the past several decades (Fisher and Henzinger, 2007). For instance, an important lesson is that increased model resolution (e.g., introducing many detailed biochemical parameters) may come at the expense of model scope (e.g., the ability to address all biological elements and generalize to new patient cohorts). Understanding Biomedical Data with Visible Machine Learning Visible machine learning offers two advantages in building intelligent models of biomedical systems. First, prior knowledge of biological structure can address the problem of data heterogeneity, since different input patterns, even when entirely distinct from one another (i.e., without common patterns), converge on common higher-order biological processing units corresponding to discrete modular components of cells and tissues. All machine-learning systems perform this type of data compression, or dimensionality reduction. In black-box models, the configuration of hidden layers that is required for sufficient data compression is inferred during the training procedure, typically requiring very large quantities of training data. In contrast, direct incorporation of the biological structure of cells and tissues, such as explored by Lin et al. (2017) and Ma et al. (2018), leads to a ready-made working model of how biological inputs, such as genotype, are compressed to determine outcomes. Second, models guided by biological structure can be interpreted mechanistically, informing our understanding of the system and suggesting potential therapeutic strategies. Given input patient data, execution of the model not only produces a final output state; it also reveals the states of internal biological systems. The most striking of these internal states provide hypotheses as to the underlying mechanisms governing patient phenotype, which is important because many internal biological states are difficult to measure through direct experimental observations. For example, Alvarez et al. (2016) used a transcriptional regulatory network to translate patient mRNA expression profiles to activities of regulatory proteins, most of which are difficult to interrogate experimentally. Internal states of the model may also indicate biological components that can be targeted by therapeutic interventions or form the basis for in silico testing of treatment combinations. Goals and Milestones for the Near Future We conclude with a short summary of milestones that research in visible machine learning might seek to achieve in the relatively near term. First is the advent of diverse algorithms to inform machine-learning systems with prior knowledge of biological structure, along with rigorous testing and validation of such algorithms. These developments may involve the application of existing mathematical approaches, require new frameworks, or both. Second, advances in our understanding of complexity are needed to assess and quantify complexity in biological systems and how it differs across the spectrum of tasks to be addressed by biomedical machine learning models. Third, investments in large-scale experimental biology will greatly expand the type and coverage of data that are available to map biological structures within cells and tissues. Generation of such data may involve new technology development to increase experimental throughput, such as advances in 3D cellular imaging or protein interaction mapping, or scale-up of existing technologies. Fourth, significant advances in computation infrastructure are needed to create high performance computing environments, along with web resources for community model development and distribution. Finally, early routes should be sought for embedding visible machine learning models in the clinic to begin evaluating best practices and validating efficacy for predicting patient outcomes and therapies within and across institutions. Notably, funding agencies have begun to promote research into some of these milestones (e.g., the NIH Data Commons or the DARPA Explainable Artificial Intelligence program), although not always with a focus on biomedicine. Parallel development of these directions will enable a new generation of biomedical machine learning, replacing black-box models that focus on isolated problem domains with visible models that survey general biological systems. Acknowledgments We are indebted to many individuals for conversations that inspired and informed this commentary, including Terry Sejnowski, Andrea Califano, Michael Kramer, and Janusz Dutkowski. We are grateful for the help of Aidan Ideker, Cherie Ng, and Charlotte Curtis in building the Visible V8 engine model shown in Figure 2A. This work was supported by grants from the NIH (R01 HG009979, OT3 TR002026, and P41 GM103504 to T.I. and R01 HG007069 and U24 CA211000 to B.J.R.). Declaration of Interests T.I. is co-founder of Data4Cure and has an equity interest. T.I. has an equity interest in Ideaya BioSciences. The terms of this arrangement have been reviewed and approved by the University of California, San Diego in accordance with its conflict of interest policies. B.J.R. is a founder of Medley Genomics and a member of its board of directors. References Alvarez et al., 2016 M.J. Alvarez Y. Shen F.M. Giorgi A. Lachmann B.B. Ding B.H. Ye A. Califano Functional characterization of somatic mutations in cancer using network-based inference of protein activity Nat. Genet. 48 2016 838 847 Boyle et al., 2017 E.A. Boyle Y.I. Li J.K. Pritchard An Expanded View of Complex Traits: From Polygenic to Omnigenic Cell 169 2017 1177 1186 Chuang et al., 2007 H.-Y. Chuang E. Lee Y.-T. Liu D. Lee T. Ideker Network-based classification of breast cancer metastasis Mol. Syst. Biol. 3 2007 140 Fisher and Henzinger, 2007 J. Fisher T.A. Henzinger Executable cell biology Nat. Biotechnol. 25 2007 1239 1249 Karr et al., 2012 J.R. Karr J.C. Sanghvi D.N. Macklin M.V. Gutschow J.M. Jacobs B. Bolival Jr. N. Assad-Garcia J.I. Glass M.W. Covert A whole-cell computational model predicts phenotype from genotype Cell 150 2012 389 401 Kourou et al., 2014 K. Kourou T.P. Exarchos K.P. Exarchos M.V. Karamouzis D.I. Fotiadis Machine learning applications in cancer prognosis and prediction Comput. Struct. Biotechnol. J. 13 2014 8 17 LeCun et al., 2015 Y. LeCun Y. Bengio G. Hinton Deep learning Nature 521 2015 436 444 Lei et al., 2016 T. Lei R. Barzilay T. Jaakkola Rationalizing neural predictions arXiv, arXiv: 1606.04155 http://arXiv.org/abs/1606.04155 2016 Leiserson et al., 2013 M.D.M. Leiserson J.V. Eldridge S. Ramachandran B.J. Raphael Network analysis of GWAS data Curr. Opin. Genet. Dev. 23 2013 602 610 Lin et al., 2017 C. Lin S. Jain H. Kim Z. Bar-Joseph Using neural networks for reducing the dimensions of single-cell RNA-Seq data Nucleic Acids Res. 45 2017 e156 Ma et al., 2018 J. Ma M.K. Yu S. Fong K. Ono E. Sage B. Demchak R. Sharan T. Ideker Using deep learning to model the hierarchical structure and function of a cell Nat. Methods 15 2018 290 298 Ribeiro et al., 2016 M.T. Ribeiro S. Singh C. Guestrin Why should I trust you?: Explaining the predictions of any classifier Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, (ACM) 2016 1135 1144 Silver et al., 2016 D. Silver A. Huang C.J. Maddison A. Guez L. Sifre G. van den Driessche J. Schrittwieser I. Antonoglou V. Panneershelvam M. Lanctot Mastering the game of Go with deep neural networks and tree search Nature 529 2016 484 489 Simon, 1962 H.A. Simon The Architecture of Complexity Proc. Am. Philos. Soc. 106 1962 467 482 Torkamani et al., 2017 A. Torkamani K.G. Andersen S.R. Steinhubl E.J. Topol High-Definition Medicine Cell 170 2017 828 843", "scopus-id": "85048162030", "pubmed-id": "29906441", "coredata": {"eid": "1-s2.0-S0092867418307190", "dc:description": "A major ambition of artificial intelligence lies in translating patient data to successful therapies. Machine learning models face particular challenges in biomedicine, however, including handling of extreme data heterogeneity and lack of mechanistic insight into predictions. Here, we argue for \u201cvisible\u201d approaches that guide model structure with experimental biology.", "openArchiveArticle": "true", "prism:coverDate": "2018-06-14", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0092867418307190", "dc:creator": [{"@_fa": "true", "$": "Yu, Michael K."}, {"@_fa": "true", "$": "Ma, Jianzhu"}, {"@_fa": "true", "$": "Fisher, Jasmin"}, {"@_fa": "true", "$": "Kreisberg, Jason F."}, {"@_fa": "true", "$": "Raphael, Benjamin J."}, {"@_fa": "true", "$": "Ideker, Trey"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0092867418307190"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0092867418307190"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0092-8674(18)30719-0", "prism:volume": "173", "prism:publisher": "Published by Elsevier Inc.", "dc:title": "Visible Machine Learning for Biomedicine", "prism:copyright": "\u00a9 2018 Published by Elsevier Inc.", "openaccess": "1", "prism:issn": "00928674", "prism:issueIdentifier": "7", "openaccessArticle": "true", "prism:publicationName": "Cell", "prism:number": "7", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "1562-1565", "prism:endingPage": "1565", "pubType": "Commentary", "prism:coverDisplayDate": "14 June 2018", "prism:doi": "10.1016/j.cell.2018.05.056", "prism:startingPage": "1562", "dc:identifier": "doi:10.1016/j.cell.2018.05.056", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "113", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0092867418307190-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "16873", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "102", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0092867418307190-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "20371", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "261", "@width": "504", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0092867418307190-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "57303", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "356", "@width": "761", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0092867418307190-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "103880", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1156", "@width": "2233", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0092867418307190-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "356525", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1575", "@width": "3370", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0092867418307190-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "894723", "@ref": "gr2", "@mimetype": "image/jpeg"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85048162030"}}
{"scopus-eid": "2-s2.0-84886313848", "originalText": "serial JL 272501 291210 291856 31 Genomics GENOMICS 2013-06-06 2013-06-06 2014-08-31T02:41:22 1-s2.0-S0888754313001213 S0888-7543(13)00121-3 S0888754313001213 10.1016/j.ygeno.2013.05.006 S300 S300.3 FULL-TEXT 1-s2.0-S0888754313X00102 2018-04-17T12:22:32.16847Z 0 0 20131001 20131031 2013 2013-06-06T00:00:00Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body mmlmath affil appendices articletitle auth authfirstini authfull authkeywords authlast highlightsabst primabst ref 0888-7543 08887543 true 102 102 4 4 Volume 102, Issue 4 9 237 242 237 242 201310 October 2013 2013-10-01 2013-10-31 2013 article fla Copyright \u00a9 2013 Elsevier Inc. All rights reserved. PPIEVOPROTEINPROTEININTERACTIONPREDICTIONPSSMBASEDEVOLUTIONARYINFORMATION ZAHIRI J 1 Introduction 2 Materials and methods 2.1 Positive interaction selection 2.2 Negative interaction selection 2.3 Feature extraction 2.4 Classification algorithm 3 Results 3.1 Evaluation of prediction accuracy 4 Discussion 5 Availability Appendix A Supplementary data References THEOFILATOS 2011 398 414 K TUNCBAG 2009 217 232 N SHOEMAKER 2007 595 601 B LO 2005 876 884 S SHEN 2007 4337 4341 J NARAYANAN 2005 231 242 E IEEEACMTRANSACTIONSCOMPUTATIONALBIOLOGYBIOINFORMATICS DISCOVERINGGENENETWORKSANEURALGENETICHYBRID LU 2005 945 953 L CHEN 2005 4394 4400 X ELEFSINIOTI 2011 A JOTHI 2005 i241 i250 R ENRIGHT 1999 86 90 A IDEKER 2002 233 240 T ISMBSUPPBIOINFORMATICS DISCOVERINGREGULATORYSIGNALLINGCIRCUITSINMOLECULARINTERACTIONNETWORKS ZHANG 2012 556 560 Q LIU 2008 G ASSESSINGPREDICTINGPROTEININTERACTIONSUSINGBOTHLOCALGLOBALNETWORKTOPOLOGICALMETRICSGENOMEINFORMATICS JAEGER 2008 S2 S YU 2010 2610 2614 J KESHAVAPRASAD 2009 D767 D772 T BENHUR 2005 i38 i46 A ZAKI 2006 N ZHANG 2004 38 L HAN 2003 250 260 D ZHANG 2011 44 52 Y EZKURDIA 2009 233 246 I QI 2005 531 542 Y WANG 2009 3752 3757 J RHODES 2005 951 959 D JANSEN 2003 449 453 R LU 2005 945 953 L BRAUN 2008 91 97 P LETUNIC 2012 D302 D305 I PUNTA 2012 29 M CHEN 2011 D750 D754 X BENHUR 2006 S2 A SHOYAIB 2013 M BROWNE 2009 2 F LIU 2012 508 520 Z STARK 2011 D698 D704 C KERRIEN 2012 D841 D846 S LICATA 2012 D857 D861 L SMIALOWSKI 2010 D540 D544 P BENHUR 2006 S2 A XENARIOS 2002 303 305 I ALTSCHUL 1997 3389 3402 S KANTARDZIC 2011 M DATAMININGCONCEPTSMODELSMETHODSALGORITHMS HAUSSER 2009 1469 1484 J GEURTS 2009 1593 1605 P CHEN 2011 55 63 X THAHIR 2010 M LI 2012 e43927 B HALL 2009 10 18 M ZAHIRIX2013X237 ZAHIRIX2013X237X242 ZAHIRIX2013X237XJ ZAHIRIX2013X237X242XJ Full 2018-04-17T13:42:00Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S0888-7543(13)00121-3 S0888754313001213 1-s2.0-S0888754313001213 10.1016/j.ygeno.2013.05.006 272501 2014-08-31T01:15:04.069746-04:00 2013-10-01 2013-10-31 1-s2.0-S0888754313001213-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/MAIN/application/pdf/9670b48dd029926d2cd568893a67be9b/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/MAIN/application/pdf/9670b48dd029926d2cd568893a67be9b/main.pdf main.pdf pdf true 560918 MAIN 6 1-s2.0-S0888754313001213-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/PREVIEW/image/png/0e5f40b3bd2bdbb033f7562f9ca43722/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/PREVIEW/image/png/0e5f40b3bd2bdbb033f7562f9ca43722/main_1.png main_1.png png 63746 849 656 IMAGE-WEB-PDF 1 1-s2.0-S0888754313001213-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/STRIPIN/image/gif/972ebd9daf60f1f57349cacc604b0d2b/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/STRIPIN/image/gif/972ebd9daf60f1f57349cacc604b0d2b/si5.gif si5 si5.gif gif 1646 27 208 ALTIMG 1-s2.0-S0888754313001213-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/STRIPIN/image/gif/4fa0442c3adeba11d55784bb9b3eca86/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/STRIPIN/image/gif/4fa0442c3adeba11d55784bb9b3eca86/si4.gif si4 si4.gif gif 1486 27 112 ALTIMG 1-s2.0-S0888754313001213-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/STRIPIN/image/gif/ba2da5e8c2377a3b315576938ecf3001/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/STRIPIN/image/gif/ba2da5e8c2377a3b315576938ecf3001/si3.gif si3 si3.gif gif 1412 27 92 ALTIMG 1-s2.0-S0888754313001213-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/STRIPIN/image/gif/9d805360ca6821c2fd2b9df55ff558f1/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/STRIPIN/image/gif/9d805360ca6821c2fd2b9df55ff558f1/si2.gif si2 si2.gif gif 2941 16 328 ALTIMG 1-s2.0-S0888754313001213-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/STRIPIN/image/gif/7f01ba4d4e1dcb6f618ba40d46530820/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/STRIPIN/image/gif/7f01ba4d4e1dcb6f618ba40d46530820/si1.gif si1 si1.gif gif 1165 26 83 ALTIMG 1-s2.0-S0888754313001213-mmc1.docx https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/mmc1/MAIN/application/msword/032667a3b7d352618efefccde1ff80e1/mmc1.docx https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/mmc1/MAIN/application/msword/032667a3b7d352618efefccde1ff80e1/mmc1.docx mmc1 mmc1.docx docx 132305 APPLICATION 1-s2.0-S0888754313001213-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr3/HIGHRES/image/jpeg/13ed2d1f96b0f5eb7b2cd3d1d183fc39/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr3/HIGHRES/image/jpeg/13ed2d1f96b0f5eb7b2cd3d1d183fc39/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 218104 1222 1684 IMAGE-HIGH-RES 1-s2.0-S0888754313001213-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr2/HIGHRES/image/jpeg/7c8c97e9b2bbe07243567e144867930c/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr2/HIGHRES/image/jpeg/7c8c97e9b2bbe07243567e144867930c/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 413534 2176 2775 IMAGE-HIGH-RES 1-s2.0-S0888754313001213-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr1/HIGHRES/image/jpeg/77046010c998a9e5b0fe76a868c7043e/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr1/HIGHRES/image/jpeg/77046010c998a9e5b0fe76a868c7043e/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 176080 410 2960 IMAGE-HIGH-RES 1-s2.0-S0888754313001213-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr3/DOWNSAMPLED/image/jpeg/d7eeabc0d6d3b55d097b2f62f4277fbf/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr3/DOWNSAMPLED/image/jpeg/d7eeabc0d6d3b55d097b2f62f4277fbf/gr3.jpg gr3 gr3.jpg jpg 30108 276 380 IMAGE-DOWNSAMPLED 1-s2.0-S0888754313001213-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr2/DOWNSAMPLED/image/jpeg/ca64323fede9193ce8371e81bc31f630/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr2/DOWNSAMPLED/image/jpeg/ca64323fede9193ce8371e81bc31f630/gr2.jpg gr2 gr2.jpg jpg 63131 492 627 IMAGE-DOWNSAMPLED 1-s2.0-S0888754313001213-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr1/DOWNSAMPLED/image/jpeg/9fd864587bc5bb50a055ff5ba513054a/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr1/DOWNSAMPLED/image/jpeg/9fd864587bc5bb50a055ff5ba513054a/gr1.jpg gr1 gr1.jpg jpg 25216 93 668 IMAGE-DOWNSAMPLED 1-s2.0-S0888754313001213-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr3/THUMBNAIL/image/gif/8a5df694143f4f8b2848b6216303db8f/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr3/THUMBNAIL/image/gif/8a5df694143f4f8b2848b6216303db8f/gr3.sml gr3 gr3.sml sml 10986 159 219 IMAGE-THUMBNAIL 1-s2.0-S0888754313001213-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr2/THUMBNAIL/image/gif/c4fcd8c057a1fc41a04c370d37398679/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr2/THUMBNAIL/image/gif/c4fcd8c057a1fc41a04c370d37398679/gr2.sml gr2 gr2.sml sml 4436 164 209 IMAGE-THUMBNAIL 1-s2.0-S0888754313001213-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0888754313001213/gr1/THUMBNAIL/image/gif/737961c699f621ef3744acb254cecf0a/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0888754313001213/gr1/THUMBNAIL/image/gif/737961c699f621ef3744acb254cecf0a/gr1.sml gr1 gr1.sml sml 2745 30 219 IMAGE-THUMBNAIL YGENO 8527 S0888-7543(13)00121-3 10.1016/j.ygeno.2013.05.006 Elsevier Inc. Fig. 1 Schematic view of constructing reliable positive and negative graph (RPG and RNG) procedure. Fig. 2 Feature extraction. a: Constructing PSSM and FPSSM. b: Extracting primary feature vectors from FPSSM. c: Computing final feature vectors with the reduced dimensionality which were used for classification. Fig. 3 The predictions performance on the three last releases of HPRD database on SD and RP datasets. Table 1 The prediction performance of RF classifier on four different datasets % (10-fold cross validation). Dataset Performance F-measure AUC RP 75.1 82.0 SD 68.3 75.8 MC 99.0 99.4 MD 99.3 99.8 Table 2 The prediction performance of RF classifier on four different datasets where features extracted from those parts of protein hat annotated as domain in the SMART or Pfam databases % (10-fold cross validation). Dataset Performance F-measure AUC RP 72.4 80.0 SD 62.2 67.5 MC 97.1 98.7 MD 98.0 98.9 PPIevo: Protein\u2013protein interaction prediction from PSSM based evolutionary information Javad Zahiri a Omid Yaghoubi b Morteza Mohammad-Noori c Reza Ebrahimpour d Ali Masoudi-Nejad a \u204e amasoudin@ibb.ut.ac.ir http://www.LBB.ut.ac.ir a Laboratory of Systems Biology and Bioinformatics (LBB), Institute of Biochemistry and Biophysics, University of Tehran, Tehran, Iran Laboratory of Systems Biology and Bioinformatics (LBB) Institute of Biochemistry and Biophysics University of Tehran Tehran Iran b Department of Computer engineering, Shamsipour Technical and Professional University, Tehran, Iran Department of Computer engineering Shamsipour Technical and Professional University Tehran Iran c School of Mathematics, Statistics, and Computer Science, College of Science, University of Tehran, Tehran, Iran School of Mathematics, Statistics, and Computer Science College of Science University of Tehran Tehran Iran d Brain and Intelligent Systems Research Lab, Department of Electrical and Computer Engineering, Shahid Rajaee Teacher Training University, Tehran, Iran Brain and Intelligent Systems Research Lab Department of Electrical and Computer Engineering Shahid Rajaee Teacher Training University Tehran Iran \u204e Corresponding author at: Laboratory of Systems Biology and Bioinformatics (LBB), Institute of Biochemistry and Biophysics, University of Tehran, Tehran, Iran. Fax: +98 21 6640 4680. Abstract Protein\u2013protein interactions regulate a variety of cellular processes. There is a great need for computational methods as a complement to experimental methods with which to predict protein interactions due to the existence of many limitations involved in experimental techniques. Here, we introduce a novel evolutionary based feature extraction algorithm for protein\u2013protein interaction (PPI) prediction. The algorithm is called PPIevo and extracts the evolutionary feature from Position-Specific Scoring Matrix (PSSM) of protein with known sequence. The algorithm does not depend on the protein annotations, and the features are based on the evolutionary history of the proteins. This enables the algorithm to have more power for predicting protein\u2013protein interaction than many sequence based algorithms. Results on the HPRD database show better performance and robustness of the proposed method. They also reveal that the negative dataset selection could lead to an acute performance overestimation which is the principal drawback of the available methods. Highlights \u2022 We introduce a novel evolutionary feature extraction algorithm for PPI prediction. \u2022 Algorithm doesn't need protein annotation and is used for genome-wide PPI prediction. \u2022 PPIevo shows better performance and robustness compared with other algorithms. \u2022 Using negative dataset selection could lead to acute performance overestimation. \u2022 PPIevo is a standalone Java program which can be run on various operating systems. Keywords Protein\u2013protein interaction map Protein interaction networks Computational intelligence Machine learning Position-specific scoring matrix 1 Introduction After the completion of the human genome project, a major research trend to emerge from it was the need for understanding the cell as a system. Proteins are the most essential and versatile macromolecules of life, and participate in almost all process within the cell, executing nearly all of the cell's functions. It has been observed that proteins in terms of the performance of their functions seldom act as isolated agents. Instead, they perform their functions by interactions with other macromolecules, and especially other proteins. Thus, knowledge of protein\u2013protein interaction can provide significant insight into the underlying mechanisms of almost all biological processes within a cell, and the elucidation of protein interactions has been, and remains, one of the central problems in systems biology [1,2]. Protein interactions can be discovered by a variety of experimental methods: low-throughput approaches (such as co-purification and co-crystallization) and high-throughput techniques (such as co-Immunoprecipitation and Yeast 2-Hybrid methods). The recent advances in high-throughput techniques have led to a sudden growth in the availability of valuable protein interaction data over the last decade. However, the resulting data from such experimental approaches has certain limitations. This is because these approaches are biased towards certain kinds of proteins (for example, there is a little PPIs data involving transmembrane proteins). Additionally, current experimental techniques are generally designed to decipher non-transient interactions. Another limitation is that, since the coverage of PPI data remains relatively low, available interactomes of many organisms are far from complete: the produced data from high-throughput methods may contain a significant error due largely to false positives. These limitations indicate the need for computational methods as a complement to experimental techniques which can be used to predict protein interactions [3]. In general, the existing work on predicting protein\u2013protein interaction can be assigned to one of the four following categories. Firstly, methods which use a machine learning algorithm that use a set of various descriptors of the proteins to build a model that can predict protein\u2013protein interactions, these methods usually use sequence features for learning. Various machine learning algorithms, such as support vector machines (SVM) [4,5], multilayer perceptron (MLP) [6], na\u00efve Bayes [7] and random forest [8,9] are used to address the protein\u2013protein interaction prediction problem. Secondly, methods that use different information from genomic context and structure of proteins such as gene neighboring [12], the phylogenetic relationship [10], gene fusion [11], gene co-expression [12], three-dimensional structural information [13]. Thirdly, methods that use network topology to predict protein\u2013protein interaction [14], and, fourthly, methods that detect protein\u2013protein interaction by using text mining and literature mining (or database searching) [15]. In this study, we introduce novel evolutionary features that were extracted from PSSMs for the purpose of protein\u2013protein interaction prediction. These types of features have two main advantages: Firstly, there is no need for special annotation that were once only available for a specific set of proteins can now be extracted for all protein with known sequence, so the learner algorithm does not bias toward a specific subspace of the proteomic space under consideration. Secondly, these features are based on the evolutionary history of the proteins, which has more power for predicting protein\u2013protein interaction than many sequence-based features [16]. We used the random forest (RF) classifier to predict protein\u2013protein interactions and used ten-cross validation to compute the F-measure and AUC as two main measures for evaluating the performance. We used those interactions in HPRD [17] that were confirmed with at least two experimental methods as a reliable positive dataset. The most complex task in gold standard construction is selecting the negative dataset. Many previous studies used random pairs as negative interactions [5,18\u201324], while a few other studies have used spatially separated or functionally dissimilar pairs for construction of negative data set. Alternatively, other ones have coded interacting protein pairs as feature vectors, then feature vectors of all the protein pairs that were absent in this positive dataset were computed. Finally, the most distant ones from the mean of these feature vectors were selected as negative dataset. Others have used genetic annotations for selecting the negative dataset [25\u201329]. To strictly assess the performance of the proposed evolutionary features and also to examine how the negative dataset selection could affect the performance estimation, we used four different strategies to construct negative interactions. Results show that the negative dataset selection could lead to acute performance overestimation, F-measure varied from 68.3 to 99.3 on the same positive dataset with different negative datasets. For further analyzing the proposed features, we extracted features only from those parts of proteins that were annotated as a domain in the SMART [30] or Pfam [31] databases. The performance of the four data sets was decreased, which suggests that this type of evolutionary information is important in the complete protein sequences. Finally we extracted features from release 7, 8 and 9 of the HPRD, the results show that the performances were increasing from release 7 to release 9, and so show the good robustness of the proposed method. Results also show that in all of the three releases the negative dataset selection could seriously affect the estimated performance. 2 Materials and methods There are several databases which store protein\u2013protein interactions in different organisms, but these databanks contain many false positives (interactions which are not biologically real and are only produced due to tools biases and errors). Those false positive results can have dangerous effects on the training process in computational methods and the results of these computational approaches could propagate in those databases which also contain the predicted protein\u2013protein interactions. Thus, there is a critical need to have gold standard data sets, which contain both positive and negative (non-interacting proteins) examples, to evaluate performance and compare newly proposed computational methods for protein\u2013protein interaction prediction. Benchmark data can affect the performance results and may lead to overestimating the prediction performance [16,32\u201336]. Recently, two web-based systems have been developed for constructing benchmark protein\u2013protein interaction data: GRIP [35] and KUPS [32] but these tools have many limitations and errors and it seems that more effort is needed to address this problem, so we also try to develop a system for selecting the most possible confident datasets (which explained below in detail). 2.1 Positive interaction selection For selecting a positive interaction dataset, we analyzed four of the most comprehensive human protein\u2013protein interaction databases, HPRD [17], BioGRID [37], IntAct [38] and MINT [39], which contain only experimentally detected interactions. We saw that there are only 4150 interactions (after eliminating self interactions in all databases) in all of these databases, this little size of intersection may be a consequence of incompleteness of human interactome or existing of many false positive interactions. For selecting a reliable positive dataset we focused on HPRD database, this database was built as a cooperative effort between Johns Hopkins University and the Institute of Bioinformatics, this resource provides a collection of human protein\u2013protein interaction. In this database, interactions are manually extracted from the literature, and each record linked to detailed information and currently contains more than 30,000 proteins and more than 39,000 protein\u2013protein interactions. Finally, after eliminating all self interactions, those interactions in HPRD that were confirmed with at least two experimental methods were then used as the reliable positive graph (RPG) which contains 12,177 out of total 39,240 interactions, also the number of nodes in the RPG (the number of proteins) was 5632. 2.2 Negative interaction selection Selecting a negative dataset is more complex and important than that of positive dataset. Despite of the importance of selecting such a dataset, there is only the Negatome database available [40] which provides experimentally supported mammalian negative interactions. However, this database is limited in size and cannot be used as a negative dataset in practice. Many studies used random pairs (which were not in the positive dataset) as negative interactions. Some other studies used spatially separated or functionally dissimilar pairs for constructing negative dataset also in some studies first protein pairs were coded as feature vectors and then feature vectors of all the protein pairs that were not in the positive dataset computed and finally most distant feature vectors from the mean vector of these feature vectors were selected as negative dataset. It is shown that uniform random selection is less biased than the other approaches for constructing a negative dataset [32,41] and spatially separated or functionally dissimilar pairs could lead to overestimating the accuracy of computational methods, nevertheless it is also shown that uniform random selection greatly affects the results [16], Yu et al. showed that the accuracy of previously published methods could decrease to a random classifier when using the negative data set with the same topology as that of the positive dataset (considering positive and negative datasets as separated graphs). For constructing a confident negative dataset, we used a two step approach (Fig. 1 ). At the first step complement graph of the positive interaction graph has been constructed as a negative graph (NG). Each edge in the NG shows a possible interaction which was not in the positive dataset. At the second stage, the intersection of NG and each one of HPRD, BioGRID, IntAct, MINT and DIP [42] databases were then eliminated from NG and considered as a reliable negative graph (RNG). Finally, for selecting a subset of the RNG with equal size of the positive dataset, we used four different strategies and in each case the proposed method has been run and performance measured. The first negative dataset was constructed using random pair selection (RP). The second dataset was built using a random pair selection so that the degree distribution of the negative interactions was the same as the positive interaction graph (SD) and finally third and fourth negative datasets has been constructed from the most close (MC) and the most distant (MD) ones from the mean of all those feature vectors in RNG. 2.3 Feature extraction We used two types of features that were extracted from sequence and evolutionary information contained in the PSSM of each protein. The PSSM matrix is composed of L\u00d720 entries, where L is the total number of amino acids in a protein. The rows and columns of the matrix are indexed by the protein residues and the 20 naive amino acids respectively (Fig. 2a), the pi,j entry represents the log odds score of the occurrence of jth naive amino acid at the ith position of the protein sequence. In this study we used the Position Specific Iterated BLAST (PSI-BLAST) tool [43] and NCBI non-redundant (NR) dataset on a local machine for creating PSSM for all proteins, we set the e-value and the number of iterations to 0.001 and 3, respectively. One of challenges for constructing feature vectors, based on PSSM matrices, is the variable length of different proteins. Accordingly, we extracted features in such a way that it would lead to fixed length feature vectors. The first type of the features makes a twenty-length feature vector D=(d 1 , d 2 ,\u2026,d 20 ) for each protein, which di shows the sum of the entries in the ith column of the PSSM. Because the values in the PSSM could be negative, it is possible that for two proteins with different evolutionary history we have a same feature vector. To overcome this difficulty, we filtered out all negative scores and also those positive scores that occurred greater than expected by random as a preprocessing step (and then compute vector D). We show the PSSM entries by pi,j and denote the obtained matrix after filtration by FPSSM (this matrix contain positive scores), where fpi,j shows the FPSSM entries (Fig. 2a). One can say that the vector D is an estimation of the amino acids distribution in the family of the corresponding protein. The components of vector D would be large in the long proteins and small in the small proteins so these values depend on the protein length. Additionally, the same number of occurrence of two different amino acids in the protein sequences may have a different significance, so we normalize the elements of vector D to remove these biases, as the following: d i = d i \u2212 min max \u00d7 L . Min and max show the minimum and maximum of the values at the ith position within the feature of all the proteins in the used dataset respectively, and L shows the corresponding protein length. A similar formula for normalizing features has been widely used in machine learning [44], here the variable L in the denominator is for removing the effect of protein length. The second feature vector for a protein is a 400-length vector S =(s 1 (1),s 2 (1),\u2026,s 20 (1),s 1 (2),s 2 (2),\u2026,s 20 (2),\u2026,s 1 (20),s 2 (20)\u2026,s 20 (20)) which was computed as the following. For computing vector S we first label the twenty amino acids according to FPSSM columns as a 1 to a 20 and then compute the elements s j (i)as the sum of all substitution scores of ai to aj (sum of the scores in the jth column of the FPSSM scores that the ith residue of the protein is ai (see Fig. 2b)). The above mentioned feature vectors code single proteins, so we used those vectors to build final feature vectors of protein pairs that were used for classification. Consider protein P with feature vectors D=(d 1 , d 2 ,\u2026,d 20 ) and S =(s 1 (1),s 2 (1),\u2026,s 20 (1),s 1 (2),s 2 (2),\u2026,s 20 (2),\u2026,s 1 (20),s 2 (20)\u2026,s 20 (20)), and protein P\u2032 with feature vectors D\u2032=(d\u2032 1 , d\u2032 2 ,\u2026,d\u2032 20 ) and S\u2032=(s\u20321 (1),s\u20322 (1),\u2026,s\u203220 (1),s\u20321 (2),s\u20322 (2)\u2026,s\u203220 (2),\u2026,s\u20321 (20) s\u20322 (20)\u2026,s\u203220 (20)) we denote the final feature vector for this protein pair as V =(v 1 (1),v 2 (1),v 3 (1),v 1 (2),v 2 (2),v 3 (2),\u2026,v 1 (20),v 2 (20),v 3 (20),v 61,v 62,\u2026,v 100) with length 100. Where the elements v 1 (i) and v 2 (i) show some statistics from vector S\u2033=(s\u20331 (1),s\u20332 (1),\u2026,s\u203320 1,s\u20331 (2),s\u20332 (2),\u2026,s\u203320 (2),\u2026,s\u20331 (20),s\u20332 (20)\u2026,s\u203320 (20)) wheres\u2033 j (i) =|s\u2033 j (i) \u2212 s\u2032 j (i)|; v 3 (i) is mutual information of twenty elements from vectors S and S\u2032. Finally, elements v 61to v 100 are obtained by concatenating elements of vectors D and D\u2032 (see Fig. 2c). More precisely, v 1 (i) and v 2 (i) are computed as the follows: 1 v 1 (i) =min(s\u20331 (i),s\u20332 (i),\u2026,s\u203320 (i)). 2 v 2 (i) =var(s\u20331 (i),s\u20332 (i),\u2026,s\u203320 (i)). Where min and var in these equations show the minimum and variance functions, respectively. Elements v 3 (i) were computed as the follows: 3 v 3 (i) =MI[(s 1 (i),s 2 (i),\u2026,s 20 (i)),(s\u20321 (i),s\u20322 (i),\u2026,s\u203220 (i))]. where MI shows mutual information of two vectors, we compute MI with entropy package [45] (Fig. 2c) (the first sixty features of final feature vector V are minimum, variance and mutual information of elements of vector S\u2033). And, elements v 61 to v 100 are computed as follows (the last forty features of final feature vector V are concatenation of vectors D and D\u2032 of two proteins P and P\u2032): 4 v 60 + k = d k for 1 \u2264 k \u2264 20 and v 60 + k = d \u2032 k for 21 \u2264 k \u2264 40. We also tested three feature selection methods, the results show no improvement on the performance (Supplementary table S1). 2.4 Classification algorithm There are various machine learning algorithms applied to address the problem of protein\u2013protein interaction prediction that employ different types of protein features. Random forest has previously been shown to be effective for many biological classification problems especially for predicting protein\u2013protein interactions [46\u201349]. A random forest consists of many decision trees, each of which in the training phase is constructed based on random features sampled from a data set independently. To classify a new protein pair, put the corresponding feature vector down each of the trees in the forest, and finally assign to the protein pair, according to the majority voting interaction or no interaction. We used the Random Forest as implemented in the Weka [50] software package which is a comprehensive open-source library of data mining and machine learning methods. We also ran three other machine learning algorithms which are widely used in bioinformatics. The results show that random forest classifier is the best one (see Supplementary table S2). 3 Results We tried to assess the performance of the newly proposed features and examine the effect of negative dataset selection on performance. Therefore, we used four different strategies namely RP, SD, MC and MD construct the negative interactions. We also used interactions in HPRD that confirmed with at least two experimental methods as reliable positive dataset (discarding self interactions). For the complete set of positive interaction (12177) and all pairs in the NG (15844719) which is the number of complement graph edges interactions, all the hundred features were extracted and the feature vectors created and then four negative datasets were constructed. 3.1 Evaluation of prediction accuracy Having gold standard dataset, the prediction performance could now be assessed with different measures based on four basic parameters: \u2022 TP (True Positive or hit) the number of interactions predicted correctly \u2022 TN (True Negative or correct rejection) the number of non-interaction predicted correctly \u2022 FP (False Positive or type I error) the number of non-interaction predicted incorrectly as interaction \u2022 FN (False Negative or type II error) the number of interactions predicted incorrectly as non-interaction. The recall measure assigns the fraction of the real positive interactions was correctly identified by the predictor. The precision measure shows the fraction of the positive interaction prediction which was found to be correct and computed as follows: 4 Recall = TP TP + FN 5 Precision = TP TP + FP . We used F-measure and AUC as two main indicators to assess the performance. The F-measure is a composite measure of classifier performance that attempts to balance precision and recall. F-Measure values range from 0 to 1, with values close to 1 indicating better performance this measure computed as the follows: 6 F-measure = 2 \u00d7 Recall \u00d7 Precision Recall + Precision . The area under the ROC (receiver operating characteristic) curve which plots sensitivity vs. one minus the specificity, AUC or \u201cArea Under Curve\u201d is another important measure of classification accuracy that we used, the closer the AUC to one the more accurate the classification. We used ten-fold cross validation for computing performance measures. The dataset is randomly partitioned into ten equal sets, out of which nine sets are used for training and the remaining one for testing. This procedure is repeated ten times, and the final prediction result is the average accuracy of the ten testing sets. Table 1 shows the RF classifier's performance on the four datasets, as we can see the SD dataset is the most challenging one. Nevertheless, to the best of our knowledge none of the previously published studies have used this strategy to construct the negative dataset. From Table 1 it is obvious that the negative dataset selection could seriously affect the performance. The negative dataset selection could lead to overestimating the performance up to thirty percent (the best F-measure is 99.3 and the worst is 68.3). We further extracted features only from those parts of proteins that annotated as a domain in the SMART or Pfam databases (available as proteins structure architecture in the HPRD database for 78% of interactions in the RPG). On average, the 38% of each protein sequence was annotated as domains. The prediction performance of the RF classifier on the newly constructed datasets with four previously mentioned strategies is shown in Table 2 . Similar to the results in Table 1, once again SD dataset is more challenging and the MC and MD datasets are simpler to classify. From Table 2 we can see that performance in all datasets was decreased compared with previous case (Table 1). This is probably due to the importance of the evolutionary information in complete protein sequences. For analyzing the robustness of new proposed features in this study we run the RF classifier on the previous releases of the HPRD. For this purpose we constructed two most challenging datasets (RP and SD). Fig. 3 summarizes the prediction performance on the last three releases of the HPRD database. Fig. 3 shows that the performances were increasing from release 7 to release 9. This shows again that dataset selection is very critical to the performance estimation (in all the three releases) and finally we can say that SD dataset was the most challenging datasets for classification in the prediction of protein\u2013protein interaction. To assess the performance of our method regarding previously proposed methods, we compared the results of our method with three sequence based methods. The results show the better performance of our method (Supplementary table S3.) 4 Discussion Protein\u2013protein interactions regulate a variety of cellular processes and understanding their nature remains an important problem in the post-genomics era. There are a large number of computational approaches for PPI prediction that use several genomic and proteomic features. In this study, we have proposed an alternative method which exploited a set of evolutionary features that were extracted from PSSMs to predict protein\u2013protein interaction. On the one hand, these features do not need special annotations that were once only available for a specific set of proteins. They can be extracted for all proteins with known sequences, so the learner algorithm does not bias toward a specific subspace of the under consideration proteomic space. On the other hand, these features are based on the evolutionary history of the proteins, which is shown to have more power for predicting protein\u2013protein interaction than many sequence based features. One of the problems for constructing feature vectors based on PSSM matrices is the variable length of different proteins (the length of the proteins in our dataset varies from 24 to 8797), so we extracted features in such a way that it leads to fixed length feature vectors. Finally we reduced the feature vector dimension to increase the classifier generalization. There are several databases which store protein\u2013protein interactions, but these contain many false positives. We used the HPRD database, which contains protein\u2013protein interactions that are manually extracted from the literature, with each record linked to detailed information. Finally, those interactions in HPRD that were confirmed with at least two experimental methods have been used as a reliable positive dataset. More complex part in gold standard construction is selecting the negative dataset and many previous studies used random pairs as negative interactions. In some studies, protein pairs were coded as feature vector and then those feature vectors of all the protein pairs absent in the positive dataset were computed and finally most distant feature vectors of the mean vector of these feature vectors were selected as the negative dataset. Some other studies also used genetic annotation for selecting the negative dataset. To strictly assess the performance of the proposed evolutionary features and also to examine how the negative dataset selection could affect the performance estimation, we used four different strategies namely RP, SD, MC and MD construct negative interactions (see Materials and methods section). We used the RF classifier to predict protein\u2013protein interactions and used ten-cross validation to compute the F-measure and AUC as two main measures for evaluating the performance. Results show that the SD dataset is the most challenging datasets for classification, however to the best of our knowledge none of the previously published studies had used this strategy to construct a negative dataset to evaluate performance of their methods. It is shown by Yu et al. [16] that the bests previously published studies with a performance reported as near perfect, act not significantly better than random classifier even on simple organisms. It should also be mentioned that AUC on the MC and MD datasets was greater than 99%, it is probably due to the elimination of those feature vectors that are close to the boundary of interacting and non-interacting classes. The results show that the negative dataset selection could lead to acute performance overestimation (the F-measure on the MD dataset was 99.3 and on the SD dataset was 68.3). To further analyze the proposed features, we extracted features only from those parts of proteins that were annotated as a domain in the SMART or Pfam databases. New performances of the four datasets were decreased which suggests that this type of evolutionary information is important in the complete protein sequences. Finally, we extracted features from release 7, 8 and 9 of the HPRD and constructed four mentioned data sets in each release and run the RF on each dataset for analyzing the robustness of new proposed features. The performances were increasing from release 7 to release 9, the results also show that among all of the three releases, the SD dataset was the most challenging datasets and the MC and the MD datasets led to performance overestimations. To assess the prediction power of proposed method on other organisms, we also ran our method on three high quality PPI data from three different model organisms (Arabidopsis thaliana, Caenorhabditis elegans and yeast). The obtained results have been shown in Supplementary figure S1. 5 Availability The Java program for feature extraction and building the dataset is available at: http://lbb.ut.ac.ir/Download/LBBsoft/PPIevo/ Appendix A Supplementary data Supplementary results and analysis. Appendix A Supplementary data Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.ygeno.2013.05.006. References [1] K.A. Theofilatos C.M. Dimitrakopoulos A.K. Tsakalidis S.D. Likothanassis S.T. Papadimitriou S.P. Mavroudi Computational approaches for the prediction of protein\u2013protein interactions: a survey Curr. Bioinforma. 6 2011 398 414 [2] N. Tuncbag G. Kar O. Keskin A. Gursoy R. Nussinov A survey of available tools and web servers for analysis of protein\u2013protein interactions and interfaces Brief. Bioinform. 10 2009 217 232 [3] B. Shoemaker A. Panchenko Deciphering protein\u2013protein interactions. Part II. Computational methods to predict protein and domain interaction partners PLoS Comput. Biol. 3 2007 595 601 [4] S.L. Lo C.Z. Cai Y.Z. Chen M.C. Chung Effect of training datasets on support vector machine prediction of protein\u2013protein interactions Proteomics 5 2005 876 884 [5] J. Shen J. Zhang X. Luo W. Zhu K. Yu K. Chen Y. Li H. Jiang Predicting protein\u2013protein interactions based only on sequences information Proc. Natl. Acad. Sci. 104 2007 4337 4341 [6] E.K.a.A. Narayanan Discovering gene networks with a neural-genetic hybrid IEEE/ACM Transactions on Computational Biology and Bioinformatics 2005 231 242 [7] L.J. Lu Y. Xia A. Paccanaro H. Yu M. Gerstein Assessing the limits of genomic data integration for predicting protein networks Genome Res. 15 2005 945 953 [8] X.W. Chen M. Liu Prediction of protein\u2013protein interactions using random decision forest framework Bioinformatics 21 2005 4394 4400 [9] A. Elefsinioti \u00d6.S. Sara\u00e7 A. Hegele C. Plake N.C. Hubner I. Poser M. Sarov A. Hyman M. Mann M. Schroeder Large-scale de novo prediction of physical protein\u2013protein association Mol. Cell Proteomics 10 2011 [10] R. Jothi M.G. Kann T.M. Przytycka Predicting protein\u2013protein interaction by searching evolutionary tree automorphism space Bioinformatics 21 Suppl. 1 2005 i241 i250 [11] A. Enright I. Iliopoulos N. Kyrpides C. Ouzounis Protein interaction maps for complete genomes based on gene fusion events Nature 402 1999 86 90 [12] T. Ideker O. Ozier B. Schwikowski A. Siegel Discovering regulatory and signalling circuits in molecular interaction networks ISMB(Supp of Bioinformatics) 2002 233 240 [13] Q.C. Zhang D. Petrey L. Deng L. Qiang Y. Shi C.A. Thu B. Bisikirska C. Lefebvre D. Accili T. Hunter Structure-based prediction of protein\u2013protein interactions on a genome-wide scale Nature 490 2012 556 560 [14] G. Liu J. Li L. Wong Assessing and Predicting Protein Interactions Using Both Local and Global Network Topological Metrics, Genome Informatics 2008 [15] S. Jaeger S. Gaudan U. Leser D. Rebholz-Schuhmann Integrating protein\u2013protein interactions and text mining for protein function prediction BMC Bioinforma. 9 Suppl. 8 2008 S2 [16] J. Yu M. Guo C. Needham Y. Huang L. Cai D. Westhead Simple sequence-based kernels do not predict protein\u2013protein interactions Bioinformatics 26 2010 2610 2614 [17] T.S. Keshava Prasad R. Goel K. Kandasamy S. Keerthikumar S. Kumar S. Mathivanan D. Telikicherla R. Raju B. Shafreen A. Venugopal L. Balakrishnan A. Marimuthu S. Banerjee D.S. Somanathan A. Sebastian S. Rani S. Ray C.J. Harrys Kishore S. Kanth M. Ahmed M.K. Kashyap R. Mohmood Y.L. Ramachandra V. Krishna B.A. Rahiman S. Mohan P. Ranganathan S. Ramabadran R. Chaerkady A. Pandey Human protein reference database\u20142009 update Nucleic Acids Res. 37 2009 D767 D772 [18] A. Ben-Hur W. Noble Kernel methods for predicting protein\u2013protein interactions Bioinformatics 21 2005 i38 i46 [19] N. Zaki S. Deris H. Alashwal Protein\u2013protein interaction detection based on substring sensitivity measure Int. J. Biol. Med. Sci. 1 2006 [20] L.V. Zhang S.L. Wong O.D. King F.P. Roth Predicting co-complexed protein pairs using genomic and proteomic data integration BMC Bioinforma. 5 2004 38 [21] D. Han H.S. Kim J. Seo W. Jang A domain combination based probabilistic framework for protein\u2013protein interaction prediction Genome Inform. Ser. 2003 250 260 [22] Y.N. Zhang X.Y. Pan Y. Huang H.B. Shen Adaptive compressive learning for prediction of protein\u2013protein interactions from primary sequence J. Theor. Biol. 283 2011 44 52 [23] I. Ezkurdia L. Bartoli P. Fariselli R. Casadio A. Valencia M.L. Tress Progress and challenges in predicting protein\u2013protein interaction sites Brief. Bioinform. 10 2009 233 246 [24] Y. Qi J. Klein-Seetharaman Z. Bar-Joseph Random forest similarity for protein\u2013protein interaction prediction from multiple sources Pac. Symp. Biocomput. 2005 531 542 [25] J. Wang C. Li E. Wang X. Wang Uncovering the rules for protein\u2013protein interactions from yeast genomic data Proc. Natl. Acad. Sci. 106 2009 3752 3757 [26] D.R. Rhodes S.A. Tomlins S. Varambally V. Mahavisno T. Barrette S. Kalyana-Sundaram D. Ghosh A. Pandey A.M. Chinnaiyan Probabilistic model of the human protein\u2013protein interaction network Nat. Biotechnol. 23 2005 951 959 [27] R. Jansen H. Yu D. Greenbaum Y. Kluger N.J. Krogan S. Chung A. Emili M. Snyder J.F. Greenblatt M. Gerstein A Bayesian networks approach for predicting protein\u2013protein interactions from genomic data Science 302 2003 449 453 [28] L.J. Lu Y. Xia A. Paccanaro H. Yu M. Gerstein Assessing the limits of genomic data integration for predicting protein networks Genome Res. 15 2005 945 953 [29] P. Braun M. Tasan M. Dreze M. Barrios-Rodiles I. Lemmens H. Yu J.M. Sahalie R.R. Murray L. Roncari A.S. De Smet An experimentally derived confidence score for binary protein\u2013protein interactions Nat. Methods 6 2008 91 97 [30] I. Letunic T. Doerks P. Bork SMART 7: recent updates to the protein domain annotation resource Nucleic Acids Res. 40 2012 D302 D305 [31] M. Punta P.C. Coggill R.Y. Eberhardt J. Mistry J. Tate C. Boursnell N. Pang K. Forslund G. Ceric J. Clements A. Heger L. Holm E.L. Sonnhammer S.R. Eddy A. Bateman R.D. Finn The Pfam protein families database Nucleic Acids Res. 40 2012 29 [32] X.W. Chen J.C. Jeong P. Dermyer KUPS: constructing datasets of interacting and non-interacting protein pairs with associated attributions Nucleic Acids Res. 39 2011 D750 D754 [33] A. Ben-Hur W.S. Noble Choosing negative examples for the prediction of protein\u2013protein interactions BMC Bioinforma. 7 2006 S2 [34] M. Shoyaib M. Abdullah-Al-Wadud O. Chae Selecting Negative Examples for Protein\u2013Protein Interaction 2013 2013 (in press) [35] F. Browne H. Wang H. Zheng F. Azuaje GRIP: a web-based system for constructing Gold Standard datasets for protein\u2013protein interaction prediction Source Code Biol. Med. 4 2009 2 [36] Z.-P. Liu L. Chen Proteome-wide prediction of protein\u2013protein interactions from high-throughput data Protein Cell 3 2012 508 520 [37] C. Stark B.J. Breitkreutz A. Chatr-Aryamontri L. Boucher R. Oughtred M.S. Livstone J. Nixon K. Van Auken X. Wang X. Shi T. Reguly J.M. Rust A. Winter K. Dolinski M. Tyers The BioGRID interaction database: 2011 update Nucleic Acids Res. 39 2011 D698 D704 [38] S. Kerrien B. Aranda L. Breuza A. Bridge F. Broackes-Carter C. Chen M. Duesbury M. Dumousseau M. Feuermann U. Hinz C. Jandrasits R.C. Jimenez J. Khadake U. Mahadevan P. Masson I. Pedruzzi E. Pfeiffenberger P. Porras A. Raghunath B. Roechert S. Orchard H. Hermjakob The IntAct molecular interaction database in 2012 Nucleic Acids Res. 40 2012 D841 D846 [39] L. Licata L. Briganti D. Peluso L. Perfetto M. Iannuccelli E. Galeota F. Sacco A. Palma A.P. Nardozza E. Santonico L. Castagnoli G. Cesareni MINT, the molecular interaction database: 2012 update Nucleic Acids Res. 40 2012 D857 D861 [40] P. Smialowski P. Pagel P. Wong B. Brauner I. Dunger G. Fobo G. Frishman C. Montrone T. Rattei D. Frishman A. Ruepp The Negatome database: a reference set of non-interacting protein pairs Nucleic Acids Res. 38 2010 D540 D544 [41] A. Ben-Hur W.S. Noble Choosing negative examples for the prediction of protein\u2013protein interactions BMC Bioinforma. 7 Suppl. 1 2006 S2 [42] I. Xenarios L. Salwinski X.J. Duan P. Higney S.M. Kim D. Eisenberg DIP, the Database of Interacting Proteins: a research tool for studying cellular networks of protein interactions Nucleic Acids Res. 30 2002 303 305 [43] S. Altschul T. Madden A. Schffer Z.J. Zhang W. Miller D. Lipman Gapped BLAST and PSI-BLAST: a new generation of protein database search programs Nucleic Acids Res. 25 1997 3389 3402 [44] M. Kantardzic Data Mining: Concepts, Models, Methods, and Algorithms 2011 Wiley-IEEE Press [45] J. Hausser K. Strimmer Entropy inference and the James-Stein estimator, with application to nonlinear gene association networks J. Mach. Learn. Res. 10 2009 1469 1484 [46] P. Geurts A. Irrthum L. Wehenkel Supervised learning with decision tree-based methods in computational and systems biology Mol. Biosyst. 5 2009 1593 1605 [47] X. Chen M. Wang H. Zhang The use of classification trees for bioinformatics Wiley Interdiscip. Rev. Data Min. Knowl. Disc. 1 2011 55 63 [48] M. Thahir C. Jaime G. Madhavi Active learning for human protein\u2013protein interaction prediction BMC Bioinforma. 11 2010 [49] B.Q. Li K.Y. Feng L. Chen T. Huang Y.D. Cai Prediction of protein\u2013protein interaction sites by random forest algorithm with mRMR and IFS PLoS One 7 2012 e43927 [50] M. Hall E. Frank G. Holmes B. Pfahringer P. Reutemann I.H. Witten The WEKA data mining software: an update ACM SIGKDD Explor. Newsl. 11 2009 10 18", "scopus-id": "84886313848", "pubmed-id": "23747746", "coredata": {"eid": "1-s2.0-S0888754313001213", "dc:description": "Abstract Protein\u2013protein interactions regulate a variety of cellular processes. There is a great need for computational methods as a complement to experimental methods with which to predict protein interactions due to the existence of many limitations involved in experimental techniques. Here, we introduce a novel evolutionary based feature extraction algorithm for protein\u2013protein interaction (PPI) prediction. The algorithm is called PPIevo and extracts the evolutionary feature from Position-Specific Scoring Matrix (PSSM) of protein with known sequence. The algorithm does not depend on the protein annotations, and the features are based on the evolutionary history of the proteins. This enables the algorithm to have more power for predicting protein\u2013protein interaction than many sequence based algorithms. Results on the HPRD database show better performance and robustness of the proposed method. They also reveal that the negative dataset selection could lead to an acute performance overestimation which is the principal drawback of the available methods.", "openArchiveArticle": "true", "prism:coverDate": "2013-10-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S0888754313001213", "dc:creator": [{"@_fa": "true", "$": "Zahiri, Javad"}, {"@_fa": "true", "$": "Yaghoubi, Omid"}, {"@_fa": "true", "$": "Mohammad-Noori, Morteza"}, {"@_fa": "true", "$": "Ebrahimpour, Reza"}, {"@_fa": "true", "$": "Masoudi-Nejad, Ali"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S0888754313001213"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S0888754313001213"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0888-7543(13)00121-3", "prism:volume": "102", "prism:publisher": "Elsevier Inc.", "dc:title": "PPIevo: Protein\u2013protein interaction prediction from PSSM based evolutionary information", "prism:copyright": "Copyright \u00a9 2013 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "08887543", "prism:issueIdentifier": "4", "dcterms:subject": [{"@_fa": "true", "$": "Protein\u2013protein interaction map"}, {"@_fa": "true", "$": "Protein interaction networks"}, {"@_fa": "true", "$": "Computational intelligence"}, {"@_fa": "true", "$": "Machine learning"}, {"@_fa": "true", "$": "Position-specific scoring matrix"}], "openaccessArticle": "true", "prism:publicationName": "Genomics", "prism:number": "4", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "237-242", "prism:endingPage": "242", "prism:coverDisplayDate": "October 2013", "prism:doi": "10.1016/j.ygeno.2013.05.006", "prism:startingPage": "237", "dc:identifier": "doi:10.1016/j.ygeno.2013.05.006", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "27", "@width": "208", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1646", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "27", "@width": "112", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1486", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "27", "@width": "92", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1412", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "328", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2941", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "26", "@width": "83", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1165", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-mmc1.docx?httpAccept=%2A%2F%2A", "@multimediatype": "Microsoft Word file", "@type": "APPLICATION", "@size": "132305", "@ref": "mmc1", "@mimetype": "application/word"}, {"@category": "high", "@height": "1222", "@width": "1684", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "218104", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2176", "@width": "2775", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "413534", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "410", "@width": "2960", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "176080", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "276", "@width": "380", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "30108", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "492", "@width": "627", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "63131", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "93", "@width": "668", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25216", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "159", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10986", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "209", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4436", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "30", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S0888754313001213-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2745", "@ref": "gr1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84886313848"}}
{"scopus-eid": "2-s2.0-46649086341", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2008-01-11 2008-01-11 2010-10-07T15:33:45 1-s2.0-S1532046408000099 S1532-0464(08)00009-9 S1532046408000099 10.1016/j.jbi.2008.01.002 S300 S300.1 FULL-TEXT 1-s2.0-S1532046408X0005X 2015-05-15T06:30:58.184067-04:00 0 0 20080801 20080831 2008 2008-01-11T00:00:00Z articleinfo crossmark dco dateupdated tomb dateloaded datesearch indexeddate issuelist volumelist yearnav articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright dateloadedtxt docsubtype doctype doi eid ewtransactionid hubeid issfirst issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder srctitle srctitlenorm srctype subheadings volfirst volissue webpdf webpdfpagecount table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast primabst ref alllist content oa subj ssids 1532-0464 15320464 41 41 4 4 Volume 41, Issue 4 9 580 587 580 587 200808 August 2008 2008-08-01 2008-08-31 2008 article fla Copyright \u00a9 2008 Elsevier Inc. All rights reserved. EXPLOITINGCONTEXTUALCUESFORBIOENTITYNAMERECOGNITIONINBIOMEDICALLITERATURE YANG Z 1 Introduction 2 Methods 2.1 CRF recognition 2.1.1 Conditional random fields 2.1.2 Feature set 2.2 Exploitation of contextual cues 2.2.1 Bracket pair 2.2.1.1 Full name\u2013abbreviation pair 2.2.1.2 Non-full name\u2013abbreviation pair 2.2.2 Heuristic syntax structure 2.2.3 Interaction words cues 3 Experimental results 3.1 Datasets 3.2 CRF recognition result 3.3 Improving performance by contextual cues 4 Conclusions and future work Acknowledgments References KIM 2003 i180 i182 J HIRSCHMAN 2005 S1 L FINKEL 2005 S5 J TSAI 2006 92 R NOCEDAL 1999 J NUMERICALOPTIMIZATION LAFFERTY 2001 282 289 J PROCEEDINGSINTERNATIONALCONFERENCEMACHINELEARNING CONDITIONALRANDOMFIELDSPROBABILISTICMODELSFORSEGMENTINGLABELINGSEQUENCEDATA MCDONALD 2005 S6 R TSAI 2006 S11 R ZHOU 2005 S7 G YANGX2008X580 YANGX2008X580X587 YANGX2008X580XZ YANGX2008X580X587XZ Full 2014-11-20T07:55:50Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(08)00009-9 S1532046408000099 1-s2.0-S1532046408000099 10.1016/j.jbi.2008.01.002 272371 2010-11-08T20:53:19.236997-05:00 2008-08-01 2008-08-31 1-s2.0-S1532046408000099-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000099/MAIN/application/pdf/158142398a400664a94ee8c7d7130a63/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000099/MAIN/application/pdf/158142398a400664a94ee8c7d7130a63/main.pdf main.pdf pdf true 149112 MAIN 8 1-s2.0-S1532046408000099-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000099/PREVIEW/image/png/896cb53072f91822dad6f5db4c30d1e5/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000099/PREVIEW/image/png/896cb53072f91822dad6f5db4c30d1e5/main_1.png main_1.png png 67592 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046408000099-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000099/STRIPIN/image/gif/4694d627c3b3223c1de9332e94bc8bfd/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000099/STRIPIN/image/gif/4694d627c3b3223c1de9332e94bc8bfd/si4.gif si4 si4.gif gif 1444 46 261 ALTIMG 1-s2.0-S1532046408000099-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000099/STRIPIN/image/gif/1563a7f00641407e4b408dc3f83cf213/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000099/STRIPIN/image/gif/1563a7f00641407e4b408dc3f83cf213/si3.gif si3 si3.gif gif 1765 50 298 ALTIMG 1-s2.0-S1532046408000099-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000099/STRIPIN/image/gif/3e3e28a1573845590a238d40200498df/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000099/STRIPIN/image/gif/3e3e28a1573845590a238d40200498df/si2.gif si2 si2.gif gif 478 17 121 ALTIMG 1-s2.0-S1532046408000099-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046408000099/STRIPIN/image/gif/def0d90756b4ab52ff7452d6311ffccf/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046408000099/STRIPIN/image/gif/def0d90756b4ab52ff7452d6311ffccf/si1.gif si1 si1.gif gif 508 17 128 ALTIMG YJBIN 1408 S1532-0464(08)00009-9 10.1016/j.jbi.2008.01.002 Elsevier Inc. Table 1 The adjusted recognition result example 1 Before adjustment After adjustment NF-Y-associated B-protein NF-Y-associated B-protein factors I-protein factors I-protein ( O ( O YAFs O YAFs B-protein ) O ) O The training and test corpus is presented in IOB notation: words outside of named entities are tagged with \u201cO\u201d, while the first word in a named entity is tagged with B-[entity class], and further named entity words receive tag I-[entity class] for inside. Table 2 The adjusted recognition result example 2 Before adjustment After adjustment Posttransplant O Posttransplant O lymphoproliferative O lymphoproliferative O disorders O disorders O ( O ( O PTLDs B-protein PTLDs O ) O ) O Table 3 The adjusted recognition result example 3 Before adjustment After adjustment Toll-like B-DNA Toll-like B-protein receptor I-DNA receptor I-protein 2 I-DNA 2 I-protein ( O ( O TLR2 B-protein TLR2 B-protein ) O ) O Table 4 Examples of heuristic syntax structure No Examples 1 \u2026two discrete complexes, NFX1.1 and NFX1.2 2 \u2026genes, including EBF, 3 TF-1 cells, an erythroleukemia cell line\u2026 4 Osteocalcin (OC) is a matrix calcium-binding protein\u2026 5 \u2026target genes such as IRF1 and c-fos 6 Mammalian sex-determining gene Sry 7 D609 is a strong electrolyte\u2026 Table 5 Examples of interaction words cues No Examples 1 \u2026basic-leucine zipper factors bind to the StRE 2 \u2026is mainly encoded by ORF 50 3 \u2026interact with 5\u2032 LTR RNA 4 \u2026phosphorylation of 14-3-3 zeta\u2026 Table 6 CRFs recognition results Recall Precision F-score Protein 77.48 69.78 73.43 DNA 66.19 68.40 67.28 RNA 71.19 68.29 69.71 Cell type 65.90 81.74 73.98 Cell line 60.80 56.09 58.35 All 72.86 70.90 71.87 BioCreative 79.24 83.52 81.32 Table 7 CRF recognition performance comparison Recall Precision F-score (before post-processing) F-score (after post-processing) A (BioCreative) 86.4 78.7 82.4 82.4 B (JNLPBA) 71.43 73.41 72.41 72.98 C (JNLPBA) 70.3 69.3 69.8 69.8 D (JNLPBA) 72.86 70.90 71.87 75.04 D (BioCreative) 79.24 83.52 81.32 83.71 A and C did not have apply post-processing methods so their F-scores before and after post-processing are equal. Table 8 Performance improvement by contextual cues JNLPBA BioCreative2004 1A Recall Precision F-score Recall Precision F-score Baseline 72.86 70.90 71.87 79.24 83.52 81.32 BP 74.32 71.41 72.84 80.45 83.80 82.09 HSS 76.96 72.76 74.80 82.18 84.26 83.21 IWC 77.23 72.98 75.04 82.92 84.52 83.71 Table 9 Detailed performance on JNLPBA2004 dataset Class Recall Precision F-score Protein 81.31 73.78 77.36 DNA 74.37 67.82 70.95 RNA 73.86 72.63 73.24 Cell type 70. 89 79.13 75.78 Cell line 67.35 57.17 61.84 Overall 77.23 72.98 75.04 Correct RIGHT 83.42 78.79 81.03 Correct LEFT 80.09 75.64 77.81 Table 10 Instance numbers and performances of the different classes Class Number of instances in training set Number of instances in test set Recall Precision F-score Protein 30269 5067 81.31 73.78 77.36 DNA 9534 1056 74.37 67.82 70.95 RNA 951 118 73.86 72.63 73.24 Cell type 6718 1921 70. 89 79.13 75.78 Cell line 3830 500 67.35 57.17 61.84 Table 11 Performance comparison with the top JNLPBA2004 and BioCreative2004 task 1A systems Recall Precision F-score Ours (JNLPBA) 77.2 73.0 75.0 Zhou (JNLPBA) 76.0 69.4 72.6 Finkel (JNLPBA) 71.6 68.6 70.1 Settles (JNLPBA) 70.3 69.3 69.8 Ours (BioCreative) 82.9 84.5 83.7 Finkel (BioCreative) [4] 82.8 83.5 83.2 Zhou (BioCreative) [22] 82.0 83.2 82.6 McDonald (BioCreative) [18] 86.4 78.7 82.4 The JNLPBA result data are achieved from [1] and the BioCreative result data are achieved from [4,22,18], respectively. Exploiting the contextual cues for bio-entity name recognition in biomedical literature Zhihao Yang \u204e yangzh@dlut.edu.cn Hongfei Lin Yanpeng Li Department of Computer Science and Engineering, Dalian University of Technology, No. 2 LingGong Road, ShaHeKou District, Dalian 116023, China \u204e Corresponding author. Fax: +86 0411 84706550. Abstract To extract biomedical information about bio-entities from the huge amount of biomedical literature, the first key step is recognizing their names in these literatures, which remains a challenging task due to the irregularities and ambiguities in bio-entities nomenclature. The recognition performances of the current popular methods, machine learning techniques, still have much space to be improved. This paper presents a Conditional Random Field-based approach used to recognize the names of bio-entities including gene, protein, cell type, cell line and studies the methods of improving the performance by the exploitation of the contextual cues including bracket pair, heuristic syntax structure and interaction words cue. Experiment results on both JNLPBA2004 and BioCreative2004 task 1A datasets show that these methods can improve Conditional Random Field-based recognition performance by more than 2 points in F-score. Keywords Text mining Information extraction Named entity recognition Conditional random fields Contextual cue 1 Introduction Along with the rapid expansion of biomedical literature, the demand for efficiently extracting biomedical information from the huge amount of resources offer an excellent opportunity for biomedical text mining, i.e., the automatic discovery of biomedical knowledge. Among others, extracting relationship between bio-entities from biomedical literature has become a research focus. To accomplish it, the fundamental task is named entity recognition (NER), which is the identification of text terms referring to items of interest. In biomedical domain, named entities (called bio-entities) include gene, protein, cell type, cell line, etc. Only when these bio-entities are correctly identified could their relationship be extracted correctly. NER is not a new task in text mining. In previous research work, many NER systems have been applied successfully in the newswire domain. But in biomedical domain it remains a challenging task due to the irregularities and ambiguities in bio-entities nomenclature. The irregularities and ambiguities are mainly the result of a lack of naming conventions, as well as the widespread practice of using many synonyms for one gene or protein. For compound entity names, there is additional requirement of determining their boundaries. These factors make NER in the biomedical domain a difficult task. The best system in JNLPBA2004 [1] achieves an F-score of 72.6% on GENIA corpus [2]; in BioCreative2004 task 1A [3] the best system [4] obtained an F-score of 83.2% using relax matching and this score reduced to 74.3% using exact matching [5]. These show the performance of NER in the biomedical domain is far below the one of NER in the general domain. To tackle these challenges, researchers use NLP techniques such as dictionary-based methods, rule-based methods and machine learning. Tsuruoka and Tsujii [6] tagged proteins in GENIA 3.01 with a combination of dictionary and Naive Bayes Classifier, achieving an F-score of 66.6%. Cohen achieved an F-score of 75.6% in gene and protein NER on GENIA 3.02 corpus through building the dictionaries from online genomics resources [7]. Fukuda et al. [8] and Olsson et al. [9] proposed rule-based approaches. The former exploited surface clues and parts of speech. The latter, in addition to surface clues, used a syntactic parser for determining protein name boundaries. Olsson et al. conducted experiments for comparing their system (Yapex) with Fukuda\u2019s system (Kex) on 200 MEDLINE abstracts and reported that they achieved a recall of 66.4% and a precision of 67.8% on Yapex and a recall of 41.1% and a precision of 40.4% on Kex in terms of exact matching. Machine learning techniques have an advantage that they can identify potential bio-entities which are not previously included in standard dictionaries. Currently, there are some research efforts using machine learning techniques to recognize bio-entities in texts. These techniques include HMM [10], SVM [11], MEMM [12], CRFs [13], etc. In JNLPBA2004, Settles achieved an F-score of 69.8% using CRFs with only several kinds of features and no external resource [13]. However, the recognition performances of machine learning techniques such as HMM, MEMM, CRFs depend heavily on the quality and quantity of the training set and the selection of feature set. But it is a time-consuming and costly work to build a large and qualified training set. For example, GENIA corpus is the largest corpus of its type currently available, comprising 2000 abstracts with 18,545 sentences containing 39,373 named entities. However, in GENIA corpus many entities were doubly classified as \u201cprotein molecule or region\u201d and \u201cDNA molecule or region\u201d, suggests that inter-annotator agreement could be low, and that many entities in fact have more than one classification. Another area where GENIA appears inconsistent is in the labeling of preceding adjectives. Take \u201cactivated\u201d for example. Of the 48 times it occurred before or at the beginning of an entity in the training data, it was recognized as a part of an entity 27 times and the resting 21 times was not. There are also inconsistencies when two entities are separated by the word \u201cand\u201d: sometimes they are tagged as one whole entity; while sometimes they are tagged as two separate entities. These inconsistent annotation cases can confuse machine learning based systems including CRFs. As shown in JNLPBA2004 and BioCreative2004 task 1A, the best systems with machine learning techniques achieved the performances of no more than 75% in F-score (using exact matching). To further improve the recognition performance, it is necessary to introduce other methods. Aiming to further improve the performance of bio-entity recognition achieved by CRFs, this paper presents the methods of exploiting the contextual cues. Experiment results show that these methods contribute to the improvement of recognition performance by more than 2 points in F-score. The remaining part of this paper is organized as follows: Section 2 describes our method. Section 3 presents and discusses the experiment results on both JNLPBA2004 and BioCreative2004 task 1A datasets. Finally, Section 4 offers some concluding remarks. 2 Methods Our method is a Conditional Random Field-based method. First we use a CRF model trained on the JNLPBA2004 (or BioCreative2004 task 1A) training set to recognize the bio-entities. Then the results are further processed via the exploitation of the contextual cues including bracket pair, heuristic syntax structure and interaction words cue. The details are described in the following sections. 2.1 CRF recognition 2.1.1 Conditional random fields Bio-entity recognition can be thought of as a sequence segmentation problem: each word is a token in a sequence to be assigned a label (e.g. protein, RNA, DNA, cell line, cell type, or other). Conditional Random Fields are undirected statistical graphical models, a special case of which is a linear chain that corresponds to a conditionally trained finite-state machine. Such models are well suited to sequence analysis. Let o = \u3008 o 1 , o 2 , \u2026 , o n \u3009 be a sequence of observed words of length n. Let S be a set of states in a finite-state machine, each of which is associated with a label \u2208L. Let s = \u3008 s 1 , s 2 , \u2026 , s n \u3009 be the sequence of states in S that correspond to the labels assigned to words in the input sequence o. Linear chain CRFs define the conditional probability of a state sequence given an input sequence to be: (1) P ( s \u2223 o ) = 1 Z exp \u2211 i = 1 n \u2211 j = 1 m \u03bb k f k ( s i - 1 , s i , o , i ) where Z is a normalization factor of all state sequences, fk (si \u22121, si , o, i) is one of m functions that describes a feature, and \u03bbk is a learned weight for each such feature function. The training process is to find the weights that maximize the log likelihood of all instances in training data: (2) LL ( D ) = \u2211 j log ( P ( s j \u2223 o j ) ) - \u2211 k \u03bb k 2 2 \u03c3 2 The second term in Eq. (2) is a spherical Gaussian prior over feature weights. Once these settings are found, the labeling for a new, unlabeled sequence can be done using a modified Viterbi algorithm. We use first-order leaner chain CRFs and LBFGS training method [14]. CRFs are presented in more complete detail by Lafferty et al. [15]. 2.1.2 Feature set Feature based statistical models like CRFs reduce the problem to finding an appropriate feature set. We used the following features: (1) Surface word features: We use words themselves as features. All the words are lower-cased to improve the recall, for example, \u201cJAK2\u201d and \u201cJak2\u201d are all gene names and the loss of information can be compensated through its combination with other features. (2) Orthographic features: Orthographic information is indicative to the class of biomedical named entity. We use regular expressions to extract several orthographic patterns (e.g. capture capitalization and digitalization) from each token of the text and assign the token a binary feature. These features are especially useful to recognize unknown terms. (3) Prefix/suffix features: Many biomedical entities have certain prefix or suffix, such as \u201cantiglobulin\u201d or \u201cinsulin\u201d. For each token the three and four characters\u2019 prefix and suffix are used as feature. For example, for the token \u201cantiglobulin\u201d, the feature tags will be \u201cprefix3=ant\u201d, \u201cprefix4=anti\u201d, \u201csuffix3=lin\u201d and \u201csuffix4=ulin\u201d. These features are all binary types. (4) Word shape features: Word shapes refer to mappings of each word to a simplified representation that encodes attributes such as its length and whether it contains capitalization, numerals, Greek letters, and so on. For example, capital letters are replaced with \u2018A\u2019, lowercase letters with \u2018a\u2019, digits with \u20180\u2019, and all other characters with \u2018x\u2019. Thus \u201cVaricella-zoster\u201d would become Xx-xxx, and \u201cCPA1\u201dwould become XXX0. (5) Compound Features: To model local context simply, neighboring words in the window [\u22121,1] are also added as features. (6) Part-of-speech features: POS may provide useful evidence about the boundaries of biomedical entity names. In our method, GENIA Tagger is applied, which is specifically tuned for biomedical text such as MEDLINE abstracts and achieves an F-score of 98.20% on GENIA corpus [16]. (7) Keyword features: Some words occur more frequently in the entity names. These words (we called keywords) such as \u201cfactor\u201d, \u201creceptor\u201d, \u201csite\u201d, etc. can help to identify entity names. We automatically extract unigram and bigram keywords which occur more than 20 times from the training data. (8) Boundary word features: Most frequent boundary terms (including 1-g and 2-g) that appear in training data more than 5 times are listed. If the text matches terms in the list, it will be assigned this feature. It may be overlapped with word feature, but in our experiment, we found that it could slightly improve the performance. 2.2 Exploitation of contextual cues Through the analysis of the CRF recognition errors, we found the performance could be further improved via the exploitation of the contextual cues. We exploited three kinds of contextual cues: bracket pair, heuristic syntax structure and interaction words cue. 2.2.1 Bracket pair \u201c\u2026Entity name1 (Entity name2)\u2026\u201d is a common phenomenon in biomedical literature which could be used to help identify the entity names and theirs class types. There are two kinds of bracket pair patterns. One is full name\u2013abbreviation pair such as \u201cglucocorticoid receptors (GR)\u201d; the other is non-full name\u2013abbreviation pair such as \u201cB-protein lymphoid Specific octamer binding protein (OTF-2B)\u201d. 2.2.1.1 Full name\u2013abbreviation pair There are many full name\u2013abbreviation pairs in biomedical literature. For example, we found 3252 such pairs appeared in the training set of JNLPBA2004, among which 2260 pairs are annotated as bio-entities, accounting for about 69.5%. Therefore, the recognition performance could be improved via these full name\u2013abbreviation pairs. There are two patterns of these pairs: \u201cexpanded form (abbreviation)\u201d and \u201cabbreviation (expanded form)\u201d. We used a name alias algorithm similar to Schwartz and Hearst [17] to extract these full name\u2013abbreviation pairs and got 654 pairs from the test set. Then the CRF recognition result is adjusted according to these pairs. Some of examples are given in Tables 1\u20133 . In Table 1, before the adjustment, \u201cNF-Y-associated factors\u201d has been recognized as a protein while its abbreviation \u201cYAFs\u201d not. Since they is a full name\u2013abbreviation pair, the abbreviation \u201cYAFs\u201d can be reasonably recognized as a protein; while in Table 2, the tag of the abbreviation \u201cPTLDs\u201d is adjusted from \u201cB-protein\u201d to \u201cO\u201d since its full name \u201cposttransplant lymphoproliferative disorders\u201d refers to a disease. Here we constructed a high frequent Post-keyword list of each class from the training set. First we extracted all the entity names in the training set and then calculated the frequencies of the last words of these entity names. The last words whose frequency is higher than a certain threshold are added to the Post-keyword list. In this case, \u201cdisorders\u201d is not a Post-keyword of any class so \u201cPTLDs\u201d is tagged as \u201cO\u201d. In Table 3 \u201cToll-like receptor 2\u201d is tagged as DNA class by CRF model, but then is adjusted to protein class according to its Post-keyword \u201creceptor\u201d, which is a high frequent Post-keyword of protein class. In addition, the newly found entity names in one Medline record are added to a list for later recognition in the following sentences of this record and those found not bio-entity names are also added to a list for filter out the other false positives in this record. Here the reason we didn\u2019t introduce external dictionary is that there exists the annotation ambiguity problem: an entity name may be annotated as one class type in one context and annotated as another class type in another context. For example, \u201cCD28\u201d can refer to a protein or DNA in different contexts. So we confine the effect of these two lists to current Medline record since in most cases an entity name should be annotated as one class type in one record. 2.2.1.2 Non-full name\u2013abbreviation pair Besides full name\u2013abbreviation pairs, our method can also process non-full name\u2013abbreviation pairs such as \u201cB-protein lymphoid Specific octamer binding protein (OTF-2B)\u201d, which is also a common phenomenon in biomedical literature. In this case, if the long form \u201cB-protein lymphoid Specific octamer binding protein\u201d is recognized as an entity and the short form \u201cOTF-2B\u201d(which has the features of proteins (genes) name, e.g. the first letter is uppercase, including digit or dash) will be classified as the same class of the long form. 2.2.2 Heuristic syntax structure In biomedical literature, there are some heuristic syntax structures that imply the existences of the bio-entities and the classes they belong to. Table 4 shows some heuristic syntax structure examples. The examples 1\u20136 demonstrate the syntax structures that help to identify bio-entities and theirs class. For example, in the example 1, \u201cNFX1.1\u201d and \u201cNFX1.2\u201d can be reasonably recognized as proteins since they are \u201ccomplexes\u201d and \u201ccomplexes\u201d is a high frequent Post-keyword of protein class. While the example 7 help to identify that \u201cD609\u201d should be tagged as \u201cO\u201d since it is an \u201celectrolyte\u201d and \u201celectrolyte\u201d is not a Post-keyword of any class. To find the heuristic syntax structures in text we compiled some heuristic syntax structure patterns manually. Most of them are the appositive and copula structures that are indicative to find the is\u2013a relations. In addition, we found that two similar names (similar length and structure) connected by \u201cand\u201d or \u201cor\u201d often belong to the same class. For example, \u201cNF-YA\u201d and \u201cNF-YB\u201d all belong to the protein class. We call such two similar names Analogy Names. If one of Analogy Names is tagged as one class and the other is tagged \u201cO\u201d, then it is reasonable to tag them as the same class. Furthermore, our method not only uses the coordination or appositives structures expressed by \u201cand\u201d and \u201cor\u201d (which connects two bio-entities) but also those expressed by \u201c,\u201d (which connects more than two bio-entities). For example, in sentence \u201can immunohistochemical study including correlation with cathepsin D, type IV collagen, laminin, fibronectin, EGFR, c-erbB-2 oncoprotein, p53\u2026\u201d, \u201ccathepsin D\u201d, \u201ctype IV collagen\u201d, \u201claminin\u201d, \u201cfibronectin\u201d, \u201cEGFR\u201d, \u201cc-erbB-2 oncoprotein\u201d, \u201cp53\u201d are coordination structure. If some of them are tagged as one class, it is reasonable to tag the rest of them as the same class. 2.2.3 Interaction words cues In biomedical literature, the occurrences of some high frequent protein(gene) interaction verbs like \u201cbind\u201d, \u201cinteract\u201d, \u201cactivate\u201d, \u201cinhibit\u201d and their variants \u201cbinding\u201d, \u201cinteraction\u201d, \u201cactivation\u201d, \u201cinhibition\u201d usually imply the existences of some protein(gene) names nearby (we call them interaction words cues). Table 5 shows some interaction words cue examples. An interaction word list of about 150 entries (including interaction verbs and their variants) was constructed. When an interaction word is detected in text, its subject and object are checked if they look like proteins (genes) (e.g. the first letter is uppercase, including digit or a high frequent Post-keyword of protein (gene) class). Here interaction word\u2019s adjacent previous NP and adjacent next NP are used as its subject and object. 3 Experimental results 3.1 Datasets We conducted experiments using both the JNLPBA2004 and BioCreative2004 task 1A datasets. The JNLPBA2004 training set is GENIA corpus version 3.02 and includes 2000 MEDLINE records retrieved using the MeSH terms \u201chuman\u201d, \u201cblood cells\u201d and \u201ctranscription factors\u201d. The test set includes 404 MEDLINE records and half of them were from the same domain as the training data and the other half of them were from the super-domain of \u201cblood cells\u201d and \u201ctranscription factors\u201d. JNLPBA2004 required participating systems to identify the five named entities of protein, RNA, DNA, cell line and cell type. BioCreative 2004 task 1A dataset consists of 20,000 sentences where 15,000 were chosen for training and the other 5000 sentences for evaluation. Entities labeled in dataset have only one type that combines proteins, DNAs, RNAs into one class labeled as \u201cNEWGENE\u201d. 3.2 CRF recognition result Our CRF recognition result is shown in Table 6 . Results are given as F-scores defined as F =(2PR)/(P + R), where P denotes Precision and R Recall. The last line is the result achieved on BioCreative2004 task 1A dataset. On JNLPBA2004 dataset our CRF model achieved an F-score of 71.87% which is fairly good performance compared with the top JNLPBA2004 systems and only lower than the best system (72.6%) while on BioCreative2004 task 1A dataset it achieved an F-score of 81.32% which is lower than the best system (83.2%). It need to be pointed out that JNLPBA2004 adopted the exact matching criterion: a candidate NE can only be counted as a match if both its boundaries and its class fully coincide with an annotated NE while BioCreative2004 task 1A adopted the relax matching criterion: it allowed several possible correct annotations, of which NER systems need only match one (e.g. both \u201cno correlation between serum <gene>LH</gene>\u201d and \u201cno correlation between <gene>serum LH</gene>\u201d are correct in BioCreAtIvE). We made comparison among four CRF-based methods: McDonald and Pereira [18], Tsai et al. [19], Settles [13] and ours (here respectively represented using A, B, C and D for short). All the four have used CRF as the main framework of machine learning model and the configuration is almost the same: first-order leaner chain CRFs and LBFGS training method. Surface Word Features, Orthographic Features, Prefix/Suffix Features, Word Shape Features and feature conjunction are almost the same in the four systems. However, there are some minor differences among the four systems. A and C did not make use of POS and chunking features, which has been used in B and D. From the results comparison, these features improve the performance by around 1 point in F-score. In addition, D proposed two types of feature i.e., keywords feature and boundary term feature which were not used in the other three systems and improved the performance by 0.5 point in F-score. A made use of gene/protein lexicon information to enhance the performance and applied an automatic feature induction method. C has also used dictionary features by constructing a lexicon of five types of entity, but the effect was little, therefore these are not included in their final system. The main original work of B is so called numerical normalization, and pattern-based post-processing which achieved an improvement of F-score is 1.61 points (from 71.37% to 72.98%). Besides, their window size is five, and all others are three. In our recent research, we find that systems with top performances in BioCreative II have used windows with the size of 5 for feature conjunction [20] [21]. The results of these four methods are shown in Table 7 . Before post-processing our CRF recognition results are not best. However, after post-processing with the methods of exploiting the contextual cues our final recognition results become best (As described in Section 3.3). 3.3 Improving performance by contextual cues To improve the CRF recognition performance we exploited three kinds of contextual cues: bracket pairs (BP), heuristic syntax structure (HSS) and interaction words cues (IWC). Their contributions to the performance are showed in Table 8 (the first line is our CRF recognition baseline result). On JNLPBA2004 dataset the F-score is improved to 75.04% from 71.87% (an improvement of 3.17 points). BP, HSS and IWC contribute 0.97%, 1.96% and 0.24%, respectively; on BioCreative2004 task 1A dataset the F-score is improved to 83.71% from 81.32% (an improvement of 2.39 points). BP, HSS and IWC contribute 0.77%, 1.12% and 0.5%, respectively. Of all three contextual cues, HSS contributes most on both datasets. However, the patterns of HSS need to be carefully designed to achieve a good performance. Performance improvement by the exploitation of contextual cues on JNLPBA2004 dataset is higher than the one on BioCreative2004 dataset (3.17 points to 2.39 points) since the former is composed of Medline records and newly found entity names in previous sentences in a record can be used in the next sentences of this record while the latter is composed of unrelated sentences and, therefore, has no this advantage. On the other hand, the exploitation of contextual cues contributes more to the improvement of Recall than to the improvement of Precision (4.37s point to 2.08s point on JNLPBA2004 and 2.68 points to 1.0 point on BioCreative2004). This shows contextual cues including bracket pairs, heuristic syntax structure and interaction words cues can find new entity names but produce some false positives at the same time. Table 9 shows the detailed performance on JNLPBA2004 dataset. The last two lines are Right Boundary Correct and Left Boundary Correct performance. The former (81.03% in F-score) is much higher than Fully Correct (75.04% in F-score) which shows that many errors occurred at left boundaries of long names. Since our method is a CRF-based one, the recognition performance of one class mainly depends on the amount of instances of this class in training corpus. The instance numbers and performances of the different classes are shown in Table 10 . The performances of DNA and cell line are relatively inferior mainly due to the small amount of instances of these classes in training corpus. However, RNA is an exception because of its regular nomenclature: most RNA instances end with some high frequent Post-keywords such as \u201cmRNA(s)\u201d, \u201cRNA(s)\u201d, and \u201ctranscript(s)\u201d. In fact, the nomenclatures of cell type and cell line are also relatively regular: most cell type instances end with \u201ccell(s)\u201d, \u201clymphocyte(s)\u201d, and \u201clineage(s)\u201d; most cell line instances end with \u201ccell(s)\u201d, \u201cline(s)\u201d, \u201clymphocyte(s)\u201d, and \u201cclone(s)\u201d. However, cell line and cell type class are difficult to distinguish even for an expert since many instances of the two classes end with some common words such as \u201ccell(s)\u201d and \u201clymphocyte(s)\u201d. The Precision of cell line is rather low (57.17%) which shows that more instances of cell type are mistakenly tagged as cell line. In addition, the number of cell line instances in test set is relatively small (500 instances) and its performance is more sensitive to the influence of wrong tagging between cell type and cell line, which is the main reason for its poor performance (61.84% in F-score). In fact, combining cell type and cell line into another single class (we call it \u201cNewcell\u201d) can effectively improve the performance. Our experiment shows that class \u201cNewcell\u201d obtain an F-score of 78.80% which is higher than the ones of cell type and cell line (75.78% and 61.84%). Table 11 shows the performance comparison among the top JNLPBA2004, BioCreative2004 systems and ours. Through the exploitation of the contextual cues our method achieved higher performances (75.0% and 83.7% in F-score, respectively) than the systems in both NLPBA2004 and BioCreative2004 task 1A. 4 Conclusions and future work This paper presents a CRF-based bio-entity name recognition approach and studies the methods of improving the performance via the exploitation of the contextual cues. Experiment results on NLPBA2004 and BioCreative2004 task 1A datasets showed that these methods improve the recognition performance by more than 2 points in F-score. At present machine learning techniques such as HMM, MEMM, CRFs are popular bio-entity name recognition approaches. However, their recognition performances seem to have encountered a threshold due to the irregularities and ambiguities of bio-entities nomenclature as well as the lack of large and qualified training set. In JNLPBA2004 and BioCreative2004 task 1A, using exact matching strategy, the best systems achieved an F-score of no more than 75% (72.6% and 74.3%, respectively) and it is difficult to improve the recognition performance even by one point in F-score. On the other hand, our experiment results on JNLPBA2004 and BioCreative2004 task 1A datasets show that the exploitation of the contextual cues maybe a promising method to further improve the recognition performance. Contextual cues such as bracket pair, heuristic syntax structure and interaction words cue could provide relatively precise information about bio-entities and their class. These contextual cues as a feature of natural language abound in biomedical literature and can help improve the recognition performance on a certain degree. In addition, the exploitation of the contextual cues is not limited to any specific dataset, thus having general applicability. In fact, the annotation rules of JNLPBA2004 and BioCreative2004 task 1A datasets are not quite the same, but the method of exploitation of the contextual cues work well on both datasets. In fact, besides the contextual cues exploited in our method, we also found other contextual cues that could be utilized. For example, in sentence \u201cSteroid identities were confirmed by gas chromatography/mass spectrometry (GC/MS)\u201d, \u201cgas chromatography/mass spectrometry\u201d and \u201cGC/MS\u201d are a full name\u2013abbreviation pair. Even though the word \u201cGC/MS\u201d has the features of a protein (or gene) (including capital letters and \u201c/\u201d) but is not likely to be a protein (or gene) since in most cases a protein (or gene) cannot \u201cconfirm\u201d and it is more like an assay method. To filter such false positive the related domain knowledge as well as syntax analysis tool need to be introduced. In fact, attempts to incorporate domain knowledge to improve recognition performance have been reported. McDonald and Pereira 2005 used ABGene lexicons as features and obtained an improvement of 2 points in F-score. These lexicons include general biological terms, amino acids, restriction enzymes, cell lines, organism names and non-biological terms. Zhou and Su made use of SwissProt and the alias list LocusLink as external dictionary features which improved the performance by 1.2 points in F-score. However, most of domain knowledge ever used is only external dictionary of protein, gene and other biological entities. Our idea is to construct a domain knowledge database which includes all kind of bio-entities class, their properties and actions they can do and can be done. Then via in-domain syntactic parser, the domain knowledge database can be used to filter out false positives and recover false negatives. Interaction words cues described in our manuscript is a simple implement of our idea and it did improve the performance (0.2 and 0.5 point on JNLPBA2004 and BioCreative2004, respectively). On the other hand, the domain knowledge database could be difficult to construct. Many online biomedical resources such as UMLS Knowledge Sources [23] (Metathesaurus and Semantic Network) and GO [24] may be utilized. Experts with backgrounds in biochemistry, genetics and molecular biology are needed to provide relative domain knowledge. In addition, at present, the performance of current in-domain syntactic parser is not good enough. All these are the problems we must solve to improve the performance by incorporating domain knowledge. Acknowledgments This work is supported by grant from the Natural Science Foundation of China (No. 60373095 and 60673039) and the National High Tech Research and Development Plan of China (2006AA01Z151). References [1] Kim JD, Ohta T, Tsuruoka Y, Tateisi Y, Collier N. Introduction to the bio-entity recognition task at JNLPBA. In: Proceedings of the international workshop on natural language processing in biomedicine and its applications, Geneva, Switzerland; 2004. p. 70\u20135. [2] J.D. Kim T. Ohta Y. Tateisi J. Tsujii GENIA corpus\u2014a semantically annotated corpus for bio-text mining Bioinformatics 19 Suppl. 1 2003 i180 i182 [3] L. Hirschman M. Colosimo A. Morgan A. Yeh Overview of BioCreAtIvE: critical assessment of information extraction for biology BMC Bioinformatics 6 Suppl. 1 2005 S1 [4] J. Finkel S. Dingare C.D. Manning M. Nissim B. Alex C. Grover Exploring the boundaries: gene and protein identification in biomedical text BMC Bioinformatics 6 Suppl. 1 2005 S5 [5] R.T. Tsai S.H. Wu W.C. Chou Y.C. Lin D. He J. Hsiang Various criteria in the evaluation of biomedical named entity recognition BMC Bioinformatics 7 2006 92 [6] Tsuruoka Y, Tsujii J. Boosting precision and recall of dictionary-based protein name recognition. In: Proceedings of the ACL-03 workshop on natural language processing in biomedicine, Sapporo, Japan; 2003. p. 41\u20138. [7] Cohen AM. Unsupervised gene/protein entity normalization using automatically extracted dictionaries. In: Proceedings of the ACL-ISMB workhop on linking biological literature, ontologies and databses: mining biological semantics, Detroit, MI; 2005. p. 14\u201324. [8] Fukuda K, Tsunoda T, Tamura A, Takagi T. Toward information extraction: identifying protein names from biological papers. In: Proceedings of the pacific symposium on biocomputing, Hawai, USA; 1998; p. 705\u201316. [9] Olsson F, Eriksson G, Franzen K, Asker L, Liden P. Notions of correctness when evaluating protein name taggers. In: Proceedings of the 19th international conference on computational linguistics, Taipei, Taiwan; 2002. p. 765\u201371. [10] Zhou G, Su J. Exploring deep knowledge resources in biomedical name recognition. In: Proceedings of the joint workshop on natural language processing in biomedicine and its applications, Geneva, Switzerland; 2004. p. 96\u20139. [11] Lee KJ, Hwang YS, Rim HC. Two-phase biomedical NE recognition based on SVMs. In: Proceedings of the ACL\u20192003 workshop on natural language processing in biomedicine, Sapporo, Japan; 2003. p. 33\u201340. [12] Finkel J, Dingare S, Nguyen H, Nissim M, Manning C, Sinclair G. Exploiting context for biomedical entity recognition: from syntax to the web. In: Proceedings of the joint workshop on natural language processing in biomedicine and its applications, Geneva, Switzerland; 2004. p. 88\u201391. [13] Settles B. Biomedical named entity recognition using conditional random fields and novel feature sets. In: Proceedings of the joint workshop on natural language processing in biomedicine and its applications, Geneva, Switzerland; 2004. p. 104\u20137. [14] J. Nocedal S.J. Wright Numerical optimization 1999 Springer Series in Operations Research New York p. 388 [15] J. Lafferty A. McCallum F. Pereira Conditional random fields: probabilistic models for segmenting and labeling sequence data Proceedings of the international conference on machine learning 2001 Morgan Kaufmann San Francisco, CA 282 289 [16] Tsuruoka Y, Tateishi Y, Kim JD, Ohta T, McNaught J, Ananiadou S, et al. Developing a Robust part-of-speech tagger for biomedical text. In: Advances in informatics\u201410th Panhellenic conference on informatics, Volos, Greece; 2005. p. 382\u201392. [17] Schwartz AS, Hearst MA. A simple algorithm for identifying abbreviation definitions in biomedical text. In: Proceedings of the pacific symposium on biocomputing, Hawai, USA; 2003. p. 451\u201362. [18] R. McDonald F. Pereira Identifying gene and protein mentions in text using conditional random fields BMC Bioinformatics 6 Suppl. 1 2005 S6 [19] R.T. Tsai C.L. Sung H.J. Dai H.C. Hung T.Y. Sung W.L. Hsu NERBio: using selected word conjunctions, term normalization, and global patterns to improve biomedical named entity recognition BMC Bioinformatics 7 Suppl. 5 2006 S11 [20] Ando RK. BioCreative II gene mention tagging system at IBM Watson. In: Proceedings of the second biocreative challenge evaluation workshop (BioCreative II), Madrid, Spain; April 2007. [21] Kuo CJ, Chang YM, Huang HS, Lin KT, Yang BH, Lin YS, et al. Rich feature set, unification of bidirectional parsing and dictionary filtering for high F-score gene mention tagging. In: Proceedings of the second BioCreative challenge evaluation workshop (BioCreative II), Madrid, Spain; April 2007. [22] G. Zhou D. Shen J. Zhang J. Su T.H. Soon C.L. Tan Recognition of protein/gene names from text using an ensemble of classifiers and effective abbreviation detection BMC Bioinformatics 6 Suppl. 1 2005 S7 [23] UMLS, Unified Medical Language System, http://www.nlm.nih.gov/pubs/factsheets/umls.html [Retrieved September 12, 2007]. [24] GO, Gene Ontology, http://www.geneontology.org/ [Retrieved September 12, 2007].", "scopus-id": "46649086341", "pubmed-id": "18272430", "coredata": {"eid": "1-s2.0-S1532046408000099", "dc:description": "Abstract To extract biomedical information about bio-entities from the huge amount of biomedical literature, the first key step is recognizing their names in these literatures, which remains a challenging task due to the irregularities and ambiguities in bio-entities nomenclature. The recognition performances of the current popular methods, machine learning techniques, still have much space to be improved. This paper presents a Conditional Random Field-based approach used to recognize the names of bio-entities including gene, protein, cell type, cell line and studies the methods of improving the performance by the exploitation of the contextual cues including bracket pair, heuristic syntax structure and interaction words cue. Experiment results on both JNLPBA2004 and BioCreative2004 task 1A datasets show that these methods can improve Conditional Random Field-based recognition performance by more than 2 points in F-score.", "openArchiveArticle": "true", "prism:coverDate": "2008-08-31", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046408000099", "dc:creator": [{"@_fa": "true", "$": "Yang, Zhihao"}, {"@_fa": "true", "$": "Lin, Hongfei"}, {"@_fa": "true", "$": "Li, Yanpeng"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046408000099"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046408000099"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(08)00009-9", "prism:volume": "41", "prism:publisher": "Elsevier Inc.", "dc:title": "Exploiting the contextual cues for bio-entity name recognition in biomedical literature", "prism:copyright": "Copyright \u00a9 2008 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "prism:issueIdentifier": "4", "dcterms:subject": [{"@_fa": "true", "$": "Text mining"}, {"@_fa": "true", "$": "Information extraction"}, {"@_fa": "true", "$": "Named entity recognition"}, {"@_fa": "true", "$": "Conditional random fields"}, {"@_fa": "true", "$": "Contextual cue"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "prism:number": "4", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "580-587", "prism:endingPage": "587", "prism:coverDisplayDate": "August 2008", "prism:doi": "10.1016/j.jbi.2008.01.002", "prism:startingPage": "580", "dc:identifier": "doi:10.1016/j.jbi.2008.01.002", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "46", "@width": "261", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000099-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1444", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "50", "@width": "298", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000099-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1765", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "121", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000099-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "478", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "128", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046408000099-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "508", "@ref": "si1", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/46649086341"}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608009000501", "dc:identifier": "doi:10.1016/j.neunet.2009.03.012", "eid": "1-s2.0-S0893608009000501", "prism:doi": "10.1016/j.neunet.2009.03.012", "pii": "S0893-6080(09)00050-1", "dc:title": "Intelligence in the brain: A theory of how it works and how to build it ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2009 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "22", "prism:issueIdentifier": "3", "prism:startingPage": "200", "prism:endingPage": "212", "prism:pageRange": "200-212", "prism:number": "3", "dc:format": "application/json", "prism:coverDate": "2009-04-30", "prism:coverDisplayDate": "April 2009", "prism:copyright": "Published by Elsevier Ltd.", "prism:issueName": "Goal-Directed Neural Systems", "dc:creator": [{"@_fa": "true", "$": "Werbos, Paul J."}], "dc:description": "\n               Abstract\n               \n                  This paper presents a theory of how general-purpose learning-based intelligence is achieved in the mammal brain, and how we can replicate it. It reviews four generations of ever more powerful general-purpose learning designs in Adaptive, Approximate Dynamic Programming (ADP), which includes reinforcement learning as a special case. It reviews empirical results which fit the theory, and suggests important new directions for research, within the scope of NSF\u2019s recent initiative on Cognitive Optimization and Prediction. The appendices suggest possible connections to the realms of human subjective experience, comparative cognitive neuroscience, and new challenges in electric power. The major challenge before us today in mathematical neural networks is to replicate the \u201cmouse level\u201d, but the paper does contain a few thoughts about building, understanding and nourishing levels of general intelligence beyond the mouse.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Intelligence"}, {"@_fa": "true", "$": "Reinforcement learning"}, {"@_fa": "true", "$": "Backpropagation"}, {"@_fa": "true", "$": "Cognitive prediction"}, {"@_fa": "true", "$": "Adaptive critic"}, {"@_fa": "true", "$": "ADP"}, {"@_fa": "true", "$": "Adaptive dynamic programming"}, {"@_fa": "true", "$": "Approximate dynamic programming"}, {"@_fa": "true", "$": "Complexity"}, {"@_fa": "true", "$": "Creativity"}, {"@_fa": "true", "$": "Neurocontrol"}, {"@_fa": "true", "$": "Comparative neuropsychology"}, {"@_fa": "true", "$": "Freud"}, {"@_fa": "true", "$": "Robust"}, {"@_fa": "true", "$": "Consciousness"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608009000501", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608009000501", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "67349247013", "scopus-eid": "2-s2.0-67349247013", "pubmed-id": "19386468", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/67349247013", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20090329", "$": "2009-03-29"}}}}}
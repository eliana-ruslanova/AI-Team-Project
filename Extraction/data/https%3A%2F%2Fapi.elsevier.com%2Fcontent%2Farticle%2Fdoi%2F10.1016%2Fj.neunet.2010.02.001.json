{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608010000262", "dc:identifier": "doi:10.1016/j.neunet.2010.02.001", "eid": "1-s2.0-S0893608010000262", "prism:doi": "10.1016/j.neunet.2010.02.001", "pii": "S0893-6080(10)00026-2", "dc:title": "Comparison of behavior-based and planning techniques on the small robot maze exploration problem ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "pubType": "\n               2010 Special Issue\n            ", "prism:issn": "08936080", "prism:volume": "23", "prism:issueIdentifier": "4", "prism:startingPage": "560", "prism:endingPage": "567", "prism:pageRange": "560-567", "prism:number": "4", "dc:format": "application/json", "prism:coverDate": "2010-05-31", "prism:coverDisplayDate": "May 2010", "prism:copyright": "Copyright \u00a9 2010 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "prism:issueName": "The 18th International Conference on Artificial Neural Networks, ICANN 2008", "dc:creator": [{"@_fa": "true", "$": "Slu\u0161n\u00fd, Stanislav"}, {"@_fa": "true", "$": "Neruda, Roman"}, {"@_fa": "true", "$": "Vidnerov\u00e1, Petra"}], "dc:description": "\n               Abstract\n               \n                  A comparison of behavior-based and planning approaches of robot control is presented in this paper. We focus on miniature mobile robotic agents with limited sensory abilities. Two reactive control mechanisms for an agent are considered\u2014a radial basis function neural network trained by evolutionary algorithm and a traditional reinforcement learning algorithm over a finite agent state space. The control architecture based on localization and planning is compared to the former method.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Evolutionary robotics"}, {"@_fa": "true", "$": "Neural networks"}, {"@_fa": "true", "$": "Reinforcement learning"}, {"@_fa": "true", "$": "Localization"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608010000262", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608010000262", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "77950252122", "scopus-eid": "2-s2.0-77950252122", "pubmed-id": "20346859", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/77950252122", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20100210", "$": "2010-02-10"}}}}}
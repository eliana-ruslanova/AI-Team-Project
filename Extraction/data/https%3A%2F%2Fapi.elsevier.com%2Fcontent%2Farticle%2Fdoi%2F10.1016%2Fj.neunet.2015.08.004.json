{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608015001586", "dc:identifier": "doi:10.1016/j.neunet.2015.08.004", "eid": "1-s2.0-S0893608015001586", "prism:doi": "10.1016/j.neunet.2015.08.004", "pii": "S0893-6080(15)00158-6", "dc:title": "Budget constrained non-monotonic feature selection ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "71", "prism:startingPage": "214", "prism:endingPage": "224", "prism:pageRange": "214-224", "dc:format": "application/json", "prism:coverDate": "2015-11-30", "prism:coverDisplayDate": "November 2015", "prism:copyright": "Copyright \u00a9 2015 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Yang, Haiqin"}, {"@_fa": "true", "$": "Xu, Zenglin"}, {"@_fa": "true", "$": "Lyu, Michael R."}, {"@_fa": "true", "$": "King, Irwin"}], "dc:description": "\n               Abstract\n               \n                  Feature selection is an important problem in machine learning and data mining. We consider the problem of selecting features under the budget constraint on the feature subset size. Traditional feature selection methods suffer from the \u201cmonotonic\u201d property. That is, if a feature is selected when the number of specified features is set, it will always be chosen when the number of specified feature is larger than the previous setting. This sacrifices the effectiveness of the non-monotonic feature selection methods. Hence, in this paper, we develop an algorithm for non-monotonic feature selection that approximates the related combinatorial optimization problem by a Multiple Kernel Learning (MKL) problem. We justify the performance guarantee for the derived solution when compared to the global optimal solution for the related combinatorial optimization problem. Finally, we conduct a series of empirical evaluation on both synthetic and real-world benchmark datasets for the classification and regression tasks to demonstrate the promising performance of the proposed framework compared with the baseline feature selection approaches.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Feature selection"}, {"@_fa": "true", "$": "Multiple kernel learning"}, {"@_fa": "true", "$": "Budget constraint"}, {"@_fa": "true", "$": "Non-monotonic"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608015001586", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608015001586", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84943528698", "scopus-eid": "2-s2.0-84943528698", "pubmed-id": "26433049", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84943528698", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20150904", "$": "2015-09-04"}}}}}
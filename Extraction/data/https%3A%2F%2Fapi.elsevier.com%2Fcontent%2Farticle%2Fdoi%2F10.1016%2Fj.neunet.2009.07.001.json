{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608009001555", "dc:identifier": "doi:10.1016/j.neunet.2009.07.001", "eid": "1-s2.0-S0893608009001555", "prism:doi": "10.1016/j.neunet.2009.07.001", "pii": "S0893-6080(09)00155-5", "dc:title": "Sparse kernel learning with LASSO and Bayesian inference algorithm ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "23", "prism:issueIdentifier": "2", "prism:startingPage": "257", "prism:endingPage": "264", "prism:pageRange": "257-264", "prism:number": "2", "dc:format": "application/json", "prism:coverDate": "2010-03-31", "prism:coverDisplayDate": "March 2010", "prism:copyright": "Copyright \u00a9 2009 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Gao, Junbin"}, {"@_fa": "true", "$": "Kwan, Paul W."}, {"@_fa": "true", "$": "Shi, Daming"}], "dc:description": "\n               Abstract\n               \n                  Kernelized LASSO (Least Absolute Selection and Shrinkage Operator) has been investigated in two separate recent papers [Gao, J., Antolovich, M., & Kwan, P. H. (2008). L1 LASSO and its Bayesian inference. In W. Wobcke, & M. Zhang (Eds.), Lecture notes in computer science: Vol. 5360 (pp. 318\u2013324); Wang, G., Yeung, D. Y., & Lochovsky, F. (2007). The kernel path in kernelized LASSO. In International conference on artificial intelligence and statistics (pp. 580\u2013587). San Juan, Puerto Rico: MIT Press]. This paper is concerned with learning kernels under the LASSO formulation via adopting a generative Bayesian learning and inference approach. A new robust learning algorithm is proposed which produces a sparse kernel model with the capability of learning regularized parameters and kernel hyperparameters. A comparison with state-of-the-art methods for constructing sparse regression models such as the relevance vector machine (RVM) and the local regularization assisted orthogonal least squares regression (LROLS) is given. The new algorithm is also demonstrated to possess considerable computational advantages.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "LASSO"}, {"@_fa": "true", "$": "RVM"}, {"@_fa": "true", "$": "Bayesian inference"}, {"@_fa": "true", "$": "Kernel models"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608009001555", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608009001555", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "73949113489", "scopus-eid": "2-s2.0-73949113489", "pubmed-id": "19604671", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/73949113489", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20090709", "$": "2009-07-09"}}}}}
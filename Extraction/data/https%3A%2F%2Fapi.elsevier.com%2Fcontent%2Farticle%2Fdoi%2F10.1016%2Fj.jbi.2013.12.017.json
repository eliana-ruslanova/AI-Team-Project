{"scopus-eid": "2-s2.0-84899475978", "originalText": "serial JL 272371 291210 291682 291870 291901 31 80 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2014-01-31 2014-01-31 2015-08-06T04:49:43 1-s2.0-S1532046414000069 S1532-0464(14)00006-9 S1532046414000069 10.1016/j.jbi.2013.12.017 S300 S300.4 FULL-TEXT 1-s2.0-S1532046414X0002X 2015-08-06T04:15:33.721744-04:00 0 0 20140401 20140430 2014 2014-01-31T00:00:00Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor highlightsabst primabst ref specialabst 1532-0464 15320464 true 48 48 C Volume 48 17 130 136 130 136 201404 April 2014 2014-04-01 2014-04-30 2014 Original Research Articles article fla Copyright \u00a9 2014 Elsevier Inc. All rights reserved. EXTRACTINGIMPORTANTINFORMATIONCHINESEOPERATIONNOTESNATURALLANGUAGEPROCESSINGMETHODS WANG H 1 Introduction 2 Background 3 Methods 3.1 Data collection and preprocessing 3.2 Data elements to extract and annotation method 3.3 Extraction strategy 3.4 Rule-based model 3.5 Conditional Random Fields based model 4 Results 5 Discussion and future work 6 Conclusion Acknowledgments References HORNBERGER 2009 110 J JONNALAGADDA 2012 129 140 S FRIEDMAN 1994 161 174 C HAUG 1995 284 288 P HAUG 1997 814 818 P FRIEDMAN 1999 256 260 C HAHN 2002 338 349 U MACK 2004 490 515 R ZENG 2006 30 Q SAVOVA 2010 507 513 G MELTON 2005 448 457 G GORYACHEV 2008 247 251 S LI 2010 563 567 Z XU 2010 19 24 H CHAPMAN 2001 301 310 W ZHENG 2011 1113 1122 J LIU 2011 163 179 K LIU 2012 177 186 Y MEYSTRE 2008 128 144 S UZUNER 2011 552 556 O PATRICK 2011 574 579 J XU 2012 Y RINK 2011 594 600 B ZHOU 2010 710 716 X LI 2008 H XU 2013 Y FRIEDMAN 1994 161 174 C OGREN 2006 273 275 P HEINTZELMAN 2012 N SOHN 2013 S UZUNER 2010 514 518 O TSAI 2006 92 R LINDBERG 1993 281 291 D WANGX2014X130 WANGX2014X130X136 WANGX2014X130XH WANGX2014X130X136XH Full 2015-04-01T00:18:08Z ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ OA-Window item S1532-0464(14)00006-9 S1532046414000069 1-s2.0-S1532046414000069 10.1016/j.jbi.2013.12.017 272371 2015-08-06T04:15:33.721744-04:00 2014-04-01 2014-04-30 1-s2.0-S1532046414000069-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/MAIN/application/pdf/f405775bcfd7e681b81b7048bbc642bb/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/MAIN/application/pdf/f405775bcfd7e681b81b7048bbc642bb/main.pdf main.pdf pdf true 1052034 MAIN 7 1-s2.0-S1532046414000069-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/PREVIEW/image/png/2ef52ee3541be7a083178238045bc3ab/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/PREVIEW/image/png/2ef52ee3541be7a083178238045bc3ab/main_1.png main_1.png png 59034 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046414000069-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/STRIPIN/image/gif/d084932204d48a1bb550b8d26bb5b23e/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/STRIPIN/image/gif/d084932204d48a1bb550b8d26bb5b23e/si3.gif si3 si3.gif gif 1558 42 236 ALTIMG 1-s2.0-S1532046414000069-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/STRIPIN/image/gif/caa8960b3bff208b20369cf45e0fad92/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/STRIPIN/image/gif/caa8960b3bff208b20369cf45e0fad92/si2.gif si2 si2.gif gif 3848 86 553 ALTIMG 1-s2.0-S1532046414000069-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/STRIPIN/image/gif/365d59fa9c0f2b61218be5a36378128f/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/STRIPIN/image/gif/365d59fa9c0f2b61218be5a36378128f/si1.gif si1 si1.gif gif 3279 86 524 ALTIMG 1-s2.0-S1532046414000069-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr1/HIGHRES/image/jpeg/5e0c9385fb2d39a7238cbe4626801921/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr1/HIGHRES/image/jpeg/5e0c9385fb2d39a7238cbe4626801921/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 202211 516 1297 IMAGE-HIGH-RES 1-s2.0-S1532046414000069-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/fx1/HIGHRES/image/jpeg/0e68829f75884f0732557e5cd9b80b09/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/fx1/HIGHRES/image/jpeg/0e68829f75884f0732557e5cd9b80b09/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 149174 810 2213 IMAGE-HIGH-RES 1-s2.0-S1532046414000069-gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr6/HIGHRES/image/jpeg/3d95c478d06f7ba430c1a36989ad69d2/gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr6/HIGHRES/image/jpeg/3d95c478d06f7ba430c1a36989ad69d2/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 91020 664 1969 IMAGE-HIGH-RES 1-s2.0-S1532046414000069-gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr5/HIGHRES/image/jpeg/41b59de56f489b3a7d945b7d27e9306b/gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr5/HIGHRES/image/jpeg/41b59de56f489b3a7d945b7d27e9306b/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 310892 809 1969 IMAGE-HIGH-RES 1-s2.0-S1532046414000069-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr4/HIGHRES/image/jpeg/e669d9f27df116298c281797c320120a/gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr4/HIGHRES/image/jpeg/e669d9f27df116298c281797c320120a/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 58620 515 1152 IMAGE-HIGH-RES 1-s2.0-S1532046414000069-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr3/HIGHRES/image/jpeg/d2c80ea1a0ce63a1ccee03334be06792/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr3/HIGHRES/image/jpeg/d2c80ea1a0ce63a1ccee03334be06792/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 76284 474 1296 IMAGE-HIGH-RES 1-s2.0-S1532046414000069-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr2/HIGHRES/image/jpeg/99355ccd54ea2cf464f402aad79d6ba8/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr2/HIGHRES/image/jpeg/99355ccd54ea2cf464f402aad79d6ba8/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 90262 720 827 IMAGE-HIGH-RES 1-s2.0-S1532046414000069-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr1/DOWNSAMPLED/image/jpeg/2d58ab4b8eb145cd874e6ff9b8fa61c2/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr1/DOWNSAMPLED/image/jpeg/2d58ab4b8eb145cd874e6ff9b8fa61c2/gr1.jpg gr1 gr1.jpg jpg 59677 194 488 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414000069-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/fx1/DOWNSAMPLED/image/jpeg/dbf7efcbe6744b70655313388fb7aa40/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/fx1/DOWNSAMPLED/image/jpeg/dbf7efcbe6744b70655313388fb7aa40/fx1.jpg fx1 true fx1.jpg jpg 29634 183 500 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414000069-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr6/DOWNSAMPLED/image/jpeg/4cc173a6d4831e8c58216e862d0076c6/gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr6/DOWNSAMPLED/image/jpeg/4cc173a6d4831e8c58216e862d0076c6/gr6.jpg gr6 gr6.jpg jpg 14734 150 444 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414000069-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr5/DOWNSAMPLED/image/jpeg/229c80567b407f60cf83537fc9f86182/gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr5/DOWNSAMPLED/image/jpeg/229c80567b407f60cf83537fc9f86182/gr5.jpg gr5 gr5.jpg jpg 29176 182 444 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414000069-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr4/DOWNSAMPLED/image/jpeg/65f9070d3896d7f2f2607e21b48f59aa/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr4/DOWNSAMPLED/image/jpeg/65f9070d3896d7f2f2607e21b48f59aa/gr4.jpg gr4 gr4.jpg jpg 17805 169 378 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414000069-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr3/DOWNSAMPLED/image/jpeg/17be033eae898f41e803740b2e33d283/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr3/DOWNSAMPLED/image/jpeg/17be033eae898f41e803740b2e33d283/gr3.jpg gr3 gr3.jpg jpg 28195 178 488 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414000069-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr2/DOWNSAMPLED/image/jpeg/71b534d160df4adb4c83339a0ea67d48/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr2/DOWNSAMPLED/image/jpeg/71b534d160df4adb4c83339a0ea67d48/gr2.jpg gr2 gr2.jpg jpg 35750 271 311 IMAGE-DOWNSAMPLED 1-s2.0-S1532046414000069-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr1/THUMBNAIL/image/gif/32dbf3de5013318ad0249ba3a9d8790f/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr1/THUMBNAIL/image/gif/32dbf3de5013318ad0249ba3a9d8790f/gr1.sml gr1 gr1.sml sml 6191 87 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414000069-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/fx1/THUMBNAIL/image/gif/2aa8ebfe386a2955a13bb1e55decf48e/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/fx1/THUMBNAIL/image/gif/2aa8ebfe386a2955a13bb1e55decf48e/fx1.sml fx1 true fx1.sml sml 3169 80 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414000069-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr6/THUMBNAIL/image/gif/5cafdfa2938e5f595f2e74974fdba68a/gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr6/THUMBNAIL/image/gif/5cafdfa2938e5f595f2e74974fdba68a/gr6.sml gr6 gr6.sml sml 4521 74 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414000069-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr5/THUMBNAIL/image/gif/a36f80d2d09852f9f4e8d50c7ed5d673/gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr5/THUMBNAIL/image/gif/a36f80d2d09852f9f4e8d50c7ed5d673/gr5.sml gr5 gr5.sml sml 6226 90 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414000069-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr4/THUMBNAIL/image/gif/5ef0efbd024c54d17d5a3cfb4ed87fbb/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr4/THUMBNAIL/image/gif/5ef0efbd024c54d17d5a3cfb4ed87fbb/gr4.sml gr4 gr4.sml sml 2599 98 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414000069-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr3/THUMBNAIL/image/gif/86b818be98cb3180c5f0cae7fb492927/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr3/THUMBNAIL/image/gif/86b818be98cb3180c5f0cae7fb492927/gr3.sml gr3 gr3.sml sml 3238 80 219 IMAGE-THUMBNAIL 1-s2.0-S1532046414000069-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046414000069/gr2/THUMBNAIL/image/gif/00e5adf073d4cee3ffb5dc428a4b67e4/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046414000069/gr2/THUMBNAIL/image/gif/00e5adf073d4cee3ffb5dc428a4b67e4/gr2.sml gr2 gr2.sml sml 6690 164 188 IMAGE-THUMBNAIL YJBIN 2109 S1532-0464(14)00006-9 10.1016/j.jbi.2013.12.017 Elsevier Inc. Fig. 1 An operation note sample written in Chinese free-text. Fig. 2 Annotation illustration. Fig. 3 Pipeline of the extracting system. Fig. 4 Example of some regular expressions and vocabulary. Fig. 5 Precision, recall and F-score for each question using CRF model with 3 binary features (exact matching). Fig. 6 Comparisons between results on training data and testing data using CRF method. Table 1 Pair-wise inter-annotator agreement results between each annotator and the gold standard. Annotator-1 (%) Annotator-2 Q1 93.91 93.04 Q2 96.25 98.75 Q3 95.24 89.29 Q4 100.00 100.00 Q5 100.00 98.10 Q6 100.00 96.43 Q7 77.68 72.32 Q8 71.05 93.86 Q9 100.00 100.00 Q10 53.45 97.41 Q11 95.37 95.37 Q12 75.00 77.50 All 85.46 92.16 Table 2 Questions for our extracting system. Question ID Question Q1 Whether the patient has tumor thrombus and specify the location if found Q2 Whether tumor capsule is intact or not Q3 Whether tumor boundary is clear or not Q4 Whether patient has hemorrhage and specify the volume if found Q5 Whether patient has ascites and specify the volume if found Q6 Whether patient has an enlargement issue Q7 Whether patient accepted blood transfusion and specify the volume if found Q8 Tumor location Q9 Degree of hepatic cirrhosis Q10 Whether patient\u2019s liver is soft or hard Q11 Tumor size Q12 Whether patient accepted portal vein blocking and specify the duration if found Table 3 Keywords for each data element and its English expression, the order of attributes is in correspondence with that in Table 2. For one attribute, more than one keyword may be assigned, which are split by \u201c|\u201d. Question ID a Shorthand English expression Keywords Q1 \u764c\u6813 Tumor thrombus \u764c\u6813|\u6813\u5b50 Q2 \u5305\u819c Tumor capsule \u5305\u819c Q3 \u8fb9\u754c Tumor boundary \u754c|\u8fb9\u754c Q4 \u51fa\u8840 Hemorrhage \u51fa\u8840 Q5 \u8179\u6c34 Ascites \u8179\u6c34 Q6 \u80bf\u5927 Lymph node enlargement \u80bf\u5927 Q7 \u8f93\u8840 Blood transfusion volume \u8f93\u8840 Q8 \u4f4d\u7f6e Tumor location \u4f4d\u4e8e|\u626a\u53ca Q9 \u786c\u5316 Hepatic cirrhosis \u786c\u5316 Q10 \u8d28 Hardness \u8d28 Q11 \u76f4\u5f84 Tumor size \u5927\u5c0f\u7ea6|\u76f4\u5f84\u7ea6|\u7ea6 Q12 \u963b\u65ad Portal vein blocking \u963b\u65ad a Refer to Table 2 for details. Table 4 Rule category. Category ID Value type Questions C1 Modality or quantity+unit Q4(\u51fa\u8840),Q5(\u8179\u6c34),Q7(\u8f93\u8840),Q12(\u963b\u65ad) C2 Modality Q1(\u764c\u6813),Q6(\u80bf\u5927) ,Q9(\u786c\u5316) C3 Quantity+unit Q11(\u76f4\u5f84) C4 Short description Q2(\u5305\u819c),Q3(\u8fb9\u754c),Q10(\u8d28) C5 Long description Q8(\u4f4d\u7f6e) Table 5 Overall performance of rule-based system and CRF model. Category Exact matching Inexact matching Precision Recall F-score Precision Recall F-score Rule-based method 0.510 0.591 0.548 0.510 0.603 0.553 CRF 0.390 0.681 0.496 0.412 0.720 0.524 CRF with 3 binary features 0.583 0.696 0.635 0.596 0.712 0.649 Table 6 Precision, recall and F-score of rule-based method for each question. Question ID Shorthand Exact matching Inexact matching Precision Recall F-score Precision Recall F-score Q1 \u764c\u6813 0.846 0.815 0.83 0.846 0.815 0.830 Q2 \u5305\u819c 0.667 0.174 0.276 0.667 0.174 0.276 Q3 \u8fb9\u754c 0.789 0.652 0.714 0.789 0.652 0.714 Q4 \u51fa\u8840 0.288 1.000 0.447 0.288 1.000 0.447 Q5 \u8179\u6c34 0.621 0.818 0.706 0.621 0.818 0.706 Q6 \u80bf\u5927 0.489 0.920 0.639 0.489 0.920 0.639 Q7 \u8f93\u8840 0.412 0.875 0.560 0.412 0.875 0.560 Q8 \u4f4d\u7f6e 0.679 0.633 0.655 0.786 0.733 0.759 Q9 \u786c\u5316 0.667 0.286 0.400 0.667 0.286 0.400 Q10 \u8d28 1.000 0.750 0.857 1.000 0.750 0.857 Q11 \u76f4\u5f84 0.207 0.194 0.200 0.207 0.194 0.200 Q12 \u963b\u65ad 0.385 0.385 0.385 0.385 0.385 0.385 Table 7 A sample of extracted result. Question ID Keyword Extracted value Q2 \u5305\u819c \u5b8c\u6574 Q3 \u754c \u6e05 Q4 \u51fa\u8840 100ml Q5 \u8179\u6c34 \u65e0 Q7 \u8f93\u8840 \u65e0 Q8 \u4f4d\u4e8e \u809d\u5de6\u53f6 Q10 \u8d28 \u786c Q12 \u963b\u65ad \u672a Extracting important information from Chinese Operation Notes with natural language processing methods Hui Wang a b c Weide Zhang d Qiang Zeng e Zuofeng Li e Kaiyan Feng f Lei Liu a b e \u204e liulei@fudan.edu.cn a Shanghai Public Health Clinical Center, Institutes of Biomedical Sciences, and Key laboratory of Medical Molecular Virology, Ministry of Education and Health, Fudan University, Shanghai, China Shanghai Public Health Clinical Center Institutes of Biomedical Sciences, and Key laboratory of Medical Molecular Virology Ministry of Education and Health Fudan University Shanghai China b Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention of Shanghai, Fudan University, Shanghai, China Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention of Shanghai Fudan University Shanghai China c Key Laboratory of Systems Biology, Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences, Shanghai, China Key Laboratory of Systems Biology Shanghai Institutes for Biological Sciences Chinese Academy of Sciences Shanghai China d Zhongshan Hospital, Fudan University, Shanghai, China Zhongshan Hospital Fudan University Shanghai China e Shanghai Center for Bioinformatics Technology, Shanghai, China Shanghai Center for Bioinformatics Technology Shanghai China f BGI-Shenzhen, Shenzhen, China BGI-Shenzhen Shenzhen China \u204e Corresponding author at: Shanghai Public Health Clinical Center, Institutes of Biomedical Sciences, and Key laboratory of Medical Molecular Virology, Ministry of Education and Health, Fudan University, Shanghai, China. Graphical abstract Highlights \u2022 A novel information extraction strategy for Chinese free-text EMR is proposed. \u2022 Both rule-base method and sequential labeling method (CRF) are explored. \u2022 Totally, 12 important data elements related to hepatic carcinomas are extracted. \u2022 Two boundary matching strategies (exact, overlapped) are introduced for evaluation. \u2022 This work provides some insights for Chinese natural language processing. Abstract Extracting information from unstructured clinical narratives is valuable for many clinical applications. Although natural Language Processing (NLP) methods have been profoundly studied in electronic medical records (EMR), few studies have explored NLP in extracting information from Chinese clinical narratives. In this study, we report the development and evaluation of extracting tumor-related information from operation notes of hepatic carcinomas which were written in Chinese. Using 86 operation notes manually annotated by physicians as the training set, we explored both rule-based and supervised machine-learning approaches. Evaluating on unseen 29 operation notes, our best approach yielded 69.6% in precision, 58.3% in recall and 63.5% F-score. Keywords Clinical operation notes Information extraction Chinese EMR Conditional random fields 1 Introduction Clinical documents contain a wealth of information for medical study. It has been advocated that electronic medical record (EMR) adoption is a key to solving problems related to quality of care, clinical decision support, and reliable information flow among individuals and departments participating in patient care [1]. But a large part of EMRs\u2019 data is saved in an unstructured textual format (such as discharge summaries and progress reports) which presents a big challenge for automated text mining. Manually annotating such narratives by domain experts is definitely a time consuming and error-prone process. Therefore, extracting relevant data elements from clinical narratives constitutes a basic enabling technology to unlock the knowledge within and support more advanced reasoning applications such as diagnosis explanation, disease progression modeling, and intelligent analysis of the effectiveness of treatment [2]. Recent years we have seen rapid adoption of hospital information system across China and medical documents in Chinese are accumulating fast. Realizing the potential of Chinese EMRs is a burgeoning field of research. A lot of approaches have been developed for English medical language processing, but studies focusing on Chinese are relatively limited. In this paper we have tried both rule-based method and sequential labeling algorithm which have been applied on English successfully. The structured representation of medical concepts and values could enable physicians a quick abstraction of patients\u2019 pathological status and also offers great convenience for large scale analysis. The results can also provide us with a lot of insights on how to design extracting models according to Chinese own characteristics. 2 Background In the past 20years, a number of tools and systems have been developed specifically for information extraction from clinical documents [3\u201310]. These systems and methods have been applied to many different tasks such as adverse events detection [11], abstraction of family history from discharge summaries [12], medication information extraction [13,14], etc. Due to the casualty and conciseness of clinical narratives, methods for fine-grained demand such as negation detection [15], coreference resolution [16], and ontology techniques [17,18] are also explored. Meystre et al. [19] presented a detailed review for extracting information from textual documents in EMRs. The i2b2 [20] organizers have held a series of shared tasks focusing on biomedical informatics since 2006. The fourth i2b2/VA shared-task and workshop [21] dealing with extraction of medical concepts, assertions and relations in clinical text was quite informative for our study. A number of novel approaches [22\u201324] were proposed by worldwide participants. Studies on Chinese NLP started in recent 10years. Research groups at Stanford University have developed several software focusing on Chinese word segmentation [25,26]. Their tools rely on a linear-chain conditional random filed (CRF) model, which treats word segmentation as a binary decision task. ICTCLAS (Institute of Computing Technology, Chinese Lexical Analysis System) [27] is an integrated Chinese lexical analysis system that uses an approach based on multi-layer HMM. ICTCLAS includes word segmentation, Part-Of-Speech tagging and unknown words recognition. Both precision and recall rates reached above 90%. Topics like Chinese named entity recognition has also been investigated, Jiang and his colleagues did a preliminary work on symptom recognition from traditional Chinese medicine records and proposed some reasonable features for machine learning models [28]. Zhao et al. reported their findings on which kind of tokens that should be taken as the graininess in NER task, characters or words [29]. Group from Zhejiang University has conducted several projects on extracting temporal relation [30] from Chinese narrative medical records and terms and negation detection [31]. Based on CRF model, they explored different templates with 63 annotated documents and achieved 86.94% accuracy in extracting temporal attributes and almost 100% accuracy in detecting negations. Researchers from Microsoft Research Asia established an annotated corpus of Chinese discharge summaries and conducted word segmentation and named entity recognition [32]. They improved the performance of both tasks by using combined techniques called dual decomposition. Our problem is not much alike named entity recognition. What we want to extract is values for our pre-defined concepts or attributes. For example, attributes like tumor size recorded in operation note is very important to clinicians, so we expect to get (attribute: value) pair like (tumor size: 2*3*3cm) automatically when given a paragraph of plain text. These attributes are questions frequently inquired by doctors. MedLEE [33] and MedKATp [34] have similar functions as our method has, but their approaches are rule-based. No machine learning method has ever been applied to solve the problems mentioned above. Our unique contribution in this paper is an extracting strategy based on keyword search, extracting answers by sequential tagging results. With this method, doctors can effectively obtain structured data from free-text operation notes. 3 Methods 3.1 Data collection and preprocessing Clinical documents we used for developing and testing our approaches were operation notes of hepatic carcinomas. We obtained a total of 115 electronic medical records from Zhongshan Hospital affiliated to Fudan University. They came from 115 individual patients who were admitted between July and November in 2008. The original EMRs from the database of the hospital contained all information of patients such as basic information, operation notes, and discharge summaries and so on. We converted the de-identified EMRs into a format of XML (each content has a tag as identifier) and isolated the operation notes from other contents. Then, 86 samples were randomly selected for training extracting models and the rest 29 operation notes were left for evaluation. Fig. 1 shows a sample of operation notes we used. 3.2 Data elements to extract and annotation method After extensive consultation with medical researchers and doctors from hepatic department of Zhong Shan hospital, we identified 12 data elements doctors wanted to get from a free-text operation note. These data were key information of operation details and usually highly related to patients\u2019 pathological status. They would be of great value for clinical studies of hepatic carcinoma if they can be automatically processed into structured format. These data elements were targets of our extracting system and they are presented as 12 questions shown in Table 2. Two doctors were recruited to annotate these 12 elements manually in all 115 samples. We used Prot\u00e9g\u00e9 [35] (version 3.3.1) to establish ontology for each clinical entity to be extracted from the operation notes. A plug-in called Knowtator [36] recorded each entity\u2019s location in the documents. A third clinical researcher was in charge of dealing with inconsistence between the two annotations. Then the annotated dataset were used as gold standard for constructing and validating our models. Table 1 lists the inter-annotator agreement results compared to the gold standard. There were 961 entities annotated, 704 in training dataset and 257 in test dataset. For each questions, there were at least 20 samples for training, and 20 for testing. An annotation sample is shown in Fig. 2 . 3.3 Extraction strategy When extracting knowledge manually from EMRs, people usually search for some keywords which related to (or indicate) the concepts they concern. For example, when looking up whether the patient has tumor thrombus, one will first locate the word \u201cthrombus\u201d and then scan for answers from its context, neighboring words of this keyword. Our extracting strategy is to simulate this procedure by computer, so our method is a two-step process. The whole pipeline of our system can be found in Fig. 3 . First we locate the attributes by identifying related keywords. According to doctors\u2019 suggestions we picked one to three keywords manually for each question. These keywords were generated purely based on doctors\u2019 clinical knowledge and experience and the doctors were not enrolled in the annotation procedure. Keywords for each question are listed in Table 3 together with their English expressions. This step can be regarded as a much simplified named entity recognition procedure. When keywords are found by string matching in one sentence, the sentence is tagged and passed into next step. In the second step we are trying to find potential answer in the context of keyword. Rule-based method and Conditional Random Fields algorithm are explored. We did not conduct word segmentation process, so we treat each individual character as a token. 3.4 Rule-based model By observing the operation notes we have noticed that doctors from the same department share some distinctive sub-language. For one specific attribute, value type and value location in its context is relatively regular. According to this fact we tried out rule-based method since it has demonstrated good performance on medical language processing [37,38]. First we classified these 12 questions into 5 categories by their value types (Table 4 ), different category adopted different rule. We also collected frequently mentioned terms into question-specific vocabulary, such as units. The extracting strategy combined with regular expression and term searching within such vocabulary. Dataset for testing is not used in vocabulary collecting and rule designing phase. Fig. 4 shows some of the regular expressions and vocabulary we manually compiled. Totally, 16 rules were developed to undertake the extraction task. For category C1\u2013C4, a look-up window with size 8 is used when detecting values surrounding keywords. For category C5, since the rule incorporated with punctuation, there was no fixed window size assigned. The content which can be matched by our rules is the output of the system. 3.5 Conditional Random Fields based model Conditional Random Fields (CRFs) are a class of undirected graphical models with exponent distribution [39]. This model is widely used on solving sequence tagging problem in medical natural language processing domain. To train such models, we remarked the training set with BIO tags indicating whether a character is the beginning of the value word, in the word or out of the word. We used basic features like Cn and CnCn +1 where C 0 represents the current character and Cn represents the nst character from the current character. 3 binary features were also added in the training template: D(Cn ), M(Cn ) and N(Cn ) indicating whether the current character is a number or a sign multiplication (e.g. \u201cx\u201d,\u201c*\u201d) or a negation word (e.g. \u201c\u65e0\u201d) respectively. We chose package CRF++ [40] to train and test our model. The parameter for cost is set to 10.0 in the training phase. Here is the list showing all the features we used in the template: (a) Cn (n =\u22123, \u22122, \u22121, 0, 1, 2, 3); (b) CnCn +1 (n =\u22123, \u22122, \u22121, 0, 1, 2); (c) D(Cn ) (n =\u22123, \u22122, \u22121, 0, 1, 2, 3); (d) M(Cn ) (n =\u22123, \u22122, \u22121, 0, 1, 2, 3); (e) N(Cn ) (n =\u22123, \u22122, \u22121, 0, 1, 2, 3); In this way, we got 12 unique models for each question. Given a sentence (sequence), the model will choose a tag (\u201cB\u201d, \u201cI\u201d or \u201cO\u201d) for each character. Then characters tagged \u201cB\u201d and \u201cI\u201d continuously will be joined together as the final output for this extraction task. 4 Results As mentioned before, both training data and testing dataset were annotated by clinicians. Every entity annotated was saved with its absolute location number (start position and end position) in the documents. To measure the performance of our extraction algorithm, 29 samples that were not utilized nor observed in the training phase were used for evaluation. The output of our system was re-organized into format like the following: model=\u201cQ5\u201d value=\u201c\u65e0\u201d pos=\u201c1580:1581\u201d Start position index and end position index were compared with that in gold standard annotation. If the two numbers are exactly the same, the record is marked correct with exact matching. While if the interval indicated by the two indexes contains the span in gold standard, it will be marked correct with inexact matching. We used standard metrics (precision, recall and F-score) for measuring the performance. Let S be the size of the ground truth list (doctors\u2019 annotations), D is the number of correct, distinct values extracted by our system and N be the total number of values returned by the system [41]. Then: recall = D S = number of correct, distinct values returned by the system size of the ground truth list precision = D N = number of correct, distinct values returned by the system total number of results returned by the system F score = 2 \u2217 precision \u2217 recall precision + recall Since the performance of keyword identification step will affect the extraction results, we first evaluate this process. In all of the 115 operation notes, our system identified 1058 keywords according to our manually specified keyword list, among which 966 is true positive. So for all the 967 entities, we achieved 91.3% precision, 99.9% recall and 95.4% F-score. To evaluate the performance of value extraction, two boundary matching strategies were adopted. One was exact matching, that is, both the start and the end of the system\u2019s output must be exactly the same with the reference annotation; the other was inexact match [42], with the system\u2019s output containing the right answers. We computed precision, recall and F-score for both matching strategies. The performance of rule-based method and CRF model can be summarized in Table 5 . Table 6 shows results for each question from our rule-based system. Since values got from exact matching can be filled into structured information table without any post-processing step, we gave more attention on the result of exact matching. Fig. 5 plotted detailed performance of each question using CRF with 3 binary features. Fig. 6 shows the comparisons between results on training dataset and testing dataset using CRF model with 3 binary features. Table 7 shows a sample of result extracted by our system, which is the most desirable output of our system. By this means we can automatically convert free-text language into structured information. 5 Discussion and future work Manual annotation by doctors was used as gold standard reference in our evaluation process. The benefits are: (1) The doctors annotated the information based on their professional background that would improve the accuracy of the results; (2) The result tagged by Prot\u00e9g\u00e9 Knowtator contained not only the text information, but also the location of the results, which was very conducive in establishing data mining models; (3) The annotating ontology was structured following human cognitive to ensure the value of the models. The keyword identification step, as mentioned earlier, is a much simplified named entity recognition procedure. Since the attributes are pre-defined and the samples came from the same department of a hospital, style of the expression of concepts (entities) were relatively fixed or stable. That\u2019s why we got pretty high accuracy in automatically recognizing them. If we hope to make the extractor more generalizable and robust, which means extend the use to other department from other hospital, more work should been done to improve it. We may consider using a Chinese medical dictionary (like UMLS [43]) and categorize the potential attribute by value types, just like we did in rule-based method. Rule-based system outperforms the CRF model we developed using 3 characters in the context. From the result of rule-based system, we can find out that there is little difference in exact and inexact matching but for Q8 (tumor location). Values for tumor location are all descriptive text without fixed length or controlled vocabulary, so the result is reasonable. If more detailed rules were added to the current system, there was still some space for the overall performance to get better. For example, Q4 and Q6 had much higher recall than precision, which means the current rules precisely captured part of potential values and missed the rest. They need other rules to capture. While for Q2 and Q9, who have relatively higher precision than recall, they need more specific rules to separate the \u201cright answer\u201d with the noise. Giving more work on rule designing may contribute to the performance, but this may also make the system even harder to generalize and bring about over fitting problem. Introducing those 3 binary features (is_digit, is_multiplication, is_negation) improved the CRF model significantly. Our best configuration for CRF reached 63.5% and 64.9% in F-score for exact and inexact matching respectively, while still have some distance compared with method developed for English language. From Fig. 5 we can see that most questions had a F-score above 50% except Q8 (tumor location), Q11 (tumor size) and Q12 (portal vein blocking). For tumor location, the reason for badly performed is still the uncertain of value length and shortage of features. As for tumor location, the desired values were either in the format like \u201c2*2*3cm\u201d or just like \u201c5cm\u201d. There were also some contexts describing two tumors together, such as \u201ctumors size are 2cm and 3cm\u201d(\u80bf\u7624\u5927\u5c0f\u7ea62cm\u548c3cm). Our model might be confused by these different circumstances due to unbalanced distribution in samples. For the attribute \u201cportal vein blocking\u201d, which belongs to category \u201cmodality or quantity+unit\u201d, we did not consider the distribution of different value type when splitting training set and testing set. There turns out to be too many \u201cmodality\u201d samples in training data while relatively more \u201cquantity+unit\u201d samples in testing set, so the model would have some preferences in specific values. It can also explain the result in Fig. 6 in which Q6 and Q9 had better performance on test dataset than on the training. This situation may be improved by a balanced group in value types. We think the power of CRF model is not fully exploited, so we may try out more lexical and syntactic features on the model in the future work, such as Part-Of-Speech tags. A combination of rule-based method and CRF model is also worth trying. Since CRF model tend to have low recall, the output of model still need some post processing step. We can design some rules to exclude the noise. 6 Conclusion In this paper, we developed two kinds of extraction method for Chinese operation notes, rule-base method and CRF model base method. We obtained 63.5% F-score by average for all 12 questions. With further study, this method can significantly improve the efficiency in processing EMRs and facilitate researchers to effectively obtain valuable information for medical research. Acknowledgments This work is supported by National High-tech R&D Program of China (Grant Nos. 2012AA02A602 and 2012AA02A604), Research Grants (Grant Nos. 2012ZX09303013-015 and 2012ZX10002010-002) from the Ministry of Science and Technology and National Health and Family Planning Commission of the People\u2019s Republic of China, Research Grant (Grant No. 201302010) from National Health and Family Planning Commission of the People\u2019s Republic of China, and Research Grant (Grant No. 13DZ1512102) from Science and Technology Commission of Shanghai Municipality. References [1] J. Hornberger Electronic health records: a guide for clinicians and administrators. Book and media review JAMA 301 1 2009 110 [2] S. Jonnalagadda T. Cohen S. Wu G. Gonzalez Enhancing clinical concept extraction with distributional semantics J Biomed Inform 45 1 2012 129 140 [3] C. Friedman P.O. Alderson J. Austin A general natural language text processor for clinical radiology J Am Med Inform Assoc 1 1994 161 174 [4] P.J. Haug S. Koehler L.M. Lau Experience with a mixed semantic/syntactic parser Proc Annu Symp Comput Appl Med Care 1995 284 288 [5] P.J. Haug L. Christensen M. Gundersen A natural language parsing system for encoding admitting diagnoses Proc AMIA Annu Fall Symp 1997 814 818 [6] C. Friedman C. Knirsch L. Shagina Automating a severity score guideline for community-acquired pneumonia employing medical language processing of discharge summaries Proc AMIA Symp 1999 256 260 [7] U. Hahn M. Romacker S. Schulz Creating knowledge repositories from biomedical reports: the MEDSYNDIKATE text mining system Pac Symp Biocomput 2002 338 349 [8] R. Mack S. Mukherjea A. Soffer Text analytics for life science using the unstructured information management architecture IBM Syst J 43 2004 490 515 [9] Q. Zeng S. Goryachev S. Weiss Extracting principal diagnosis, comorbidity and smoking status for asthma research: evaluation of a natural language processing system BMC Med Inform Decis Mak 6 2006 30 [10] G.K. Savova J.J. Masanz P.V. Ogren Mayo clinical text analysis and knowledge extraction system (cTAKES): architecture, component evaluation and applications J Am Med Inform Assoc 17 2010 507 513 [11] G.B. Melton G. Hripcsak Automated detection of adverse events using natural language processing of discharge summaries J Am Med Inform Assoc 12 2005 448 457 [12] S. Goryachev H. Kim Q. Zeng-Treitler Identification and extraction of family history information from clinical reports AMIA Annu Symp Proc 2008 247 251 [13] Z. Li F. Liu L. Antieau Y. Cao H. Yu Lancet: a high precision medication event extraction system for clinical text J Am Med Inform Assoc 17 2010 563 567 [14] H. Xu S.P. Stenner S. Doan MedEx: a medication information extraction system for clinical narratives J Am Med Inform Assoc 17 2010 19 24 [15] W.W. Chapman W. Bridewell P. Hanbury G.F. Cooper B.G. Buchanan A simple algorithm for identifying negated findings and diseases in discharge summaries J Biomed Inform 2001 301 310 [16] J. Zheng W.W. Chapman R.S. Crowley G.K. Savova Coreference resolution: a review of general methodologies and applications in the clinical domain J Biomed Inform 44 6 2011 1113 1122 [17] K. Liu W.R. Hogan R.S. Crowley Natural language processing methods and systems for biomedical ontology learning J Biomed Inform 44 2011 163 179 [18] Y. Liu A. Coulet P. LePendu Using ontology-based annotation to profile disease research J Am Med Inform Assoc 19 2012 177 186 [19] S.M. Meystre G.K. Savova K.C. Kipper-Schuler Extracting information from textual documents in the electronic health record: a review of recent research Yearb Med Inform 2008 128 144 [20] Informatics for Integrating Biology and the Bedside (i2b2). NIH-funded National Center for Biomedical Computing (NCBC) based at Partners HealthCare System in Boston, MA; established in 2004. <http://www.i2b2.org/NLP> [accessed 31.07.12]. [21] O. Uzuner B. South S. Shen I2b2/VA challenge on concepts, assertions, and relations in clinical text J Am Med Inform Assoc 18 2011 552 556 [22] J.D. Patrick D.H. Nguyen Y. Wang M. Li A knowledge discovery and reuse pipeline for information extraction in clinical notes J Am Med Inform Assoc 18 2011 574 579 [23] Y. Xu K. Hong J. Tsujii Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries J Am Med Inform Assoc 2012 10.1136/amiajnl-2011-000776 [24] B. Rink S. Haraba giu K. Roberts Automatic extraction of relations between medical concepts in clinical texts J Am Med Inform Assoc 18 2011 594 600 [25] Pradhan S, Sun H, Ward W, Martin JH, Jurafsky D. Parsing arguments of nominalizations in English and Chinese. In: The human language technology conference/North American chapter of the association for computational linguistics annual meeting (HLT/NAACL-2004). [26] Chang PC, Galley M, Manning C. Optimizing Chinese word segmentation for machine translation performance. In: ACL workshop on statistical, machine translation; 2008. p. 224\u201332. [27] Zhang HP, Yu HK, Xiong DY, Liu Q. HHMM-based Chinese lexical analyzer ICTCLAS. In: Proceedings of SIGHAN, workshop; 2003. [28] Jiang Y, Yu Z, Wang Y, Liu Y, Chen L. A preliminary work on symptom name recognition from free-text clinical records of traditional Chinese medicine using conditional random fields and reasonable features. In: BioNLP: Proceedings of the 2012 workshop on biomedical natural language processing. [29] Liu Z, Zhu C, Zhao T. Chinese named entity recognition with a sequence labeling approach: based on characters, or based on words. In: Advanced intelligent computing theories and applications 2010. With aspects of artificial intelligence, vol. 6216; 2010. p. 634\u201340. [30] X.J. Zhou H.M. Li H.L. Duan X.D. Lu The automatic extraction of temporal relation from Chinese narrative medical records using conditional random fields Chin J Biomed Eng 29 5 2010 710 716 [31] H.M. Li Y. Li H.L. Duan X.D. Lu Term extraction and negation detection method in Chinese clinical document Chin J Biomed Eng 27 5 2008 [32] Y. Xu Y. Wang T. Liu Joint segmentation and named entity recognition using dual decomposition in Chinese discharge summaries J Am Med Inform Assoc 2013 [33] C. Friedman P.O. Alderson J. Austin A general natural language text processor for clinical radiology J Am Med Inform Assoc 1 1994 161 174 [34] http://ohnlp.sourceforge.net/MedKATp/. [35] http://protege.stanford.edu/. [36] P.V. Ogren Knowtator: a Prot\u00e9g\u00e9 plug-in for annotated corpus construction Proc Hum Lang Technol 2006 273 275 [37] N.H. Heintzelman R.J. Taylor G.S. Bova Longitudinal analysis of pain in patients with metastatic prostate cancer using natural language processing of medical record text J Am Med Inform Assoc 2012 [38] S. Sohn K.B. Wagholikar D. Li S.R. Jonnalagadda C. Tao R.K. Elayavilli Comprehensive temporal information detection from clinical text: medical events, time, and TLINK identification J Am Med Inform Assoc 2013 [39] Lafferty JD, McCallum A, Pereira FCN. Conditional random fields: probabilistic models for segmenting and labeling sequence data. In: Proceedings of the 18th international conference on machine learning. Burlington, MA, USA: Morgan Kaufmann Publishers Inc.; 2001. p. 282\u20139. [40] Kudo T.CRF++: Yet Another CRF Toolkit. <http://crfpp.sourceforge.net/>. [41] O. Uzuner I. Solti E. Cadag Extracting medication information from clinical text J Am Med Inform Assoc 17 2010 514 518 [42] R.T.H. Tsai S.H. Wu W.C. Chou Y.C. Lin D. He J. Hsiang Various criteria in the evaluation of biomedical named entity recognition BMC Bioinform 7 2006 92 [43] D.A.B. Lindberg B.L. Humphreys A.T. McCray The unified medical language system Methods Inf Med 32 1993 281 291", "scopus-id": "84899475978", "pubmed-id": "24486562", "coredata": {"eid": "1-s2.0-S1532046414000069", "dc:description": "Abstract Extracting information from unstructured clinical narratives is valuable for many clinical applications. Although natural Language Processing (NLP) methods have been profoundly studied in electronic medical records (EMR), few studies have explored NLP in extracting information from Chinese clinical narratives. In this study, we report the development and evaluation of extracting tumor-related information from operation notes of hepatic carcinomas which were written in Chinese. Using 86 operation notes manually annotated by physicians as the training set, we explored both rule-based and supervised machine-learning approaches. Evaluating on unseen 29 operation notes, our best approach yielded 69.6% in precision, 58.3% in recall and 63.5% F-score.", "openArchiveArticle": "true", "prism:coverDate": "2014-04-30", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046414000069", "dc:creator": [{"@_fa": "true", "$": "Wang, Hui"}, {"@_fa": "true", "$": "Zhang, Weide"}, {"@_fa": "true", "$": "Zeng, Qiang"}, {"@_fa": "true", "$": "Li, Zuofeng"}, {"@_fa": "true", "$": "Feng, Kaiyan"}, {"@_fa": "true", "$": "Liu, Lei"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046414000069"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046414000069"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(14)00006-9", "prism:volume": "48", "prism:publisher": "Elsevier Inc.", "dc:title": "Extracting important information from Chinese Operation Notes with natural language processing methods", "prism:copyright": "Copyright \u00a9 2014 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Clinical operation notes"}, {"@_fa": "true", "$": "Information extraction"}, {"@_fa": "true", "$": "Chinese EMR"}, {"@_fa": "true", "$": "Conditional random fields"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "130-136", "prism:endingPage": "136", "prism:coverDisplayDate": "April 2014", "prism:doi": "10.1016/j.jbi.2013.12.017", "prism:startingPage": "130", "dc:identifier": "doi:10.1016/j.jbi.2013.12.017", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "42", "@width": "236", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1558", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "86", "@width": "553", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3848", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "86", "@width": "524", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "3279", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "high", "@height": "516", "@width": "1297", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "202211", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "810", "@width": "2213", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "149174", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "664", "@width": "1969", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr6_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "91020", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "809", "@width": "1969", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "310892", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "515", "@width": "1152", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "58620", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "474", "@width": "1296", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "76284", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "720", "@width": "827", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "90262", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "194", "@width": "488", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "59677", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "183", "@width": "500", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "29634", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "150", "@width": "444", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "14734", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "182", "@width": "444", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "29176", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "169", "@width": "378", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "17805", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "178", "@width": "488", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "28195", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "271", "@width": "311", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "35750", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "87", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6191", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "80", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3169", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "74", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4521", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "90", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6226", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "98", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2599", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "80", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3238", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "188", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046414000069-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6690", "@ref": "gr2", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899475978"}}
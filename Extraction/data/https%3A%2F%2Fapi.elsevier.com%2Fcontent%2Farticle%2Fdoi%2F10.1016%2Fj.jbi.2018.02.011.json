{"scopus-eid": "2-s2.0-85043403231", "originalText": "serial JL 272371 291210 291682 291870 291901 31 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2018-02-26 2018-02-26 2018-03-09 2018-03-09 2019-03-18T15:57:50 1-s2.0-S1532046418300303 S1532-0464(18)30030-3 S1532046418300303 10.1016/j.jbi.2018.02.011 S300 S300.2 FULL-TEXT 1-s2.0-S1532046418X00045 2019-04-01T00:41:48.500272Z 0 0 20180401 20180430 2018 2018-02-26T16:34:59.583675Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor highlightsabst primabst ref specialabst 1532-0464 15320464 true 80 80 C Volume 80 10 64 77 64 77 201804 April 2018 2018-04-01 2018-04-30 2018 Original research papers article fla \u00a9 2018 Elsevier Inc. DEEPNEURALMODELSFORICD10CODINGDEATHCERTIFICATESAUTOPSYREPORTSINFREETEXT DUARTE F 1 Introduction 2 Related work 3 The proposed approach 3.1 Deep neural networks for text classification 3.2 The neural network architecture for automated ICD-10 coding 3.3 Initializing the weights of the output nodes through label co-occurrence 4 Experimental evaluation 4.1 Datasets and experimental methodology 4.2 Results for comparison of different models with data from 2013\u20132015 4.3 Results when considering the prediction of common causes of death 4.4 Assessing the impact of the autopsy reports in the model predictions 4.5 Results in a near real-time surveillance scenario with data from 2016 4.6 Visualizing and interpreting the model predictions 5 Conclusions and future work Acknowledgements References PINTO 2016 C DALIANIS 2014 H PROFESSIONALSEARCHINMODERNWORLD CLINICALTEXTRETRIEVALOVERVIEWBASICBUILDINGBLOCKSAPPLICATIONS KOOPMAN 2015 B KOOPMAN 2015 B PEROTTE 2013 A WANG 2016 S RUMELHART 1988 D GOLDBERG 2016 Y LEE 1999 D LIN 2007 C ZHOU 2016 G GREFF 2016 K BOJANOWSKI 2017 P CHAWLA 2002 N MCNOWN 1992 R DUARTEX2018X64 DUARTEX2018X64X77 DUARTEX2018X64XF DUARTEX2018X64X77XF Full 2019-04-01T00:22:55Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ 2019-03-09T00:00:00.000Z http://creativecommons.org/licenses/by-nc-nd/4.0/ \u00a9 2018 Elsevier Inc. This article is made available under the Elsevier license. item S1532-0464(18)30030-3 S1532046418300303 1-s2.0-S1532046418300303 10.1016/j.jbi.2018.02.011 272371 2019-03-18T16:11:02.270016Z 2018-04-01 2018-04-30 1-s2.0-S1532046418300303-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/MAIN/application/pdf/53b142ad2ca51a1efff3478171f5d6e7/main.pdf main.pdf pdf true 1289057 MAIN 14 1-s2.0-S1532046418300303-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/PREVIEW/image/png/bef37d3a51631f5f4b3b6f4d78cb00bc/main_1.png main_1.png png 54383 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046418300303-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/fx1/THUMBNAIL/image/gif/deadf3510c911e0a21226b1d21058f2a/fx1.sml fx1 true fx1.sml sml 10842 147 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr1/THUMBNAIL/image/gif/a1048035eea9612120cae5b48c224a54/gr1.sml gr1 gr1.sml sml 9848 152 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr2/THUMBNAIL/image/gif/a879b9db6dff7ed4f6fb9cc85597e04f/gr2.sml gr2 gr2.sml sml 10399 137 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr3/THUMBNAIL/image/gif/8a8dad7877d014563aaf222408429700/gr3.sml gr3 gr3.sml sml 7476 96 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr4/THUMBNAIL/image/gif/a16f580a1f7ae903751dcf49ff264ac0/gr4.sml gr4 gr4.sml sml 5455 75 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr5/THUMBNAIL/image/gif/9e558ab25c7cb717009ab5346ac76a6f/gr5.sml gr5 gr5.sml sml 4619 74 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr6/THUMBNAIL/image/gif/dbb68c48f83095b4a8175092a6a20737/gr6.sml gr6 gr6.sml sml 4964 74 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr7/THUMBNAIL/image/gif/b949df8c2e8c8df89b3e0c3aaa66c287/gr7.sml gr7 gr7.sml sml 6349 74 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr8/THUMBNAIL/image/gif/599c343d05c78dd31ebe4c15747c0e41/gr8.sml gr8 gr8.sml sml 3540 61 219 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr9/THUMBNAIL/image/gif/a1175a413c7bb9c4a1b8e066ed29efac/gr9.sml gr9 gr9.sml sml 5368 163 116 IMAGE-THUMBNAIL 1-s2.0-S1532046418300303-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/fx1/DOWNSAMPLED/image/jpeg/5a2c0843add6b5d92dd650bb00e6ae49/fx1.jpg fx1 true fx1.jpg jpg 19441 200 299 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr1/DOWNSAMPLED/image/jpeg/28991d44e50da8d76e2d7476e03309f7/gr1.jpg gr1 gr1.jpg jpg 47064 401 578 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr2/DOWNSAMPLED/image/jpeg/b5a361d8f31ed7a10e218482935acdd7/gr2.jpg gr2 gr2.jpg jpg 62315 362 578 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr3/DOWNSAMPLED/image/jpeg/81f87d73a04ba93a8e252ef7f446a6e5/gr3.jpg gr3 gr3.jpg jpg 36294 253 578 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr4/DOWNSAMPLED/image/jpeg/0de0916ff6058dcf371271b0844d9b0c/gr4.jpg gr4 gr4.jpg jpg 31091 198 579 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr5/DOWNSAMPLED/image/jpeg/3b97387b659f9aaaf952b23819bb59aa/gr5.jpg gr5 gr5.jpg jpg 30517 195 579 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr6/DOWNSAMPLED/image/jpeg/3d3675918ba7e139965fb63572c8b803/gr6.jpg gr6 gr6.jpg jpg 31667 196 579 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr7/DOWNSAMPLED/image/jpeg/5ec07e8fed5b26c3f87c5a472552e5ea/gr7.jpg gr7 gr7.jpg jpg 36842 195 579 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr8/DOWNSAMPLED/image/jpeg/e7148afbeecdd8c679a952ddd68f656a/gr8.jpg gr8 gr8.jpg jpg 14729 156 562 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr9/DOWNSAMPLED/image/jpeg/abf5bcb4abeb3f6f6caf4479ca4db5c9/gr9.jpg gr9 gr9.jpg jpg 56530 789 560 IMAGE-DOWNSAMPLED 1-s2.0-S1532046418300303-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/fx1/HIGHRES/image/jpeg/188ca3ff7b92421ce76516ef65f3a05a/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 174964 886 1324 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr1/HIGHRES/image/jpeg/8180ec2b3ccc1adb4a4cc02afef157f5/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 164552 1064 1535 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr2/HIGHRES/image/jpeg/8dcec083d607c4539a143709bb4334a1/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 500190 1605 2561 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr3/HIGHRES/image/jpeg/dd631cb65662dc624c16ea4da49c55d2/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 134140 673 1535 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr4/HIGHRES/image/jpeg/a70cb742f6267c95b9563e10611f20e0/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 202122 853 2497 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr5/HIGHRES/image/jpeg/7ac9e5cf10e1efad18ea2aa8c294c5fb/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 199354 836 2480 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr6/HIGHRES/image/jpeg/e7c5e570d2cfd0a8663c27f973dc511f/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 209941 843 2484 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr7/HIGHRES/image/jpeg/db12d2f89b7fe020244eb9220af1a2b1/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 245709 865 2563 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr8_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr8/HIGHRES/image/jpeg/e98b3bae37d23d7a92eefbebcb07aac8/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 113406 689 2488 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-gr9_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/gr9/HIGHRES/image/jpeg/d739219efcff2e21cb71021fe43a852f/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 345998 3494 2480 IMAGE-HIGH-RES 1-s2.0-S1532046418300303-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/ebf9e95a133204c8289466d98bd21477/si1.gif si1 si1.gif gif 319 14 33 ALTIMG 1-s2.0-S1532046418300303-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/90c711b7bf81492f3c5f33667b4fa9eb/si10.gif si10 si10.gif gif 458 13 127 ALTIMG 1-s2.0-S1532046418300303-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/a8dfc6be4b06d179d8a4fb99eee5aa13/si11.gif si11 si11.gif gif 290 17 30 ALTIMG 1-s2.0-S1532046418300303-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/2e370389aff7b545823ef8cf82f360e4/si12.gif si12 si12.gif gif 1645 52 297 ALTIMG 1-s2.0-S1532046418300303-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/1e4297d5e3b900649658110db7f9a8e2/si13.gif si13 si13.gif gif 1016 19 218 ALTIMG 1-s2.0-S1532046418300303-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/8b769cd0476355345c106eb08e96d8d0/si14.gif si14 si14.gif gif 190 10 11 ALTIMG 1-s2.0-S1532046418300303-si15.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/d8f07f82eb30d6a05cd45a08426b692c/si15.gif si15 si15.gif gif 203 13 12 ALTIMG 1-s2.0-S1532046418300303-si16.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/81b5b80d70cac70b4e7ef2864ce8ce2a/si16.gif si16 si16.gif gif 203 13 13 ALTIMG 1-s2.0-S1532046418300303-si17.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/d5497b652a448513b32055aa62783754/si17.gif si17 si17.gif gif 188 10 10 ALTIMG 1-s2.0-S1532046418300303-si18.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/08997d0cecce8abf7184fcbe34b3eabe/si18.gif si18 si18.gif gif 209 12 11 ALTIMG 1-s2.0-S1532046418300303-si19.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/1ca4fa23d8789738d03a8323d3f04f6b/si19.gif si19 si19.gif gif 203 14 10 ALTIMG 1-s2.0-S1532046418300303-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/226ea5b480e742f69ca0c61660db08d4/si2.gif si2 si2.gif gif 328 14 34 ALTIMG 1-s2.0-S1532046418300303-si20.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/fe6a48f561a91700e13da06c91caac9f/si20.gif si20 si20.gif gif 240 13 19 ALTIMG 1-s2.0-S1532046418300303-si21.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/d45e1d0ff1dbdd4d89d4860260716a98/si21.gif si21 si21.gif gif 215 13 14 ALTIMG 1-s2.0-S1532046418300303-si22.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/3219165e8ac10b6b522500f511e8b5f4/si22.gif si22 si22.gif gif 355 17 56 ALTIMG 1-s2.0-S1532046418300303-si26.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/ccb628aee53970cae52b0d5c25f74c19/si26.gif si26 si26.gif gif 572 17 134 ALTIMG 1-s2.0-S1532046418300303-si27.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/03c08bade8732a6c868faa116ebd94d6/si27.gif si27 si27.gif gif 221 16 15 ALTIMG 1-s2.0-S1532046418300303-si28.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/7839ffd3408f8f72c4bede1563bec068/si28.gif si28 si28.gif gif 897 19 198 ALTIMG 1-s2.0-S1532046418300303-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/b5c6d249add1838e4b4f167b5b942562/si3.gif si3 si3.gif gif 657 17 107 ALTIMG 1-s2.0-S1532046418300303-si30.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/21f58730fa30dd5b2fa0c7e24243d425/si30.gif si30 si30.gif gif 210 11 15 ALTIMG 1-s2.0-S1532046418300303-si31.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/1f4cf7d70d8866aebc657f3480f1d55f/si31.gif si31 si31.gif gif 234 12 18 ALTIMG 1-s2.0-S1532046418300303-si32.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/9e77a05cc43e2f69d8ba43998d2030e8/si32.gif si32 si32.gif gif 251 16 28 ALTIMG 1-s2.0-S1532046418300303-si33.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/582d85946c1b9713f89c999d10b05a64/si33.gif si33 si33.gif gif 208 13 13 ALTIMG 1-s2.0-S1532046418300303-si37.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/e4201cc4061dba3c9d63a10120402a37/si37.gif si37 si37.gif gif 191 11 13 ALTIMG 1-s2.0-S1532046418300303-si38.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/a85142d9da9a639abcf02136ad6a5f7b/si38.gif si38 si38.gif gif 202 11 14 ALTIMG 1-s2.0-S1532046418300303-si39.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/48e44018981de1f20540677162ded7a3/si39.gif si39 si39.gif gif 234 20 15 ALTIMG 1-s2.0-S1532046418300303-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/347148a89de79349802cab3e565d5f37/si4.gif si4 si4.gif gif 382 14 47 ALTIMG 1-s2.0-S1532046418300303-si40.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/972f41975beb416f61db6d37ee68b349/si40.gif si40 si40.gif gif 847 23 211 ALTIMG 1-s2.0-S1532046418300303-si41.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/996c87d42729a79017c70b051607e7b0/si41.gif si41 si41.gif gif 1011 19 241 ALTIMG 1-s2.0-S1532046418300303-si42.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/1085b03b8a5c54c5ad60748b13f0fb5b/si42.gif si42 si42.gif gif 1366 23 318 ALTIMG 1-s2.0-S1532046418300303-si43.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/9a2c32bb48ceada5b75237a83d79b87e/si43.gif si43 si43.gif gif 984 19 239 ALTIMG 1-s2.0-S1532046418300303-si44.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/e7b3684c7fd3337d2b0750a6f304c420/si44.gif si44 si44.gif gif 272 22 23 ALTIMG 1-s2.0-S1532046418300303-si45.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/4a0983e1758ad33f1b175069854068f1/si45.gif si45 si45.gif gif 256 24 19 ALTIMG 1-s2.0-S1532046418300303-si46.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/ea4414c9b72ce467e760b3c291a2c28b/si46.gif si46 si46.gif gif 537 25 97 ALTIMG 1-s2.0-S1532046418300303-si47.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/4ac50bc150aefd59211552d07636f651/si47.gif si47 si47.gif gif 237 16 18 ALTIMG 1-s2.0-S1532046418300303-si48.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/bcf98832350307b6da337c38a847f8b8/si48.gif si48 si48.gif gif 227 11 18 ALTIMG 1-s2.0-S1532046418300303-si49.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/50a2bc4814fa4bf6feb24696f36a9c50/si49.gif si49 si49.gif gif 233 11 18 ALTIMG 1-s2.0-S1532046418300303-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/fc8f648cebb6aee65ff69a0f8804e542/si5.gif si5 si5.gif gif 407 14 48 ALTIMG 1-s2.0-S1532046418300303-si50.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/a2932f02529a7ad5c3b7042f14f88de3/si50.gif si50 si50.gif gif 230 12 20 ALTIMG 1-s2.0-S1532046418300303-si52.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/d0b694874a59bc5554f12afebde7f23e/si52.gif si52 si52.gif gif 937 19 193 ALTIMG 1-s2.0-S1532046418300303-si53.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/9233b8df9824c19a41ac2c3c3e149cce/si53.gif si53 si53.gif gif 1337 45 166 ALTIMG 1-s2.0-S1532046418300303-si54.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/0e0de57b2c2857878a0639121bd28548/si54.gif si54 si54.gif gif 662 34 114 ALTIMG 1-s2.0-S1532046418300303-si55.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/dc6d7a1e56a4ca2f1b2bef96f8183bd0/si55.gif si55 si55.gif gif 198 11 12 ALTIMG 1-s2.0-S1532046418300303-si56.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/cf4bdf1b7c136f3c8bf1f2c126775713/si56.gif si56 si56.gif gif 469 17 70 ALTIMG 1-s2.0-S1532046418300303-si57.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/77f9e4f88302688045b06b2cd586caa9/si57.gif si57 si57.gif gif 298 14 34 ALTIMG 1-s2.0-S1532046418300303-si58.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/5d1ba6ef0ab61f223ea7ca54af07da09/si58.gif si58 si58.gif gif 276 16 31 ALTIMG 1-s2.0-S1532046418300303-si59.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/6af3dd2e8316056c8151f75af222a419/si59.gif si59 si59.gif gif 614 25 108 ALTIMG 1-s2.0-S1532046418300303-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/8f07a56c1c430a95dce5808b7e0adf46/si6.gif si6 si6.gif gif 413 14 48 ALTIMG 1-s2.0-S1532046418300303-si60.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/b65217e72f5678062990ee8b95431abf/si60.gif si60 si60.gif gif 326 14 41 ALTIMG 1-s2.0-S1532046418300303-si61.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/46eae2dc5ad1e21087d11c98831a628b/si61.gif si61 si61.gif gif 287 17 35 ALTIMG 1-s2.0-S1532046418300303-si63.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/bbcba30783c4f48541f6b733f288b3bb/si63.gif si63 si63.gif gif 559 19 90 ALTIMG 1-s2.0-S1532046418300303-si64.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/75c6a808e69b4c970326fede96795b89/si64.gif si64 si64.gif gif 241 14 20 ALTIMG 1-s2.0-S1532046418300303-si66.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/785208965995b226c0f8797496df68be/si66.gif si66 si66.gif gif 632 17 143 ALTIMG 1-s2.0-S1532046418300303-si67.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/123e981f09661bd725bfdd7c5bfde98d/si67.gif si67 si67.gif gif 285 16 32 ALTIMG 1-s2.0-S1532046418300303-si68.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/ea3fa3f08276143a83c7411fbd969b7c/si68.gif si68 si68.gif gif 2207 47 401 ALTIMG 1-s2.0-S1532046418300303-si69.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/42d6d4d0f643cbaaf1ad36764dde74e8/si69.gif si69 si69.gif gif 324 14 33 ALTIMG 1-s2.0-S1532046418300303-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/7cff03e3721c48ef9c32cd94ea270599/si7.gif si7 si7.gif gif 397 14 47 ALTIMG 1-s2.0-S1532046418300303-si70.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/5d7f230c4626909ad132159f3ece0ab3/si70.gif si70 si70.gif gif 422 17 54 ALTIMG 1-s2.0-S1532046418300303-si71.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/2aa4880ee32bf918e5560f80d6217ba3/si71.gif si71 si71.gif gif 261 14 24 ALTIMG 1-s2.0-S1532046418300303-si72.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/5035f8175e96193ad8d2a2d3f0e21a37/si72.gif si72 si72.gif gif 455 14 66 ALTIMG 1-s2.0-S1532046418300303-si73.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/2ae049e8ff0895f15ff433e3fbdce387/si73.gif si73 si73.gif gif 472 14 66 ALTIMG 1-s2.0-S1532046418300303-si74.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/a5912da09e52e5eb5618c037a49226e2/si74.gif si74 si74.gif gif 437 14 57 ALTIMG 1-s2.0-S1532046418300303-si75.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/91c880ebba50ddf3853b86059353247c/si75.gif si75 si75.gif gif 455 14 57 ALTIMG 1-s2.0-S1532046418300303-si76.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/64eb29aab22233340368207602de5b71/si76.gif si76 si76.gif gif 361 14 43 ALTIMG 1-s2.0-S1532046418300303-si77.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/898fb5055aa2f82365909f21bcdc1218/si77.gif si77 si77.gif gif 370 14 44 ALTIMG 1-s2.0-S1532046418300303-si78.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/050d2f11de48780a4be1e1f1a33c5d0f/si78.gif si78 si78.gif gif 344 14 44 ALTIMG 1-s2.0-S1532046418300303-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/0801b85dcbd93ca9a4b4f85ddefbff88/si8.gif si8 si8.gif gif 252 17 23 ALTIMG 1-s2.0-S1532046418300303-si80.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/29d896b16ae823571fb7d179063337b2/si80.gif si80 si80.gif gif 511 14 67 ALTIMG 1-s2.0-S1532046418300303-si81.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/472b1e9127e945d050714e08ced585a1/si81.gif si81 si81.gif gif 485 14 67 ALTIMG 1-s2.0-S1532046418300303-si82.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/9bd9208f367d7e3f54513e8b8282071b/si82.gif si82 si82.gif gif 497 14 67 ALTIMG 1-s2.0-S1532046418300303-si83.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/88123e7f3510879d7e57c633970cdca1/si83.gif si83 si83.gif gif 509 14 66 ALTIMG 1-s2.0-S1532046418300303-si84.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/d6526d718430d242ad63b6e2f6e3ba25/si84.gif si84 si84.gif gif 305 14 33 ALTIMG 1-s2.0-S1532046418300303-si85.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/2ae10ae3e231865abb6564aa3dda55b8/si85.gif si85 si85.gif gif 328 14 34 ALTIMG 1-s2.0-S1532046418300303-si86.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/a39c8943db663ddddf7062b838bf8268/si86.gif si86 si86.gif gif 363 14 47 ALTIMG 1-s2.0-S1532046418300303-si87.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/f261b69ca4d22f6f3e8b067bf3a1f193/si87.gif si87 si87.gif gif 469 14 65 ALTIMG 1-s2.0-S1532046418300303-si88.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/54960bd5ce0bae52270c0e399662ea24/si88.gif si88 si88.gif gif 498 14 66 ALTIMG 1-s2.0-S1532046418300303-si89.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/3a2662e38308f5372343620538facf37/si89.gif si89 si89.gif gif 492 14 67 ALTIMG 1-s2.0-S1532046418300303-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/e4d3c0365aabd8890a324860f61ce362/si9.gif si9 si9.gif gif 344 14 34 ALTIMG 1-s2.0-S1532046418300303-si90.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/b6ed74717d0cc0bee188ca09fbfd7c97/si90.gif si90 si90.gif gif 452 14 57 ALTIMG 1-s2.0-S1532046418300303-si91.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/bc81648d067ee1cccefa86a922bcadb0/si91.gif si91 si91.gif gif 449 14 57 ALTIMG 1-s2.0-S1532046418300303-si92.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/6853455ffaa01308577f26a07afa9295/si92.gif si92 si92.gif gif 422 14 56 ALTIMG 1-s2.0-S1532046418300303-si93.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/d62b5a78f51abc02f18ce4d48c989667/si93.gif si93 si93.gif gif 436 14 56 ALTIMG 1-s2.0-S1532046418300303-si94.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/1b80d678d43db9be186352f785e52c9b/si94.gif si94 si94.gif gif 448 14 57 ALTIMG 1-s2.0-S1532046418300303-si95.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/b521eef77be382594d72acd8bbc30dcb/si95.gif si95 si95.gif gif 434 14 57 ALTIMG 1-s2.0-S1532046418300303-si96.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/325179cb6b312cde44370634edb83a4e/si96.gif si96 si96.gif gif 428 14 57 ALTIMG 1-s2.0-S1532046418300303-si97.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046418300303/STRIPIN/image/gif/de437dd5d914d65cec9bed5901a3df8e/si97.gif si97 si97.gif gif 447 14 57 ALTIMG YJBIN 2933 S1532-0464(18)30030-3 10.1016/j.jbi.2018.02.011 Elsevier Inc. Fig. 1 The electronic form used in Portugal for death certificates registration, and for entering ICD-10 terms to code causes of death. Fig. 2 The proposed neural network architecture. Fig. 3 Number of occurrences of the 50 most common ICD-10 codes in the dataset. Fig. 4 Percentage of weekly deaths in 2016 for ICD-10 blocks I20-I25. Fig. 5 Percentage of weekly deaths in 2016 for ICD-10 blocks I60-I69. Fig. 6 Percentage of weekly deaths in 2016 for ICD-10 blocks J09-J18. Fig. 7 Percentage of weekly deaths in 2016 for ICD-10 blocks J95-J99. Fig. 8 Distribution of attention weights given to different fields and tokens in two instances. Fig. 9 Distribution of the attention weights given to four specific word tokens, namely AVC, demncia, neoplasia, and pneumonia. Table 1 Statistical characterization of the dataset used in our experiments. Number of distinct ICD-10 codes for the underlying cause of death 1,418 Number of distinct ICD-10 blocks for the underlying cause of death 611 Number of distinct ICD-10 chapters for the underlying cause of death 19 Number of distinct ICD-10 codes for auxiliary and/or contributing conditions 2,446 Number of entries in the dataset 121,536 Number of entries with filled death certificates 114,228 Number of entries with autopsy reports 5653 Number of entries with clinical bulletins 3003 Number of textual fields 274,501 Average number of words per textual field 668 Training set vocabulary size 29,284 Testing set out-of-vocabulary tokens 5260 Table 2 Performance metrics for SVM baselines and for 6 variants of the neural model. Macro-averages ICD Level Accuracy Precision Recall F1-Score SVM with joint representation Chapter 79.802 63.251 58.119 60.685 Block 70.754 36.516 34.095 35.306 Full-code 67.404 26.932 26.823 26.585 SVM with separate representations Chapter 79.614 62.224 57.865 60.045 Block 70.754 36.443 33.806 35.125 Full-code 67.457 26.212 25.539 25.876 Average of word embeddings Chapter 74.362 38.733 39.679 38.219 Block 54.930 9.512 9.163 8.616 Full-code 49.760 4.487 4.679 4.120 Hierarchical GRUs Chapter 83.570 52.227 51.115 51.582 Block 72.420 27.712 24.210 24.675 Full-code 67.647 18.032 16.139 15.983 Hierarchical GRUs with attention Chapter 88.938 65.228 62.406 63.265 Block 80.588 36.569 34.667 34.033 Full-code 75.043 24.386 23.913 22.584 Combined model Chapter 89.267 68.522 63.780 65.478 Block 81.132 37.022 35.125 34.398 Full-code 75.632 23.222 23.174 21.619 Combined model with frequent itemset initialization Chapter 89.320 67.656 64.297 65.372 Block 81.349 38.792 36.011 35.782 Full-code 76.112 25.136 24.228 23.084 Combined model with NMF initialization Chapter 89.159 64.092 62.202 62.907 Block 81.207 44.649 39.900 40.505 Full-code 75.947 29.513 27.773 27.042 Table 3 Number of instances and obtained results for each of the ICD-10 chapters. The column percentage gives the fraction of instances, in the training and testing splits of the main dataset, corresponding to each ICD-10 chapter. Occurrences Chapter Train Test Percentage Precision Recall F1-Score I 1957 655 2.149 69.521 73.130 71.280 II 24,128 8026 26.456 97.626 95.290 96.444 III 409 140 0.452 56.081 59.286 57.639 IV 485 1623 5.330 75.500 81.454 78.364 V 2450 815 2.686 75.151 76.074 75.610 VI 3105 1039 3.410 87.236 79.596 83.241 VII 0 0 0.000 \u2014 \u2014 \u2014 VIII 3 2 0.004 0.000 0.000 0.000 IX 27,438 9148 30.140 92.789 92.840 92.815 X 11,317 3772 12.415 83.975 89.608 86.700 XI 4155 1385 4.558 87.480 80.217 83.691 XII 106 35 0.116 50.000 51.429 50.704 XIII 376 128 0.415 64.286 42.188 50.943 XIV 2735 909 2.998 77.890 76.348 77.111 XV 2 1 0.002 0.000 0.000 0.000 XVI 4 2 0.005 0.000 0.000 0.000 XVII 88 32 0.099 62.500 46.875 53.571 XVIII 4119 1371 4.517 86.022 93.363 89.542 XIX 0 0 0.000 \u2014 \u2014 \u2014 XX 3860 1301 4.246 87.592 81.937 84.670 XXI 0 0 0.000 \u2014 \u2014 \u2014 XXII 0 0 0.000 \u2014 \u2014 \u2014 Total: 91,152 30,384 Average: 64.092 62.202 62.907 Table 4 Results for blocks and full-codes within ICD Chapters II and IX. Macro-averages ICD Level Accuracy Precision Recall F1-Score Chapter II Block 90.518 34.762 31.317 32.546 Full-code 86.743 31.846 29.914 29.756 Chapter IX Block 82.313 18.199 14.487 15.492 Full-code 78.389 17.812 14.201 15.027 Table 5 Performance metrics for test instances associated with an autopsy report. Macro-averages ICD Level Accuracy Precision Recall F1-Score Without using the autopsy reports Chapter 62.013 39.108 33.511 31.871 Block 43.571 21.866 18.051 18.530 Full-code 36.297 13.971 11.710 11.306 Only using the autopsy reports Chapter 78.398 35.443 35.624 33.886 Block 55.841 21.421 20.916 19.786 Full-code 45.114 13.217 12.768 11.854 Complete input information Chapter 85.084 44.538 42.125 41.168 Block 62.528 28.931 28.122 27.026 Full-code 49.596 17.144 16.823 15.783 Table 6 Performance metrics over the 2016 dataset. Macro-averages ICD Level Accuracy Precision Recall F1-Score All Chapters Chapter 89.129 59.994 52.748 54.510 Block 80.615 34.938 29.525 30.363 Full-code 75.901 21.349 19.343 18.832 Chapter II Block 89.991 27.142 24.210 25.203 Full-code 86.367 24.495 22.085 22.197 Chapter IX Block 80.811 14.874 10.432 11.687 Full-code 77.107 13.939 10.761 11.353 Deep neural models for ICD-10 coding of death certificates and autopsy reports in free-text Francisco Duarte a \u204e francisco.ribeiro.duarte@tecnico.ulisboa.pt Bruno Martins a bruno.g.martins@tecnico.ulisboa.pt C\u00e1tia Sousa Pinto b catiasousapinto@dgs.min-saude.pt M\u00e1rio J. Silva a mario.gaspar.silva@tecnico.ulisboa.pt a INESC-ID, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal INESC-ID Instituto Superior T\u00e9cnico Universidade de Lisboa Portugal b Dire\u00e7\u00e3o-Geral da Sa\u00fade, Portugal Dire\u00e7\u00e3o-Geral da Sa\u00fade Portugal \u204e Corresponding author. Graphical abstract Highlights \u2022 We propose a neural model for ICD-10 coding of text describing causes of death. \u2022 We describe the application to data from the Portuguese Ministry of Health. \u2022 The proposed model makes accurate predictions, outperforming simpler baselines. \u2022 We show accuracies of 89%, 81%, and 76%, for ICD chapters, blocks, and full-codes. \u2022 The model can produce interpretable results, useful for public health surveillance. Abstract We address the assignment of ICD-10 codes for causes of death by analyzing free-text descriptions in death certificates, together with the associated autopsy reports and clinical bulletins, from the Portuguese Ministry of Health. We leverage a deep neural network that combines word embeddings, recurrent units, and neural attention, for the generation of intermediate representations of the textual contents. The neural network also explores the hierarchical nature of the input data, by building representations from the sequences of words within individual fields, which are then combined according to the sequences of fields that compose the inputs. Moreover, we explore innovative mechanisms for initializing the weights of the final nodes of the network, leveraging co-occurrences between classes together with the hierarchical structure of ICD-10. Experimental results attest to the contribution of the different neural network components. Our best model achieves accuracy scores over 89%, 81%, and 76%, respectively for ICD-10 chapters, blocks, and full-codes. Through examples, we also show that our method can produce interpretable results, useful for public health surveillance. Keywords Automated ICD coding Clinical text mining Deep learning Natural language processing Artificial intelligence in medicine 1 Introduction The systematic collection of mortality data is essential for the surveillance of a population\u2019s health, and for conducting mortality and epidemiologic studies. For these and other legal purposes, doctors have to write death certificates, i.e. reports containing personal data of the deceased and textual descriptions for the causes of death, as well as any contributing conditions or injuries. In Portugal, for data collection and registry purposes, doctors submit death certificates in electronic format to a Death Certificate Information System (SICO) [1]. The analysis of causes of death also includes classifying the death certificates according to revision 10 of the International Statistical Classification of Diseases and Related Health Problems (ICD 1 http://www.who.int/classifications/icd/ 1 ), which is distributed by the World Health Organization. ICD defines diseases, and other health conditions, in a comprehensive hierarchical fashion. Despite having all the data centrally in digital form, the assignment of ICD-10 codes to the free-text descriptions provided by doctors is still made manually by mortality coders, after submission to SICO. Fig. 1 presents a screen-shot of the online form presented by SICO to collect a death certificate. The form has two parts, delimited by the solid lines in the figure. Part I comprises up to four fields of text (i.e., boxes marked from (a) to (d)) for reporting a chain of events leading directly to death, where the underlying cause of death should be given in the lowest line and the immediate cause in the first one. Part II is optional, and it is used for reporting other significant diseases, conditions, or injuries that contributed to death, but are not part of the main causal sequence leading to death. In complement to the death certificate, a clinical information bulletin is also filled by the doctor before the death certificate itself, describing relevant clinical information of the patient. The clinical bulletin is recommended and even mandatory in specific circumstances (e.g., for violent or unknown causes of death), but doctors often do not associate the clinical bulletin to the death certificate. In case of violent and unknown causes of death, an autopsy report can also be requested by the Public Ministry. These auxiliary reports can be accessed from the death certificate form within SICO, as shown at the bottom of Fig. 1. After a manual review of the data, the mortality coder should assign the ICD-10 code corresponding to the underlying cause of death in the box shown under the dashed line. The manual coding of the free-text contents in death certificates and/or autopsy reports is a challenging, expensive, and time consuming task [2], which slows down the process of disseminating mortality statistics and prevents real-time surveillance. However, given the past efforts in manually coding death certificates, the pre-existing labeled data can be used to inform supervised machine leaning methods capable of assigning codes automatically. Such automated approaches can be used to speed-up the process of publishing mortality statistics, by quickly producing results that can latter be revised through manual coding. When integrated into existing platforms, automated approaches can also facilitate the task of manual coding, by providing hints. If sufficiently accurate, automatic coding also has the potential to reduce the cost of physician involvement, and to increase coding consistency. Several previous studies have already addressed the automated ICD coding of free-text descriptions from death certificates [3\u20136]. Recently, increasing attention has been given to this problem through the CLEF eHealth clinical information extraction tasks, organized in 2016 and 2017 [7,8]. However, the previously published methods are still behind the current state-of-the-art for general text classification, in the sense that they are using machine learning methods limited to linear models and manual feature engineering. In this article, extending on previous work also reported by our team [9], we propose a deep neural network that processes the full-text contents of death certificates, clinical bulletins, and autopsy reports. The network is trained end-to-end from a set of manually coded instances, and it combines different mechanisms for generating intermediate representations, including two levels of Gated Recurrent Units (GRUs) for modeling sequential data within and between the textual fields that compose the inputs [10,11], averages of word embeddings similarly to the proposal by Joulin et al. [12], and neural attention mechanisms for highlighting relevant parts of the inputs [13,11]. Three output nodes are also considered on the model, in an attempt to leverage relations between ICD-10 classes (e.g., the underlying hierarchical class structure) to further improve results. These correspond to (i) a softmax node that outputs an ICD-10 full-code, (ii) a softmax node that outputs the ICD-10 block, and (iii) a sigmoid activation node that outputs all ICD-10 codes associated to auxiliary and contributing conditions present in the death certificate (e.g., through the SICO platform, the human coders can also provide ICD-10 codes for the contributing conditions or injuries mentioned in the textual contents). Moreover, in an attempt to also leverage frequent co-occurrences between ICD-10 codes, we considered two different strategies for initializing the weights of the final nodes in the neural network. We report on experiments with a dataset referring to 121,536 deceased individuals, covering all cases between the years from 2013 up to 2015 in continental Portugal, except for neonatal and perinatal mortality. The available data was randomly split into two subsets (i.e., 75 % for model training and 25 % for testing) considering a balanced class distribution for instances in both subsets. We evaluated the predictive capabilities of the proposed approach by measuring results in terms of classification accuracy, as well as macro-averaged precision, recall, and F1-scores. Given the hierarchical organization of ICD-10 (i.e., the codes are organized hierarchically into chapters, blocks and full-codes), we also measured results according to different levels of code specification. Our complete model achieved an accuracy of 89.2 % , 81.2 % , and 75.9 % , respectively when considering ICD-10 chapters (i.e., a total of 19 different classes appearing in our dataset), blocks (i.e., 611 different classes) and full-codes (i.e., 1418 different classes). Our full model also achieved F1-scores of 96.4 % and 92.8 % , respectively in terms of correctly identifying causes of death related to ICD-10 Chapters II (i.e., neoplasms) and IX (i.e., diseases of the circulatory system), that together represent 56.6 % of the instances in the dataset. We argue that the obtained results indicate that automatic approaches leveraging supervised machine learning can indeed contribute to a faster processing of death certificates, with a satisfactory margin of error. Our experiments have also showed that neural attention mechanisms lead to an increased performance, at the same time offering much needed model interpretability, by allowing us to see which parts of the input are attended to, when making predictions. In complement to the main set of experiments, we also report on tests with a second dataset, referring to the year of 2016 and still undergoing manual coding at the time of preparing this article. Leveraging the full-model from the first round of tests, trained with 75% of the data from 2013 to 2015, we again measured the predictive accuracy of the proposed method, in an attempt to see if it could generalize across time periods. Similar results were obtained on the 2016 dataset and, through time-series plots showing the weekly evolution of the percentage of deaths associated to specific causes (e.g., ischaemic heart diseases or cerebrovascular diseases), we also illustrate the usefulness of the proposed method for near real-time public health surveillance. Automated ICD-10 coding is indeed capable of approximating the results of manual coding with a high accuracy, and it can significantly accelerate the publication of mortality statistics, even if only being used to produce approximate values. The rest of this document is organized as follows: Section 2 surveys previous related work. Section 3 details the proposed approach, presenting the architecture of the deep neural network that was considered for addressing ICD-10 coding as a supervised classification task. Section 4 presents the experimental evaluation of the proposed method, detailing the datasets, the evaluation methodology, and the obtained results. Finally, Section 5 summarizes our main conclusions and presents possible directions for future work. 2 Related work Various studies have addressed the automatic assignment of ICD codes to clinical text. Different methods were for instance presented at the 2007 Computational Medicine Challenge (CMC), which involved about 50 participants [14]. The goal was to automate the assignment of ICD-9 codes to free-text radiology reports, with basis on a training set of 978 documents and a test set of 976 documents. The top-performing system used an ensemble of models that achieved a micro-averaged F1-score of 0.89, while the mean F1-score among all participants was of 0.77. The inter-annotator agreement, measured as the F1-score of individual annotators against an aggregated score obtained through majority voting, was comparable to those of the best systems. The CMC dataset remains, to this day, a frequently used evaluation resource. In a recent study leveraging this dataset, Zhang et al. [15] proposed to use PubMed to alleviate the problems of data sparsity and high class imbalancement, specifically by gathering titles and abstracts from articles about diseases corresponding to rare ICD-9 codes, thus creating new training instances. The authors concluded that supplementary training data can boost the performance in a small dataset such as that from the CMC, although this technique has no significant effect when enough training data is available. Perotte et al. stressed how the current volume of healthcare data can support the automated assignment of ICD codes to clinical text [16]. The authors used the publicly available Multiparameter Intelligent Monitoring in Intensive Care II (MIMIC II) repository of records for patients in Intensive Care Units (ICUs), to assess the performance of standard text classification methods for automatically coding patient discharge summaries. The MIMIC II dataset comprises records collected from a variety of ICUs (i.e., medical, surgical, coronary care, and neonatal), consisting of multiple fields (e.g., discharge summaries, nursing progress notes, and reports for cardiac catheterization, ECGs, radiology and echo tests). A total of 22,815 non-empty discharge summaries, with a mean length of 1083 words, were used in this study. The documents were represented as sparse vectors encoding individual words, considering TF-IDF (i.e., term frequency times inverse document frequency) term weights and using the top 10,000 terms with the highest TF-IDF scores across the entire collection. A total of 5030 distinct ICD-9 codes were considered within a multi-label classification framework (i.e., one or more labels could be assigned to each given document). Two different methods were tested, namely a flat classifier based on Support Vector Machines (SVMs), with one binary SVM per ICD-9 class, and a method based on a tree of SVM models, leveraging the hierarchical structure of ICD-9 (i.e., a method where the classifier associated with a given code in the hierarchy is applied only if its parent code has been classified as positive). Both strategies were compared through a variety of metrics adapted for hierarchical multi-label classification (e.g., in the definitions of precision and recall, true positives were extended to consider ancestors, descendants, or codes identical to a gold-standard code), leveraging 90% of the available data for model training and 10% for testing. Perotte et al. showed that the hierarchical method outperformed the simpler approach that treated each ICD-9 code independently [16]. Boytcheva presented an approach for assigning ICD-10 codes to diagnoses extracted from patient discharge letters written in Bulgarian [17]. The proposed method leverages one-versus-all multi-class SVMs, with basis on binary sparse vector representations for word occurrence in the diagnose sections of the discharge letters. Particular attention was given to the development of pre-processing techniques for improving the input representations (e.g., for expanding abbreviations, transliterating between the Cyrillic and Latin alphabets, handling synonyms, hyponyms, processing negations, or normalizing words). Yan et al. [18] and Wang et al. [19] have both proposed methods for automated ICD coding of data within electronic health records, combining linear classifiers (i.e., logistic regression models or SVMs) with regularization procedures that explore inter-code relationships (e.g., label co-occurrences over the training data, or other available prior knowledge) for improving multi-label classification. For instance, Wang et al. compared different multi-label classification methods for ICD-9 coding, also using the MIMIC II dataset [19]. The inputs for classification considered both structured (e.g., patients\u2019 raw health conditions collected from medical devices) and unstructured (i.e., free-text descriptions) data, associated to chart events and medical note fields within MIMIC II. The chart and the note information were each represented as dense vectors with 500 dimensions, leveraging a data pre-processing pipeline that combines multiple operations (e.g., TF-IDF term weighting, a probabilistic topic model for representing note features as distributions over latent topics, and a bag-of-words model encoding occurrence counts for a vocabulary of 500 clustering-based features). The biggest innovation in the work from Wang et al. [19] relates to a classification method based on logistic regression (i.e., the authors used a logistic loss combined with a \u2113 2 , 1 -norm for inducing sparsity in the parameters), which incorporates a graph structure that reflects the correlations between diseases (i.e., the regularization term of the model combines the feature weights with a class affinity matrix where each cell corresponds to the cosine similarity between a pair of classes, with basis on the class associations to individual training instances). The novel method was compared against previous approaches specifically designed for multi-label classification, using metrics that are also specific for multi-label problems (i.e., the Hamming loss and the ranking loss). The method leveraging disease correlations outperformed 6 alternative approaches and, in most cases, the note features had better results than the chart features. Despite the fact that modern text mining methods, in many different domains, often leverage word embeddings (i.e., dense real-valued vector representations of words capturing similarities between them) together with deep neural networks, these techniques are still rarely seen on clinical and/or biomedical text mining studies. Some authors have nonetheless reported on preliminary studies concerning with the usage of pre-trained word embeddings [20,21], including studies related to text classification [22,23]. For instance, Karimi et al. described a deep learning method for ICD-9 coding [22], reporting on tests over the aforementioned CMC dataset of radiology reports [14]. The authors proposed to use a simple Convolutional Neural Network (CNN) architecture (i.e., one convolutional layer using multiple filters and filter sizes, followed by a max pooling and a fully-connected layer to assign the ICD code), attempting to quantify the impact of using pre-trained word embeddings for model initialization, together with different hyper-parameters. The subset of data used in the experiments corresponds to a total of 894 documents with 16 unique ICD-9 codes, with each code appearing in at least 15 documents. The best CNN model outperformed baseline classifiers (i.e., SVM, random forest, and logistic regression models leveraging TF-IDF feature vectors) on stratified 10-fold cross-validation tests, with an overall accuracy of 0.84 and a macro-averaged F1 score of 0.82. The CNN model appears to be comparable to the best-performing systems over the CMC dataset, although not clearly outperforming them. Specifically on what regards death certificates, Koopman et al. described the use of SVM classifiers for identifying cancer related causes of death in natural language descriptions [5]. The textual contents were encoded as sparse binary feature vectors (i.e., vectors encoding the presence of terms, term n-grams, and SNOMED CT concepts recognized by a clinical natural language processing system named Medtex), and these representations were used as features to train a two-level hierarchy of SVM models: the first level was a binary classifier for identifying the presence of cancer, and the second level consisted of a set of classifiers (i.e., one for each cancer type) for identifying the type of cancer using the ICD-10 classification system (i.e., according to 85 different ICD-10 blocks, of which 20 instances corresponded to 85 % of all cases). The system was highly effective at identifying cancer as the underlying cause of death, having obtained a macro-averaged F1-score of 0.94 for the first level classifier. It was also effective at determining the type of common cancers (macro-averaged F1-score of 0.7). However, rare cancers for which there was little training data available were difficult to classify accurately (macro-averaged F1-score of 0.12). In a separate study, Koopman et al. described machine learning and rule-based methods to classify death certificates according to 4 high impact diseases of interest: diabetes, influenza, pneumonia, and HIV [6]. The rule-based method leveraged sets of keyword-matching rules, while the machine learning method was again based on SVM classifiers, using binary feature vectors (i.e., presence of terms, term n-grams, and SNOMED CT concepts recognized by Medtex). In the learning approach, a separate model was trained for each of the 4 diseases of interest, and more fine-grained classifiers were trained for each of the relevant ICD-10 blocks. An empirical evaluation was conducted using 340,142 certificates, of which 80% were reserved for model training and 20% for testing, covering deaths from 2000\u20132007 in New South Wales, Australia. The results showed that classification into the 4 general disease classes was highly accurate, with a macro-averaged F1-score of 0.95 for the rule-based method, and 0.94 when using machine learning. More fine-grained ICD-10 classification had nonetheless a more variable effectiveness, with less accurate classifications for blocks with little training data available. Results were nonetheless still high, with a macro-averaged F1-score of 0.80 when discriminating over 9 different ICD-10 blocks. The error analysis revealed that word variations (e.g., pneumonitis or pneumonic as variants for pneumonia) as well as certain word combinations adversely affected classification. In addition, anomalies in the ground truth data likely led to an underestimation of the effectiveness (i.e., the authors observed some class confusions, e.g. in ICD blocks E10 versus E11). Mujtaba et al. tested different methods for coding death certificates into 9 ICD-10 codes [4], aiming to assist pathologists in determining causes of death from autopsy findings. The dataset used in these tests consisted of 2200 autopsy reports from a large hospital in Kuala Lumpur, and the classification methods under study involved feature selection and also 5 different learning algorithms. Random forests and J48 decision trees, parameterized using expert-driven feature selection and leveraging a feature subset size of 30, yielded the best results (e.g., approximately 90% in terms of a macro-averaged F1-score). Lavergne et al. described a large-scale dataset prepared from French death certificates, suitable to the application of machine learning methods for ICD-10 coding [8]. The dataset comprised 93,694 death certificates referring to 3457 unique ICD-10 codes, and it was made available for international shared tasks organized in the context of CLEF. The 2016 edition of the CLEF eHealth shared task on ICD-10 coding attracted 5 participating teams, which presented systems relying either on dictionary linking or statistical learning [7]. The shared task was defined at the level of each statement (i.e., lines varying from 1 to 30 words, with outliers at 120 words and with the most frequent length at 2 tokens) in a death certificate, and statements could be associated with zero, one or more ICD-10 codes. The best-performing system achieved a micro-averaged F1-score (i.e., harmonic mean of precision and recall weighted by the class size) of 0.848, leveraging dictionaries built from the shared task data. At the time of preparing this article, the 2017 edition of the CLEF eHealth shared task was still underway. Leveraging the dataset from the 2016 CLEF eHealth competition, Zweigenbaum et al. presented hybrid methods for ICD-10 coding of death certificates [3], combining dictionary linking with supervised machine learning (i.e., an SVM classifier leveraging word tokens, character trigrams, and the year of the certificate as features). The best hybrid model corresponded to the union of the results produced by the dictionary-based and learning-based methods, outperforming the best system at the 2016 CLEF eHealth shared task, with a micro-averaged F1-score of 0.8586. Although different approaches for ICD coding of clinical text have been proposed in the literature, some of which specifically focusing on death certificates and/or autopsy reports, the current state-of-the-art is still relying on methods that are much simpler than those that constitute the current best practice on other text classification problems. Our work builds on ideas from the work surveyed in this section, in particular exploring class co-occurrences and the hierarchical nature of ICD-10, but we introduce recent machine learning approaches based on the supervised training of deep neural networks that involve mechanisms such as recurrent nodes and neural attention. 3 The proposed approach Taking inspiration on previous work within the natural language processing community [12,11], we propose a deep neural network for assigning ICD-10 codes to underlying causes of death, by analysis of the free-text information within death certificates, clinical bulletins, and/or autopsy reports. Given different strings, encoding events leading to death and/or auxiliary conditions, our model outputs the ICD-10 code of the underlying cause of death \u2013 see Fig. 1. Fig. 2 presents the proposed neural network, which is detailed in the next sections. The network explores a combination of mechanisms to generate intermediate representations for the textual contents, such as word embeddings, a hierarchical arrangement of recurrent units, and neural attention. It also considers multiple outputs in an attempt to further improve classification results (e.g., given the hierarchical class structure of ICD-10, and since most of the full-codes are only sparsely used in the training data, using ICD-10 blocks as a secondary classification target can further assist the training procedure). Moreover, we also explore innovative mechanisms for initializing the weights of the final nodes of the network, leveraging co-occurrences between classes in the training data, together with the hierarchical structure of ICD-10. The entire model is trained end-to-end from a set of coded certificates, leveraging the back-propagation algorithm [24] in conjunction with the Adam optimization method [25]. The implementation of the model relied mostly on the keras 2 http://keras.io 2 deep learning library, although the scikit-learn 3 http://scikit-learn.org 3 package was also used for specific operations (e.g., for computing evaluation metrics, or for supporting the experiments with baselines corresponding to linear classifiers). Section 3.1 gives a brief introduction to deep neural networks, while Section 3.2 details the internal structure of the proposed network architecture, focusing on the parts that are responsible for generating representations from the input data. In turn, Section 3.3 details the particularities associated to the output nodes of the network, presenting the mechanisms that were considered for initializing weights with basis on co-occurrences between ICD-10 codes. 3.1 Deep neural networks for text classification Neural networks are computational artifacts that channel information through a series of mathematical operations, with the general purpose of accurately classifying inputs [26]. Mathematically, neural networks can be seen as nested composite functions, whose parameters can be trained directly to minimize a given loss function computed over the outputs and the expected results. This is achieved through a training procedure known as back-propagation [24], in combination with gradient descent optimization of the parameters [26,25]. In the simplest case, and similarly to linear models such as SVMs or logistic regression classifiers, a single-node neural network computes a single output from multiple real-valued inputs by forming a linear combination according to input weights, and then putting the output through some activation function. Mathematically, this can be written as shown in Eq. (1), where y refers to the returned prediction, x = < x 1 , \u2026 , x n > is the vector of input features, w denotes the vector of weights, b is a bias term, and \u03c6 ( . ) is an activation function (e.g., a logistic sigmoid or an hyperbolic tangent). (1) y = \u03c6 \u2211 i = 1 n w i \u00d7 x i + b = \u03c6 w T \u00b7 x + b Although a single neural network node has a limited mapping ability, the same idea can be used a the main building block of more complex models. For instance, a Multi-Layer Perceptron (MLP) consists of a set of nodes forming the input layer, one or more hidden layers of computation nodes, and an output layer of nodes. The input signal propagates through the network layer-by-layer, until it reaches the output node(s). In a feed-forward network with a single hidden layer, the corresponding computations can be written as shown in Eq. (2), and the generalization to more hidden layers would be simple. (2) y = \u03c6 B \u00d7 \u03c6 \u2032 ( A \u00d7 x + a ) + b In the previous equation, x is a vector of inputs and y a vector of outputs. The matrix A represents the weights of the first layer and a is the bias vector of the first layer, while B and b are, respectively, the weight matrix and the bias vector of the second layer. The functions \u03c6 \u2032 and \u03c6 denote element-wise non-linearities, i.e. activation functions respectively associated to nodes in the hidden layer, and in the output layer. Training the network corresponds to adapting all the weights and biases (e.g., the parameters A , B , a and b , in the case of the feed-forward network expressed in the previous equation) to their optimal values, given a training set of inputs x together with the corresponding outputs y . This problem can be solved with the back-propagation algorithm, which consists of two steps [24]. In a forward pass, the predicted outputs corresponding to the given inputs are evaluated. In a backward pass, partial derivatives (i.e., the relationships between rates of change) of a given loss function with respect to the different parameters are propagated back through the network. In other words, back-propagation in neural networks moves backward from the final error through the outputs, weights, and inputs of each layer, assigning those weights responsibility for a portion of the error, by calculating their partial derivatives. The chain rule of differentiation can be used to compute the derivatives associated to nested composite functions. Those derivatives are used by a gradient-based optimization algorithm to adjust the weights and biases up or down, whichever direction decreases error over the training instances, as measured through a loss function. An optimization procedure that has been frequently used to train deep neural networks is the Adaptive Moment Estimation (Adam) algorithm [25]. Adam computes parameter updates leveraging an exponentially decaying average of past gradients, together with adaptive learning rates for each parameter. In practice, it performs larger updates for infrequent parameters, and smaller updates for frequent parameters. Recurrent Neural Networks (RNNs) constitute an extension of conventional feed-forward networks, with the objective of handling variable-length inputs (i.e., they were designed to recognize patterns in sequences of data, such as textual strings, and hence are commonly used in text classification tasks). RNNs handle variable-length sequences by having a recurrent hidden state whose activation at each time step is dependent on that of the previous time step. Whereas in classic feed-forward networks the examples are fed to an input layer and straightly transformed into an output, never performing computations over a given node twice, in RNNs we take not just the current input instance (e.g., the representation for a given word within a string) but also what was perceived one step back in time (e.g., the previous word in the sequence). More formally, given a sequence X = ( x 1 , x 2 , \u2026 , x T ) , an RNN updates its recurrent hidden state h t by sequentially processing the input sequence and computing: (3) h t = \u03c6 W \u00d7 x t + U \u00d7 h t - 1 In brief, we have that the hidden state h t at time step t is a function of the input at the same time step x t , modified by a weight matrix W . This result is added to the hidden state of the previous time step h t - 1 , multiplied by its own hidden-state-to-hidden-state matrix U . The weight matrices are essentially filters that determine how much importance should be given to both the present input and the past state. Previous research has noted that standard RNNs have difficulties in modeling long sequences, and extensions have been proposed to handle this problem. A well-known example are Gated Recurrent Units (GRUs), originally proposed by Cho et al. [10] and detailed in the next section. 3.2 The neural network architecture for automated ICD-10 coding Noting that the inputs to our model can be seen as having a hierarchical structure (i.e., words form different fields, and the fields from the death certificate, clinical bulletin, and autopsy report, as shown in Figs. 1 and 2, form an input entry), our model first builds representations of individual fields, and then aggregates those into an encompassing representation. This two-level hierarchical approach is illustrated in Fig. 2, with the word-level part of the model (i.e., the part that generates a representation from a given field) shown in the box at the top. A recurrent neural network node known as a Gated Recurrent Unit (GRU) is used at both levels to build the representations, and we specifically considered bi-directional GRUs [10]. Notice that the GRUs in the first level leverage word embeddings as input, whereas the second level uses as input the field representations generated at the first level. GRUs model sequential data by having a recurrent hidden state whose activation at each time step is dependent on that of the previous step. A GRU computes the next hidden state h t given a previous hidden state h t - 1 and the current input x t using two gates (i.e., a reset gate r t and an update gate z t ), that control how the information is updated, as shown in Eq. (4). The update gate (Eq. (5)) determines how much past information is kept and how much new information is added, while the reset gate (Eq. (7)) is responsible for how much the past state contributes to the candidate state. In Eqs. (4)\u2013(7), h \u0303 t stands for the current new state, W is the parameter matrix for the actual state, U is the parameter matrix for the previous state, and b a bias vector. (4) h t = ( 1 - z t ) \u2299 h t - 1 + z t \u2299 h \u0303 t (5) z t = \u03c3 W z \u00d7 x t + U z \u00d7 h t - 1 + b z (6) h \u0303 t = tanh W h \u00d7 x t + r t \u2299 ( U h \u00d7 h t - 1 + b h ) (7) r t = \u03c3 W r \u00d7 x t + U r \u00d7 h t - 1 + b r Bi-directional GRUs perceive the context of each input in a sequence by outlining the information from both directions. Concatenating the output of processing a sequence forward h \u2192 it and backwards h \u2190 it grants a summary of the information around each position, h it = [ h \u2192 it , h \u2190 it ] . Since the different words and fields can be differently informative in specific contexts, the model also includes two levels of attention mechanisms (i.e., one at the word level and one at the field level), that let the model pay more or less attention to individual words/fields when constructing representations (i.e., different weights will be used for the elements in the sequence of GRU outputs). For instance, in the case of the word-level part of the network, the outputs h it of the bi-directional GRU encoder are fed to a feed-forward node (Eq. (8)), resulting in vectors u it representing words in the input. A normalized importance \u03b1 it (i.e., the attention weights) is calculated as shown in Eq. (9), using a context vector u w that is randomly initialized. The importance weights in \u03b1 it are then summed over the whole sequence, as shown in Eq. (10). (8) u it = tanh ( W w \u00d7 h it + b w ) (9) \u03b1 it = exp ( u it T \u00d7 u w ) \u2211 t exp ( u it T \u00d7 u w ) (10) s i = \u2211 t \u03b1 it \u00d7 h it The vector s i from Eq. (10), corresponding to a weighted sum of the bi-directional GRU outputs, is finally taken as the representation of the input. The part of the network that processes the sequence of fields similarly uses bi-directional GRUs with an attention mechanism, taking as input the representations produced for each field, as shown in Fig. 2. The representation that is produced as the output of the field-level attention mechanism, which encompasses the entire output, is also concatenated with an alternative representation built through a simpler mechanism which, taking inspiration on the good results reported by Joulin et al. [12], computes the average of the embeddings for all words in the input fields. The word embeddings are randomly initialized and adjusted during model training. They are also shared by the hierarchical attention and the averaging mechanisms, and thus while one part of the model uses multiple parameters to compute representations for the inputs, the other part of the model can more directly propagate errors back into the embeddings, so that they can be updated. 3.3 Initializing the weights of the output nodes through label co-occurrence In the neural architecture illustrated on Fig. 2, the representations resulting from the different fields are finally passed to feed-forward output nodes. Three separate outputs are considered in the model, namely (i) a softmax node that outputs the ICD-10 full-code of the underlying cause of death, (ii) another softmax node that outputs the ICD-10 block of the underlying cause of death, and (iii) a sigmoid node that outputs multiple ICD-10 codes, corresponding to all contributing and auxiliary conditions, together with the the cause of death. Following the suggestion of Nam et al. [27], we used the sigmoid activation function and the binary cross-entropy loss function in the case of the node with the model outputs corresponding to multiple ICD-10 codes, given its superior performance in handling multi-label classification problems. In the training data, the target labels for this node are represented as a binary vector in which the possible ICD-10 codes are set to one. The two softmax nodes are associated to categorical cross-entropy loss functions, and the combined loss from all three outputs corresponds to a weighted average with parameters 0.8 , 0.85 and 0.75 . All three output nodes of the model can be initialized with weights that, given the list of auxiliary codes associated to each instance in the training set, try to capture the co-occurrences between ICD-10 codes. We tested two different approaches to compute the weight matrices of the output nodes. One of these approaches is based on the method from Kurata et al. [28], which has also been previously tested in biomedical text classification [23], leveraging the the Apriori algorithm [29] to find significant and frequent label co-occurrence patterns. The second approach uses a non-negative matrix factorization [30,31] over a label co-occurrence matrix, considering a number of components for the decomposition that is equal to the dimensionality of the combined input representation (i.e., the dimensionality of the outputs for the node that is located immediately before the output nodes \u2013 see Fig. 2). In the first strategy, the initial part of the Apriori algorithm is used for finding the sets ICD-10 codes that frequently appear together in the training data (i.e., the frequent itemsets). These sets of auxiliary codes are used to initialize the weight matrices for the output nodes, following the method proposed by Kurata et al. [28]. For each output node, a matrix X n , m , where n stands for the dimensionality of the hidden node immediately before the output node, and where m stands for the dimensionality of the output node, is initialized with the n most common sets of co-occurring ICD-10 labels. Each row in X represents a label co-occurrence pattern and, in the columns corresponding to the labels occurring in the pattern, an initialization value v = f \u00d7 6 n + m is attributed [28,23]. In the previous equation, f stands for the itemset frequency (i.e., the number of times the co-occurrence pattern appears in the training data), while n and m respectively correspond to the dimensionality of the hidden and output nodes. The Apriori algorithm was originally proposed by Agrawal and Srikant [29], leveraging the idea that if an itemset is infrequent then all its subsets must also be infrequent, in order to reduce the number of itemsets that need to be analyzed when consolidating the list of frequent itemsets. We start with itemsets containing just a single label, and then determine their support (i.e., the proportion of instances in which the itemset appears). We keep the itemsets that meet a minimum support threshold (i.e., 0.001 of the instances), and use them to generate all the possible itemset configurations. These steps are repeated until there are no more new itemsets. We finally select the n itemsets involving more ICD-10 labels, using support to break ties. The second technique that was considered for initializing the weights of the output nodes leverages the components of the decomposition that results from a Non-negative Matrix Factorization (NMF), applied to a matrix that encodes label co-occurrences in the training data. A square matrix X m , m , where m stands for the dimensionality of the output node, is first built from the training data with basis on label co-occurrence information (i.e., each matrix cell corresponds to the number of co-occurrences of a pair of ICD-10 labels, and the values at the diagonal simply reflect the frequency of the label in the training data). To reduce the impact of the most common labels and their prevalence in co-occurrence information, the X m , m matrix is scaled with a binary logarithm (i.e., log 2 ( 1 + x i , j ) for each matrix entry x i , j ). The NMF is then used to decompose the X m , m matrix into a product of two matrices, namely X m , m \u2248 W m , n \u00d7 H n , m , where n stands for the dimensionality of the hidden node that captures the representation of the input. The matrix H n , m is finally used as the initialization. The problem of finding two non-negative matrices W and H whose product is approximately equal to the original non-negative matrix X relies on minimizing the following objective function with an alternating minimization of W and H: (11) arg min W , H 1 2 \u2225 X - W \u00d7 H \u2225 Frobenius 2 = 1 2 \u2211 i , j X ij \u00d7 W \u00d7 H ij 2 4 Experimental evaluation This section describes the experimental evaluation of the proposed method. We first present a statistical characterization of the datasets that supported our tests, together with the considered experimental methodology. Then, the following subsections present and discuss the obtained results. 4.1 Datasets and experimental methodology The main dataset used in our experiments consists of the death certificates in SICO for the years 2013 to 2015 (excluding neonatal and perinatal mortality). We included all supplemental clinical bulletin and autopsy reports, although these mostly corresponded to deaths associated to accidents, suicides, or homicides. A simple statistical profile of the dataset in given in Table 1 . For each death certificate, we use the textual contents of the SICO fields labeled from (a) to (d) in Part I, as well as the contents from Part II \u2013 see Fig. 1. Each field is the concatenation of the strings labeled as Outro, Valor and Tempo. The fields Valor and Tempo can be used to encode the approximated interval between the onset of the respective condition and the date of death, which can be relevant in cases like a stroke that occurred long before the time of death. Hence, we decided to also include this information in the textual contents that are analyzed by the model, together with the string labeled as Outro. Clinical bulletins and autopsy reports are small free-text documents that can be associated with a death certificate. A clinical bulletin contains additional information or the clinical situation of the deceased. It is filled by the doctor before the death certificate, being mandatory in cases of violent deaths or unknown causes of death. A clinical bulletin comprises six fields: circumstances of admission, clinical situation, clinical evolution, complementary exams, clinical background, and diagnosis. Only the circumstances of admission, clinical situation, and diagnosis fields are used by our model, since the remaining fields are significantly less informative. An autopsy report can also be requested by the Public Prosecution Service to further investigate the causes of death, and its content consists of a small textual description of the autopsy results. When present, we used the textual contents of the autopsy report as a separate field. Each instance in the dataset thus consists of 9 different strings, some of them possibly empty: 5 strings for each field in the death certificate, 3 for the clinical bulletin, and 1 for the autopsy report. Each of the 9 strings is padded with special symbols to encode the beginning/termination of the textual contents. The input information is stored together with the ICD-10 full-code corresponding to the underlying cause of death, the ICD-10 block for the underlying cause of death, and ICD-10 codes corresponding to auxiliary conditions or injuries present in the deceased, other than those from the underlying cause of death in our dataset. It should be noted that the aforementioned dataset is unbalanced, given that some ICD-10 codes are much more common than others. In Fig. 3 we show the distribution for the number of occurrences of the 50 most common ICD-10 full-codes corresponding to an underlying cause of death in our dataset. The available data was randomly split into two subsets, with 75% (91,152 instances) for model training and 25% (30,384 instances) for testing. In the training set, 2241 instances were associated with a clinical bulletin, 4231 instances had an autopsy report, and 1012 instances had both a clinical bulletin and an autopsy report. In the testing set, 762 instances were associated with a clinical bulletin, 1422 with an autopsy report, and 336 instances had both. Table 3 presents the distribution for the number of instances associated to each ICD-10 chapter. Notice that some ICD-10 chapters have no instances in our dataset, given that the corresponding health problems are seldom related to death (i.e., Chapter VII, corresponding to diseases of the eye and adnexa). The word vocabulary that is considered by the model was generated using the instances of the training subset. When pre-processing the testing set, out-of-vocabulary words (i.e., words from the testing set that were not present in the training set) were substituted by the most similar word on the vocabulary, according to the Jaro-Winkler string distance metric [32]. This set of words, 5260 in total, corresponds to approximately 18 % of the vocabulary built from the training set. A manual analysis of the results showed that the certificates often include misspellings or alternative spellings for words (e.g., without diacritics), and hence the use of string similarity. To further test the performance of the proposed method, and to assess its effectiveness in a near real-time surveillance scenario, a second dataset was used, consisting of 86 , 071 instances corresponding to deaths occurring in 2016, also manually assigned to ICD-10 codes. Death certificates from 2016 were still undergoing the process of manual coding at the time of preparing this article. It takes the human experts from the Portuguese Directorate-General of Health approximately nine months to process one year of data, and while some of the months from 2016 have more than 95% of the corresponding death certificates already coded, for some of the other months we only have approximately 50% of coded data. The second dataset was pre-processed identically to the testing set, and thus out-of-vocabulary words in the 2016 instances were substituted by the most similar words on the vocabulary built from the training set. This set of words, 15,295 in total, corresponds to approximately 52% of the vocabulary build from the 2013\u20132015 training set. Albeit the large amount of out-of-vocabulary words, and similarly to the testing set, we noticed that these instances included many misspellings or alternative spellings for words, which were effectively handled through the string similarity metric. Using the second dataset, we computed the accuracy of the proposed method in specific blocks of ICD-10 codes, namely I20-I25 (i.e., ischaemic heart diseases), I60-I69 (i.e., cerebrovascular diseases), J09-J18 (i.e., influenza and pneumonia), and J95-J99 (i.e., other diseases of the respiratory system). These blocks were chosen because the corresponding health problems are intimately related with seasonality, and thus they are of high interest for real-time monitoring. The experiments with neural networks relied on the keras 4 http://keras.io 4 library, and specific tests involving SVM models or non-negative matrix factorization relied on implementations from scikit-learn 5 http://scikit-learn.org 5 . The word embedding layer in the first level of the neural model considered a dimensionality of 175, and the output of the GRUs also had a dimensionality of 175. Model training was made in batches of 32 instances, using the Adam optimization algorithm [25] with default parameters. Training also considered a stopping criteria based on the combined training loss, finishing when the difference between epochs was less than 0.3 . For assessing the quality of the model predictions, we measured the classification accuracy over the test split (and separately over the 2016 data), as well the macro-averaged precision, recall and F1-scores (i.e., macro-averages assign an equal importance to each class, thus providing useful information in the case of datasets with a highly unbalanced class distribution and when the system is required to perform consistently across all classes, regardless of how densely populated these are). Given the hierarchical organization of ICD-10, we also measured results according to different levels of specialization for ICD-10 terms, i.e., considering chapters, blocks, and full-codes. 4.2 Results for comparison of different models with data from 2013\u20132015 Our first experiments compared deep neural models against simpler baselines leveraging linear classifiers and bag-of-words representations, in at attempt to better compare our proposal with previous methods advanced in the literature. We specifically used one-versus-all multi-class SVM classifiers with representations based on individual words and TF-IDF weights, either (i) jointly representing all the textual contents, or (ii) building separate representations from the text in the death certificates, and from the text in the autopsy reports and clinical bulletins. A grid-search procedure was used to tune the regularization parameter C in the SVM models, as considered in the implementation provided by the scikit-learn package. These baselines also used the Jaro-Winkler similarity measure to handle out-of-vocabulary words (i.e., in the vector representations for the test instances, occurrences of previously unseen words were considered as occurrences of their most-similar words in the vocabulary built from the training data). Besides the SVM baselines, we also evaluated 6 different neural network architectures, corresponding to variants of the full model outlined in Section 3, in an attempt to assess the contribution of the different mechanisms that were considered in the full model. The considered model variants are as follows: 1. A model that only uses the average word embedding mechanism; 2. A hierarchical model with two levels of GRUs but without the attention mechanisms, thus using the hidden states at the edges of the sequences in order to build the intermediate representations; 3. A hierarchical model with two levels of GRUs, with attention mechanisms at each level, inspired on the proposal from Yang et al. [11]; 4. A model that combines the previous hierarchical attention approach with the average word embedding mechanism; 5. The full model combining hierarchical attention and average word embeddings, as described in Section 3, with 3 output nodes and initializing the weights of the output nodes by exploring frequent co-occurrence patterns; 6. The full model, as described in Section 3, leveraging non-negative matrix factorization for initializing the weights of the output nodes. Table 2 presents the results obtained by each model (i.e., linear classifiers and neural network architectures), and Table 3 further details the results obtained with Model 6 (i.e., the neural model with the best results in terms of the macro-averaged F1-score for predicting full-codes), by showing evaluation scores for each individual ICD-10 chapter. The best value in terms of accuracy for full-code prediction was obtained by the full neural model leveraging initialization with basis on frequent itemsets (i.e., Model 5), corresponding to a value of 76.112 % . The initialization with basis on non-negative matrix factorization lead to very similar values in terms of accuracy (i.e., 75.947 % when predicting full-codes), although performing better in terms of macro-averaged F1-scores (e.g., 27.04 % when predicting full-codes, instead of 23.08 % ). It should also be noted that although the SVM baselines achieved competitive results (e.g., they outperformed some of the simpler neural architectures in some of the metrics), the combined neural network outperformed the SVM models, specifically when considering the NMF strategy for initialization. Due to the computational effort involved in training deep neural networks, it would be prohibitively expensive to systematically test all our model variants using different random splits of training/testing instances, or using k-fold cross validation to further affirm the differences between the models. We nonetheless performed some additional tests during the development of the research reported on this article, with different random data splits and with some of the model variations that are present in Table 2. In all cases, we only saw small differences in terms of the evaluation metrics when considering different splits. For instance, in the case of the SVM baseline considering a joint representation of the textual inputs, in 5 tests using different random data splits the results ranged from 67.15% to 67.55% in terms of the full-code accuracy, and from 25.90% to 26.75% in terms of the full-code macro-averaged F1. The results in Table 2, for all the models, where obtained with one of these 5 data splits. To further assess the overall performance of our best method, we also computed the Mean Reciprocal Rank (MRR) of the correct class, when sorting classes according to the probability assigned prior to performing the softmax operation associated to full ICD-10 codes. Model 6 has a MRR of 0.804 when assigning full-codes, 0.845 for blocks, and 0.915 for ICD-10 chapters, again attesting to the good predictive accuracy of the proposed neural architecture. 4.3 Results when considering the prediction of common causes of death The most common causes of death in our dataset correspond to ICD-10 Chapters II (i.e, neoplasms) and IX (i.e., diseases of the circulatory system). Together, these ICD-10 codes represent approximately 56.6 % of the instances. Table 4 further details the results obtained by Model 6 in these two important chapters. In Table 3, we can also see that deaths with underlying cause in Chapter XVIII (i.e., symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified) were also predicted with high effectiveness (i.e., an F1-score of 89.542 % , the third largest in terms of individual chapters). Some of the previous research addressing the problem of automatically coding death certificates has focused on deaths related to cancer [5], which are particularly frequent also in our dataset. When considering the 20 most common ICD cancer blocks in our test split of the data, Model 6 achieves a macro-averaged F1-score of 92.254 % . When we consider the 10 or the 50 most common ICD-10 full-codes in the dataset (i.e., the codes shown in Fig. 3), Model 6 respectively achieves macro-averaged F1-scores of 89.251 % or 80.573 % . 4.4 Assessing the impact of the autopsy reports in the model predictions To assess the impact of the information in the autopsy reports over model predictions, we conducted a separate experiment using the 1422 test instances that are associated with an autopsy report. Approximately 51 % of those instances have an underlying cause of death from Chapter XX (i.e., external causes of morbidity and mortality, namely, accidents, intentional self-harm, assault and others), and approximately 32 % are associated to ICD-10 codes from Chapter IX (i.e., diseases of the circulatory system). Table 5 presents the obtained results, using Model 6 with parameters inferred from the complete training dataset, comparing the use of the complete input data against (a) using only the autopsy reports, or (b) using only the death certificates and the clinical bulletins, when available. The results confirm the importance of using the descriptions in the autopsy reports. A manual analysis of the data also showed that, for deaths associated to ICD-10 Chapter XX, the death certificate is often incomplete and the underlying cause of death is only described in the autopsy report. 4.5 Results in a near real-time surveillance scenario with data from 2016 In 2016 there were a total of 111,279 deaths in Portugal and, by July of 2017, a fraction of 77.3 % of these cases, corresponding to 86,071 death certificates, had already been manually reviewed and coded according to ICD-10. In a second round of experiments, we attempted to classify these 86,071 instances from 2016, leveraging Model 6 from the previous experiments, trained with data from 2013\u20132015. The number of instances for each of the ICD-10 chapters in the 2016 dataset is similar to the one in Table 3, and the performance metrics for ICD-10 chapters, blocks and full-codes can be seen in Table 6 . The accuracy values are very similar to those obtained from the test subset (i.e., an accuracy of 75.901 % for full-codes, 80.615 % for blocks, and 89.129 % for chapters), confirming that the proposed approach can generalize across different time periods. For comparison, Table 6 also presents results for ICD-10 Chapters II and IX, although in this case showing worse results than those reported on Table 4. Given the motivation of using automatic classification to monitor the prevalence of specific causes of death in near real-time, we used weekly time-series of deaths occurring on 2016 to compare the assignments of the DGS mortality coders against the assignments produced by our neural network. In Figs. 4\u20137 , we show the percentage of weekly occurrences for specific groups of ICD-10 codes. The black solid line corresponds to the percentage of occurrences per week, as assigned by the human coders, whereas the black dashed line corresponds to the percentage of occurrences estimated by our model (i.e., the true positives plus the false positives). The true positives of the model are shown in the green lines, and the false positives are shown in red. Figs. 4 and 5 illustrate the results for two blocks of ICD-10 codes from Chapter IX, respectively ischaemic heart diseases, and cerebrovascular diseases. In both cases, the model made zero false positive predictions, only slightly under-estimating the number of diseased individuals. The mean absolute differences between the manually-assigned codes and the predictions was 0.578 % for ischaemic heart diseases (Fig. 4) and 0.873 % for cerebrovascular diseases (Fig. 5), with maximum differences between the number of occurrences respectively at 1.003 % and 1.852 % . In turn, Figs. 6 and 7 illustrate the results for two blocks of ICD-10 codes from Chapter X, respectively influenza/pneumonia, and other diseases of the respiratory system. Both blocks had false positive predictions, although the automated results still approximate the manual assignments with a high accuracy. The model approximately estimated 0.095 % more occurrences for influenza and pneumonia (Fig. 4), and 0.327 % more occurrences for other diseases of the respiratory system (Fig. 5). The number of misclassified cases is somewhat compensated by the number of cases that are missed, and the plots confirm that the automated method is indeed capable of approximating the results produced by the human coders, even in the case of less common causes of death (e.g., other diseases of the respiratory system). 4.6 Visualizing and interpreting the model predictions Besides applications in near real-time surveillance of specific causes of death, the proposed approach can also be useful for assisting human coders. The results from Table 2, particularly when comparing the cells corresponding to Models 2 and 3, have already shown that the neural attention mechanisms can led to an increased performance. More interestingly, neural attention can also offer model interpretability, by allowing users to see which parts of the input (i.e., which fields and which words) are attended to when making predictions. Fig. 8 illustrates the attention weights calculated as shown in Eq. (9), for the contents of two death certificates in our testing set. These instances were not associated to a clinical bulletin or an autopsy report, and thus the figure is only showing the first four textual fields. The certificate shown in Fig. 8a was correctly assigned to code C719 (i.e., malignant neoplasm of brain, unspecified) with a confidence of 95.21 % , and the figure shows the words glioblastoma multiforme having a significant impact. In turn, the certificate in Fig. 8b was correctly assigned to code J40 (i.e., bronchitis, not specified as acute or chronic) with a confidence of 92.39 % . In this example, the words insufici\u00eancia card\u00edaca descompensada in the first field have much less impact than the word traqueobronquite on the second field. Fig. 9 shows the distribution of the attention weights for the case of four particular word tokens, contrasting 250 random death certificates from an ICD-10 chapter related to the word tokens, against random 250 certificates from the remaining chapters. The token AVC (i.e., the Portuguese acronym for cerebrovascular accident) is often used to denote a stroke, and the attention weights in Chapter IX (i.e., diseases of the circulatory system) are generally higher, as shown in Fig. 9a. Figs. 9b, c, and d show similar examples (e.g., in the case of Fig. 9b, showing the token demncia and considering Chapter V, which corresponds to mental and behavioural disorders). At the time of preparing this article, the proposed classification mechanism is being integrated into a platform 6 http://evm.min-saude.pt 6 from the Portuguese Ministry of Health for near real-time death cause surveillance, advancing the publication of statistics that are latter revised by human coders. We also believe that the SICO platform for manual ICD-10 coding of death certificates can be complemented with automatic code suggestion mechanisms, and with visualization methods [33\u201335] leveraging the results from the neural model (e.g, visualizations based on the attention weights, similar to those from Figs. 8 and 9). 5 Conclusions and future work We presented a deep learning method for coding the free-text descriptions for the underlying cause of death, included in death certificates, clinical bulletins, and autopsy reports obtained from the Portuguese Ministry of Health\u2019s Directorate-General of Health, according to ICD-10. Experimental results show that although ICD-10 coding is a difficult task, due to the large number of classes that are sparsely used, we can still obtain a high classification accuracy. We argue that our approach can indeed contribute to a faster processing of death certificates, supporting near real-time surveillance of relevant ICD-10 blocks. Our approach can also help in the task of manual coding the certificates, providing ICD-10 code suggestions that are interpretable, based on visualizations built from the neural attention weights highlighting the elements of the input data that contribute to particular predictions. Despite the already interesting results, there are also many open possibilities for future work. Although other previous studies have advanced methods for ICD coding of death certificates [3\u20136], their results are not directly comparable ours, given the focus on different languages and different formulations of the task. Some of these studies considered a single textual field as input, and the prediction tasks also differed in the number of classes and/or in accepting multiple codes as output. To comparatively assess our approach, a possible experiment would involve testing an adapted version of our neural model over the French and English datasets from the CLEF eHealth shared task [8]. Our model leverages GRUs to encode sequences, but other types of recurrent nodes have also been recently been proposed. For instance, the Minimal Gated Unit approach [36,37] relies on a simplified model with just a single gate. Having less parameters to train can contribute to improving the model effectiveness. In contrast, Multi-Function Recurrent Units (Mu-FuRUs) adopt an elaborate gating mechanism that allows for additional differentiable functions as composition operations, leading to models that can better capture the nuances involved in encoding sequences [38]. Other alternatives include Long Short-Term Memory (LSTM) networks with coupled gates [39], Structurally Constrained Recurrent Networks [40], IRNNs [41], and many other LSTM or GRU model variants [39,42]. Besides different types of recurrent nodes, many other options can also be considered for improving the neural architecture. For instance, to better handle out-of-vocabulary words (e.g., the names of particular conditions with slightly different spellings, that often appear in the death certificates) we can consider alternative mechanisms for exploring context in the generation of the word embeddings, or replacing/enriching the embeddings with mechanisms that generate representations from individual characters or character n-grams [43,44]. Another idea for improving the embeddings layer, at the same time also allowing us to explore knowledge encoded in ICD-10, would be to share a subset of the weights between the embeddings of words that belong to the same semantic group(s), as recently proposed by Zhang et al. [45]. Another idea worth exploring relates to the use of sparse modeling methods as an approach to improve the predictions at the output nodes [46], e.g. by using sparsemax instead of the softmax and sigmoid activations at the model outputs [47]. Sparse modelling methods could also be used as an approach to improve the interpretability of the attention mechanisms [48] (i.e., standard attention tends to produce dense outputs, in the sense that all elements in the input always make at least a small contribution to the decision, while sparse alternatives can better encourage parsimony and interpretability). Our empirical results have also evidenced problems in handling the highly skewed class distribution, with much worse results for infrequent ICD-10 codes. To further improve results, we can consider training procedures that, based on the SMOTE technique [49], over-sample the minority classes and introduce minor perturbations on these training instances. Another possibility relates to exploring previously proposed ideas for one-shot or few-shot learning [50\u201353], e.g. using neural architectures augmented with memory capacities, including using an external memory to encode training instances, and an attention mechanism to retrieve similar instances, which would enable making accurate predictions even if seeing only a few samples. Besides real-time surveillance, the ideas advanced in this article could also be used in the context of methods for disease and/or mortality forecasting. In fact, several previous studies have reported on the use of information from death certificates to predict the future incidence of particular health problems [54], for instance by leveraging auto-regressive time-series models (e.g., ARIMA models in which the value for a variable at a particular period depends on its value in the previous period(s)). For future work, it would be interesting to compare the performance of forecasting models leveraging manually coded information, versus models leveraging the automatic coding of the death causes (i.e., it might be the case that disease forecasting models leveraging the automatically coded data are equally informative). In the context of surveillance applications interested in the analysis of time-series for particular causes of death (e.g., in cases like those illustrated in Figs. 4\u20137), one can also consider the usage of auto-regressive models to improve the predictions given by the model that is outlined in this article, using information from the recent past to try to correct the number of occurrences that is estimated at each time-step. Acknowledgements This work was partially supported by Funda\u00e7\u00e3o para a Ci\u00eancia e Tecnologia (FCT), through the INESC-ID multi-annual funding from the PIDDAC program (i.e., the project grant with reference UID/CEC/50021/2013). References [1] C\u00e1tia Sousa Pinto Robert N. Anderson Cristiano Marques Cristiana Maia Henrique Martins Maria do Carmo Borralho Improving the mortality information system in Portugal Eurohealth 22 2 2016 [2] Hercules Dalianis Clinical text retrieval \u2013 an overview of basic building blocks and applications Georgios Paltoglou Fernando Loizides Preben Hansen Professional Search in the Modern World 2014 Springer [3] Pierre Zweigenbaum, Thomas Lavergne, Hybrid methods for ICD-10 coding of death certificates, in: Proceedings of the International Workshop on Health Text Mining and Information Analysis, 2016. [4] Ghulam Mujtaba, Liyana Shuib, Ram Gopal Raj, Retnagowri Rajandram, Khairunisa Shaikh, Mohammed Ali Al-Garadi, Automatic ICD-10 multi-class classification of cause of death from plaintext autopsy reports through expert-driven feature selection, PLOS ONE 12(2) (2017). [5] Bevan Koopman Guido Zuccon Anthony Nguyen Anton Bergheim Narelle Grayson Automatic ICD-10 classification of cancers from free-text death certificates Int. J. Med. Informatics 84 11 2015 [6] Bevan Koopman Sarvnaz Karimi Anthony Nguyen Rhydwyn McGuire David Muscatello Madonna Kemp Donna Truran Ming Zhang Sarah Thackway Automatic classification of diseases from free-text death certificates for real-time surveillance BMC Med. Inform. Decis. Mak. 15 1 2015 [7] Liadh Kelly, Lorraine Goeuriot, Hanna Suominen, Aur\u00e9lie N\u00e9v\u00e9ol, Jo\u00e3o Palotti, Guido Zuccon, Overview of the CLEF eHealth Evaluation Lab 2016, in: Proceedings of the International Conference of the Cross-Language Evaluation Forum for European Languages, 2016. [8] Thomas Lavergne, Aur\u00e9lie N\u00e9v\u00e9ol, Aude Robert, Cyril Grouin, Gr\u00e9goire Rey, Pierre Zweigenbaum, A dataset for ICD-10 coding of death certificates: creation and usage, in: Proceedings of the Workshop on Building and Evaluating Resources for Biomedical Text Mining, 2016. [9] Francisco Duarte, Bruno Martins, C\u00e1tia Sousa Pinto, M\u00e1rio J. Silva, A deep learning method for ICD-10 coding of free-text death certificates, in: Proceedings of the Portuguese Conference on Artificial Intelligence, 2017. [10] KyungHyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, Yoshua Bengio, On the properties of neural machine translation: encoder-decoder approaches, in: Proceedings of the Workshop on Synthax, Semantics and Structure in Statistical Translation, 2014. [11] Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, Eduard Hovy, Hierarchical attention networks for document classification, in: Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics, 2016. [12] Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov, Bag of tricks for efficient text classification, in: Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics, 2017. [13] Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Neural machine translation by jointly learning to align and translate, in: Proceedings of the International Conference on Learning Representations, 2014. [14] John P. Pestian, Christopher Brew, Pawe\u0142 Matykiewicz, Dj J. Hovermale, Neil Johnson, K. Bretonnel Cohen, W\u0142odzis\u0142aw Duch, A shared task involving multi-label classification of clinical free text, in: Proceedings of the Workshop on Biological, Translational, and Clinical Language Processing, 2007. [15] Danchen Zhang, Daqing He, Sanqiang Zhao, Lei Li, Enhancing automatic ICD-9-CM code assignment for medical texts with PubMed, in: Proceedings of the ACL-SIGBioMed Workshop on Biomedical Natural Language Processing, 2017. [16] Adler Perotte Rimma Pivovarov Karthik Natarajan Nicole Weiskopf Frank Wood No\u00e9mie Elhadad Diagnosis code assignment: models and evaluation metrics J. Am. Med. Inform. Assoc. 21 2 2013 [17] Svetla Boytcheva. Automatic matching of ICD-10 codes to diagnoses in discharge letters, in: Proceedings of the ACL-SIGBioMed Workshop on Biomedical Natural Language Processing, 2011. [18] Yan Yan, Glenn Fung, Jennifer G. Dy, Romer Rosales, Medical coding classification by leveraging inter-code relationships, in: Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2010. [19] Sen Wang Xiaojun Chang Xue Li Guodong Long Lina Yao Quan Z. Sheng Diagnosis code assignment using sparsity-based disease correlation embedding IEEE Trans. Knowl. Data Eng. 28 12 2016 [20] S. Pyysalo, F. Ginter, H. Moen, T. Salakoski, S. Ananiadou, Distributional semantics resources for biomedical text processing, in: Proceedings of the International Symposium on Languages in Biology and Medicine, 2013. [21] Kevin Patel, Divya Patel, Mansi Golakiya, Pushpak Bhattacharyya, Nilesh Birari, Adapting pre-trained word embeddings for use in medical coding, in: Proceedings of the ACL-SIGBioMed Workshop on Biomedical Natural Language Processing, 2017. [22] Sarvnaz Karimi, Xiang Dai, Hamedh Hassanzadeh, Anthony Nguyen, Automatic diagnosis coding of radiology reports: a comparison of deep learning and conventional classification methods, in: Proceedings of the ACL-SIGBioMed Workshop on Biomedical Natural Language Processing, 2017. [23] Simon Baker, Anna Korhonen, Initializing neural networks for hierarchical multi-label text classification, in: Proceedings of the ACL-SIGBioMed Workshop on Biomedical Natural Language Processing, 2017. [24] David E. Rumelhart Geoffrey E. Hinton Ronald J. Williams Learning representations by back-propagating errors Cogn. Model. 5 3 1988 [25] Diederik Kingma, Jimmy Ba. Adam: a method for stochastic optimization, in: Proceedings of the International Conference for Learning Representations, 2015. [26] Yoav Goldberg A primer on neural network models for natural language processing J. Artif. Int. Res. 57 2016 [27] Jinseok Nam, Jungi Kim, Iryna Gurevych, Johannes F\u00fcrnkranz. Large-scale multi-label text classification \u2013 revisiting neural Networks, in: Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databeses, 2013. [28] Gakuto Kurata, Bing Xiang, and Bowen Zhou. Improved neural network-based multi-label classification with better initialization leveraging label co-occurrence, in: Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics, 2016. [29] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules, in: Proceedings of the International Conference on Very Large Data Bases, 1994. [30] Daniel D. Lee H. Sebastian Seung Learning the parts of objects by non-negative matrix factorization Nature 401 6755 1999 [31] Chih-Jen Lin Projected gradient methods for nonnegative matrix factorization Neural Comput. 19 10 2007 [32] William E. Winkler, The state of record linkage and current research problems, Technical Report 2006-2, Statistical Research Division of the US Census Bureau, 2006. [33] Jiwei Li, Xinlei Chen, Eduard Hovy, Dan Jurafsky, Visualizing and understanding neural models in nlp, in: Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics, 2016. [34] Yao Ming, Shaozu Cao, Ruixiang Zhang, Zhen Li, Yuanzhe Chen, Yangqiu Song, Huamin Qu, Understanding hidden memories of recurrent neural networks, in: Proceedings of the IEEE Conference on Visual Analytics Science and Technology, 2017. [35] Ying Sha and May D. Wang. Interpretable predictions of clinical outcomes with an attention-based recurrent neural network, in: Proceedings of the ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics, 2017. [36] Guo-Bing Zhou Jianxin Wu Chen-Lin Zhang Zhi-Hua Zhou Minimal gated unit for recurrent neural networks Int. J. Autom. Comput. 13 3 2016 [37] Joel Heck, Fathi M. Salem. Simplified minimal gated unit variations for recurrent neural networks. arXiv preprint arXiv:1701.03452, 2017. [38] Dirk Weissenborn, Tim Rockt\u00e4schel, Mu-FuRU: The multi-function recurrent unit, in: Proceedings of the ACL Workshop on Representation Learning for NLP, 2016. [39] Klaus Greff Rupesh K. Srivastava Jan Koutn\u00edk Bas R Steunebrink J\u00fcrgen Schmidhuber LSTM: A search space odyssey IEEE Transactions on Neural Networks and Learning Systems PP 99 2016 [40] Tomas Mikolov, Armand Joulin, Sumit Chopra, Micha\u00ebl Mathieu, Marc\u2019Aurelio Ranzato. Learning longer memory in recurrent neural networks. arXiv preprint arXiv:1412.7753, 2014. [41] Quoc V. Le, Navdeep Jaitly, Geoffrey E. Hinton, A simple way to initialize recurrent networks of rectified linear units. arXiv preprint arXiv:1504.00941, 2015. [42] Rafal Jozefowicz, Wojciech Zaremba, Ilya Sutskever, An empirical exploration of recurrent network architectures, in: Proceedings of the International Conference on Machine Learning, 2015. [43] Piotr Bojanowski Edouard Grave Armand Joulin Tomas Mikolov Enriching word vectors with subword information Trans. Assoc. Comput. Linguist. 5 2017 [44] F. Horn, Context encoders as a simple but powerful extension of word2vec, in: Proceedings of the ACL Workshop on Representation Learning for NLP, 2017. [45] Ye Zhang, Matthew Lease, Byron C. Wallace, Exploiting domain knowledge via grouped weight sharing with application to text categorization. arXiv preprint arXiv:1702.02535, 2017. [46] Jaehong Yoon, Sung Ju Hwang, Combined group and exclusive sparsity for deep neural networks, in: Proceedings of the International Conference on Machine Learning, 2017. [47] Andr\u00e9 F. T. Martins, Ram\u00f3n Fern\u00e1ndez Astudillo, From softmax to sparsemax: a sparse model of attention and multi-label classification, in: Proceedings of the International Conference on Machine Learning, 2016. [48] V. Niculae, M. Blondel, A regularized framework for sparse and structured neural attention. arXiv preprint arXiv:1705.07704, 2017. [49] Nitesh V. Chawla Kevin W. Bowyer Lawrence O. Hall W Philip Kegelmeyer SMOTE: Synthetic minority over-sampling technique J. Artif. Intel. Res. 16 2002 [50] Lukasz Kaiser, Ofir Nachum, Aurko Roy, Samy Bengio, Learning to remember rare events, in: Proceedings of the International Conference on Learning Representations, 2017. [51] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy P. Lillicrap, One-shot learning with memory-augmented neural networks. arXiv preprint arXiv:1605.06065, 2016. [52] Gregory Koch, Richard Zemel, Ruslan Salakhutdinov, Siamese neural networks for one-shot image recognition, in: Proceedings of the ICML Deep Learning Workshop, 2015. [53] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra, Matching networks for one shot learning, in: Proceedings of the Conference on Neural Information Processing Systems, 2016. [54] Robert McNown Andrei Rogers Forecasting cause-specific mortality using time series methods Int. J. Forecast. 8 3 1992", "scopus-id": "85043403231", "pubmed-id": "29496630", "coredata": {"eid": "1-s2.0-S1532046418300303", "dc:description": "Abstract We address the assignment of ICD-10 codes for causes of death by analyzing free-text descriptions in death certificates, together with the associated autopsy reports and clinical bulletins, from the Portuguese Ministry of Health. We leverage a deep neural network that combines word embeddings, recurrent units, and neural attention, for the generation of intermediate representations of the textual contents. The neural network also explores the hierarchical nature of the input data, by building representations from the sequences of words within individual fields, which are then combined according to the sequences of fields that compose the inputs. Moreover, we explore innovative mechanisms for initializing the weights of the final nodes of the network, leveraging co-occurrences between classes together with the hierarchical structure of ICD-10. Experimental results attest to the contribution of the different neural network components. Our best model achieves accuracy scores over 89%, 81%, and 76%, respectively for ICD-10 chapters, blocks, and full-codes. Through examples, we also show that our method can produce interpretable results, useful for public health surveillance.", "openArchiveArticle": "true", "prism:coverDate": "2018-04-30", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046418300303", "dc:creator": [{"@_fa": "true", "$": "Duarte, Francisco"}, {"@_fa": "true", "$": "Martins, Bruno"}, {"@_fa": "true", "$": "Pinto, C\u00e1tia Sousa"}, {"@_fa": "true", "$": "Silva, M\u00e1rio J."}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046418300303"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046418300303"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(18)30030-3", "prism:volume": "80", "prism:publisher": "Elsevier Inc.", "dc:title": "Deep neural models for ICD-10 coding of death certificates and autopsy reports in free-text", "prism:copyright": "\u00a9 2018 Elsevier Inc.", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Automated ICD coding"}, {"@_fa": "true", "$": "Clinical text mining"}, {"@_fa": "true", "$": "Deep learning"}, {"@_fa": "true", "$": "Natural language processing"}, {"@_fa": "true", "$": "Artificial intelligence in medicine"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "64-77", "prism:endingPage": "77", "prism:coverDisplayDate": "April 2018", "prism:doi": "10.1016/j.jbi.2018.02.011", "prism:startingPage": "64", "dc:identifier": "doi:10.1016/j.jbi.2018.02.011", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "147", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10842", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "152", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "9848", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "137", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10399", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "96", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7476", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "75", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5455", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "74", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4619", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "74", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4964", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "74", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6349", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "61", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "3540", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "116", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5368", "@ref": "gr9", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "200", "@width": "299", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "19441", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "401", "@width": "578", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "47064", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "362", "@width": "578", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "62315", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "253", "@width": "578", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "36294", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "198", "@width": "579", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "31091", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "195", "@width": "579", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "30517", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "196", "@width": "579", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "31667", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "195", "@width": "579", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "36842", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "156", "@width": "562", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "14729", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "789", "@width": "560", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "56530", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "886", "@width": "1324", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "174964", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1064", "@width": "1535", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "164552", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1605", "@width": "2561", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "500190", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "673", "@width": "1535", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "134140", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "853", "@width": "2497", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "202122", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "836", "@width": "2480", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "199354", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "843", "@width": "2484", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr6_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "209941", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "865", "@width": "2563", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr7_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "245709", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "689", "@width": "2488", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr8_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "113406", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "3494", "@width": "2480", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-gr9_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "345998", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "14", "@width": "33", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "319", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "127", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "458", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "30", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "290", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "52", "@width": "297", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1645", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "218", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1016", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "10", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "190", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si15.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "203", "@ref": "si15", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si16.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "203", "@ref": "si16", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "10", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si17.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "188", "@ref": "si17", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "11", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si18.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "209", "@ref": "si18", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "10", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si19.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "203", "@ref": "si19", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "34", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "328", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si20.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "240", "@ref": "si20", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si21.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "215", "@ref": "si21", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "56", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si22.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "355", "@ref": "si22", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "134", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si26.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "572", "@ref": "si26", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si27.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "221", "@ref": "si27", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "198", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si28.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "897", "@ref": "si28", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "107", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "657", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si30.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "210", "@ref": "si30", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si31.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "234", "@ref": "si31", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "28", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si32.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "251", "@ref": "si32", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "13", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si33.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "208", "@ref": "si33", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "13", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si37.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "191", "@ref": "si37", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "14", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si38.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "202", "@ref": "si38", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "20", "@width": "15", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si39.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "234", "@ref": "si39", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "47", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "382", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "211", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si40.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "847", "@ref": "si40", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "241", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si41.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1011", "@ref": "si41", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "23", "@width": "318", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si42.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1366", "@ref": "si42", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "239", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si43.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "984", "@ref": "si43", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "22", "@width": "23", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si44.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "272", "@ref": "si44", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "24", "@width": "19", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si45.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "256", "@ref": "si45", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "25", "@width": "97", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si46.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "537", "@ref": "si46", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si47.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "237", "@ref": "si47", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si48.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "227", "@ref": "si48", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "18", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si49.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "233", "@ref": "si49", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "48", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "407", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "12", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si50.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "230", "@ref": "si50", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "193", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si52.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "937", "@ref": "si52", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "45", "@width": "166", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si53.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1337", "@ref": "si53", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "34", "@width": "114", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si54.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "662", "@ref": "si54", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "11", "@width": "12", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si55.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "198", "@ref": "si55", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si56.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "469", "@ref": "si56", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "34", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si57.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "298", "@ref": "si57", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "31", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si58.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "276", "@ref": "si58", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "25", "@width": "108", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si59.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "614", "@ref": "si59", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "48", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "413", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si60.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "326", "@ref": "si60", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "35", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si61.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "287", "@ref": "si61", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "90", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si63.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "559", "@ref": "si63", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "20", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si64.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "241", "@ref": "si64", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "143", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si66.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "632", "@ref": "si66", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "16", "@width": "32", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si67.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "285", "@ref": "si67", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "47", "@width": "401", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si68.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2207", "@ref": "si68", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "33", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si69.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "324", "@ref": "si69", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "47", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "397", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "54", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si70.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "422", "@ref": "si70", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "24", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si71.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "261", "@ref": "si71", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "66", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si72.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "455", "@ref": "si72", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "66", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si73.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "472", "@ref": "si73", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si74.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "437", "@ref": "si74", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si75.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "455", "@ref": "si75", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "43", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si76.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "361", "@ref": "si76", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "44", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si77.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "370", "@ref": "si77", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "44", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si78.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "344", "@ref": "si78", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "23", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "252", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "67", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si80.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "511", "@ref": "si80", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "67", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si81.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "485", "@ref": "si81", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "67", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si82.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "497", "@ref": "si82", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "66", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si83.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "509", "@ref": "si83", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "33", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si84.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "305", "@ref": "si84", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "34", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si85.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "328", "@ref": "si85", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "47", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si86.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "363", "@ref": "si86", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "65", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si87.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "469", "@ref": "si87", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "66", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si88.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "498", "@ref": "si88", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "67", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si89.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "492", "@ref": "si89", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "34", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "344", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si90.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "452", "@ref": "si90", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si91.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "449", "@ref": "si91", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "56", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si92.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "422", "@ref": "si92", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "56", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si93.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "436", "@ref": "si93", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si94.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "448", "@ref": "si94", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si95.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "434", "@ref": "si95", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si96.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "428", "@ref": "si96", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "57", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046418300303-si97.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "447", "@ref": "si97", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85043403231"}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608013001913", "dc:identifier": "doi:10.1016/j.neunet.2013.07.006", "eid": "1-s2.0-S0893608013001913", "prism:doi": "10.1016/j.neunet.2013.07.006", "pii": "S0893-6080(13)00191-3", "dc:title": "Fully corrective boosting with arbitrary loss and regularization ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "48", "prism:startingPage": "44", "prism:endingPage": "58", "prism:pageRange": "44-58", "dc:format": "application/json", "prism:coverDate": "2013-12-31", "prism:coverDisplayDate": "December 2013", "prism:copyright": "Copyright \u00a9 2013 Elsevier Ltd. Published by Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd. Published by Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Shen, Chunhua"}, {"@_fa": "true", "$": "Li, Hanxi"}, {"@_fa": "true", "$": "van den Hengel, Anton"}], "dc:description": "\n               Abstract\n               \n                  We propose a general framework for analyzing and developing fully corrective boosting-based classifiers. The framework accepts any convex objective function, and allows any convex (for example, \n                        \n                           \n                              \u2113\n                           \n                           \n                              p\n                           \n                        \n                     -norm, \n                        p\n                        \u2265\n                        1\n                     ) regularization term. By placing the wide variety of existing fully corrective boosting-based classifiers on a common footing, and considering the primal and dual problems together, the framework allows a direct comparison between apparently disparate methods. By solving the primal rather than the dual the framework is capable of generating efficient fully-corrective boosting algorithms without recourse to sophisticated convex optimization processes. We show that a range of additional boosting-based algorithms can be incorporated into the framework despite not being fully corrective. Finally, we provide an empirical analysis of the performance of a variety of the most significant boosting-based classifiers on a few machine learning benchmark datasets.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Boosting"}, {"@_fa": "true", "$": "Ensemble learning"}, {"@_fa": "true", "$": "Convex optimization"}, {"@_fa": "true", "$": "Column generation"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608013001913", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608013001913", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "84881251636", "scopus-eid": "2-s2.0-84881251636", "pubmed-id": "23917694", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/84881251636", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20130716", "$": "2013-07-16"}}}}}
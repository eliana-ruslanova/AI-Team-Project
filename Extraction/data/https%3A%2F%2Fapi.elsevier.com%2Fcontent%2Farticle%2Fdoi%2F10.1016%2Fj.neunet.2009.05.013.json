{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608009001038", "dc:identifier": "doi:10.1016/j.neunet.2009.05.013", "eid": "1-s2.0-S0893608009001038", "prism:doi": "10.1016/j.neunet.2009.05.013", "pii": "S0893-6080(09)00103-8", "dc:title": "Evolutionary artificial neural networks by multi-dimensional particle swarm optimization ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "22", "prism:issueIdentifier": "10", "prism:startingPage": "1448", "prism:endingPage": "1462", "prism:pageRange": "1448-1462", "prism:number": "10", "dc:format": "application/json", "prism:coverDate": "2009-12-31", "prism:coverDisplayDate": "December 2009", "prism:copyright": "Copyright \u00a9 2009 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Kiranyaz, Serkan"}, {"@_fa": "true", "$": "Ince, Turker"}, {"@_fa": "true", "$": "Yildirim, Alper"}, {"@_fa": "true", "$": "Gabbouj, Moncef"}], "dc:description": "\n               Abstract\n               \n                  In this paper, we propose a novel technique for the automatic design of Artificial Neural Networks (ANNs) by evolving to the optimal network configuration(s) within an architecture space. It is entirely based on a multi-dimensional Particle Swarm Optimization (MD PSO) technique, which re-forms the native structure of swarm particles in such a way that they can make inter-dimensional passes with a dedicated dimensional PSO process. Therefore, in a multidimensional search space where the optimum dimension is unknown, swarm particles can seek both positional and dimensional optima. This eventually removes the necessity of setting a fixed dimension a priori, which is a common drawback for the family of swarm optimizers. With the proper encoding of the network configurations and parameters into particles, MD PSO can then seek the positional optimum in the error space and the dimensional optimum in the architecture space. The optimum dimension converged at the end of a MD PSO process corresponds to a unique ANN configuration where the network parameters (connections, weights and biases) can then be resolved from the positional optimum reached on that dimension. In addition to this, the proposed technique generates a ranked list of network configurations, from the best to the worst. This is indeed a crucial piece of information, indicating what potential configurations can be alternatives to the best one, and which configurations should not be used at all for a particular problem. In this study, the architecture space is defined over feed-forward, fully-connected ANNs so as to use the conventional techniques such as back-propagation and some other evolutionary methods in this field. The proposed technique is applied over the most challenging synthetic problems to test its optimality on evolving networks and over the benchmark problems to test its generalization capability as well as to make comparative evaluations with the several competing techniques. The experimental results show that the MD PSO evolves to optimum or near-optimum networks in general and has a superior generalization capability. Furthermore, the MD PSO naturally favors a low-dimension solution when it exhibits a competitive performance with a high dimension counterpart and such a native tendency eventually yields the evolution process to the compact network configurations in the architecture space rather than the complex ones, as long as the optimality prevails.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Particle swarm optimization"}, {"@_fa": "true", "$": "Multi-dimensional search"}, {"@_fa": "true", "$": "Evolutionary artificial neural networks and multi-layer perceptrons"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608009001038", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608009001038", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "71749096569", "scopus-eid": "2-s2.0-71749096569", "pubmed-id": "19556105", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/71749096569", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20090608", "$": "2009-06-08"}}}}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0893608019302667", "dc:identifier": "doi:10.1016/j.neunet.2019.09.005", "eid": "1-s2.0-S0893608019302667", "prism:doi": "10.1016/j.neunet.2019.09.005", "pii": "S0893-6080(19)30266-7", "dc:title": "Rethinking the performance comparison between SNNS and ANNS ", "prism:publicationName": "Neural Networks", "prism:aggregationType": "Journal", "prism:issn": "08936080", "prism:volume": "121", "prism:startingPage": "294", "prism:endingPage": "307", "prism:pageRange": "294-307", "dc:format": "application/json", "prism:coverDate": "2020-01-31", "prism:coverDisplayDate": "January 2020", "prism:copyright": "\u00a9 2019 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Deng, Lei"}, {"@_fa": "true", "$": "Wu, Yujie"}, {"@_fa": "true", "$": "Hu, Xing"}, {"@_fa": "true", "$": "Liang, Ling"}, {"@_fa": "true", "$": "Ding, Yufei"}, {"@_fa": "true", "$": "Li, Guoqi"}, {"@_fa": "true", "$": "Zhao, Guangshe"}, {"@_fa": "true", "$": "Li, Peng"}, {"@_fa": "true", "$": "Xie, Yuan"}], "dc:description": "\n               Abstract\n               \n                  Artificial neural networks (ANNs), a popular path towards artificial intelligence, have experienced remarkable success via mature models, various benchmarks, open-source datasets, and powerful computing platforms. Spiking neural networks (SNNs), a category of promising models to mimic the neuronal dynamics of the brain, have gained much attention for brain inspired computing and been widely deployed on neuromorphic devices. However, for a long time, there are ongoing debates and skepticisms about the value of SNNs in practical applications. Except for the low power attribute benefit from the spike-driven processing, SNNs usually perform worse than ANNs especially in terms of the application accuracy. Recently, researchers attempt to address this issue by borrowing learning methodologies from ANNs, such as backpropagation, to train high-accuracy SNN models. The rapid progress in this domain continuously produces amazing results with ever-increasing network size, whose growing path seems similar to the development of deep learning. Although these ways endow SNNs the capability to approach the accuracy of ANNs, the natural superiorities of SNNs and the way to outperform ANNs are potentially lost due to the use of ANN-oriented workloads and simplistic evaluation metrics.\n                  In this paper, we take the visual recognition task as a case study to answer the questions of \u201cwhat workloads are ideal for SNNs and how to evaluate SNNs makes sense\u201d. We design a series of contrast tests using different types of datasets (ANN-oriented and SNN-oriented), diverse processing models, signal conversion methods, and learning algorithms. We propose comprehensive metrics on the application accuracy and the cost of memory & compute to evaluate these models, and conduct extensive experiments. We evidence the fact that on ANN-oriented workloads, SNNs fail to beat their ANN counterparts; while on SNN-oriented workloads, SNNs can fully perform better. We further demonstrate that in SNNs there exists a trade-off between the application accuracy and the execution cost, which will be affected by the simulation time window and firing threshold. Based on these abundant analyses, we recommend the most suitable model for each scenario. To the best of our knowledge, this is the first work using systematical comparisons to explicitly reveal that the straightforward workload porting from ANNs to SNNs is unwise although many works are doing so and a comprehensive evaluation indeed matters. Finally, we highlight the urgent need to build a benchmarking framework for SNNs with broader tasks, datasets, and metrics.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Spiking neural networks"}, {"@_fa": "true", "$": "Artificial neural networks"}, {"@_fa": "true", "$": "Deep learning"}, {"@_fa": "true", "$": "Neuromorphic computing"}, {"@_fa": "true", "$": "Benchmark"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0893608019302667", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0893608019302667", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "85072762450", "scopus-eid": "2-s2.0-85072762450", "pubmed-id": "31586857", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/85072762450", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20190919", "$": "2019-09-19"}}}}}
{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0169260717315456", "dc:identifier": "doi:10.1016/j.cmpb.2018.08.013", "eid": "1-s2.0-S0169260717315456", "prism:doi": "10.1016/j.cmpb.2018.08.013", "pii": "S0169-2607(17)31545-6", "dc:title": "A facial expression controlled wheelchair for people with disabilities ", "prism:publicationName": "Computer Methods and Programs in Biomedicine", "prism:aggregationType": "Journal", "prism:issn": "01692607", "prism:volume": "165", "prism:startingPage": "89", "prism:endingPage": "105", "prism:pageRange": "89-105", "dc:format": "application/json", "prism:coverDate": "2018-10-31", "prism:coverDisplayDate": "October 2018", "prism:copyright": "\u00a9 2018 Elsevier B.V. All rights reserved.", "prism:publisher": "Elsevier B.V.", "dc:creator": [{"@_fa": "true", "$": "Rabhi, Yassine"}, {"@_fa": "true", "$": "Mrabet, Makrem"}, {"@_fa": "true", "$": "Fnaiech, Farhat"}], "dc:description": "\n               Abstract\n               \n                  Background and Objectives\n                  In order to improve assistive technologies for people with reduced mobility, this paper develops a new intelligent real-time emotion detection system to control equipment, such as electric wheelchairs (EWC) or robotic assistance vehicles. Every year, degenerative diseases and traumas prohibit thousands of people to easily control the joystick of their wheelchairs with their hands. Most current technologies are considered invasive and uncomfortable such as those requiring the user to wear some body sensor to control the wheelchair.\n               \n               \n                  Methods\n                  In this work, the proposed Human Machine Interface (HMI) provides an efficient hands-free option that does not require sensors or objects attached to the user's body. It allows the user to drive the wheelchair using its facial expressions which can be flexibly updated. This intelligent solution is based on a combination of neural networks (NN) and specific image preprocessing steps. First, the Viola-Jones combination is used to detect the face of the disability from a video. Subsequently, a neural network is used to classify the emotions displayed on the face. This solution called \"The Mathematics Behind Emotion\" is capable of classifying many facial expressions in real time, such as smiles and raised eyebrows, which are translated into signals for wheelchair control. On the hardware side, this solution only requires a smartphone and a Raspberry Pi card that can be easily mounted on the wheelchair.\n               \n               \n                  Results\n                  Many experiments have been conducted to evaluate the efficiency of the control acquisition process and the user experience in driving a wheelchair through facial expressions. The classification accuracy can expect 98.6% and it can offer an average recall rate of 97.1%. Thus, all these experiments have proven that the proposed system is able of accurately recognizing user commands in real time. Indeed, the obtained results indicate that the suggested system is more comfortable and better adapted to severely disabled people in their daily lives, than conventional methods. Among the advantages of this system, we cite its real time ability to identify facial emotions from different angles.\n               \n               \n                  Conclusions\n                  The proposed system takes into account the patient's pathology. It is intuitive, modern, doesn't require physical effort and can be integrated into a smartphone or tablet. The results obtained highlight the efficiency and reliability of this system, which ensures safe navigation for the disabled patient.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Smart wheelchair"}, {"@_fa": "true", "$": "Facial expression"}, {"@_fa": "true", "$": "Engineering rehabilitation"}, {"@_fa": "true", "$": "Artificial intelligence"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0169260717315456", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0169260717315456", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "85052210734", "scopus-eid": "2-s2.0-85052210734", "pubmed-id": "30337084", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/85052210734", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20180818", "$": "2018-08-18"}}}}}
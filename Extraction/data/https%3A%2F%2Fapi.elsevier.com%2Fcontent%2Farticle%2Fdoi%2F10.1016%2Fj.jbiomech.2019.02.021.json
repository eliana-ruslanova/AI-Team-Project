{"coredata": {"prism:url": "https://api.elsevier.com/content/article/pii/S0021929019301551", "dc:identifier": "doi:10.1016/j.jbiomech.2019.02.021", "eid": "1-s2.0-S0021929019301551", "prism:doi": "10.1016/j.jbiomech.2019.02.021", "pii": "S0021-9290(19)30155-1", "dc:title": "Markerless 2D kinematic analysis of underwater running: A deep learning approach ", "prism:publicationName": "Journal of Biomechanics", "prism:aggregationType": "Journal", "prism:issn": "00219290", "prism:volume": "87", "prism:startingPage": "75", "prism:endingPage": "82", "prism:pageRange": "75-82", "dc:format": "application/json", "prism:coverDate": "2019-04-18", "prism:coverDisplayDate": "18 April 2019", "prism:copyright": "\u00a9 2019 Elsevier Ltd. All rights reserved.", "prism:publisher": "Elsevier Ltd.", "dc:creator": [{"@_fa": "true", "$": "Cronin, Neil J."}, {"@_fa": "true", "$": "Rantalainen, Timo"}, {"@_fa": "true", "$": "Ahtiainen, Juha P."}, {"@_fa": "true", "$": "Hynynen, Esa"}, {"@_fa": "true", "$": "Waller, Ben"}], "dc:description": "\n               Abstract\n               \n                  Kinematic analysis is often performed with a camera system combined with reflective markers placed over bony landmarks. This method is restrictive (and often expensive), and limits the ability to perform analyses outside of the lab. In the present study, we used a markerless deep learning-based method to perform 2D kinematic analysis of deep water running, a task that poses several challenges to image processing methods. A single GoPro camera recorded sagittal plane lower limb motion. A deep neural network was trained using data from 17 individuals, and then used to predict the locations of markers that approximated joint centres. We found that 300\u2013400 labelled images were sufficient to train the network to be able to position joint markers with an accuracy similar to that of a human labeler (mean difference\u202f<\u202f3 pixels, around 1\u202fcm). This level of accuracy is sufficient for many 2D applications, such as sports biomechanics, coaching/training, and rehabilitation. The method was sensitive enough to differentiate between closely-spaced running cadences (45\u201385 strides per minute in increments of 5). We also found high test\u2013retest reliability of mean stride data, with between-session correlation coefficients of 0.90\u20130.97. Our approach represents a low-cost, adaptable solution for kinematic analysis, and could easily be modified for use in other movements and settings. Using additional cameras, this approach could also be used to perform 3D analyses. The method presented here may have broad applications in different fields, for example by enabling markerless motion analysis to be performed during rehabilitation, training or even competition environments.\n               \n            ", "openaccess": "0", "openaccessArticle": false, "openaccessType": null, "openArchiveArticle": false, "openaccessSponsorName": null, "openaccessSponsorType": null, "openaccessUserLicense": null, "dcterms:subject": [{"@_fa": "true", "$": "Deep water running"}, {"@_fa": "true", "$": "Kinematics"}, {"@_fa": "true", "$": "Deep learning"}, {"@_fa": "true", "$": "Artificial intelligence"}, {"@_fa": "true", "$": "Motion analysis"}], "link": [{"@href": "https://api.elsevier.com/content/article/pii/S0021929019301551", "@rel": "self", "@_fa": "true"}, {"@href": "https://www.sciencedirect.com/science/article/pii/S0021929019301551", "@rel": "scidir", "@_fa": "true"}]}, "scopus-id": "85062329650", "scopus-eid": "2-s2.0-85062329650", "pubmed-id": "30850178", "link": {"@href": "https://api.elsevier.com/content/abstract/scopus_id/85062329650", "@rel": "abstract"}, "originalText": {"xocs:doc": {"xocs:meta": {"xocs:open-access": {"xocs:oa-article-status": {"@is-open-access": "0", "@is-open-archive": "0"}}, "xocs:available-online-date": {"@yyyymmdd": "20190301", "$": "2019-03-01"}}}}}
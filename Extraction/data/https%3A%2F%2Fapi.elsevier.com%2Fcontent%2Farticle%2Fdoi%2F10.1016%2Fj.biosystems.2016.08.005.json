{"scopus-eid": "2-s2.0-84993990240", "originalText": "serial JL 271079 291210 291715 291840 291850 291928 31 90 Biosystems BIOSYSTEMS 2016-08-16 2016-08-16 2016-10-18 2016-10-18 2017-04-09T06:13:56 1-s2.0-S030326471630168X S0303-2647(16)30168-X S030326471630168X 10.1016/j.biosystems.2016.08.005 S300 S300.2 FULL-TEXT 1-s2.0-S0303264716X0010X 2017-04-09T01:20:01.936317-04:00 0 0 20161001 20161031 2016 2016-08-17T00:35:57.692924Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids confeditor contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb vol volfirst volissue volumelist webpdf webpdfpagecount yearnav figure body acknowledge affil articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor primabst pubtype ref 0303-2647 03032647 UNLIMITED NONE true 148 148 C Volume 148 4 4 11 4 11 201610 October 2016 2016-10-01 2016-10-31 2016 What Synthetic Biology can offer to Artificial Intelligence Dr. Luisa Damiano General, University of Bergamo, P.le S. Agostino 2, Bergamo, 24129, Italy, luisa.damiano@gmail.com Dr. Yutetsu Kuruma Dept. of Life Science, Tokyo Institute of Technology, 2-12-1-14-12 O-okayama, Meguro-ku, Tokyo, 152-8550, Japankuruma@elsi.jp Dr. Pasquale Stano Dept. of Biology, Universit\u00e0 di Roma Tre, viale G. Marconi 446, Roma, 00146, Italy, stano@uniroma3.it article rev \u00a9 2016 The Author. Published by Elsevier Ireland Ltd. BODYKNOWLEDGEROLELIVINGBODYINGROUNDINGEMBODIEDCOGNITION ZIEMKE T 1 Introduction 2 What\u2019s that thing called embodiment? 3 Does life matter to embodied cognition? 4 Discussion and conclusion Acknowledgement References ANDERSON 2003 91 130 M BARANDIARAN 2006 171 185 X BEER 1995 173 215 R 2003 147 150 BICKHARD 1993 285 333 M BICKHARD 2009 75 84 M BLACK 2014 D EMBODIMENTMECHANISATIONRECIPROCALUNDERSTANDINGBODYMACHINERENAISSANCPRESENT BROOKS 1991 569 595 R PROCEEDINGSTWELFTHINTERNATIONALJOINTCONFERENCEARTIFICIALINTELLIGENCEIJCAI91 INTELLIGENCEWITHOUTREASON BROOKS 1993 153 154 R PROCEEDINGSFIFTEENTHANNUALCONFERENCECOGNITIVESCIENCESOCIETY ENGINEERINGPHYSICALGROUNDING CHEMERO 2009 A RADICALEMBODIEDCOGNITIVESCIENCE CHRISLEY 2002 1102 1108 R ENCYCLOPEDIACOGNITIVESCIENCE EMBODIMENT CHRISLEY 2003 131 150 R CHRISTENSEN 2000 133 157 W CLARK 1997 A BEING CLARK 1999 345 351 A COSTALL 2006 A BODYLANGUAGEMINDVOLUME1EMBODIMENT BRINGINGBODYBACKLIFEJAMESGIBSONSECOLOGYAGENCY DAMASIO 2013 143 152 A DAMASIO 1994 A DESCARTESERROR DAMASIO 1998 83 86 A DAMASIO 1999 A FEELINGHAPPENSBODYEMOTIONMAKINGCONSCIOUSNESS DAMASIO 2003 A LOOKINGFORSPINOZAJOYSORROWFEELINGBRAIN DAMASIO 2004 A FEELINGSEMOTIONSAMSTERDAMSYMPOSIUM EMOTIONSFEELINGSANEUROBIOLOGICALPERSPECTIVE DREYFUS 1979 H COMPUTERSCANT FROESE 2009 466 500 T GALLAGHER 2005 S HOWBODYSHAPESMIND GOLDINGER 2016 959 978 S GREENSPAN 2005 219 230 R HARNAD 1989 5 25 S HARNAD 1990 335 346 S JAMES 1884 188 205 W JOHNSON 2007 M MEANINGBODYAESTHETICSHUMANUNDERSTANDING LANGE 1885 C OMSINDSBEVAEGELSERETPSYKOFYSIOLOGISKSTUDIE LINDBLOM 2015 J EMBODIEDSOCIALCOGNITION LOEB 1918 J FORCEDMOVEMENTSTROPISMSANIMALCONDUCT LOWE 2011 346 R LUNGARELLA 2003 151 190 M MATURANA 1980 H AUTOPOIESISCOGNITION MATURANA 1987 H TREEKNOWLEDGEBIOLOGICALROOTSHUMANUNDERSTANDING MONTEBELLI 2013 299 315 A MORSE 2011 312 324 A NOLFI 2000 S EVOLUTIONARYROBOTICS PANKSEPP 2005 30 80 J PAVLOV 1927 I CONDITIONEDREFLEXES PEZZULO 2013 612 G PFEIFER 1999 R UNDERSTANDINGINTELLIGENCE PFEIFER 1995 47 70 R 2002 VIEWSCHINESEROOMNEWESSAYSSEARLEARTIFICIALINTELLIGENCE PRINZ 2004 J GUTREACTIONSAPERCEPTUALTHEORYEMOTION SCHULKIN 2011 111 J SEARLE 1980 417 457 J SETH 2013 565 573 A SHAPIRO 2010 L EMBODIEDCOGNITION SHARKEY 1998 361 391 N SHARKEY 2001 251 262 N SKINNER 1938 B BEHAVIORORGANISMS STEELS 1994 75 110 L STERLING 2004 17 64 P ALLOSTASISHOMEOSTASISCOSTSADAPTATION PRINCIPLESALLOSTASIS STERLING 2012 5 15 P STEWART 1996 311 326 J THOMPSON 2007 E MINDINLIFE VARELA 1974 187 196 F VARELA 1991 F EMBODIEDMINDCOGNITIVESCIENCEHUMANEXPERIENCE VARELA 1979 F PRINCIPLESBIOLOGICALAUTONOMY VARELA 1997 72 87 F VERNON 2015 1660 D VONUEXKULL 1928 J THEORETISCHEBIOLOGIE WATSON 1925 J BEHAVIORISM WILSON 2013 58 A ZIEMKE 2009 104 117 T ZIEMKE 2001 701 746 T ZIEMKE 2014 49 53 T SOCIABLEROBOTSFUTURESOCIALRELATIONS ROBOTSNOTEMBODIEDCONCEPTIONSEMBODIMENTIMPLICATIONSFORSOCIALHUMANROBOTINTERACTION 2006 BODYLANGUAGEMINDVOLUME1EMBODIMENT ZIEMKE 1999 T UNDERSTANDINGREPRESENTATIONINCOGNITIVESCIENCES RETHINKINGGROUNDING ZIEMKE 2000 T SITUATEDNEUROROBOTICSINTERACTIVECOGNITIONDOCTORALDISSERTATION ZIEMKE 2001 163 233 T ZIEMKE 2001 75 83 T PROCEEDINGSFIRSTINTERNATIONALWORKSHOPEPIGENETICROBOTICSMODELLINGCOGNITIVEDEVELOPMENTINROBOTICSYSTEMS ROBOTSEMBODIED ZIEMKE 2003 1305 1310 T PROCEEDINGS25THANNUALCONFERENCECOGNITIVESCIENCESOCIETY WHATSTHINGCALLEDEMBODIMENT ZIEMKE 2004 27 36 T EMBODIEDARTIFICIALINTELLIGENCE EMBODIEDAISCIENCEMODELSEMBODIEDCOGNITIONEMBODIEDMODELSCOGNITIONBOTH ZIEMKE 2007 48 66 T ARTIFICIALCONSCIOUSNESS WHATSLIFEGOT ZIEMKE 2008 401 408 T ZLATEV 2001 155 195 J ZLATEV 2002 253 296 J ZLATEV 2001 1 4 J PROCEEDINGSFIRSTINTERNATIONALWORKSHOPEPIGENETICROBOTICSMODELLINGCOGNITIVEDEVELOPMENTINROBOTICSYSTEMS INTRODUCTIONEPIGENETICROBOTICS ZIEMKEX2016X4 ZIEMKEX2016X4X11 ZIEMKEX2016X4XT ZIEMKEX2016X4X11XT Full 2016-08-13T19:21:03Z Author http://creativecommons.org/licenses/by-nc-nd/4.0/ 2017-10-18T00:00:00.000Z UnderEmbargo http://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license. \u00a9 2016 The Author. Published by Elsevier Ireland Ltd. item S0303-2647(16)30168-X S030326471630168X 1-s2.0-S030326471630168X 10.1016/j.biosystems.2016.08.005 271079 2017-04-09T01:20:01.936317-04:00 2016-10-01 2016-10-31 UNLIMITED NONE 1-s2.0-S030326471630168X-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/MAIN/application/pdf/3cfd031c87327f4fe163a338a6b10611/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/MAIN/application/pdf/3cfd031c87327f4fe163a338a6b10611/main.pdf main.pdf pdf true 797396 MAIN 8 1-s2.0-S030326471630168X-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/PREVIEW/image/png/2175f066ec4a5883b458c2be0b60ac82/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/PREVIEW/image/png/2175f066ec4a5883b458c2be0b60ac82/main_1.png main_1.png png 48063 849 656 IMAGE-WEB-PDF 1 1-s2.0-S030326471630168X-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/gr1/THUMBNAIL/image/gif/9c98ea6381cd3e505ca5d34ee435fdf1/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/gr1/THUMBNAIL/image/gif/9c98ea6381cd3e505ca5d34ee435fdf1/gr1.sml gr1 gr1.sml sml 5494 158 219 IMAGE-THUMBNAIL 1-s2.0-S030326471630168X-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/gr2/THUMBNAIL/image/gif/d47058065d6331757baf1f5623894885/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/gr2/THUMBNAIL/image/gif/d47058065d6331757baf1f5623894885/gr2.sml gr2 gr2.sml sml 5740 116 219 IMAGE-THUMBNAIL 1-s2.0-S030326471630168X-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/gr1/DOWNSAMPLED/image/jpeg/e38076933782f034470b9df759f293a9/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/gr1/DOWNSAMPLED/image/jpeg/e38076933782f034470b9df759f293a9/gr1.jpg gr1 gr1.jpg jpg 17672 271 376 IMAGE-DOWNSAMPLED 1-s2.0-S030326471630168X-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/gr2/DOWNSAMPLED/image/jpeg/efc547d173f5e6f3e6817b1953ea67a9/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/gr2/DOWNSAMPLED/image/jpeg/efc547d173f5e6f3e6817b1953ea67a9/gr2.jpg gr2 gr2.jpg jpg 16166 199 376 IMAGE-DOWNSAMPLED 1-s2.0-S030326471630168X-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/gr1/HIGHRES/image/jpeg/67923689c03df767a4fbee56f69fc508/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/gr1/HIGHRES/image/jpeg/67923689c03df767a4fbee56f69fc508/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 149285 1201 1667 IMAGE-HIGH-RES 1-s2.0-S030326471630168X-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S030326471630168X/gr2/HIGHRES/image/jpeg/a02128b02e23d4a8aa2278d138d81d0a/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S030326471630168X/gr2/HIGHRES/image/jpeg/a02128b02e23d4a8aa2278d138d81d0a/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 140338 882 1667 IMAGE-HIGH-RES BIO 3690 S0303-2647(16)30168-X 10.1016/j.biosystems.2016.08.005 The Author Fig. 1 Current notions of embodied cognitive science and their historical roots. Adapted from Chemero (2009: 30). Fig. 1 Fig. 2 Damasio\u2019s illustration of \u2018levels of automated homeostatic regulation, from simple to complex\u2019, constituting what Panksepp (2005) called \u201ca multi-tiered affectively embodied view of mind\u201d. Illustration from Ziemke (2008: 406); adapted from Damasio (2003: 32). Fig. 2 Review article The body of knowledge: On the role of the living body in grounding embodied cognition Tom Ziemke a b \u204e tom.ziemke@liu.se tom.ziemke@his.se a Interaction Lab, School of Informatics, University of Sk\u00f6vde, 54128 Sk\u00f6vde, Sweden Interaction Lab School of Informatics University of Sk\u00f6vde Sk\u00f6vde 54128 Sweden b Cognition & Interaction Lab, Human-Centered Systems Division, Department of Computer & Information Science, Link\u00f6ping University, 58183 Link\u00f6ping, Sweden Cognition & Interaction Lab Human-Centered Systems Division Department of Computer & Information Science Link\u00f6ping University Link\u00f6ping 58183 Sweden \u204e Correspondence address: IDA, Link\u00f6ping University, 58183 Link\u00f6ping, Sweden. Abstract Embodied cognition is a hot topic in both cognitive science and AI, despite the fact that there still is relatively little consensus regarding what exactly constitutes \u2018embodiment\u2019. While most embodied AI and cognitive robotics research views the body as the physical/sensorimotor interface that allows to ground computational cognitive processes in sensorimotor interactions with the environment, more biologically-based notions of embodied cognition emphasize the fundamental role that the living body \u2013 and more specifically its homeostatic/allostatic self-regulation \u2013 plays in grounding both sensorimotor interactions and embodied cognitive processes. Adopting the latter position \u2013 a multi-tiered affectively embodied view of cognition in living systems \u2013 it is further argued that modeling organisms as layered networks of bodily self-regulation mechanisms can make significant contributions to our scientific understanding of embodied cognition. Keywords Allostasis Cognitive systems Grounding Homeostasis Embodied AI Embodied cognition Emotion Intentionality Predictive regulation Representation 1 Introduction At some point in the long and winding write-up of this paper, its title was \u201cWhat makes embodied AI embodied?\u201d. That title eventually disappeared again, but the question is still highly relevant to this paper \u2013 and the answer is not as straightforward as one might think. Robots are, no doubt, considered \u2018embodied\u2019 by most AI researchers, and in fact the obvious AI approach to modeling natural embodied cognition or synthesizing artificial equivalents thereof (cf., e.g. Ziemke, 2003; Morse et al., 2011). Much embodied AI research, however, also makes use of simulated robots or other types of non-physical agents, e.g. so-called virtual agents or different types of more abstract artificial-life agents. Hence, one might ask (cf. Ziemke, 2004) whether embodied AI really is about embodied (i.e. physical, robotic, etc.) models of cognition, or rather about models \u2013 any type of model: robotic ones obviously, but also purely computational ones \u2013 of embodied cognition (whatever that is), or maybe both? If you find that question somewhat confusing, you are not alone. As discussed in more detail in Section 2, despite more than 25 years of research on embodied cognition and AI, and by now a number of books on the topic (e.g. Varela et al., 1991; Clark, 1997; Pfeifer and Scheier, 1999; Gallagher, 2005; Ziemke et al., 2006; Johnson, 2007; Thompson, 2007; Shapiro, 2010; Lindblom, 2015), there still is a perplexing diversity of notions of embodied cognition as well as claims concerning its nature and relevance. Given that this paper is part of a journal special issue on the relation between embodied AI and synthetic biology, it should come as no surprise that it is argued here that synthetic biology research might be able to make significant contributions to embodied AI (the details of how are beyond the scope of this paper though) \u2013 and thereby also might help to clarify the role that biological embodiment plays in natural cognition. To what degree the underlying biological mechanisms really do play a role in cognitive processes and capacities, is another open question in the cognitive sciences, and in fact not everybody would agree that they actually do play any role at all, other than that of a particular physical implementation that could just as well be replaced by another, non-biological \u2013 e.g. computational and/or robotic \u2013 implementation. Different arguments supporting the view that the underlying biology in general, and bodily self-regulation in particular, actually does play a crucial role in embodied cognition are discussed in more detail in Section 3. Section 4 then, finally, presents some discussion and conclusions. It will be argued that embodied cognition is not only grounded in sensorimotor interaction with the environment \u2013 a claim that most proponents of embodied cognition, and even some of its opponents, would agree to \u2013 but that at least natural cognition is furthermore also deeply rooted in the underlying biological mechanisms, and more specifically layered/nested networks of homeostatic/allostatic bodily self-regulation mechanisms. Hence, the potential contribution of synthetic biology to embodied cognition and AI, it will be argued, lies first and foremost in modeling/understanding/synthesizing the nature of organisms as such layered networks. This would be an important complement to current work in embodied AI and cognitive architectures/robotics, much of which is predominantly concerned with layered architectures for dealing with the complexities of perceiving and acting in the external environment. 2 What\u2019s that thing called embodiment? The embodied approach in cognitive science and AI has received increasingly much attention in recent years. In fact, \u201cEmbodied Cognition is sweeping the planet\u201d, at least according to Fred Adams\u2019 backcover book endorsement of the paperback edition of Shapiro\u2019s (2010) book on the topic. Research on embodied cognition has received significant attention in the cognitive sciences for at least 25 years now, if you count from the appearance of Varela, Thompson and Rosch\u2019s book \u201cThe Embodied Mind\u201d in 1991. It should be noted though that despite this, at least at this point in time, there actually is no such thing as the embodied mind thesis or paradigm. This is reflected, for example, by recent paper titles such as \u201cEmbodied cognition is not what you think it is\u201d (Wilson and Golonka, 2013) and recent debates about the alleged \u201cpoverty of embodied cognition\u201d (Goldinger et al., 2016; Killeen, 2016) that reveal deep misunderstandings and wildly different (mis-) conceptions of even the most basic tenets of embodied cognition research. From the embodied AI researcher\u2019s perspective, on the other hand, what is and what is not embodied might seem relatively straightforward: the computer programs of traditional AI research are widely considered \u2018disembodied\u2019, whereas robots obviously are embodied \u2013 at least in some sense (cf. Ziemke, 2001b; Ziemke and Thill, 2014). Much early embodied AI research was to some degree driven by criticisms of traditional AI formulated by philosophers such as Dreyfus (1979), Searle (1980) and Harnad (1990). A key point in these criticisms was the lack of interaction between the internal representations \u2013 at the time typically symbolic ones \u2013 of AI programs and the external world they were supposed to represent. Dreyfus (1979), for example, inspired by Heidegger\u2019s notion of being-in-the-world, argued that any computer program \u201cis not always-already-in-a-situation. Even if it represents all human knowledge in its stereotypes, including all possible types of human situations, it represents them from the outside \u2026 It isn\u2019t situated in any one of them, and it may be impossible to program it to behave as if it were\u201d. Searle\u2019s (1980) criticism of computational AI systems, based on his famous Chinese Room Argument, was that \u201cthe operation of such a machine is defined solely in terms of computational processes over formally defined elements\u201d, and that such \u201cformal properties are not by themselves constitutive of intentionality\u201d \u2013 which is the characteristic of human cognition that allows it to be about the world. Harnad\u2019s (1990) argument was based on Searle\u2019s, but he referred to the problem of intentionality as a lack of \u2018intrinsic meaning\u2019 in purely computational systems, which he argued could be resolved by what he termed symbol grounding, i.e. the grounding of internal symbolic representations in sensorimotor interactions with the environment. Embodied approaches to AI \u2013 using robotic or simulated \u2018autonomous agents\u2019 \u2013 at least at a first glance, allow computer programs and the representations they are using, if any, to be grounded in interactions with the physical environment through the robot/agent platform\u2019s sensorimotor capacities. Brooks, for example, one of the pioneers of embodied AI, formulated what he called \u201cthe two cornerstones of the new approach to Artificial Intelligence, situatedness and embodiment\u201d (Brooks, 1991). Embodiment from this perspective simply means that \u201crobots have bodies and experience the world directly \u2013 their actions are part of a dynamic with the world and have immediate feedback on their own sensations\u201d (Brooks, 1991). According to Brooks, such systems are physically grounded, and hence internally \u201ceverything is grounded in primitive sensor motor patterns of activation\u201d (Brooks, 1993). Situatedness, accordingly, means that \u201crobots are situated in the world \u2013 they do not deal with abstract descriptions, but with the here and now of the world directly influencing the behavior of the system\u201d (Brooks, 1991). Hence, from the embodied AI perspective, things might seem relatively uncomplicated: robots are embodied and situated in roughly the same sense that humans and other animals are, and thereby they at least potentially can overcome traditional AI\u2019s problems with intentionality or intrinsic meaning. The problem of computer programs dealing with ungrounded representations is solved through physical grounding and either not having any representations at all (a la Brooks) or acquiring internal representations through symbol/representation grounding (a la Harnad), i.e. developing such representations in the course of interaction with the external world (e.g. learning a map of the environment). It should be noted though that this does not necessarily resolve the philosophical problems discussed above. Searle, for example, already back in 1980, presented \u2013 and rejected \u2013 what he called the \u2018robot reply\u2019 to his own Chinese Room Argument. This entailed pretty much exactly what is now called embodied AI, namely computer programs running inside robots that interact with their environment through sensors and actuators. In the terms of Searle\u2019s argument, to the person inside the Chinese Room, it does not make any difference whether or not inputs to and outputs from the Chinese Room are connected to the sensors and motors of a robot \u2013 the person inside the room still lacks the intentionality that characterizes human cognition. At this point it should be noted that for the purposes of this paper it does not actually matter at all whether or not the reader is familiar with the details of Searle\u2019s Chinese Room Argument, let alone convinced of its validity. The argument has been discussed for more than 35 years now (e.g. Harnad, 1989, 1990; Ziemke, 1999; Zlatev, 2001; Preston and Bishop, 2002) without reaching much consensus. What is more interesting here though is that there are quite many embodied AI researchers who \u2013 like Searle \u2013 take the Chinese Room Argument to be a valid argument against traditional AI, but at the same time \u2013 unlike Searle \u2013 consider the physical and sensorimotor embodiment provided by current robots to be sufficient to overcome the problem (e.g. Harnad, 1989, 1990; Brooks, 1991, 1993; Clark, 1999; Zlatev, 2001; Chrisley and Ziemke, 2002; cf. Ziemke, 1999). In Harnad\u2019s (1989) terms, this type of embodied AI has gone from a computational functionalism to a robotic functionalism. Zlatev (2001), for example, explicitly formulated the functionalist position that there is \u201cno good reason to assume that intentionality is an exclusively biological property (pace e.g. Searle)\u201d, and \u201cthus a robot with bodily structures, interaction patterns and development similar to those of human beings \u2026 could possibly recapitulate [human] ontogenesis, leading to the emergence of intentionality, consciousness and meaning\u201d. Others, including Searle naturally, do indeed believe that there are good reasons to assume that human-like \u2013 or, more generally, organism-like \u2013 intentionality is in fact a biological property, and that it does in fact require a biological body (e.g. Varela et al., 1991; Stewart, 1996; Varela, 1997; Ziemke, 2001a,b, 2007, 2008; Sharkey and Ziemke, 2001; Zlatev, 2002; Bickhard, 2009; Froese and Ziemke, 2009; Vernon et al., 2015). The latter perspective is elaborated in more detail in Section 3. But, before we get there, let us a have quick look at Chemero\u2019s (2009) characterization of the current embodied cognition research landscape, which is illustrated in Fig. 1 . Chemero points out that there currently are at least two very different positions/traditions that are both referred to as \u2018embodied cognitive science\u2019. One of these, which Chemero refers to as radical embodied cognitive science, is grounded in the anti-representationalist and anti-computationalist traditions of eliminativism, American naturalism, and Gibsonian ecological psychology. The other, more mainstream version of embodied cognitive science, on the other hand, in line with what was referred to as robotic functionalism above, is derived from traditional representationalist and computationalist theoretical frameworks, and therefore also still is more or less compatible with these \u2013 as illustrated maybe most prominently by the notion of symbol/representation grounding, as opposed to the more radical position of anti-representationalism. As Chemero rightly points out, although \u2013 or maybe because \u2013 the mainstream version of embodied cognitive science can be considered a \u201cwatered-down\u201d version of its more radical counterpart, it currently receives significantly more attention in the cognitive sciences. The position of radical embodied cognition, according to Chemero (2009), can be summarized in two positive claims and one negative one: 1. Representational and computational views of embodied cognition are wrong. 2. Embodied cognition should be explained using a particular set of tools T, including dynamical systems theory. 3. The explanatory tools in set T do not posit mental representations. To summarize the discussion so far, it should now be clearer why exactly it is still surprisingly difficult to pinpoint what embodied cognition is, or what kind of embodiment an artificial cognitive system might require. There are different positions along at least a couple of dimensions of embodiment: physicality, the view of representation, and the role of the underlying biology. Embodied AI researchers emphasize the importance of physical grounding, but in their research practice they commonly make use of software simulations (cf. Ziemke, 2003), and the computer programs controlling their robots \u2013 physical or simulated \u2013 are for the most part still just as computational as the computer programs of traditional AI. Radical embodied cognitive science, at least according to Chemero, is strictly anti-representationalist, whereas mainstream embodied cognitive science more or less still embraces the traditional computationalist/representationalist framework, but emphasizes the need for representations to be grounded, i.e. a robotic functionalism instead of the traditional computational functionalism. Naturally, the role of the biological mechanisms underlying (embodied) cognition is also fundamentally different on the left and the right side of Chemero\u2019s diagram (cf. Fig. 1). While on the right/mainstream side, the biological embodiment of natural cognition would be considered as just one possible \u2018implementation\u2019, which could as well be replaced by alternative, e.g. computational and/or robotic implementations, the left/radical side is at least more open to the idea of the living body actually having some fundamental role in constituting embodied cognition. Which leads us to the next section. 3 Does life matter to embodied cognition? As pointed out in the previous section, the nature, role, and conception of \u2018the body\u2019 are actually still far from well-defined in embodied cognitive science \u2013 and embodied AI in particular. As discussed in more detail elsewhere (Ziemke, 2000, 2004, 2007), on the one hand, much embodied AI research, in particular the widespread emphasis of the importance of physical embodiment (e.g. Brooks, 1991, 1993; Steels, 1994; Pfeifer, 1995; Pfeifer and Scheier, 1999), is actually to a high degree compatible with the view of robotic functionalism (Harnad, 1989), according to which embodiment is mainly about symbol/representation grounding (Harnad, 1990; cf. Anderson, 2003; Chrisley, 2003; Pezzulo et al., 2013), whereas cognition can still be conceived of as computation. On the other hand, much of the rhetoric in the embodied AI field, in particular early embodied AI researchers\u2019 rejection of traditional notions of representation and cognition as computation (e.g. Brooks, 1991; Pfeifer, 1995; Pfeifer and Scheier, 1999), suggests sympathy for more radical notions of embodied cognition that view all of cognition as embodied and/or rooted in the mechanisms of the living body (e.g. Maturana and Varela, 1987; Varela et al., 1991; Thompson, 2007; Johnson, 2007; Froese and Ziemke, 2009). More specifically, part of the problem with embodied AI is that, despite its strong biological inspiration, early embodied AI research very much focused on establishing itself as a new paradigm within AI and cognitive science, i.e. as an alternative to the traditional functionalist/computationalist paradigm (e.g. Beer, 1995; Pfeifer, 1995; Pfeifer and Scheier, 1999). Less effort was made, on the other hand, to make the connection to other theories, outside AI, e.g. in theoretical biology or phenomenology, addressing core conceptual issues of autonomy, embodiment, etc. Similarly, much embodied AI research distinguishes itself from its traditional AI counterpart in its interactive view of knowledge. For example, work on adaptive robotics, in particular evolutionary robotics (Nolfi and Floreano, 2000) and developmental/epigenetic robotics (e.g. Zlatev and Balkenius, 2001; Berthouze and Ziemke, 2003; Lungarella et al., 2003), is largely compatible with the constructivist/enactivist/interactivist view (e.g. Piaget, 1954; Varela et al., 1991; Bickhard, 1993, 2009; Ziemke, 2001a) of knowledge construction in sensorimotor interaction with the environment, with the goal of achieving some \u2018fit\u2019 or \u2018equilibrium\u2019 between internal, conceptual/behavior-generating mechanisms and the external environment (for a more detailed discussion of this aspect see Ziemke, 2001a). However, the organic roots of these processes, which were emphasized in, for example, the theoretical biology of von Uexk\u00fcll (1928, 1982) or Maturana and Varela\u2019s (1980, 1987) theory of autopoiesis (cf. below), are usually ignored in embodied AI, most of which still operates with a view of the body that is largely compatible with mechanistic theories in psychology and a view of control mechanisms that is still largely compatible with computationalism (cf. Ziemke, 2000, 2001a). That means, the robot body is typically viewed as some kind of input and output device that provides physical grounding to the internal computational mechanisms. As discussed above, this view of the physical body as the computational mind\u2019s sensorimotor interface to the world pervades much of cognitive science and philosophy of mind. Thus, in practice, embodied AI as a result of its history and interdisciplinary influences, has become a theoretical hybrid, combining a mechanical/behaviorist view of the body with the constructivist notion of interactive knowledge as well as the functionalist hardware-software distinction and its view of the activity of the nervous system as computational (cf. Ziemke, 2000, 2001a,b, 2004, 2007). As Greenspan and Baars (2005) have pointed out (cf. also Sharkey and Ziemke, 1998, 2001; Ziemke, 2001a), the mechanistic/reductionistic approach to biology and psychology of leading early 19th-century researchers like Loeb (1918) and Pavlov (1927) paved the way for the strong dominance of behaviorism in psychology, as pursued by Watson (1925) and Skinner (1938). Cognitive science, with its traditional emphasis on representation and computation, is widely considered to have replaced the overly mechanistic view of behaviorism. However, as Costall (2006) pointed out that, \u201cit is not the case that mainstream cognitive psychology entirely replaced the traditional mechanistic model. It retains the old mechanistic image of the body. The new mechanism of mind has been merely assimilated to the old dualism of mind and body, along with the existing conception of the body as a passive machine\u201d. Although Costall\u2019s critique is directed mainly at traditional cognitive science and AI, rather than embodied AI, it should be noted that the mind/body or hardware/software dualism that he accuses modern psychology of is the exact same dualism that Searle (1980) accuses computationalist theories of. And, as discussed above, as Searle pointed out already back then in his robot reply, whether or not the computational mind resides in a slightly less passive robotic body, i.e. a physical container that allows the computational mind to interact with its environment through sensors and actuators, really does not make much of a difference when it comes to such computational/robotic systems as models of human cognition, intentionality, etc. So, what is the alternative then? We have already seen various glimpses of theoretical frameworks that emphasize the biological nature and/or the organismic roots of natural embodied cognition, but what exactly are these frameworks? Let us start with the theory of autopoiesis (Varela et al., 1974; Maturana and Varela, 1980, 1987; Varela, 1979, 1997). According to Varela (1997, p. 75): \u201cAn autopoietic system \u2013 the minimal living organization \u2013 is one that continuously produces the components that specify it, while at the same time realizing it (the system) as a concrete unit in space and time, which makes the network of production of components possible. More precisely defined: An autopoietic system is organized (defined as a unity) as a network of processes of production (synthesis and destruction) of components such that these components: (i) continuously regenerate and realize the network that produces them, and (ii) constitute the system as a distinguishable unity in the domain in which they exist\u201d. Prime examples of autopoiesis are living cells and organisms, also referred to as \u201cfirst-order\u201d and \u201csecond-order autopoietic unities\u201d respectively (e.g. Maturana and Varela, 1987). Somewhat controversially, Maturana and Varela (1980, 1987) actually consider all living systems to be cognitive systems. Naturally, this has been criticized by a number of authors who wish to reserve the term \u2018cognitive\u2019 for higher-level psychological processes (cf., e.g., Clark, 1997; Barandiaran and Moreno, 2006). Varela, however, defended the use of the term \u2018cognitive\u2019 as follows: \u201cThe reader may balk at my use of the term cognitive for cellular systems. But from what I have said it should be clear that the constitution of a cognitive domain links organisms and their worlds in a way that is the very essence of intentionality as used in modern cognitive science, and as it was originally introduced in phenomenology. My proposal makes explicit the process through which intentionality arises: it amounts to an explicit hypothesis about how to transform the philosophical notion of intentionality into a principle of natural science. The use of the term cognitive here is thus justified because it is at the very base of how intentionality arises in nature\u201d (Varela, 1997, pp. 80\u201381). For a competing, but closely related theoretical framework, let us also have a look at Christensen and Hooker\u2019s (2000) theory of autonomy, aimed to propose a naturalistic theory of intelligent agency as an embodied feature of organized, typically living, dynamical systems. According to their view, agents are entities that engage in goal-directed, normatively constrained, interaction with their environment. More specifically, \u201c[l]iving systems are a particular kind of cohesive system \u2026 in which there are dynamical bonds amongst the elements of the system which individuate the system from its environment\u201d. Some examples: A gas has no internal cohesion, its shape and condition are imposed by the environment. A rock, on the other hand, has internal bonds and behaves as an integral whole. However, these cohesive bonds are passive and rigid (i.e. stable deep-energy-well interactions are constraining the constituents spatially), and they are local (i.e. there are no essential constraints on the boundary of the system). A cell, finally, has cohesive bonds and acts as an integrated whole, but those bonds are active (i.e. chemical bonds formed by shallow-energy-well interactions and continually actively remade), flexible (i.e. interactions can vary, are sensitive to system and environmental changes), and holistic (i.e. binding forces depend on globally organized interactions; i.e. local processes must interact globally to ensure the cell\u2019s survival). Autonomous systems then, according to Christensen and Hooker (2000), are cohesive systems of the same general type as the cell. Their examples of autonomous systems include cells and organisms, as for autopoiesis, but also molecular catalytic bi-cycles, species, and colonies (for details see Christensen and Hooker, 2000). Regarding the differences between their theory of autonomy and the theory of autopoiesis, Christensen and Hooker (2000) argue that the paradigm case of autopoiesis is the operationally closed system that produces all its components within itself, whereas their theory of autonomy emphasizes agent-environment interaction and a \u201cdirective organisation [that] induces pattern-formation of energy flows from the environmental milieu into system-constitutive processes\u201d. However, as Varela (1997:82) pointed out, in the theory of autopoiesis the term operational closure \u201cis used in its mathematical sense of recursivity, and not in the sense of closedness or isolation from interaction, which would be, of course, nonsense\u201d. What these theoretical frameworks share is the view that living organisms have a particular organization, and that they take this organization to be fundamental to natural cognition. This is also the case for Bickhard\u2019s (1993, 2009) notion of cognitive systems as recursively self-maintaining, far-from-thermodynamic-equilibrium systems. As Bickhard (personal communication) points out, current robots have \u201cno intrinsic stake in the world nor in their existence in the world nor in their existence as social agents\u201d. Discussing the case of a robot that regularly recharges its battery, which is a common scenario in embodied AI research (e.g. Montebelli et al., 2013), Bickhard (2009) emphasizes that the \u201ccontrast with the biological case arises in the fact that most of the robot\u2019s body is not far-from-equilibrium, cannot be self-maintained, and certainly not recursively self-maintained. Conversely, the only part of the robot that is far from equilibrium, the battery, is not self-maintaining\u201d. Interestingly, despite all similarities in the above theoretical frameworks, while the theory of autopoiesis and the underlying biology of cognition adopt a strictly anti-representationalist view of cognition, in Bickhard\u2019s interactivist theory of mind, with which also Christensen and Hooker sympathize, so-called interactive representations play a crucial role. This indicates that Chemero\u2019s above illustration of the embodied cognition research landscape might not necessarily provide a complete picture, and there might be room for conceptions of cognition as a biological phenomenon that reject the traditional functionalist/computationalist view, and maybe also reject the traditional notion of representation, but without necessarily committing to the eliminativism/anti-representationalism that characterizes radical embodied cognition according to Chemero. We will get back to this point. The above characterizations of cognitive systems as autonomous, self-maintaining, and to some degree self-producing, living systems of course have a number of historical precursors. This includes the concept of autonomy in von Uexk\u00fcll\u2019s (1928, 1982) theoretical biology and theory of meaning (cf. Ziemke, 2000, 2001a; Ziemke and Sharkey, 2001) as well as Spinoza\u2019s 17-th century concept of the conatus, which Damasio (2003) summarized as follows: \u201cIt is apparent that the continuous attempt at achieving a state of positively regulated life is a deep and defining part of our existence \u2013 the first reality of our existence as Spinoza intuited when he described the relentless endeavour (conatus) of each being to preserve itself. \u2026 Interpreted with the advantages of current hindsight, Spinoza\u2019s notion implies that the living organism is constructed so as to maintain the coherence of its structures and functions against numerous life-threatening odds. The conatus subsumes both the impetus for self-preservation in the face of danger and opportunities and the myriad actions of self-preservation that hold the parts of the body together. In spite of the transformations the body must undergo as it develops, renews its constituent, and ages, the conatus continues to form the same individual and respect the same structural design.\u201d (Damasio, 2003, p. 36) Damasio has criticized \u201cthe prevalent absence of a notion of organism in the sciences of mind and brain\u201d as a problem, which he elaborated as follows: \u201cIt is not just that the mind remained linked to the brain in a rather equivocal relationship, but that the brain remained consistently separated from the body and thus not part of the deeply interwoven mesh of body and brain that defines a complex living organism\u201d (Damasio, 1998, p. 84). His own theoretical framework, much in line with his above interpretation of Spinoza, is based on the view that \u201c[nature has] built the apparatus of rationality not just on top of the apparatus of biological regulation, but also from it and with it\u201d (Damasio, 1994, p. 128). This view is shared by somatic theories of emotion and consciousness, including the work of Damasio (1998, 1999, 2003), Panksepp (2005), and Prinz (2004), as well their historical predecessors, James (1884) and Lange (1885). What these theories agree on, in a nutshell, is that emotions arise from multiple, nested levels of homeostatic regulation of bodily activity (cf. Fig. 2 ), and that emotional feelings are feelings of such bodily changes (cf. Prinz, 2004). According to Panksepp (2005), somatic theories constitute \u201ca multi-tiered affectively embodied view of mind\u201d (Panksepp, 2005, p. 63). Such somatic theories can be considered a biologically-based, but representational view of cognition, although with a non-traditional twist: here the representations are not body-internal representations of body- or agent-external objects or states of affairs, but rather the brain\u2019s representations of first and foremost bodily activity, albeit indirectly of course also the environment. According to Prinz, \u201cemotions can represent core relational themes without explicitly describing them. Emotions track bodily states that reliably co-occur with important organism\u2013environment relations, so emotions reliably co-occur with important organism\u2013environment relations. Each emotion is both an internal body monitor and a detector of dangers, threats, losses, or other matters of concern. Emotions are gut reactions; they use our bodies to tell us how we are faring in the world\u201d (Prinz, 2004, p. 69). Similarly, Damasio has proposed that the essence of feelings of emotion lies in the mapping of bodily emotional states in the body-sensing regions of the brain, including somato-sensory cortex (Damasio, 1999, 2004). Such mental imagery of emotional bodily reactions is also crucial to Damasio\u2019s concept of the as-if body loop, a neural internal simulation mechanism (using the brain\u2019s body maps, bypassing the actual body), whose cognitive function and adaptive value are as follows: \u201cWhereas emotions provide an immediate reaction to certain challenges and opportunities \u2026 [t]he adaptive value of feelings comes from amplifying the mental impact of a given situation and increasing the probabilities that comparable situations can be anticipated and planned for in the future so as to avert risks and take advantage of opportunities\u201d (Damasio, 2004, pp. 56\u201357). Since in the above discussion of somatic theories the notion of homeostatic bodily regulation has been mentioned, it should be noted that the term homeostasis here is used in the wider sense, as used by Damasio and Carvalho (2013), i.e. the \u201cprocess of maintaining the internal milieu physiological parameters (such as temperature, pH and nutrient levels) of a biological system within the range that facilitates survival and optimal function\u201d, rather than the narrower sense that emphasizes constancy. As discussed in more detail elsewhere (Vernon et al., 2015), of particular relevance to theories and models of embodied cognition is in fact the concept of predictive (self-) regulation or allostasis (Sterling, 2004, 2012; Schulkin, 2011). In line with the notion of the as-if body loop discussed above, Sterling (2012) points out: \u201cThe brain monitors a very large number of external and internal parameters to anticipate changing needs, evaluate priorities, and prepare the organism to satisfy them before they lead to errors. The brain even anticipates its own local needs, increasing flow to certain regions \u2014 before there is an error signal\u201d. In a similar vein, Seth (2013) has argued that \u201can organism should maintain well-adapted predictive models of its own physical body \u2026 and of its internal physiological condition\u201d (Seth, 2013, p. 567). To sum up this section, before we move to the next, there are a number of overlapping theoretical frameworks that take cognition to be a genuinely biological phenomenon occurring in living organisms, and therefore emphasize the fundamental role played by the living body in general, and mechanisms of homeostatic/allostatic self-regulation in particular, in natural embodied cognition in living organisms. This clearly goes beyond the somewhat mechanistic view of the physical body as the computational mind\u2019s sensorimotor interface to the world, which pervades much of mainstream (embodied) cognitive science and in particular embodied AI. While the controversial issue of \u2018representation\u2019 naturally is too complex to discuss in detail \u2013 let alone resolve \u2013 in this paper, the above discussion hopefully illustrates at least to some degree the potential role and nature of non-traditional \u2018representations\u2019 1 1 Considering the emphasis on prediction, it might in fact be more accurate to think of them as pre-presentations, or simply pre-sentations. \u2013 in the sense of predictive models \u2013 in biologically-based, non-functionalist conceptions of embodied cognition. 4 Discussion and conclusion As Black (2014) has recently pointed out, we \u201cseem to have an innate propensity to see bodies wherever we look\u201d (p. 16). This is due to the the fact we \u201cconsistently anthropomorphise machines, our attempts to conceptualise unfamiliar new artefacts falling back on the most fundamental and sophisticated frameworks for understanding animation we have \u2013 those related to the human body\u201d (Black, 2014, p. 38). Hence, the question \u201cWhat is a body?\u201d or \u201cWhat is embodied?\u201d is actually rarely asked. In embodied AI research robots are usually considered as \u2018embodied\u2019 as a matter of fact, simply because, unlike most traditional AI systems, they are physical and can interact with their environment through sensors and actuators. The fact that robot bodies in most cases actually have very little in common with the bodies of living organisms is not given equally much attention. As discussed in Section 2, most work in embodied cognitive science falls into the category Chemero (2009) refers to as mainstream embodied cognitive science, which still is more or less compatible with traditional computationalist and representationalist conceptions of cognition, which to some degree reduce the body to the computational mind\u2019s physical/sensorimotor interface to the world that it represents internally. Radical embodied cognitive science rejects these traditional notions, but at least in Chemero\u2019s formulation of the main claims/tenets of radical embodied cognition, it also does not emphasize the biological nature of embodied cognition as such, but focuses on explaining perception and action in dynamical-systems terms rather than representational terms. Accordingly, most research in embodied AI, of both the representationalist and the anti-representationalist type, has focused on sensorimotor interaction between agents and their physical and social environments, i.e. on grounding cognition in sensorimotor interaction. Naturally, physical robots and simulated robotic agents are the tools of choice for this type of embodied AI. From the perspective of the theories discussed in Section 3 though, embodied cognition is not only grounded in sensorimotor interaction with the environment. At least in the case of natural cognition, that sensorimotor interaction with the environment is itself deeply rooted in the underlying biological mechanisms, and more specifically layered/nested networks of bodily self-regulation mechanisms. According to Damasio and others, the connection lies in emotional mechanisms playing a crucial role in this self-regulation, fulfilling on the one hand a survival-related (bioregulatory, adaptive, homeostatic/allostatic) function, and, on the other hand, constituting the basis of higher-level cognition, self and consciousness. Panksepp (2005) refers to this as \u201ca multi-tiered affectively embodied view of mind\u201d, which clearly goes beyond the physical/sensorimotor embodiment that current robots are limited to. If we adopt the latter view of embodied cognition as a first and foremost biological phenomenon, then clearly embodied AI is still lacking in complex models of such multi-level networks/hierarchies of self-regulation mechanisms \u2013 reaching from low-level bioregulatory mechanisms to higher levels of embodied emotion and cognition \u2013 and possibly the development of computational cognitive architectures for robotic systems taking into account some of these mechanisms (cf. Ziemke and Lowe, 2009; Lowe and Ziemke, 2011; Vernon et al., 2015). Accordingly, an important potential contribution of synthetic biology research to embodied AI, and the understanding of natural embodied cognition, then probably lies first and foremost in modeling/understanding/synthesizing the nature of organisms as such layered networks. This would be an important complement to current work in embodied AI and cognitive robotics, much of which is predominantly concerned with layered architectures for dealing with the complexities of perceiving and acting in the world. In closing, and at the risk of pointing out the obvious, it should also be noted that the two types of embodied AI discussed here, focusing on grounding embodied cognition in sensorimotor interaction, and on grounding sensorimotor interaction in bodily regulation, respectively, are of course highly complementary. This applies not only to embodied AI, but also to our understanding of embodied cognition in general. Hence, Johnson\u2019s (2007) description of his own work on the embodiment of language, which initially focused on understanding the grounding of language in sensorimotor interaction, also characterizes very well the development of embodied approaches in cognitive science and AI in general: \u201cIn retrospect I now see that the structural aspects of our bodily interactions with our environments upon which I was focusing were themselves dependent on even more submerged dimensions of bodily understanding. It was an important step to probe below concepts, propositions, and sentences into the sensorimotor processes by which we understand our world, but what is now needed is a far deeper exploration into the qualities, feelings, emotions, and bodily processes that make meaning possible.\u201d (Johnson, 2007). Acknowledgement This work was supported in part by the Knowledge Foundation, Stockholm, under SIDUS grant agreement no. 20140220 (AIR, \u201cAction and intention recognition in human interaction with autonomous systems\u201d). The author would like to thank Luisa Damiano, Sam Thellman, and the anonymous reviewers for useful feedback on earlier versions of this paper. References Anderson, 2003 M. Anderson Embodied cognition: a field guide Artif. Intell. 149 1 2003 91 130 Barandiaran and Moreno, 2006 X. Barandiaran A. Moreno On what makes certain dynamical systems cognitive: a minimally cognitive organization program Adapt. Behav. 14 2 2006 171 185 Beer, 1995 R.D. Beer A dynamical systems perspective on agent-environment interaction Artif. Intell. 72 1995 173 215 Berthouze and Ziemke, 2003 Epigenetic robotics: modelling cognitive development in robotic systems L. Berthouze T. Ziemke Connect. Sci. 15 4 2003 147 150 Bickhard, 1993 M.H. Bickhard Representational content in humans and machines J. Exp. Theor. Artif. Intell. 5 1993 285 333 Bickhard, 2009 M.H. Bickhard The biological foundations of cognitive science New Ideas Psychol. 27 2009 75 84 Black, 2014 D. Black Embodiment and Mechanisation: Reciprocal Understanding of Body and Machine from the Renaissanc to the Present 2014 Ashgate Farnham, UK Brooks, 1991 R.A. Brooks Intelligence without reason Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (IJCAI-91) 1991 Morgan Kauffmann San Mateo, CA 569 595 Brooks, 1993 R.A. Brooks The engineering of physical grounding Proceedings of The Fifteenth Annual Conference of the Cognitive Science Society 1993 Lawrence Erlbaum Associates, Inc Boulder, Colorado 153 154 Chemero, 2009 A. Chemero Radical Embodied Cognitive Science 2009 MIT Press Cambridge, MA Chrisley and Ziemke, 2002 R. Chrisley T. Ziemke Embodiment Encyclopedia of Cognitive Science 2002 Macmillan Publishers London 1102 1108 Chrisley, 2003 R. Chrisley Embodied artificial intelligence Artif. Intell. 149 1 2003 131 150 Christensen and Hooker, 2000 W.D. Christensen C.A. Hooker Autonomy and the emergence of intelligence: organised interactive construction Commun. Cogn. \u2013 Artif. Intell. 17 3\u20134 2000 133 157 Clark, 1997 A. Clark Being There 1997 MIT Press Cambridge, MA Clark, 1999 A. Clark An embodied cognitive science? Trends Cogn. Sci. 9 1999 345 351 Costall, 2006 A. Costall Bringing the body back to life: James Gibson\u2019s ecology of agency T. Ziemke J. Zlatev R. Frank Body, Language and Mind. Volume 1: Embodiment 2006 Mouton de Gruyter Berlin Damasio and Carvalho, 2013 A. Damasio G.B. Carvalho The nature of feelings: evolutionary and neurobiological origins Nat. Rev. Neurosci. 14 2013 143 152 10.1038/nrn3403 Damasio, 1994 A.R. Damasio Descartes\u2019 Error 1994 Vintage Books Damasio, 1998 A.R. Damasio Emotion in the perspective of an integrated nervous system Brain Res. Rev. 26 1998 83 86 Damasio, 1999 A.R. Damasio The Feeling of What Happens: Body, Emotion and the Making of Consciousness 1999 Vintage London Damasio, 2003 A.R. Damasio Looking for Spinoza: Joy, Sorrow and the Feeling Brain 2003 Harcourt Orlando, FL Damasio, 2004 A.R. Damasio Emotions and feelings: a neurobiological perspective A. Manstead N. Frijda A. Fischer Feelings and Emotions \u2013 The Amsterdam Symposium 2004 Cambridge University Press Dreyfus, 1979 H. Dreyfus What Computers Can\u2019t Do 1979 MIT Press Cambridge, MA Froese and Ziemke, 2009 T. Froese T. Ziemke Enactive artificial intelligence: investigating the systemic organization of life and mind Artif. Intell. 173 2009 466 500 10.1016/j.artint.2008.12.001 Gallagher, 2005 S. Gallagher How the Body Shapes the Mind 2005 Oxford University Press Oxford Goldinger et al., 2016 S.D. Goldinger M.H. Papesh A.S. Barnhart W.A. Hansen M.C. Hout The poverty of embodied cognition Psychon. Bull. Rev. 23 2016 959 978 10.3758/s13423-015-0860-1 Greenspan and Baars, 2005 R.J. Greenspan B.J. Baars Consciousness eclipsed: Jacques Loeb, Ivan P. Pavlov, and the rise of reductionistic biology after 1900 Conscious. Cogn. 24 2005 219 230 Harnad, 1989 S. Harnad Minds, machines and Searle J. Exp. Theor. Artif. Intell. 1 1 1989 5 25 Harnad, 1990 S. Harnad The symbol grounding problem Phys. D 42 1990 335 346 James, 1884 W. James What is an emotion? Mind 9 1884 188 205 Johnson, 2007 M. Johnson The Meaning of the Body: Aesthetics of Human Understanding 2007 University of Chicago Press Chicago Killeen, 2016 Killeen, P., 2016. The House of the Mind. Commentary on Goldinger et al. (2016) The poverty of embodied cognition. Available at: https://asu.academia.edu/PeterKilleen (05.08.16). Lange, 1885 C.G. Lange Om Sindsbev\u00e6gelser \u2013 Et Psyko-fysiologisk Studie 1885 Jacob Lunds Copenhagen Lindblom, 2015 J. Lindblom Embodied Social Cognition 2015 Springer Verlag Heidelberg, Germany Loeb, 1918 Jacques Loeb Forced Movements, Tropisms, and Animal Conduct 1918 Lippincott Company Philadelphia Lowe and Ziemke, 2011 R. Lowe T. Ziemke The feeling of action tendencies: on the emotional regulation of goal-directed behavior Front. Psychol. 2 2011 346 10.3389/fpsyg.2011.00346 Lungarella et al., 2003 M. Lungarella G. Metta R. Pfeifer G. Sandini Developmental robotics: a survey Connect. Sci. 15 4 2003 151 190 Maturana and Varela, 1980 H.R. Maturana F.J. Varela Autopoiesis and Cognition 1980 Reidel Dordrecht Maturana and Varela, 1987 H.R. Maturana F.J. Varela The Tree of Knowledge \u2013 The Biological Roots of Human Understanding 1987 Shambhala Boston, MA Montebelli et al., 2013 A. Montebelli R. Lowe T. Ziemke Towards metabolic robotics: insights from modeling embodied cognition in a bio-mechatronic symbiont Artif. Life 19 3\u20134 2013 299 315 Morse et al., 2011 A. Morse C. Herrera R. Clowes A. Montebelli T. Ziemke The role of robotic modeling in cognitive science New Ideas Psychol. 29 3 2011 312 324 Nolfi and Floreano, 2000 S. Nolfi D. Floreano Evolutionary Robotics 2000 MIT Press Cambride, MA Panksepp, 2005 J. Panksepp Affective consciousness: core emotional feelings in animals and humans Conscious. Cogn. 14 2005 30 80 Pavlov, 1927 I.P. Pavlov Conditioned Reflexes 1927 Oxford University Press London Pezzulo et al., 2013 G. Pezzulo L.W. Barsalou A. Cangelosi M.H. Fischer K. McRae M.J. Spivey Computational Grounded Cognition: a new alliance between grounded cognition and computational modeling Front. Psychol. 3 2013 612 10.3389/fpsyg.2012.00612 Pfeifer and Scheier, 1999 R. Pfeifer C. Scheier Understanding Intelligence 1999 MIT Press Cambridge, MA Pfeifer, 1995 R. Pfeifer Cognition \u2013 perspectives from autonomous agents Rob. Auton. Syst. 15 1995 47 70 Piaget, 1954 Piaget, J., 1954. The Construction of Reality in the Child. New York: Basic Books. Originally appeared as Piaget (1937) La construction du r\u00e9el chez l\u2019enfant. Neuch\u00e2tel, Switzerland : Delachaux et Niestl\u00e9. Preston and Bishop, 2002 J. Preston M. Bishop Views Into the Chinese Room: New Essays on Searle and Artificial Intelligence 2002 Oxford University Press Oxford Prinz, 2004 J. Prinz Gut Reactions \u2013 A Perceptual Theory of Emotion 2004 Oxford University Press Oxford Schulkin, 2011 J. Schulkin Social allostasis: anticipatory regulation of the internal milieu Front. Evolut. Neurosci. 2 2011 111 10.3389/fnevo.2010.00111 Searle, 1980 J.R. Searle Minds, brains, and programs Behav. Brain Sci. 3 3 1980 417 457 Seth, 2013 A.K. Seth Interoceptive inference, emotion, and the embodied self Trends Cogn. Sci. 17 2013 565 573 10.1016/j.tics.2013.09.007 Shapiro, 2010 L. Shapiro Embodied Cognition 2010 Routledge Sharkey and Ziemke, 1998 N.E. Sharkey T. Ziemke A consideration of the biological and psychological foundations of autonomous robotics Connect. Sci. 10 3\u20134 1998 361 391 Sharkey and Ziemke, 2001 N.E. Sharkey T. Ziemke Mechanistic vs. phenomenal embodiment: can robot embodiment lead to strong AI? Cognit. Syst. Res. 2 4 2001 251 262 Skinner, 1938 B.F. Skinner The Behavior of Organisms 1938 Appleton-Century-Crofts New York Steels, 1994 L. Steels The artificial life roots of artificial intelligence Artif. Life 1 1994 75 110 Sterling, 2004 P. Sterling Principles of allostasis J. Schulkin Allostasis, Homeostasis, and the Costs of Adaptation 2004 Cambridge University Press Cambridge 17 64 Sterling, 2012 P. Sterling Allostasis: a model of predictive regulation Physiol. Behav. 106 2012 5 15 10.1016/j.physbeh.2011.06.004 Stewart, 1996 J. Stewart Cognition=life: implications for higher-level cognition Behav. Process. 35 1996 311 326 Thompson, 2007 E. Thompson Mind in Life 2007 Harvard University Press Cambridge, MA Varela et al., 1974 F.J. Varela H.R. Maturana R. Uribe Autopoiesis: the organization of living systems: its characterization and a model Biosystems 5 1974 187 196 Varela et al., 1991 F.J. Varela E. Thompson E. Rosch The Embodied Mind: Cognitive Science and Human Experience 1991 MIT Press Cambridge, MA Varela, 1979 F.J. Varela Principles of Biological Autonomy 1979 Elsevier New York Varela, 1997 F.J. Varela Patterns of life: intertwining identity and cognition Brain Cogn. 34 1997 72 87 Vernon et al., 2015 D. Vernon R. Lowe S. Thill T. Ziemke Embodied cognition and circular causality: on the role of constitutive autonomy in the reciprocal coupling of perception and action Front. Psychol. 6 2015 1660 10.3389/fpsyg.2015.01660 von Uexk\u00fcll, 1928 J. von Uexk\u00fcll Theoretische Biologie 1928 Springer Verlag Berlin von Uexk\u00fcll, 1982 von Uexk\u00fcll, J., 1982. The Theory of Meaning. Semiotica, 42 (1), 25\u201382. Originally appeared as: von Uexk\u00fcll, J., 1940. Bedeutungslehre. Leipzig: Verlag J.A. Barth. Watson, 1925 J. Watson Behaviorism 1925 Norton New York Wilson and Golonka, 2013 A.D. Wilson S. Golonka Embodied cognition is not what you think it is Front. Psychol. 4 2013 58 10.3389/fpsyg.2013.00058 Ziemke and Lowe, 2009 T. Ziemke R. Lowe On the role of emotion in embodied cognitive architectures: from organisms to robots Cogn. Comput. 1 2009 104 117 10.1007/s12559-009-9012-0 Ziemke and Sharkey, 2001 T. Ziemke N.E. Sharkey A stroll through the worlds of robots and animals Semiotica 134 1\u20134 2001 701 746 Ziemke and Thill, 2014 T. Ziemke S. Thill Robots are not embodied! Conceptions of embodiment and their implications for social human\u2013robot interaction Seibt Hakli N\u00f8rskov Sociable Robots and the Future of Social Relations 2014 IOS Press Amsterdam 49 53 Ziemke et al., 2006 T. Ziemke J. Zlatev R. Frank Body, Language and Mind. Volume 1: Embodiment 2006 Mouton de Gruyter Berlin Ziemke, 1999 T. Ziemke Rethinking grounding A. Riegler M. Peschl A. von Stein Understanding Representation in the Cognitive Sciences 1999 Plenum Press New York Ziemke, 2000 T. Ziemke Situated Neuro-robotics and Interactive Cognition. Doctoral Dissertation 2000 University of Sheffield UK Ziemke, 2001a T. Ziemke The construction of \u2018Reality\u2019 in the robot Found. Sci. 6 1 2001 163 233 Ziemke, 2001b T. Ziemke Are robots embodied? C. Balkenius J. Zlatev C. Brezeal K. Dautenhahn H. Kozima Proceedings of the First International Workshop on Epigenetic Robotics: Modelling Cognitive Development in Robotic Systems vol. 85 2001 Lund University Cognitive Studies Lund, Sweden 75 83 Ziemke, 2003 T. Ziemke What\u2019s that thing called embodiment? R. Alterman D. Kirsh Proceedings of the 25th Annual Conference of the Cognitive Science Society 2003 Lawrence Erlbaum Mahwah, NJ 1305 1310 Ziemke, 2004 T. Ziemke Embodied AI as science: models of embodied cognition, embodied models of cognition, or both? F. Iida R. Pfeifer L. Steels Y. Kuniyoshi Embodied Artificial Intelligence 2004 Springer Heidelberg 27 36 Ziemke, 2007 T. Ziemke What\u2019s life got to do with it? A. Chella R. Manzotti Artificial Consciousness 2007 Imprint Academic Exeter 48 66 Ziemke, 2008 T. Ziemke On the role of emotion in biological and robotic autonomy Biosystems 91 2008 401 408 Zlatev, 2001 J. Zlatev The epigenesis of meaning in human beings, and possibly robots Minds Mach. 11 2 2001 155 195 Zlatev, 2002 J. Zlatev Meaning=life (+culture): an outline of a unified biocultural theory of meaning Evol. Commun. 4 2002 253 296 Zlatev and Balkenius, 2001 J. Zlatev C. Balkenius Introduction: why epigenetic robotics? C. Balkenius J. Zlatev C. Brezeal K. Dautenhahn H. Kozima Proceedings of the First International Workshop on Epigenetic Robotics: Modelling Cognitive Development in Robotic Systems vol. 85 2001 Lund University Cognitive Studies Lund, Sweden 1 4", "scopus-id": "84993990240", "pubmed-id": "27543133", "coredata": {"eid": "1-s2.0-S030326471630168X", "dc:description": "Abstract Embodied cognition is a hot topic in both cognitive science and AI, despite the fact that there still is relatively little consensus regarding what exactly constitutes \u2018embodiment\u2019. While most embodied AI and cognitive robotics research views the body as the physical/sensorimotor interface that allows to ground computational cognitive processes in sensorimotor interactions with the environment, more biologically-based notions of embodied cognition emphasize the fundamental role that the living body \u2013 and more specifically its homeostatic/allostatic self-regulation \u2013 plays in grounding both sensorimotor interactions and embodied cognitive processes. Adopting the latter position \u2013 a multi-tiered affectively embodied view of cognition in living systems \u2013 it is further argued that modeling organisms as layered networks of bodily self-regulation mechanisms can make significant contributions to our scientific understanding of embodied cognition.", "openArchiveArticle": "false", "prism:coverDate": "2016-10-31", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S030326471630168X", "dc:creator": {"@_fa": "true", "$": "Ziemke, Tom"}, "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S030326471630168X"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S030326471630168X"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S0303-2647(16)30168-X", "prism:volume": "148", "prism:publisher": "The Author. Published by Elsevier Ireland Ltd.", "dc:title": "The body of knowledge: On the role of the living body in grounding embodied cognition", "prism:copyright": "\u00a9 2016 The Author. Published by Elsevier Ireland Ltd.", "prism:issueName": "What Synthetic Biology can offer to Artificial Intelligence", "openaccess": "1", "prism:issn": "03032647", "dcterms:subject": [{"@_fa": "true", "$": "Allostasis"}, {"@_fa": "true", "$": "Cognitive systems"}, {"@_fa": "true", "$": "Grounding"}, {"@_fa": "true", "$": "Homeostasis"}, {"@_fa": "true", "$": "Embodied AI"}, {"@_fa": "true", "$": "Embodied cognition"}, {"@_fa": "true", "$": "Emotion"}, {"@_fa": "true", "$": "Intentionality"}, {"@_fa": "true", "$": "Predictive regulation"}, {"@_fa": "true", "$": "Representation"}], "openaccessArticle": "true", "prism:publicationName": "Biosystems", "openaccessSponsorType": "Author", "prism:pageRange": "4-11", "prism:endingPage": "11", "pubType": "Review article", "prism:coverDisplayDate": "October 2016", "prism:doi": "10.1016/j.biosystems.2016.08.005", "prism:startingPage": "4", "dc:identifier": "doi:10.1016/j.biosystems.2016.08.005", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "158", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S030326471630168X-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5494", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "116", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S030326471630168X-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5740", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "271", "@width": "376", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S030326471630168X-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "17672", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "199", "@width": "376", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S030326471630168X-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "16166", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1201", "@width": "1667", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S030326471630168X-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "149285", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "882", "@width": "1667", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S030326471630168X-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "140338", "@ref": "gr2", "@mimetype": "image/jpeg"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84993990240"}}
{"originalText": "serial JL 313379 291210 291682 291690 291711 291735 291767 291777 291786 291795 291802 291806 291828 291838 291845 291848 291861 291871 291875 291876 291884 291889 291919 291929 291934 291938 31 90 Heliyon HELIYON 2019-11-01 2019-11-01 2019-11-01 2019-11-01 2020-01-30T00:17:46 1-s2.0-S2405844019363595 S2405-8440(19)36359-5 S2405844019363595 10.1016/j.heliyon.2019.e02699 S300 S300.10 FULL-TEXT 1-s2.0-S2405844018X00115 2020-01-30T00:44:26.084629Z 0 0 20191001 20191031 2019 2019-11-01T16:05:35.776103Z articleinfo articlenumber articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issfirst issn issnnorm issuelist itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pii piinorm pubdateend pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath affil articletitle auth authfirstini authfull authkeywords authlast orcid primabst pubtype ref teaserabst 2405-8440 24058440 UNLIMITED NONE true 5 5 10 10 Volume 5, Issue 10 41 e02699 e02699 e02699 201910 October 2019 2019-10-01 2019-10-31 2019 article fla \u00a9 2019 The Authors. Published by Elsevier Ltd. DOMAININDEPENDENTREDUNDANCYELIMINATIONBASEDFLOWVECTORSFORSTATICVIDEOSUMMARIZATION MOHAN J 1 Introduction 2 Methodology 2.1 Uniform sampling 2.2 Extraction of feature descriptors 2.3 Construction of pyramid 2.4 Calculation of displacement vector 2.4.1 Belief networks 2.5 Selection of frames 3 Analysis 3.1 Performance metrics 3.2 Results and discussion 3.2.1 Trade off in varying the size of sliding window 3.2.2 Finding the number of levels of the pyramid 3.2.3 Determination of sampling rate 3.2.4 Parameter setting of the energy function 3.2.5 Comparison with other techniques 3.2.6 Impact of redundancy elimination step 3.2.7 Limitations and future work 4 Conclusion Declarations Author contribution statement Funding statement Competing interest statement Additional information References THOMAS 2017 549 555 S FURINI 2010 47 69 M KUNCHEVA 2018 118 130 L GAO 2017 581 588 Z DEAVILA 2008 103 110 S IEEEXXIBRAZILIANSYMPOSIUMCOMPUTERGRAPHICSIMAGEPROCESSING2008 VSUMMAPPROACHFORAUTOMATICVIDEOSUMMARIZATIONQUANTITATIVEEVALUATION EJAZ 2012 1031 1040 N GUAN 2013 729 734 G HANNANE 2016 89 104 R CHANG 2014 1383 1397 H ZHU 2018 1 9 D MAHASSENI 2017 B PROCEEDINGSIEEECONFERENCECOMPUTERVISIONPATTERNRECOGNITION UNSUPERVISEDVIDEOSUMMARIZATIONADVERSARIALLSTMNETWORKS FEI 2017 207 217 M MA 2019 11763 11774 M DEAVILA 2011 56 68 S KUANAR 2013 1212 1227 S SONG 2014 783 794 G CHATTOPADHYAY 2016 319 326 C TSAI 2015 1897 1906 D TASDEMIR 2014 1049 1057 K LOWE 2004 91 110 D BROX 2004 25 36 T EUROPEANCONFERENCECOMPUTERVISION HIGHACCURACYOPTICALFLOWESTIMATIONBASEDATHEORYFORWARPING SUN 2010 2432 2439 D 2010IEEECONFERENCECOMPUTERVISIONPATTERNRECOGNITION SECRETSOPTICALFLOWESTIMATIONPRINCIPLES PEARL 1986 241 288 J FELZENSZWALB 2006 41 54 P CHAMASEMANI 2017 1 16 F ZHANG 2017 253 265 H CIRNE 2017 1 19 M WU 2016 1 17 J MOHANX2019Xe02699 MOHANX2019Xe02699XJ Full 2019-10-17T02:39:27Z Author http://creativecommons.org/licenses/by-nc-nd/4.0/ This is an open access article under the CC BY-NC-ND license. \u00a9 2019 The Authors. Published by Elsevier Ltd. item S2405-8440(19)36359-5 S2405844019363595 1-s2.0-S2405844019363595 10.1016/j.heliyon.2019.e02699 313379 2020-01-30T00:44:26.084629Z 2019-10-01 2019-10-31 UNLIMITED NONE 1-s2.0-S2405844019363595-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/MAIN/application/pdf/22ddc52585507a6e384791aa77d9af00/main.pdf main.pdf pdf true 706914 MAIN 8 1-s2.0-S2405844019363595-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/PREVIEW/image/png/5e8c7fc7393a03269122805d53f68bbc/main_1.png main_1.png png 53522 849 656 IMAGE-WEB-PDF 1 1-s2.0-S2405844019363595-gr001.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr001/DOWNSAMPLED/image/jpeg/8d70defec472b716185ba536533b7ccf/gr001.jpg gr001 gr001.jpg jpg 19415 152 452 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr003.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr003/DOWNSAMPLED/image/jpeg/832947a0c41ea7ac78221f002b8b01c0/gr003.jpg gr003 gr003.jpg jpg 65425 387 816 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr004.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr004/DOWNSAMPLED/image/jpeg/2375b8d54deba6babe1ba496e594c1e4/gr004.jpg gr004 gr004.jpg jpg 43112 594 362 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr005.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr005/DOWNSAMPLED/image/jpeg/8ae4ca1330569c8511b7a824d6ad7ddb/gr005.jpg gr005 gr005.jpg jpg 15991 267 343 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr006.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr006/DOWNSAMPLED/image/jpeg/134b5b293e4e7566f9716859e8c953c1/gr006.jpg gr006 gr006.jpg jpg 13715 195 379 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr007.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr007/DOWNSAMPLED/image/jpeg/eedd7d03e00a7ecaf50a0047856ea589/gr007.jpg gr007 gr007.jpg jpg 39775 436 435 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr008.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr008/DOWNSAMPLED/image/jpeg/38cdb4a78cd9e7b4f4374d150b898e6d/gr008.jpg gr008 gr008.jpg jpg 74094 732 432 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr002.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr002/DOWNSAMPLED/image/gif/62bbca3aeae8f999bdbb84e16d0d10af/gr002.gif gr002 gr002.gif gif 16778 311 374 IMAGE-DOWNSAMPLED 1-s2.0-S2405844019363595-gr001.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr001/THUMBNAIL/image/gif/76637d3d6f8a03bb39d5645b33e4bb51/gr001.sml gr001 gr001.sml sml 5024 74 219 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr003.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr003/THUMBNAIL/image/gif/16b000926b69d818bf4ede4e5f66dd28/gr003.sml gr003 gr003.sml sml 4805 104 219 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr004.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr004/THUMBNAIL/image/gif/3a6cba366dd1605f6ef830143808f16d/gr004.sml gr004 gr004.sml sml 4205 164 100 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr005.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr005/THUMBNAIL/image/gif/218f8f1b976f91d6a6eeebec32cd7af7/gr005.sml gr005 gr005.sml sml 7532 164 211 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr006.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr006/THUMBNAIL/image/gif/30bde446ec48ac4e099d54da38a605c4/gr006.sml gr006 gr006.sml sml 4646 112 219 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr007.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr007/THUMBNAIL/image/gif/146a6fef0dbed2bb6f74bace44916b28/gr007.sml gr007 gr007.sml sml 6434 163 163 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr008.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr008/THUMBNAIL/image/gif/b2998202e10772d8a4c52e0129d5c741/gr008.sml gr008 gr008.sml sml 4765 163 96 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr002.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr002/THUMBNAIL/image/gif/cec7ff6a1da7b8965d17a846536b63b1/gr002.sml gr002 gr002.sml sml 7392 164 197 IMAGE-THUMBNAIL 1-s2.0-S2405844019363595-gr001_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr001/HIGHRES/image/jpeg/6948ae25be83bbe9df2a69ca60187d8d/gr001_lrg.jpg gr001 gr001_lrg.jpg jpg 164532 673 2004 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-gr003_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr003/HIGHRES/image/jpeg/20dfa26a897843e431a4536c43843ea5/gr003_lrg.jpg gr003 gr003_lrg.jpg jpg 265826 1028 2168 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-gr004_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr004/HIGHRES/image/jpeg/337b53e73ece2a8de8402e04d07ab481/gr004_lrg.jpg gr004 gr004_lrg.jpg jpg 289906 2631 1603 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-gr005_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr005/HIGHRES/image/jpeg/ddbd75cc07c8f35fafa6ac6bde7987ed/gr005_lrg.jpg gr005 gr005_lrg.jpg jpg 124579 1181 1519 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-gr006_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr006/HIGHRES/image/jpeg/394c75c2cf85872726829625c9eab784/gr006_lrg.jpg gr006 gr006_lrg.jpg jpg 100042 861 1677 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-gr007_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr007/HIGHRES/image/jpeg/29640335cdd3a3497b65f125e413d5a9/gr007_lrg.jpg gr007 gr007_lrg.jpg jpg 281958 1931 1927 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-gr008_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr008/HIGHRES/image/jpeg/e04619e6fcc16f722dfd41225ca79af0/gr008_lrg.jpg gr008 gr008_lrg.jpg jpg 511161 3242 1914 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-gr002_lrg.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/gr002/HIGHRES/image/gif/0105757dd622a5535508994edcb13c2d/gr002_lrg.gif gr002 gr002_lrg.gif gif 89898 2755 3315 IMAGE-HIGH-RES 1-s2.0-S2405844019363595-si1.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/2466aa513b1cafd7dbff82a744185a22/si1.svg si1 si1.svg svg 5967 ALTIMG 1-s2.0-S2405844019363595-si10.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/798908ff250d434ddd84edad651a881b/si10.svg si10 si10.svg svg 2043 ALTIMG 1-s2.0-S2405844019363595-si11.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/14c003e4d9780ee311ea09116ead5376/si11.svg si11 si11.svg svg 3466 ALTIMG 1-s2.0-S2405844019363595-si12.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/7072bfb1fd36fc8f667aa0c85955682e/si12.svg si12 si12.svg svg 3537 ALTIMG 1-s2.0-S2405844019363595-si13.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/c1d57343b0d8805c210e4d73a6057315/si13.svg si13 si13.svg svg 7144 ALTIMG 1-s2.0-S2405844019363595-si14.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/06a2b78e1eb2eb84bb083e696168a11e/si14.svg si14 si14.svg svg 10316 ALTIMG 1-s2.0-S2405844019363595-si15.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/7fb515a0fb2110aad141450d0e54fcd1/si15.svg si15 si15.svg svg 3533 ALTIMG 1-s2.0-S2405844019363595-si16.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/539f894f667b27ecdef103c87fb136b4/si16.svg si16 si16.svg svg 5016 ALTIMG 1-s2.0-S2405844019363595-si17.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/59ba19d667a1019d58be23561aeb222d/si17.svg si17 si17.svg svg 4548 ALTIMG 1-s2.0-S2405844019363595-si18.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/3ec95fbf36fce96d7762404e2d7ec19c/si18.svg si18 si18.svg svg 5190 ALTIMG 1-s2.0-S2405844019363595-si19.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/c1ebf02aafcb0132d7e8dd0e6451b714/si19.svg si19 si19.svg svg 8713 ALTIMG 1-s2.0-S2405844019363595-si2.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/693bdda649da68bf23ecd80a41b66801/si2.svg si2 si2.svg svg 1897 ALTIMG 1-s2.0-S2405844019363595-si20.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/5269113ec0299bdd0b54b61b9d6c3a9d/si20.svg si20 si20.svg svg 4838 ALTIMG 1-s2.0-S2405844019363595-si21.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/984edfb52145b4914ba904c3efbc2668/si21.svg si21 si21.svg svg 4316 ALTIMG 1-s2.0-S2405844019363595-si22.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/8dc3edfb54cf6a7e6ff636c6592faacd/si22.svg si22 si22.svg svg 11577 ALTIMG 1-s2.0-S2405844019363595-si23.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/717ba2f13605bce15b1757794d1ca21c/si23.svg si23 si23.svg svg 13233 ALTIMG 1-s2.0-S2405844019363595-si24.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/465843c03b97366e04e1ed7c48fe8e48/si24.svg si24 si24.svg svg 2150 ALTIMG 1-s2.0-S2405844019363595-si25.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/2bbc8699d1d1146c7640ef101f59ebd3/si25.svg si25 si25.svg svg 1872 ALTIMG 1-s2.0-S2405844019363595-si26.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/7441fa99a3170c4345c5ef0708db0672/si26.svg si26 si26.svg svg 2507 ALTIMG 1-s2.0-S2405844019363595-si27.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/1ddc5be958336688431b1c9f824da6c5/si27.svg si27 si27.svg svg 4782 ALTIMG 1-s2.0-S2405844019363595-si28.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/854a5532fa64f8004183765a377538c5/si28.svg si28 si28.svg svg 2240 ALTIMG 1-s2.0-S2405844019363595-si3.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/9c6a2bb53d227a7ab6adb803fc50f48e/si3.svg si3 si3.svg svg 2917 ALTIMG 1-s2.0-S2405844019363595-si30.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/141ff3efda27be296f9a30af87463218/si30.svg si30 si30.svg svg 2019 ALTIMG 1-s2.0-S2405844019363595-si31.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/e57671d68874438d82190bce7abee42c/si31.svg si31 si31.svg svg 2045 ALTIMG 1-s2.0-S2405844019363595-si32.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/130273d74bab9194b83e28d24884481e/si32.svg si32 si32.svg svg 3538 ALTIMG 1-s2.0-S2405844019363595-si33.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/8c9bfb8412e83eccb0a37a3c69557f14/si33.svg si33 si33.svg svg 2114 ALTIMG 1-s2.0-S2405844019363595-si34.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/fa84a68160c9806a88dd8290eabc590b/si34.svg si34 si34.svg svg 3312 ALTIMG 1-s2.0-S2405844019363595-si35.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/2fd2dff04ac7c3cf086e59cb6553093d/si35.svg si35 si35.svg svg 2535 ALTIMG 1-s2.0-S2405844019363595-si36.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/1cb79823ac1c208dac15e3a1d3baace2/si36.svg si36 si36.svg svg 3917 ALTIMG 1-s2.0-S2405844019363595-si37.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/536c75b782d240a3333c3be813c17492/si37.svg si37 si37.svg svg 2035 ALTIMG 1-s2.0-S2405844019363595-si38.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/99e977219c934740904c23104ef294d2/si38.svg si38 si38.svg svg 2938 ALTIMG 1-s2.0-S2405844019363595-si39.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/136134474f06a91d9377e917ba97333a/si39.svg si39 si39.svg svg 27759 ALTIMG 1-s2.0-S2405844019363595-si4.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/8042620e7ba461c956169e78a970c6c8/si4.svg si4 si4.svg svg 2944 ALTIMG 1-s2.0-S2405844019363595-si40.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/51a0f737b562b8cabb0bea7b6bd5bc94/si40.svg si40 si40.svg svg 2363 ALTIMG 1-s2.0-S2405844019363595-si41.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/1a0eed6f308bf73ae05b76f2845a8822/si41.svg si41 si41.svg svg 3667 ALTIMG 1-s2.0-S2405844019363595-si42.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/375601f4ab442b5e13585265a22c82a9/si42.svg si42 si42.svg svg 3935 ALTIMG 1-s2.0-S2405844019363595-si43.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/23b9f9e265f7e76a2b5f2c464872fdee/si43.svg si43 si43.svg svg 17329 ALTIMG 1-s2.0-S2405844019363595-si44.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/30aea6dc48b1f79d91622a4d78c893ef/si44.svg si44 si44.svg svg 4762 ALTIMG 1-s2.0-S2405844019363595-si45.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/05ca874a3049fd2cad337f393d0464fe/si45.svg si45 si45.svg svg 3657 ALTIMG 1-s2.0-S2405844019363595-si46.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/f78287b2ae18893aa81b47c57274d761/si46.svg si46 si46.svg svg 3670 ALTIMG 1-s2.0-S2405844019363595-si47.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/98da05adae47f44f3c30b8d169aebdac/si47.svg si47 si47.svg svg 11553 ALTIMG 1-s2.0-S2405844019363595-si48.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/fb531dd15e26dbcc4cc5862551489e9b/si48.svg si48 si48.svg svg 4316 ALTIMG 1-s2.0-S2405844019363595-si49.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/6dcf17c682c9d7202c038d49fd7c7dbe/si49.svg si49 si49.svg svg 8657 ALTIMG 1-s2.0-S2405844019363595-si5.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/a3ff1f2ae68a4eb293be2332bc22daf3/si5.svg si5 si5.svg svg 2625 ALTIMG 1-s2.0-S2405844019363595-si50.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/3137f51812b381bea37277f2476da1ea/si50.svg si50 si50.svg svg 7746 ALTIMG 1-s2.0-S2405844019363595-si51.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/d72830b444fca0c52d5003cf1d652bd4/si51.svg si51 si51.svg svg 7473 ALTIMG 1-s2.0-S2405844019363595-si52.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/f86b246e3f2d2635fba0e77d31c4f160/si52.svg si52 si52.svg svg 1814 ALTIMG 1-s2.0-S2405844019363595-si53.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/94bb91eb5950c8c585ab9aaad195302e/si53.svg si53 si53.svg svg 4257 ALTIMG 1-s2.0-S2405844019363595-si54.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/13e88817bc3d3bb964fb14fe0e7448d4/si54.svg si54 si54.svg svg 12301 ALTIMG 1-s2.0-S2405844019363595-si55.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/1d986e3c8e3f872b971d329f5b81aeff/si55.svg si55 si55.svg svg 14148 ALTIMG 1-s2.0-S2405844019363595-si56.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/8cc930c93f8b31d05a1d4f9a68b1f061/si56.svg si56 si56.svg svg 11861 ALTIMG 1-s2.0-S2405844019363595-si57.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/37e0423d85510e7d2b03b0eae154a809/si57.svg si57 si57.svg svg 6020 ALTIMG 1-s2.0-S2405844019363595-si58.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/886bf92fea188babf7c8d48239c01ec1/si58.svg si58 si58.svg svg 4910 ALTIMG 1-s2.0-S2405844019363595-si59.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/28dbf29d3584ae6889d0fb23b976ae99/si59.svg si59 si59.svg svg 4337 ALTIMG 1-s2.0-S2405844019363595-si60.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/853b4e25a394af72f5f021907e367289/si60.svg si60 si60.svg svg 6067 ALTIMG 1-s2.0-S2405844019363595-si61.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/54fb5601297843d39e49da96a6830f86/si61.svg si61 si61.svg svg 3275 ALTIMG 1-s2.0-S2405844019363595-si62.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/26f485147ca2ce627a0542cffa1085bf/si62.svg si62 si62.svg svg 4258 ALTIMG 1-s2.0-S2405844019363595-si63.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/21570ae9ff0955b00e51b4832ea4c6f4/si63.svg si63 si63.svg svg 3241 ALTIMG 1-s2.0-S2405844019363595-si64.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/870c913ef03aaa64b287120a556a45b8/si64.svg si64 si64.svg svg 3522 ALTIMG 1-s2.0-S2405844019363595-si65.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/a502a82b467a47aba2beb97b831778a9/si65.svg si65 si65.svg svg 2826 ALTIMG 1-s2.0-S2405844019363595-si7.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/47670dd9f773573e6f7cf37782c0f9f4/si7.svg si7 si7.svg svg 2857 ALTIMG 1-s2.0-S2405844019363595-si8.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/fbe4ae257b2e1af872dc5808c3852ba1/si8.svg si8 si8.svg svg 1973 ALTIMG 1-s2.0-S2405844019363595-si9.svg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2405844019363595/STRIPIN/image/svg+xml/dceacf21383c171932e51437d91c2723/si9.svg si9 si9.svg svg 2496 ALTIMG HLY 2699 e02699 S2405-8440(19)36359-5 10.1016/j.heliyon.2019.e02699 The Authors Figure 1 Overview of proposed approach. Figure 1 Figure 2 Coarse to fine matching using BP network. Figure 2 Algorithm 1 Redundancy elimination from videos. Algorithm 1 Figure 3 Comparison of RR, CUS E and MR at window size = 2, 3 and 4. Figure 3 Figure 4 Magnitude of displacement between consecutive frames of cartoon video v 11.flv in VSUMM dataset. Figure 4 Figure 5 Comparison of time for different pyramid levels. Figure 5 Figure 6 Comparison of results of redundancy elimination step of the proposed method with other state-of-the-art methods. Figure 6 Figure 7 Comparison with other methods showing the impact of redundancy elimination step on final results. Figure 7 Table 1 RR, CUS E and MR of proposed method. Table 1 Dataset RR CUS E MR VSUMM 97.13 9.49 0 OVP 97.8 8.5 0 Table 2 Results of various categories of videos in VSUMM dataset. Table 2 Category Metric Ours SVD MI US Cartoon RR 96.88 81.45 94.11 96.0 CUS E 2.97 22.24 6.28 3.85 MR 0 20 0 0 Sports RR 97.15 93.53 95.59 96.04 CUS E 17.29 119.03 22.84 19.47 MR 0 65.17 0 0 News RR 97.3 94.34 95.73 96.39 CUS E 15.11 26.88 19.86 16.49 MRNews 0 43.2 0 0 Research article Domain independent redundancy elimination based on flow vectors for static video summarization Jesna Mohan a b \u204e jesnamohan@gmail.com Madhu S. Nair c a Department of Computer Science, University of Kerala, Kariavattom, Thiruvananthapuram-695581, Kerala, India Department of Computer Science University of Kerala Kariavattom Thiruvananthapuram Kerala 695581 India Department of Computer Science, University of Kerala, Kariavattom, Thiruvananthapuram-695581, Kerala, India b Department of Computer Science, Mar Baselios College of Engineering and Technology, Thiruvananthapuram-695015, Kerala, India Department of Computer Science Mar Baselios College of Engineering and Technology Thiruvananthapuram Kerala 695015 India Department of Computer Science, Mar Baselios College of Engineering and Technology, Thiruvananthapuram-695015, Kerala, India c Artificial Intelligence & Computer Vision Lab, Department of Computer Science, Cochin University of Science and Technology, Kochi-682022, Kerala, India Artificial Intelligence & Computer Vision Lab Department of Computer Science Cochin University of Science and Technology Kochi Kerala 682022 India Artificial Intelligence & Computer Vision Lab, Department of Computer Science, Cochin University of Science and Technology, Kochi-682022, Kerala, India \u204e Corresponding author at: Department of Computer Science, University of Kerala, Kariavattom, Thiruvananthapuram-695581, Kerala, India. Department of Computer Science University of Kerala Kariavattom Thiruvananthapuram Kerala 695581 India Abstract Video summarization aims to find a compact representation of input videos. The method finds out interesting parts of the video by discarding the remaining parts of the video. The abstracts thus generated enhances browsing and retrieval of video data. The quality of summaries generated by video summarization algorithms can be improved if the redundant frames in the input video are taken care of before summarization. This paper presents a novel domain-independent method for redundancy elimination from input videos before summarization maintaining keyframes in the original video. The frames of input video are first presampled by selecting two frames in one second. The flow vectors between consecutive frames are computed using SIFT Flow algorithm. The magnitude of flow vectors at each pixel position of the frame are summed up to find the displacement magnitude between the consecutive frames. The redundant frames are filtered out based on local averaging of the displacement values. The evaluation of the method is done using two standard datasets namely VSUMM and OVP. The results demonstrate that an average reduction rate of 97.64% is achieved consistently on videos of all categories. The method also gives superior results compared to other state-of-the-art redundancy elimination methods for video summarization Computer science; Video summarization; Keyframes; SIFT flow; Uniform sampling; Dual Layer Loopy Belief Propagation Network (DLBPN) Keywords Computer science Video summarization Keyframes SIFT flow Uniform sampling Dual Layer Loopy Belief Propagation Network (DLBPN) 1 Introduction With the recent advancements in the digital world, there has been an exponential increase in the volume of the video data. This data explosion has put our existing network infrastructure at risk. As a result, any interested user has to browse through substantial video repositories to find the relevant video data. However, these users cannot decide without viewing the entire video content which is time-consuming. Time is of the essence. A summarized video can aid any interested user to make quick decisions. Moreover, a summarized video data can be stored and retrieved efficiently [1]. Video summarization extracts an abstract representation of the original video by selecting the keyframes of the videos and discarding the redundant parts. The keyframes are those frames which contain prime parts of the video. When a set of keyframes are viewed together, it can convey the essential message of the video. The video abstracts can be stored in less space and users can perceive the contents in less time compared to the original video. The abstracts must also be consistent with the human vision so that humans can understand the information conveyed by a video which spans hours long in few minutes. The video abstracts can be still abstracts (static storyboard representation) [2] or moving abstracts (video skims) [3], [4]. The still abstracts convey the essential message of the video as a sequence of frames. The temporal component in the input video is lost in still abstracts. Whereas, video skims represent summarized output as a short video which retains the temporal component. The still abstracts are simple to put into practice than the moving abstracts. There exists a number of works for automated video summarization. Avila et al. in [5] emphasize on processing videos based on color histogram. Ejaz et al. [6] used aggregation of global features to detect keyframes. But, the global features fail to capture local characteristics of frames which is relevant for detecting content change between frames. Guan et al. in [7] used local SIFT features for detecting the key-frames. Later, Hannane et al. in [8] combined local features with optical flow for generating a good quality summary. Summarization was also done at content level [9] by selecting frames using dynamic programming approach. Zhu et al. [10] emphasized object level processing of frames to extract key parts of the input video. Recently, with the development of high performance computers with GPUs, deep learning based methods have been developed for video summarization. Mahasseni et al. in [11] proposed the long short-term memory network (LSTM) to select the key-frames. The network is trained so that the reconstruction error is minimum. Fei et al. in [12] proposed video summarization framework based on entropy and memorability score. The memorability score is computed using Hybrid-AlexNet. The quality of summaries generated by these methods reveal that deep features can represent the frames more efficiently than handcrafted features. The sparse dictionary based method for summarization is explored in [13]. However, most of the existing methods consider the whole video for processing. The computational complexity of these methods is very high since a video has many redundant frames. The duplication of similar visual content in the input is unfavorable for generating a brief but comprehensive representation of the original video. The efficiency of video summarization framework can be improved if ambiguous frames are detected and discarded initially so that set of frames with less redundancy can be used for further processing. Various techniques have been explored in literature to eliminate redundant frames before summarization. Avila et al. in [14] discarded redundant frames using a uniform sampling method by randomly selecting one frame in a second from the input video. Kuanar et al. in [15] identified that the frames corresponding to the significant valley of mutual information curve carry the essential content of the video. These frames must also be added to the presampled set of frames to prevent information loss. Song et al. in [16] selected those frames with minimum Euclidean distance to the average histogram of a shot as candidate frames for summarization. But these methods fail to achieve consistent results on videos of all categories. Thus, a technique that could remove the redundancy from input videos retaining every distinct frame and which generate consistent results for all categories of video is in demand and attracted researchers in this area. Recent works on video analysis [17], [18] has proved the significance of motion vectors and temporal analysis in capturing the content change in video data. Moreover, the work in [19] suggests motion vectors are more discriminative when it is calculated after reducing the number of redundant frames from the input videos. Thus, an attempt to reduce redundancy based on motion vectors after an initial sampling would be helpful to reduce the computational burden of subsequent summarization step. So, to reduce running time and redundancy, we propose here a domain-independent redundancy elimination method for video summarization based on flow vectors after performing uniform sampling on the set of input frames. The method makes use of SIFT Flow algorithm to find the magnitude of displacement between consecutive frames after uniform sampling. Then, the redundant frames are eliminated using threshold value which is determined based on local averaging of the displacement magnitude. The method is tested on VSUMM and OVP dataset and it achieves high reduction rate of 97.64% and less error compared to other state-of-the-art methods. The rest of this paper is organized as follows. Section 2 describes the proposed methodology for eliminating redundancy from input video before summarization. Experimental results and discussions are illustrated in Section 3. We conclude the paper in Section 4. 2 Methodology The proposed system is a redundancy elimination technique using uniform presampling followed by filtering out of ambiguous frames based on flow vectors. The method makes use of SIFT Flow algorithm for the calculation of flow vectors between consecutive frames. The magnitude of flow vectors is then used to find out the abrupt transition in motion and to track the frames where a scene change occurs. The magnitude of displacement is thresholded locally to eliminate redundant frames of input video preserving keyframes. The method works adaptively on videos of all categories. The resultant set of frames can be used for summarization. The algorithm works on a frame by frame basis. Fig. 1 gives an overview of the proposed approach. The detailed steps of the method is as follows. 2.1 Uniform sampling Suppose, F be the set of frames and fps be the frame rate associated with input video V. Uniform sampling is done by selecting frames in F based on the assumption that most of the frames that constitute video in one second is similar. Most of the existing methods select a single frame in one second to reduce redundancy. But randomly selecting any one frame may lead to keyframe miss especially for low frame rate videos like cartoon videos. Also, the high sampling rate will gain high reduction rate and subsequently reduce the time taken for summarization. But it may lead to loss of relevant information from the input video. A low sampling rate will preserve the information of the original video but will increase the complexity of summarization step. The sampling rate should be chosen carefully so that all unique frames in the video should be present in the output of the sampling step for further processing. The sampling rate used in the proposed approach is two frames in one second. First, F is divided into N segments S 1 , S 2 , S 3 , . . . . S N based on fps. Suppose fps be 30. Frames from F 1 to F 30 form first segment, F 31 to F 60 form second segment and so on. Then, the first frame and middle frame of each segment are selected to form F s . F s include F 1 , F 15 of S 1 , F 31 , F 46 of S 2 and so on. 2.2 Extraction of feature descriptors Let F 1 \u204e , F 2 \u204e , F 3 \u204e , . . . . . F n s \u204e be the elements of F s . The algorithm converts each frame of F s into SIFT image. A SIFT image is formed by replacing each pixel with 128 dimensional SIFT descriptor [20]. Each input image in F s is first blurred and downsampled at different scales by convolving with a gaussian filter given by (1). (1) G ( x , y , \u03c3 ) = 1 2 \u03c0 \u03c3 2 e \u2212 ( x 2 + y 2 ) 2 \u03c3 2 where the amount of blur is determined by \u03c3 and ( x , y ) are coordinates of the pixel under consideration. The blurred image L ( x , y , \u03c3 ) obtained by convolving the input image F ( x , y ) with G ( x , y , \u03c3 ) is computed as in (2). (2) L ( x , y , \u03c3 ) = F ( x , y ) \u22c6 G ( x , y , \u03c3 ) The magnitude m ( x , y ) and orientation \u03b8 ( x , y ) are computed for each pixel at a particular scale \u03c3 in Gaussian-blurred image based on intensity differences computed using (3) and (4). (3) m ( x , y ) = ( ( L ( x + 1 , y ) \u2212 L ( x \u2212 1 , y ) ) 2 + ( L ( x , y + 1 ) \u2212 L ( x , y \u2212 1 ) ) 2 ) 1 2 (4) \u03b8 ( x , y ) = atan2 ( L ( x , y + 1 ) \u2212 L ( x , y \u2212 1 ) , L ( x + 1 , y ) \u2212 L ( x \u2212 1 , y ) ) A 16 \u00d7 16 neighborhood is specified around each pixel and orientation histogram of 8 bins is computed for each of 16 ( 4 \u00d7 4 ) sub-block of the neighborhood. The histogram of 16 blocks which consists of 8 bins gives a 128-D SIFT feature descriptor. Thus if size of F 1 \u204e is M \u00d7 N , then it is converted into SIFT image of size M \u00d7 N \u00d7 128 . 2.3 Construction of pyramid A pyramid is constructed by using smoothened and downsampled images from each frame of F s after convolution with a Gaussian filter. The number of levels of pyramid is specified by the user. A four-level pyramid corresponding to F 1 \u204e with size M \u00d7 N has F 1 \u204e at level 0. Let it be d 0 . Then, image d 1 of size M / 2 \u00d7 N / 2 constructed from d 0 form level 1 of the pyramid. Similarly, d 2 of size M / 4 \u00d7 N / 4 constructed from d 1 form level 2 and finally d 3 of size M / 8 \u00d7 N / 8 constructed from d 2 form level 3. 2.4 Calculation of displacement vector The flow vector for all pixels of F 1 \u204e is computed from F 2 \u204e by matching SIFT descriptors extracted at each pixel of F 1 \u204e and F 2 \u204e . The matching is done from coarse level to fine level. Consider pixel x 1 in d 3 of pyramid constructed from F 1 \u204e . Define a window of size M / 8 \u00d7 N / 8 around the pixel at the same location in d 3 of pyramid constructed from F 2 \u204e . The flow vector for each pixel is initialised to 0. Then, the optimal values for vectors are calculated using the energy function in (5). The energy function is modified version of energy function used in the calculation of optical flow [21], [22] and is the weighted sum of data term, small displacement term and the smoothness term. Suppose, ( u , v ) denotes flow vectors at each pixel position of F 1 \u204e and F 2 \u204e . \u2018u\u2019 represents the horizontal component and \u2018v\u2019 represents the vertical component. Let, p in F 1 \u204e and q in F 2 \u204e are the pixels under consideration. The variables \u2018t\u2019 and \u2018d\u2019 represent the threshold term for data term and smoothness term respectively. (5) E ( w ) = \u2211 p m i n ( | | s 1 ( p ) \u2212 s 2 ( p + w ( p ) | | 1 , t ) + \u2211 p \u03b7 ( | u ( p ) | + | v ( p ) | ) + \u2211 ( p , q ) \u03f5 \u03b5 m i n ( \u03b1 | u ( p ) \u2212 u ( q ) | , d ) + m i n ( \u03b1 | v ( p ) \u2212 v ( q ) | , d ) The first term in (5) is the data term which allows SIFT descriptors to be matched along flow vectors. The second term is the displacement term. The third term is the smoothness term which constrains irregularities at object boundaries. The truncated L1 norm in data and smoothness terms threshold the differences and give a constant cost to the terms above the threshold value. The optimum flow vector is calculated by minimizing energy using dual layer Loopy Belief Propagation Network. The horizontal and vertical components of flow vectors are processed separately by two layers of the network. The values of flow vectors thus obtained are passed to level 2 which is used to initialize the flow vectors of each pixel of d 2 at level 2. Then, d 2 is warped based on these values of flow vectors to get d 2 \u02c6 . Matching is done between d 2 at level 2 of first pyramid and d 2 \u02c6 . The flow vectors are then optimized as in level 3. The flow vector from level 2 is used to find flow vectors in level 1 which in turn is used to find flow vectors in level 0. The vectors at level 0 represent the final optimal flow vector ( u , v ) of each pixel. The process is illustrated in Fig. 2 . The displacement vector is calculated between every consecutive frame in F s . 2.4.1 Belief networks Belief Networks [23] are graph-based models in which nodes of the graph represent variables and connection between the nodes represent the relationship between the variables. The loopy belief propagation network [24] is similar to belief network except that it includes loops which process neighboring nodes in parallel. Let X be a pixel in an image and L be the set of possible values of flow vectors. The belief propagation network will find a label for X from labels in L based on minimizing energy function in (5). The algorithm works by passing messages between nodes of graph. The nodes are four neighbors of pixel under consideration. Each message has dimension same as number of possible states of flow vector. Suppose m r s t is the message send by node r to the neighboring points. The message is initialized to zero. At each iteration t, the message is updated using (6) (6) m r s t = min f r \u2061 ( V ( f r , f s ) + D r ( f r ) + \u2211 e \u03f5 N ( r ) \\ s m e r t \u2212 1 ( f r ) where V ( f r , f s ) and D r ( f r ) denote data term and discontinuity term of energy function and N ( r ) \\ s denotes neighbors of r other than s. After T iterations a belief vector is computed for each node. The flow vector that minimizes belief vector is selected. The belief vector is given by (7). (7) b s ( f s ) = D s ( f s ) + \u2211 r \u03f5 N ( r ) m r s T ( f s ) 2.5 Selection of frames The redundant frames are eliminated from F s based on the magnitude of flow vectors. Let ( u 1 , v 1 ) be the flow vector of a pixel in F 1 \u204e . The magnitude of displacement is calculated from ( u 1 , v 1 ) as (8) m a g = u 1 2 + v 1 2 The sum of the magnitude of displacement for all the pixels in F 1 \u204e gives the magnitude of displacement of entire frame ( d 1 ) . The magnitude of displacement is computed between each pair of consecutive frames in F s . Let D represent the set consisting of displacement magnitude of consecutive frames in F s . Suppose d 1 , d 2 , d 3 . . . . . . d n s \u2212 1 be the values of D. To eliminate the redundant frames, a local threshold value is chosen based on frames within a sliding window. The sliding window size specifies the number of frames to be considered for finding local threshold value. Here, sliding window size of 3 is chosen so that the displacement magnitude of four consecutive frames is used to find local threshold value. The local threshold value for the first four consecutive frames of F s is determined as the mean of d 1 , d 2 and d 3 . The mean value is chosen since it is simple to compute. Based on the analysis done, the mean value of the magnitude of displacement perform best to filter out redundant frames. Then, the frames having displacement greater than the local threshold value M is added to the reduced set of frames V s . Similarly, thresholding and selection of frames is done for each sliding window over the entire set D. The sequence of steps for the proposed approach is given in Algorithm 1 . 3 Analysis The performance of the proposed method has been evaluated on VSUMM and OVP dataset. VSUMM consists of cartoon, sports and news videos which span 1 to 4 minutes duration. The OVP dataset has 50 documentary videos. Datasets also include ground truth created with user summaries of 5 different users for each video. All implementation is done in MATLAB 2016a on Windows 10 Pro with an Intel(R) Core(TM) i7-3770 CPU at 3.40 GHz with 4.00 GB RAM running 64-bit operating system. 3.1 Performance metrics The commonly used performance metrics for evaluating summaries are precision, recall and F-score. Since the proposed method is redundancy elimination step before summarization, three other metrics Reduction Rate (RR), error factor on comparison with user summaries ( C U S E ) in [14] and Miss Rate (MR) are used to prove its efficiency. RR measures the percentage of redundant frames eliminated from videos, C U S E measures the fraction of redundant frames in output compared to frames in user summary and MR measures the ratio of number of misses to the number of frames in ground truth. These metrics are calculated using (9), (10) and (11). (9) R R = N i n p u t \u2212 N o u t p u t N i n p u t \u204e 100 (10) C U S E = N o u t p u t \u2212 N m a t c h N U S (11) M R = N m i s s N U S \u204e 100 where N i n p u t represents total number of frames in input video V, N o u t p u t represents total number of frames in output, N m i s s represents number of frames in user summary that is not present in the output, N m a t c h represents number of frames in ground truth that are present in output V s and N U S represents number of frames in user summary. 3.2 Results and discussion The RR, C U S E and MR of our proposed approach on VSUMM and OVP dataset is given in Table 1 . The high reduction rate of our method shows that it can eliminate 97% of redundant frames from the frames remaining after uniform sampling. The MR of 0% shows that in spite of eliminating redundant frames, our method still preserve all the keyframes in the ground truth. So, the set of frames available for keyframe extraction after redundancy elimination step is only 3% of input frames preserving keyframes. 3.2.1 Trade off in varying the size of sliding window The window size in our method specifies the number of frames to be considered at a time to find local threshold value. Here, a window size of 3 is chosen based on the analysis done on the results of proposed approach using videos of different categories. The comparison of evaluation metrics on results for three window sizes in cartoon videos of VSUMM dataset is presented in Fig. 3 . It illustrates that the reduction rate is more and the error factor is less for each video with window size 4. Results also show that a miss rate is 0 for window size 2 and 3. When window size 4 is chosen, some of the frames in the ground truth are missed from the set of output frames. This is because the frames selected for local averaging must be such that it belongs to same scene of a video. As shown in Fig. 4 displacement of consecutive frames varies abruptly and choice of window size including the frames after the abrupt change of displacement values leads to keyframe miss since those frames belong to a different scene. The redundancy elimination algorithm for video summarization should never miss a single keyframe since this affect the efficiency of video abstracts. So, a window size of 3 is chosen to be optimum though window size of 4 is better in terms of RR and C U S E . 3.2.2 Finding the number of levels of the pyramid The number of levels in the pyramid is determined based on the analysis of time taken for the proposed method using different levels as in Fig. 5 . It shows the average time taken by each category of video in VSUMM dataset and time taken by OVP dataset in seven pyramid levels. It shows the time is less at level 4 and it increases when the level is less than or greater than 4. This is because as the number of level increases, time decreases since the flow vectors computed at the coarse levels are used to initialize flow vectors at finer levels. But when the number of levels is 5, the size of the image at coarse level is too small and SIFT descriptors cannot be extracted from the image and its size is resized by padding which increases the time. So, pyramid level of 4 is chosen as best choice in the proposed method. 3.2.3 Determination of sampling rate The sampling rate for the uniform sampling step is chosen to be two frames per second. It is chosen based on the analysis done on different sampling rates. A trade-off between sampling rate and loss of information is very essential in case of summarization. Since this is only a preliminary stage we aim to preserve each distinct frame in the input video by reducing the redundancy. Most of the approaches in [25], [14], [15] selects one frame per second. This may lead to missing of distinct frames when low frame rate videos are used. If the frame rate is high the changes between consecutive frames is less and sampling rate of one frame per second yield good results. The uniform sampling step in the proposed approach achieved average RR of 91% on OVP and VSUMM database with no keyframe miss. The remaining 9% of frames are processed to find the magnitude of displacement between the consecutive frames. 3.2.4 Parameter setting of the energy function The value parameters \u03b7, \u03b1 and d of the energy function given in (1) is fixed in our experiments and taken as in [26] for object tracking in videos such that \u03b1 = 300 , \u03b7 = 0.5 and d = 3 . 3.2.5 Comparison with other techniques We compared the performance of proposed method with other redundancy elimination methods Uniform Sampling (US) [27], Mutual Information (MI) [15], Singular Value Decomposition (SVD) [28]. Fig. 6 shows the comparison of performance of proposed method with other methods. We achieved the highest reduction rate with less error on VSUMM and OVP dataset though SVD and US achieved 0%MR. Detailed results on category basis are summarized in Table 2 . It shows that method attain RR of 97% consistently on videos of all categories with 0%MR. But, for sports videos C U S E is more which shows that a small fraction of redundant frames are eliminated. This is so because in sports videos scene change is gradual compared to other two categories of videos which shows an abrupt scene change. As a result, in sports videos displacement of pixels between consecutive frames is less. However, our method when compared to existing redundancy elimination methods gained less C U S E for sports videos. The uniform sampling is computationally simple. The uniform sampling method achieved 0%MR and RR and C U S E close to our method. But the analysis shows that rather than using random uniform selection, eliminating similar frames based on flow vectors achieved better results. 3.2.6 Impact of redundancy elimination step To evaluate effectiveness of our redundancy elimination step, we compared the results of the methods presented in VISCOM [27], VRHDPS [28], VSUMM [14] after including proposed redundancy elimination step before summarization. Fig. 7 (a)-(f) shows the results of comparison. Results show that the methods achieved better accuracy when summarization is done using set of frames from which redundant frames are discarded. This is so because the features between consecutive frames are more discriminative when the redundant frames between two distinctive frames are eliminated. 3.2.7 Limitations and future work Though our method attained better results, it has some limitations. We were able to achieve an error factor of only 17.29 for sports videos. Even though this value is low compared to the error factor of the existing approaches, it still reveals the presence of some redundant frames in the output. This is mainly due to the presence of multiple redundant frames between two distinct frames and the displacement between these frames are too low compared to other categories of videos used for evaluation. The motion vectors used by the method failed to make these displacements more evident. The small displacements can be captured using other features which can represent the high-level characteristics of the video. The major concern in including such a step prior to summarization is that it raises the overall complexity of the summarization algorithm. Hence, the appropriate method should be chosen in such a way that the quality of the summaries generated are not compromised while maintaining the computational complexity in limited range. In our future work we plan to address this issue. 4 Conclusion We proposed a novel method for redundancy elimination from input videos using uniform sampling followed by SIFT Flow algorithm so that none of the keyframes is missed. This reduced set of frames which maintain content of the original video can be used for summarization. The approach achieved high reduction rate with less error factor and 0% Miss Rate. The method when tested on videos of different categories achieved promising results. The proposed method of redundancy elimination is applied on existing summarization methods to prove the impact of the step in the final results. Declarations Author contribution statement Jesna Mohan, Madhu S. Nair: Conceived and designed the experiments; Performed the experiments; Analyzed and interpreted the data; Contributed reagents, materials, analysis tools or data; Wrote the paper. Funding statement This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors. Competing interest statement The authors declare no conflict of interest. Additional information No additional information is available for this paper. References [1] S.S. Thomas S. Gupta K. Venkatesh Perceptual synoptic view-based video retrieval using metadata Signal Image Video Process. 11 2017 549 555 Thomas, S.S., Gupta, S., Venkatesh, K., 2017. Perceptual synoptic view-based video retrieval using metadata. Signal, Image and Video Processing 11, 549\u2013555. [2] M. Furini F. Geraci M. Montangero M. Pellegrini STIMO: STIll and MOving video storyboard for the web scenario Multimed. Tools Appl. 46 2010 47 69 Furini, M., Geraci, F., Montangero, M., Pellegrini, M., 2010. Stimo: Still and moving video storyboard for the web scenario. Multimedia Tools and Applications 46, 47\u201369. [3] L.I. Kuncheva P. Yousefi J. Almeida Edited nearest neighbour for selecting keyframe summaries of egocentric videos J. Vis. Commun. Image Represent. 52 2018 118 130 Kuncheva, L.I., Yousefi, P., Almeida, J., 2018. Edited nearest neighbour for selecting keyframe summaries of egocentric videos. Journal of Visual Communication and Image Representation 52, 118\u2013130. [4] Z. Gao G. Lu P. Yan L. Wang Retrospective analysis of time series for frame selection in surveillance video summarization Signal Image Video Process. 11 2017 581 588 Gao, Z., Lu, G., Yan, P., Wang, L., 2017. Retrospective analysis of time series for frame selection in surveillance video summarization. Signal, Image and Video Processing 11, 581\u2013588. [5] S.E. de Avila A. da Luz Jr A.d.A Ara\u00fajo M. Cord VSUMM: An approach for automatic video summarization and quantitative evaluation IEEE XXI Brazilian Symposium on Computer Graphics and Image Processing, 2008 SIBGRAPI'08 2008 103 110 de Avila, S.E., da Luz Jr, A., Ara\u00fajo, A.d.A., Cord, M., 2008. Vsumm: An approach for automatic video summarization and quantitative evaluation, in: Computer Graphics and Image Processing, 2008. SIBGRAPI'08. XXI Brazilian Symposium on, IEEE. pp. 103\u2013110. [6] N. Ejaz T.B. Tariq S.W. Baik Adaptive key frame extraction for video summarization using an aggregation mechanism J. Vis. Commun. Image Represent. 23 2012 1031 1040 Ejaz, N., Tariq, T.B., Baik, S.W., 2012. Adaptive key frame extraction for video summarization using an aggregation mechanism. Journal of Visual Communication and Image Representation 23, 1031\u20131040. [7] G. Guan Z. Wang S. Lu J. Da Deng D.D. Feng Keypoint-based keyframe selection IEEE Trans. Circuits Syst. Video Technol. 23 2013 729 734 Guan, G., Wang, Z., Lu, S., Da Deng, J., Feng, D.D., 2013. Keypoint-based keyframe selection. IEEE Transactions on circuits and systems for video technology 23, 729\u2013734. [8] R. Hannane A. Elboushaki K. Afdel P. Naghabhushan M. Javed An efficient method for video shot boundary detection and keyframe extraction using sift-point distribution histogram Int. J. Multimed. Inf. Retr. 5 2016 89 104 Hannane, R., Elboushaki, A., Afdel, K., Naghabhushan, P., Javed, M., 2016. An efficient method for video shot boundary detection and keyframe extraction using sift-point distribution histogram. International Journal of Multimedia Information Retrieval 5, 89\u2013104. [9] H.C. Chang C.K. Yang Fast content-aware video length reduction Signal Image Video Process. 8 2014 1383 1397 Chang, H.C., Yang, C.K., 2014. Fast content-aware video length reduction. Signal, Image and Video Processing 8, 1383\u20131397. [10] D. Zhu Y. Luo L. Dai X. Shao Q. Zhou L. Itti J. Lu Salient object detection via a local and global method based on deep residual network J. Vis. Commun. Image Represent. 54 2018 1 9 Zhu, D., Luo, Y., Dai, L., Shao, X., Zhou, Q., Itti, L., Lu, J., 2018. Salient object detection via a local and global method based on deep residual network. Journal of Visual Communication and Image Representation 54, 1\u20139. [11] B. Mahasseni M. Lam S. Todorovic Unsupervised video summarization with adversarial LSTM networks Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition CVPR 2017 Mahasseni, B., Lam, M., Todorovic, S., 2017. Unsupervised video summarization with adversarial lstm networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). [12] M. Fei W. Jiang W. Mao Memorable and rich video summarization J. Vis. Commun. Image Represent. 42 2017 207 217 Fei, M., Jiang, W., Mao, W., 2017. Memorable and rich video summarization. Journal of Visual Communication and Image Representation 42, 207\u2013217. [13] M. Ma S. Mei S. Wan Z. Wang D. Feng Video summarization via nonlinear sparse dictionary selection IEEE Access 7 2019 11763 11774 Ma, M., Mei, S., Wan, S., Wang, Z., Feng, D., 2019. Video summarization via nonlinear sparse dictionary selection. IEEE Access 7, 11763\u201311774. [14] S.E.F. De Avila A.P. Brand\u00e3o Lopes A. da Luz A. de Albuquerque Ara\u00fajo VSUMM: A mechanism designed to produce static video summaries and a novel evaluation method Pattern Recognit. Lett. 32 2011 56 68 De Avila, S.E.F., Lopes, Brand\u00e3o, A.P., da Luz, A., de Albuquerque Ara\u00fajo Arnaldo, 2011. Vsumm: A mechanism designed to produce static video summaries and a novel evaluation method. Pattern Recognition Letters 32, 56\u201368. [15] S.K. Kuanar R. Panda A.S. Chowdhury Video key frame extraction through dynamic Delaunay clustering with a structural constraint J. Vis. Commun. Image Represent. 24 2013 1212 1227 Kuanar, S.K., Panda, R., Chowdhury, A.S., 2013. Video key frame extraction through dynamic delaunay clustering with a structural constraint. Journal of Visual Communication and Image Representation 24, 1212\u20131227. [16] G.H. Song Q.G. Ji Z.M. Lu Z.D. Fang Z.H. Xie A novel video abstraction method based on fast clustering of the regions of interest in key frames AE\u00dc, Int. J. Electron. Commun. 68 2014 783 794 Song, G.H., Ji, Q.G., Lu, Z.M., Fang, Z.D., Xie, Z.H., 2014. A novel video abstraction method based on fast clustering of the regions of interest in key frames. AEU-International Journal of Electronics and Communications 68, 783\u2013794. [17] C. Chattopadhyay S. Das Use of trajectory and spatiotemporal features for retrieval of videos with a prominent moving foreground object Signal Image Video Process. 10 2016 319 326 Chattopadhyay, C., Das, S., 2016. Use of trajectory and spatiotemporal features for retrieval of videos with a prominent moving foreground object\u201d. Signal, Image and Video Processing 10, 319\u2013326. [18] D.M. Tsai W.Y. Chiu M.H. Lee Optical flow-motion history image (OF-MHI) for action recognition Signal Image Video Process. 9 2015 1897 1906 Tsai, D.M., Chiu, W.Y., Lee, M.H., 2015. Optical flow-motion history image (of-mhi) for action recognition. Signal, Image and Video Processing 9, 1897\u20131906. [19] K. Ta\u015fdemir A.E. Cetin Content-based video copy detection based on motion vectors estimated using a lower frame rate Signal Image Video Process. 8 2014 1049 1057 Ta\u015fdemir, K., Cetin, A.E., 2014. Content-based video copy detection based on motion vectors estimated using a lower frame rate. Signal, Image and Video Processing 8, 1049\u20131057. [20] D.G. Lowe Distinctive image features from scale-invariant keypoints Int. J. Comput. Vis. 60 2004 91 110 Lowe, D.G., 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision 60, 91\u2013110. [21] T. Brox A. Bruhn N. Papenberg J. Weickert High accuracy optical flow estimation based on a theory for warping European Conference on Computer Vision 2004 Springer 25 36 Brox, T., Bruhn, A., Papenberg, N., Weickert, J., 2004. High accuracy optical flow estimation based on a theory for warping, in: European conference on computer vision, Springer. pp. 25\u201336. [22] D. Sun S. Roth M.J. Black Secrets of optical flow estimation and their principles 2010 IEEE Conference on Computer Vision and Pattern Recognition CVPR 2010 2432 2439 Sun, D., Roth, S., Black, M.J., 2010. Secrets of optical flow estimation and their principles, in: Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE. pp. 2432\u20132439. [23] J. Pearl Fusion, propagation, and structuring in belief networks Artif. Intell. 29 1986 241 288 Pearl, J., 1986. Fusion, propagation, and structuring in belief networks. Artificial intelligence 29, 241\u2013288. [24] P.F. Felzenszwalb D.P. Huttenlocher Efficient belief propagation for early vision Int. J. Comput. Vis. 70 2006 41 54 Felzenszwalb, P.F., Huttenlocher, D.P., 2006. Efficient belief propagation for early vision. International journal of computer vision 70, 41\u201354. [25] F.F. Chamasemani L.S. Affendey N. Mustapha F. Khalid Video abstraction using density-based clustering algorithm Vis. Comput. 2017 1 16 Chamasemani, F.F., Affendey, L.S., Mustapha, N., Khalid, F., 2017. Video abstraction using density-based clustering algorithm. The Visual Computer , 1\u201316. [26] H. Zhang Y. Wang L. Luo X. Lu M. Zhang Sift flow for abrupt motion tracking via adaptive samples selection with sparse representation Neurocomputing 249 2017 253 265 Zhang, H., Wang, Y., Luo, L., Lu, X., Zhang, M., 2017. Sift flow for abrupt motion tracking via adaptive samples selection with sparse representation. Neurocomputing 249, 253\u2013265. [27] M.V.M. Cirne H. Pedrini VISCOM: A robust video summarization approach using color co-occurrence matrices Multimed. Tools Appl. 2017 1 19 Cirne, M.V.M., Pedrini, H., 2017. Viscom: A robust video summarization approach using color co-occurrence matrices. Multimedia Tools and Applications , 1\u201319. [28] J. Wu S.h. Zhong J. Jiang Y. Yang A novel clustering method for static video summarization Multimed. Tools Appl. 76 2016 1 17 Wu, J., Zhong, S.h., Jiang, J., Yang, Y., 2016. A novel clustering method for static video summarization. Multimedia Tools and Applications 76, 1\u201317.", "coredata": {"eid": "1-s2.0-S2405844019363595", "dc:description": "Abstract Video summarization aims to find a compact representation of input videos. The method finds out interesting parts of the video by discarding the remaining parts of the video. The abstracts thus generated enhances browsing and retrieval of video data. The quality of summaries generated by video summarization algorithms can be improved if the redundant frames in the input video are taken care of before summarization. This paper presents a novel domain-independent method for redundancy elimination from input videos before summarization maintaining keyframes in the original video. The frames of input video are first presampled by selecting two frames in one second. The flow vectors between consecutive frames are computed using SIFT Flow algorithm. The magnitude of flow vectors at each pixel position of the frame are summed up to find the displacement magnitude between the consecutive frames. The redundant frames are filtered out based on local averaging of the displacement values. The evaluation of the method is done using two standard datasets namely VSUMM and OVP. The results demonstrate that an average reduction rate of 97.64% is achieved consistently on videos of all categories. The method also gives superior results compared to other state-of-the-art redundancy elimination methods for video summarization", "openArchiveArticle": "false", "prism:coverDate": "2019-10-31", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S2405844019363595", "dc:creator": [{"@_fa": "true", "$": "Mohan, Jesna"}, {"@_fa": "true", "$": "Nair, Madhu S."}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S2405844019363595"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S2405844019363595"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S2405-8440(19)36359-5", "prism:volume": "5", "articleNumber": "e02699", "prism:publisher": "The Authors. Published by Elsevier Ltd.", "dc:title": "Domain independent redundancy elimination based on flow vectors for static video summarization", "prism:copyright": "\u00a9 2019 The Authors. Published by Elsevier Ltd.", "openaccess": "1", "prism:issn": "24058440", "prism:issueIdentifier": "10", "dcterms:subject": [{"@_fa": "true", "$": "Computer science"}, {"@_fa": "true", "$": "Video summarization"}, {"@_fa": "true", "$": "Keyframes"}, {"@_fa": "true", "$": "SIFT flow"}, {"@_fa": "true", "$": "Uniform sampling"}, {"@_fa": "true", "$": "Dual Layer Loopy Belief Propagation Network (DLBPN)"}], "openaccessArticle": "true", "prism:publicationName": "Heliyon", "prism:number": "10", "openaccessSponsorType": "Author", "prism:pageRange": "e02699", "pubType": "Research article", "prism:coverDisplayDate": "October 2019", "prism:doi": "10.1016/j.heliyon.2019.e02699", "prism:startingPage": "e02699", "dc:identifier": "doi:10.1016/j.heliyon.2019.e02699", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "standard", "@height": "152", "@width": "452", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr001.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "19415", "@ref": "gr001", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "387", "@width": "816", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr003.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "65425", "@ref": "gr003", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "594", "@width": "362", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr004.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "43112", "@ref": "gr004", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "267", "@width": "343", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr005.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "15991", "@ref": "gr005", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "195", "@width": "379", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr006.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "13715", "@ref": "gr006", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "436", "@width": "435", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr007.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "39775", "@ref": "gr007", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "732", "@width": "432", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr008.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "74094", "@ref": "gr008", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "311", "@width": "374", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr002.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "16778", "@ref": "gr002", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "74", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr001.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5024", "@ref": "gr001", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "104", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr003.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4805", "@ref": "gr003", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "100", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr004.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4205", "@ref": "gr004", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "211", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr005.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7532", "@ref": "gr005", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "112", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr006.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4646", "@ref": "gr006", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "163", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr007.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6434", "@ref": "gr007", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "96", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr008.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "4765", "@ref": "gr008", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "197", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr002.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7392", "@ref": "gr002", "@mimetype": "image/gif"}, {"@category": "high", "@height": "673", "@width": "2004", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr001_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "164532", "@ref": "gr001", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1028", "@width": "2168", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr003_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "265826", "@ref": "gr003", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2631", "@width": "1603", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr004_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "289906", "@ref": "gr004", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1181", "@width": "1519", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr005_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "124579", "@ref": "gr005", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "861", "@width": "1677", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr006_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "100042", "@ref": "gr006", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1931", "@width": "1927", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr007_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "281958", "@ref": "gr007", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "3242", "@width": "1914", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr008_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "511161", "@ref": "gr008", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2755", "@width": "3315", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-gr002_lrg.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-HIGH-RES", "@size": "89898", "@ref": "gr002", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si1.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "5967", "@ref": "si1", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si10.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2043", "@ref": "si10", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si11.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3466", "@ref": "si11", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si12.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3537", "@ref": "si12", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si13.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "7144", "@ref": "si13", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si14.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "10316", "@ref": "si14", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si15.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3533", "@ref": "si15", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si16.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "5016", "@ref": "si16", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si17.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4548", "@ref": "si17", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si18.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "5190", "@ref": "si18", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si19.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "8713", "@ref": "si19", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si2.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "1897", "@ref": "si2", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si20.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4838", "@ref": "si20", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si21.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4316", "@ref": "si21", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si22.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "11577", "@ref": "si22", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si23.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "13233", "@ref": "si23", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si24.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2150", "@ref": "si24", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si25.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "1872", "@ref": "si25", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si26.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2507", "@ref": "si26", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si27.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4782", "@ref": "si27", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si28.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2240", "@ref": "si28", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si3.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2917", "@ref": "si3", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si30.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2019", "@ref": "si30", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si31.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2045", "@ref": "si31", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si32.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3538", "@ref": "si32", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si33.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2114", "@ref": "si33", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si34.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3312", "@ref": "si34", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si35.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2535", "@ref": "si35", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si36.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3917", "@ref": "si36", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si37.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2035", "@ref": "si37", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si38.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2938", "@ref": "si38", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si39.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "27759", "@ref": "si39", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si4.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2944", "@ref": "si4", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si40.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2363", "@ref": "si40", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si41.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3667", "@ref": "si41", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si42.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3935", "@ref": "si42", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si43.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "17329", "@ref": "si43", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si44.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4762", "@ref": "si44", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si45.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3657", "@ref": "si45", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si46.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3670", "@ref": "si46", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si47.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "11553", "@ref": "si47", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si48.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4316", "@ref": "si48", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si49.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "8657", "@ref": "si49", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si5.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2625", "@ref": "si5", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si50.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "7746", "@ref": "si50", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si51.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "7473", "@ref": "si51", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si52.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "1814", "@ref": "si52", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si53.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4257", "@ref": "si53", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si54.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "12301", "@ref": "si54", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si55.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "14148", "@ref": "si55", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si56.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "11861", "@ref": "si56", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si57.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "6020", "@ref": "si57", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si58.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4910", "@ref": "si58", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si59.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4337", "@ref": "si59", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si60.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "6067", "@ref": "si60", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si61.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3275", "@ref": "si61", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si62.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "4258", "@ref": "si62", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si63.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3241", "@ref": "si63", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si64.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "3522", "@ref": "si64", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si65.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2826", "@ref": "si65", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si7.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2857", "@ref": "si7", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si8.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "1973", "@ref": "si8", "@mimetype": "image/svg+xml"}, {"@category": "thumbnail", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S2405844019363595-si9.svg?httpAccept=%2A%2F%2A", "@multimediatype": "Scalable Vector Graphics file", "@type": "ALTIMG", "@size": "2496", "@ref": "si9", "@mimetype": "image/svg+xml"}]}}
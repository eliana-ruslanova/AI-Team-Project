{"scopus-eid": "2-s2.0-85027532546", "originalText": "serial JL 272371 291210 291682 291870 291901 31 Journal of Biomedical Informatics JOURNALBIOMEDICALINFORMATICS 2015-02-10 2015-02-10 2015-04-17T08:48:12 1-s2.0-S1532046415000192 S1532-0464(15)00019-2 S1532046415000192 10.1016/j.jbi.2015.02.001 S300 S300.1 FULL-TEXT 1-s2.0-S1532046415X00037 2016-03-31T20:12:22.638923-04:00 0 0 20150401 20150430 2015 2015-02-10T04:44:35.136407Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight openaccess openarchive pg pgfirst pglast pii piinorm pubdateend pubdatestart pubdatetxt pubyr sectiontitle sortorder srctitle srctitlenorm srctype ssids alllist content subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table body mmlmath acknowledge affil articletitle auth authfirstini authfull authkeywords authlast grantsponsor grantsponsorid highlightsabst primabst ref specialabst 1532-0464 15320464 true 54 54 C Volume 54 23 220 229 220 229 201504 April 2015 2015-04-01 2015-04-30 2015 Original research papers article fla Copyright \u00a9 2015 Elsevier Inc. All rights reserved. IMPROVEDELECTROMAGNETISMLIKEMECHANISMALGORITHMAPPLICATIONPREDICTIONDIABETESMELLITUS WANG K 1 Introduction 2 Related literature 2.1 Feature selection problem 2.2 Electromagnetism-like mechanism algorithm 2.3 Nearest neighbor classifier (1NN) 2.4 Opposite sign test (OST) 2.5 Feature selection and classification methods 3 The proposed improved electromagnetism like mechanism 3.1 Particle representation 3.2 Fitness measurement 4 Experiments and results 4.1 Experimental framework 4.1.1 Dataset 4.1.1.1 UCI dataset 4.1.1.2 Gestational diabetes mellitus dataset 4.1.2 Experiment setting 4.1.3 Benchmark methods 4.1.4 Statistical test method for performance comparisons 4.2 Results 4.3 Discussion 5 Conclusion Acknowledgments References ALMUALLIM 1994 279 305 H BACHE 2013 K UCIMACHINELEARNINGREPOSITORY BAN 2010 H BENDAVID 2007 875 885 A BIRBIL 2003 263 282 I BLUM 1992 117 127 A BROADINSTITUTETCGAGENOMEDATAANALYSISCENTER 2013 CANCERPROGRAMDATASETS CHANDRA 2011 529 535 B CHEN 2012 167 182 L CHO 2008 37 53 B CORTES 1995 273 297 C COVER 1967 21 27 T DANAEI 2011 31 40 G DEHAROGARCIA 2012 58 77 A DEMSAR 2006 1 30 J GREENOP 2014 493 498 K HALL 2009 M HUANG 2007 251 262 Y KAWABE 2004 148 155 T KOHONEN 1982 59 69 T KOHAVI 1997 273 324 R LIN 2013 95 102 H METZGER 1993 1598 1605 B PARK 1991 246 257 J PENG 2010 15 23 Y POGGIO 1990 1481 1497 T QUINLAN 1993 J C45PROGRAMSFORMACHINELEARNING RUMELHART 1986 533 536 D SINGER 2014 4 14 E SHOUMAN 2012 220 223 M STEHMAN 1997 77 89 S SU 2011 972 986 C SU 2009 192 205 C TSAI 2013 240 247 C WANG 2012 2651 2654 G WANG 2014 126 145 K WITTEN 2005 I DATAMININGPRACTICALMACHINELEARNINGTOOLSTECHNIQUES YAN 2014 379 391 A YIN 2007 H PRINCIPALMANIFOLDSFORDATAVISUALIZATIONDIMENSIONREDUCTION LEARNINGNONLINEARPRINCIPALMANIFOLDSBYSELFORGANISINGMAPS YUEN 2011 1667 1686 C WANGX2015X220 WANGX2015X220X229 WANGX2015X220XK WANGX2015X220X229XK Full 2016-04-01T00:00:47Z OA-Window ElsevierBranded http://www.elsevier.com/open-access/userlicense/1.0/ item S1532-0464(15)00019-2 S1532046415000192 1-s2.0-S1532046415000192 10.1016/j.jbi.2015.02.001 272371 2015-04-17T05:00:58.95683-04:00 2015-04-01 2015-04-30 1-s2.0-S1532046415000192-main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/MAIN/application/pdf/9fc75aed7b32601f3329071511ffd43d/main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/MAIN/application/pdf/9fc75aed7b32601f3329071511ffd43d/main.pdf main.pdf pdf true 1108225 MAIN 10 1-s2.0-S1532046415000192-main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/PREVIEW/image/png/a67d33be0d9c234fda2042b98bb34794/main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/PREVIEW/image/png/a67d33be0d9c234fda2042b98bb34794/main_1.png main_1.png png 62084 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1532046415000192-si14.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/059656ee46bcdd7677df20f222918698/si14.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/059656ee46bcdd7677df20f222918698/si14.gif si14 si14.gif gif 1587 43 261 ALTIMG 1-s2.0-S1532046415000192-si13.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/2fd5af60965affe755dd43cc89288d3a/si13.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/2fd5af60965affe755dd43cc89288d3a/si13.gif si13 si13.gif gif 1308 39 232 ALTIMG 1-s2.0-S1532046415000192-si2.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/fa1f01f6db178dd5ce744244d3f91f96/si2.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/fa1f01f6db178dd5ce744244d3f91f96/si2.gif si2 si2.gif gif 2622 64 310 ALTIMG 1-s2.0-S1532046415000192-si1.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/df161951a84eef62bf2223eaf0e80204/si1.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/df161951a84eef62bf2223eaf0e80204/si1.gif si1 si1.gif gif 2132 45 332 ALTIMG 1-s2.0-S1532046415000192-si9.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/beb142d19103d19bd1a79c7444677390/si9.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/beb142d19103d19bd1a79c7444677390/si9.gif si9 si9.gif gif 426 17 62 ALTIMG 1-s2.0-S1532046415000192-si8.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/fdeb9932d2c591d723458ccf0d076d44/si8.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/fdeb9932d2c591d723458ccf0d076d44/si8.gif si8 si8.gif gif 434 19 70 ALTIMG 1-s2.0-S1532046415000192-si7.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/f621ce8d80bf0352c46af5fa92d25c32/si7.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/f621ce8d80bf0352c46af5fa92d25c32/si7.gif si7 si7.gif gif 373 17 52 ALTIMG 1-s2.0-S1532046415000192-si6.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/860f4fefac47d4d55ce256075f9094c1/si6.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/860f4fefac47d4d55ce256075f9094c1/si6.gif si6 si6.gif gif 325 15 43 ALTIMG 1-s2.0-S1532046415000192-si5.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/9d11d7dab3c58922ff6f3f5edb17bfde/si5.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/9d11d7dab3c58922ff6f3f5edb17bfde/si5.gif si5 si5.gif gif 411 18 54 ALTIMG 1-s2.0-S1532046415000192-si4.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/1f9733b125b8304c6bebb99eff423330/si4.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/1f9733b125b8304c6bebb99eff423330/si4.gif si4 si4.gif gif 295 14 41 ALTIMG 1-s2.0-S1532046415000192-si3.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/3589f0dccec6247100f9eda82debaf95/si3.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/3589f0dccec6247100f9eda82debaf95/si3.gif si3 si3.gif gif 397 18 61 ALTIMG 1-s2.0-S1532046415000192-si12.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/d180176d2d0f9528d70ec72b74db2784/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/d180176d2d0f9528d70ec72b74db2784/si12.gif si12 si12.gif gif 318 19 34 ALTIMG 1-s2.0-S1532046415000192-si11.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/d180176d2d0f9528d70ec72b74db2784/si12.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/d180176d2d0f9528d70ec72b74db2784/si12.gif si11 si11.gif gif 318 19 34 ALTIMG 1-s2.0-S1532046415000192-si10.gif https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/STRIPIN/image/gif/37155f14788f554acd854921e85256a5/si10.gif https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/STRIPIN/image/gif/37155f14788f554acd854921e85256a5/si10.gif si10 si10.gif gif 952 19 181 ALTIMG 1-s2.0-S1532046415000192-gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr1/HIGHRES/image/jpeg/876535373d426dd21976f3cef25f39d8/gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr1/HIGHRES/image/jpeg/876535373d426dd21976f3cef25f39d8/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 38601 521 984 IMAGE-HIGH-RES 1-s2.0-S1532046415000192-fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/fx1/HIGHRES/image/jpeg/ffc92e666ae05c79468b134bca8231ab/fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/fx1/HIGHRES/image/jpeg/ffc92e666ae05c79468b134bca8231ab/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 227441 876 2213 IMAGE-HIGH-RES 1-s2.0-S1532046415000192-gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr4/HIGHRES/image/jpeg/6da90dbc8c399d95f347128ca5bfbe3b/gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr4/HIGHRES/image/jpeg/6da90dbc8c399d95f347128ca5bfbe3b/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 189551 2974 1124 IMAGE-HIGH-RES 1-s2.0-S1532046415000192-gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr3/HIGHRES/image/jpeg/f40de1a2130c0e4eb75ac0df0ea9e103/gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr3/HIGHRES/image/jpeg/f40de1a2130c0e4eb75ac0df0ea9e103/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 342298 2506 1183 IMAGE-HIGH-RES 1-s2.0-S1532046415000192-gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr2/HIGHRES/image/jpeg/09cc2cdc9c20e3ad0e59219d2ffacc95/gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr2/HIGHRES/image/jpeg/09cc2cdc9c20e3ad0e59219d2ffacc95/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 254407 1348 1720 IMAGE-HIGH-RES 1-s2.0-S1532046415000192-gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr1/DOWNSAMPLED/image/jpeg/cd652c5574a273008a857c19a55a5b9e/gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr1/DOWNSAMPLED/image/jpeg/cd652c5574a273008a857c19a55a5b9e/gr1.jpg gr1 gr1.jpg jpg 13541 118 222 IMAGE-DOWNSAMPLED 1-s2.0-S1532046415000192-fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/fx1/DOWNSAMPLED/image/jpeg/0f14d81cf7d303a66150a00bd800df42/fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/fx1/DOWNSAMPLED/image/jpeg/0f14d81cf7d303a66150a00bd800df42/fx1.jpg fx1 true fx1.jpg jpg 33614 198 500 IMAGE-DOWNSAMPLED 1-s2.0-S1532046415000192-gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr4/DOWNSAMPLED/image/jpeg/95159cbe92491e8584148d3837450859/gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr4/DOWNSAMPLED/image/jpeg/95159cbe92491e8584148d3837450859/gr4.jpg gr4 gr4.jpg jpg 25128 672 254 IMAGE-DOWNSAMPLED 1-s2.0-S1532046415000192-gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr3/DOWNSAMPLED/image/jpeg/c09b3513420d7f85ecaca2b91cebe96d/gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr3/DOWNSAMPLED/image/jpeg/c09b3513420d7f85ecaca2b91cebe96d/gr3.jpg gr3 gr3.jpg jpg 93923 943 445 IMAGE-DOWNSAMPLED 1-s2.0-S1532046415000192-gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr2/DOWNSAMPLED/image/jpeg/3f8dacc44261fb4c98e828bf6f0847cf/gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr2/DOWNSAMPLED/image/jpeg/3f8dacc44261fb4c98e828bf6f0847cf/gr2.jpg gr2 gr2.jpg jpg 89002 435 555 IMAGE-DOWNSAMPLED 1-s2.0-S1532046415000192-gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr1/THUMBNAIL/image/gif/9860674787fdc54bef0e4e0f30dda548/gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr1/THUMBNAIL/image/gif/9860674787fdc54bef0e4e0f30dda548/gr1.sml gr1 gr1.sml sml 2058 116 219 IMAGE-THUMBNAIL 1-s2.0-S1532046415000192-fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/fx1/THUMBNAIL/image/gif/36c03dc742915af175889b46f434edd9/fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/fx1/THUMBNAIL/image/gif/36c03dc742915af175889b46f434edd9/fx1.sml fx1 true fx1.sml sml 5075 87 219 IMAGE-THUMBNAIL 1-s2.0-S1532046415000192-gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr4/THUMBNAIL/image/gif/7f8d739148dc21a9345703105b03348f/gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr4/THUMBNAIL/image/gif/7f8d739148dc21a9345703105b03348f/gr4.sml gr4 gr4.sml sml 2719 164 62 IMAGE-THUMBNAIL 1-s2.0-S1532046415000192-gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr3/THUMBNAIL/image/gif/5534d00f0e763c9405fc33a15cbf42d4/gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr3/THUMBNAIL/image/gif/5534d00f0e763c9405fc33a15cbf42d4/gr3.sml gr3 gr3.sml sml 2254 163 77 IMAGE-THUMBNAIL 1-s2.0-S1532046415000192-gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1532046415000192/gr2/THUMBNAIL/image/gif/b58054838e6343424de95c8b113544e4/gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1532046415000192/gr2/THUMBNAIL/image/gif/b58054838e6343424de95c8b113544e4/gr2.sml gr2 gr2.sml sml 7439 164 209 IMAGE-THUMBNAIL YJBIN 2294 S1532-0464(15)00019-2 10.1016/j.jbi.2015.02.001 Elsevier Inc. Fig. 1 Attraction and repulsion mechanism in EM. Fig. 2 An example of ROST. Fig. 3 The IEM algorithm for feature selection. Fig. 4 IEM flowchart for feature selection. Table 1 Summarization of dataset characteristics. No. Dataset Abbreviation Number of instances Number of attributes Number of classes UCI & KEEL 1 Abalone ABA 4177 8 3 2 Appendicitis APP 106 7 2 3 Australian AUS 690 14 2 4 Balance BAL 625 4 3 5 Banana BAN 5300 2 2 6 Wisconsin WIS 699 9 2 7 Bupa BUP 343 6 2 8 Chess CHE 3196 36 2 9 Coil-ticdata2000 COI 5822 85 2 10 CMC CMC 1473 9 3 11 Dermatology DER 366 34 6 12 Ecoli ECO 336 7 8 13 Glass GLA 214 9 6 14 Haberman HAB 306 3 2 15 Heart-Statlog HEA 270 13 2 16 Ionosphere ION 351 34 2 17 Iris IRI 150 4 3 18 Led7digit LED 500 7 10 19 Letter-recognition LET 20,000 16 26 20 Lung-cancer LUN 32 56 3 21 Mfeatures MFE 2000 649 10 22 Monk-2 MON 432 7 2 23 Movement-libras MOV 360 91 15 24 New-thyroid NEW 215 5 3 25 Page-blocks PAG 5473 10 5 26 Phoneme PHO 5404 5 2 27 Pima indian PIM 768 8 2 28 Post-operative POS 90 8 3 29 Ringnorm RIN 7400 20 2 30 Saheart SAH 462 9 2 31 Satimage SAT 4435 36 6 32 Segmentation SEG 2310 19 7 33 Shuttle SHU 101,500 9 7 34 Sonar SON 208 60 2 35 Spambase SPA 4601 57 2 36 Spect_train SPT 267 22 2 37 Spectf SPF 269 44 2 38 TAE TAE 151 5 3 39 Texture TEX 5500 40 11 40 Tictactoe TIC 958 9 2 41 Titanic TIT 24 3 2 42 Twonorm TWO 7400 20 2 43 Vehicle VEH 846 18 4 44 Vowel VOW 990 13 11 45 Waveform WAV 5000 40 3 46 Wine WIN 178 13 3 Microarray 1 ALLAML ALL 72 7129 2 2 Breast Cancer BCA 174 9182 11 3 Carcinoma CAR 50 4435 4 4 DLBCL DLB 203 3312 4 5 GLIOMA GLI 102 5966 2 6 LUNG LUN 89 15,154 2 7 PROSTATE_GE PGE 78 24,481 2 8 PROSTATE_MS PMS 58 7129 2 Table 2 Factors for GDM case. Code Attribute Description F 1 Maternal age F 2 50-g oral glucose challenge test value Test on the 24th to 28th week of gestation; If result \u2a7e140mg/dL proceed F 6 F 3 Fasting glucose value GDM suspect if \u2a7e105mg/dL F 4 1-h 100-g oral glucose tolerance test value GDM suspect if \u2a7e190mg/dL F 5 2-h 100-g oral glucose tolerance test value GDM suspect if \u2a7e165mg/dL F 6 3-h 100-g oral glucose tolerance test value GDM suspect if \u2a7e145mg/dL F 7 Body mass index before pregnancy F 8 Weight before pregnancy F 9 Weight gain during pregnancy F 10 Weight of neonate F 11 Family history of DM F 12 The number of pregnancy times Table 3 Classification accuracy and kappa index of 9 methods on the 54 datasets (unit: %). Dataset IGA EM-1NN IEM SVM BPNN LR C4.5 RBF SOM LVQ Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. ABA 51.76 0.2714 49.68 0.2429 54.68 0.3168 54.30 0.2973 36.58 0.0000 55.54 0.3301 52.81 0.2886 53.34 0.295 52.33 0.2763 51.71 0.2727 APP 88.68 0.6162 85.85 0.5625 89.74 0.6760 87.74 0.5586 85.85 0.5293 85.85 0.5108 85.85 0.5108 83.96 0.4228 75.47 0.5161 85.85 0.5293 AUS 86.53 0.7284 82.03 0.6366 88.67 0.7495 85.51 0.7116 84.93 0.6937 86.96 0.7373 85.22 0.6997 82.75 0.6457 67.25 0.3122 66.23 0.2919 BAL 89.28 0.8043 80.16 0.6430 89.84 0.8052 88.32 0.7834 58.56 0.2315 89.60 0.8204 76.64 0.5773 87.20 0.7658 73.44 0.5091 84.80 0.7228 BAN 88.30 0.7625 86.96 0.7366 90.15 0.8001 55.17 0.0000 71.75 0.4017 55.89 0.0397 89.15 0.7790 73.70 0.4601 82.26 0.6365 85.55 0.7047 WIS 97.00 0.9337 95.28 0.8952 99.42 0.9509 97.00 0.9337 95.28 0.8958 96.57 0.9240 94.56 0.8799 95.85 0.9093 95.99 0.9177 95.85 0.9077 BUP 64.35 0.2621 62.029 0.2317 77.61 0.4763 60.29 0.1571 66.96 0.3128 72.17 0.4246 64.93 0.2863 61.74 0.2148 54.20 0.0624 63.77 0.2457 CHE 95.37 0.9072 93.2103 0.8637 96.36 0.9519 95.84 0.9166 99.28 0.9856 97.43 0.9486 97.90 0.9580 68.24 0.3476 65.64 0.3091 85.61 0.7111 COI 93.99 0.0629 90.4328 0.0561 94.02 0.0000 93.99 \u22120.0007 91.65 0.0999 93.73 0.0135 93.89 0.0168 94.02 0.0000 94.01 0.0000 93.95 \u22120.0014 CMC 48.47 0.1738 44.9423 0.1416 52.56 0.2212 42.70 0.0000 34.96 0.0000 42.70 0.0000 48.13 0.2000 48.47 0.1887 47.93 0.1495 50.92 0.2171 DER 96.45 0.9556 93.7158 0.9215 98.45 0.9756 96.45 0.9554 97.54 0.9692 98.09 0.9760 95.90 0.9488 95.08 0.9385 31.42 0.0169 56.01 0.4315 ECO 86.31 0.8088 78.2738 0.7003 86.31 0.8102 83.63 0.7708 85.71 0.8029 86.31 0.8111 84.23 0.7826 84.52 0.7862 76.19 0.702 81.25 0.7384 GLA 85.12 0.7956 70.0935 0.5951 85.56 0.8005 55.61 0.3496 67.29 0.5466 64.02 0.507 66.82 0.55 64.02 0.5039 63.55 0.5088 62.15 0.4626 HAB 74.84 0.1905 71.2418 0.1767 77.86 0.2497 73.53 0.0000 72.88 0.206 74.84 0.1657 71.90 0.1882 74.18 0.1527 73.86 0.2311 68.63 0.0774 HEA 82.22 0.6400 76.6667 0.5287 91.15 0.8464 81.48 0.6231 77.41 0.5444 83.70 0.6683 76.67 0.5271 84.07 0.6767 61.48 0.256 62.59 0.2303 ION 92.02 0.8210 86.3248 0.6817 100.00 1.0000 88.60 0.7406 91.17 0.8008 88.89 0.7530 91.45 0.8096 92.31 0.8337 80.06 0.5872 85.19 0.6539 IRI 97.33 0.9600 95.3333 0.93 97.00 0.9677 96.00 0.9400 97.33 0.9600 96.00 0.9400 96.00 0.94 95.33 0.93 90.00 0.9463 96.00 0.9400 LED 83.19 0.7153 70.8 0.6752 83.80 0.7152 73.80 0.7086 70.20 0.6685 74.00 0.7108 71.20 0.6796 69.80 0.6641 66.00 0.6298 61.60 0.5725 LET 87.48 0.8697 92.395 0.9209 96.07 0.9591 82.48 0.8178 81.09 0.8033 77.30 0.7639 88.05 0.8757 \u2013 \u2013 15.71 0.1231 18.38 0.1511 LUN 62.50 0.4311 46.875 0.1881 100.00 1.0000 50.00 0.2482 43.75 0.1504 34.38 0.003 40.63 0.0979 53.12 0.3023 25.00 0.2381 56.25 0.3353 MFE 81.93 0.5932 78.7171 0.526 97.53 0.8832 79.15 0.5198 85.87 0.6776 79.11 0.5174 85.06 0.6614 78.43 0.4916 69.88 0.2211 75.42 0.3999 MON 69.21 0.2723 72.4537 0.2664 83.80 0.6355 67.13 0 80.79 0.5805 66.20 \u22120.0183 80.05 0.663 63.43 0.0362 64.35 \u22120.0181 69.68 0.2345 MOV 42.22 0.3810 86.1111 0.8512 86.39 0.8542 74.72 0.7292 80.56 0.7917 68.61 0.6637 69.72 0.6756 76.67 0.75 33.89 0.2958 37.50 0.3304 NEW 96.74 0.9307 97.2093 0.9403 98.21 0.9477 89.77 0.7515 96.74 0.9307 96.74 0.9292 92.09 0.8298 95.35 0.8993 81.86 0.6933 89.30 0.7416 PAG 93.50 0.5927 95.8889 0.7764 96.05 0.7842 92.93 0.467 96.05 0.7772 96.46 0.8026 96.25 0.7964 94.87 0.7221 89.69 0.0034 90.83 0.2862 PHO 93.06 0.5954 89.2302 0.7353 93.27 0.7605 77.24 0.4366 80.98 0.5489 75.07 0.3591 86.42 0.6765 77.70 0.4492 78.16 0.4698 79.05 0.5121 PIM 76.69 0.4603 69.1406 0.307 75.13 0.4014 76.56 0.4579 75.13 0.4445 77.21 0.4734 73.83 0.4164 75.39 0.4303 71.22 0.3729 72.79 0.3399 POS 71.11 0.0813 63.3333 \u22120.0171 92.95 0.5613 68.89 \u22120.0048 57.78 \u22120.028 65.56 0.0085 67.78 0.0057 63.33 0.031 63.33 \u22120.0987 64.44 0.0003 RIN 94.28 0.8856 76.2432 0.5226 94.88 0.8951 77.11 0.5413 91.88 0.8375 76.36 0.5268 91.30 0.8259 50.49 0.0000 75.89 0.5173 63.20 0.1392 SAH 72.51 0.3519 61.9048 0.1331 77.73 0.4186 71.00 0.3319 67.10 0.2328 72.51 0.3639 70.78 0.328 68.83 0.2754 62.77 0.1687 63.20 0.1392 SAT 87.42 0.8438 89.7858 0.8738 92.10 0.8877 86.56 0.8329 86.75 0.8408 85.93 0.825 86.07 0.8273 84.94 0.8133 81.71 0.7717 74.24 0.6995 SEG 90.82 0.8929 97.2727 0.9682 98.10 0.9762 93.07 0.9192 96.06 0.954 95.89 0.952 96.93 0.9641 87.19 0.8505 63.25 0.5712 94.15 0.8264 SHU 99.98 0.9994 99.74 0.9927 99.98 0.9994 97.02 0.9162 99.74 0.9927 96.85 0.9105 99.99 0.9996 97.88 0.9406 96.38 0.9028 78.37 0.5599 SON 92.93 0.9196 84.6154 0.6877 96.50 0.9379 75.96 0.5164 82.21 0.6419 73.08 0.4584 71.15 0.422 72.12 0.4455 54.33 0.1771 69.98 0.3393 SPA 88.50 0.7576 90.263 0.7959 90.78 0.8068 74.59 0.4078 84.69 0.6931 92.41 0.8402 88.31 0.754 80.66 0.6100 72.09 0.4028 79.78 0.3899 SPT 89.30 0.6173 79.0262 0.3674 91.90 0.6200 82.40 0.4353 91.22 0.8152 81.27 0.4197 80.90 0.3872 80.52 0.3965 74.53 0.3809 79.78 0.3899 SPF 83.27 0.4008 73.2342 0.3001 95.04 0.7368 79.55 0.0000 79.40 0.3827 80.30 0.4141 74.72 0.1786 79.93 0.3082 74.35 0.2101 80.30 0.3551 TAE 52.98 0.2945 65.5629 0.4829 72.25 0.4338 53.64 0.306 70.58 0.2999 54.30 0.3160 58.28 0.3737 52.98 0.2951 41.72 0.1507 44.37 0.1654 TEX 93.73 0.9310 98.8545 0.9874 98.96 0.9886 83.11 0.8142 47.02 0.2067 92.15 0.9136 93.13 0.9244 88.51 0.8736 61.76 0.5794 73.05 0.7036 TIC 91.91 0.9110 81.0021 0.5352 91.91 0.9110 65.34 0.0000 81.52 0.5653 69.42 0.2089 88.52 0.7417 69.21 0.2656 67.75 0.1806 78.39 0.4807 TIT 58.33 0.4167 20.8333 \u22120.6056 86.09 0.7190 54.17 \u22120.0476 25.00 0.5429 54.17 0.0435 58.33 0.0000 20.83 \u22120.6056 25.00 \u22120.5575 20.83 \u22120.6056 TWO 97.55 0.9511 93.6351 0.8727 97.36 0.9473 97.80 0.9559 97.24 0.9449 97.78 0.9557 85.28 0.7057 97.65 0.953 97.36 0.9473 53.66 0.3824 VEH 69.03 0.5874 69.1489 0.5885 80.86 0.7980 74.47 0.6597 80.51 0.7466 79.79 0.7304 72.58 0.6343 66.67 0.5559 48.35 0.3134 53.66 0.000 VOW 98.18 0.9800 98.8889 0.9878 99.29 0.9922 69.49 0.6644 84.65 0.8311 69.19 0.6611 81.82 0.8000 83.64 0.8200 16.06 0.0770 31.01 0.2411 WAV 82.72 0.7408 73.84 0.6075 83.12 0.7469 72.04 0.5817 33.62 0.1479 75.24 0.6288 75.08 0.6262 85.16 0.7775 83.72 0.7560 82.44 0.7368 WIN 97.75 0.9363 96.6292 0.949 97.63 0.9666 95.51 0.9318 26.97 0.0000 97.19 0.9574 93.82 0.9058 98.31 0.9743 61.80 0.4633 74.16 0.6102 ALL 96.61 0.9491 96.61 0.9491 98.81 0.9748 96.61 0.9491 70.83 0.3854 90.28 0.7875 79.17 0.5361 93.06 0.8482 54.17 0.4091 77.78 0.5004 BCA 95.92 0.8972 100.00 1.0000 100.00 1.0000 57.89 0.2323 36.84 0.0000 78.95 0.5476 73.68 0.5078 36.84 0.5234 36.84 0.000 36.84 0.000 CAR 90.72 0.9563 91.52 0.9399 95.23 0.9977 93.10 0.9221 13.22 \u22120.0245 94.25 0.9352 77.59 0.7467 81.61 0.7911 58.62 0.5997 72.99 0.6932 DLB 50.00 0.0210 100.00 1.0000 100.00 1.0000 55.17 0.0805 46.55 \u22120.1252 50.00 \u22120.0686 53.45 0.0756 41.38 \u22120.1851 53.45 0.3941 55.17 0.1066 GLI 90.77 0.8751 88.55 0.7933 93.92 0.9285 76.00 0.6714 24.00 \u22120.0795 68.00 0.5647 58.00 0.4269 70.00 0.5884 50.00 0.6400 80.00 0.7281 LUN 74.38 0.5673 96.79 0.9298 97.39 0.9522 96.06 0.9197 68.47 0.0000 95.07 0.9009 94.58 0.8929 92.12 0.8289 87.68 0.8581 90.64 0.8033 PGE 92.09 0.8709 92.09 0.8321 97.12 0.9460 91.18 0.8237 50.98 0.0000 91.12 0.8623 75.49 0.5087 72.55 0.4503 64.71 0.7147 81.37 0.6272 PMS 95.24 0.9377 94.33 0.9178 100.00 1.0000 98.88 0.9725 0.76 0.2939 97.75 0.9444 95.51 0.8913 88.76 0.7283 70.79 0.6560 91.01 0.7776 Avg. 83.38 0.6687 81.75 0.6319 90.73 0.7903 78.74 0.5477 70.01 0.4823 79.87 0.5911 79.77 0.5955 74.80 0.5330 65.02 0.4014 70.47 0.4282 Note: The bold typefaces emphasize the best solutions. Table 4 p-value of Wilcoxon test for average classification accuracy and kappa on the 54 datasets. IGA EM-1NN IEM SVM BPNN LR C4.5 RBF SOM LVQ Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. Acc. Kap. IGA 0.654 0.719 0.001 0.007 0.069 0.045 0.003 0.005 0.183 0.163 0.077 0.128 0.008 0.021 0.000 0.000 0.000 0.000 EM-1NN 0.001 0.004 0.164 0.103 0.023 0.026 0.363 0.277 0.219 0.291 0.032 0.056 0.000 0.000 0.000 0.000 IEM 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 SVM 0.282 0.487 0.647 0.482 0.808 0.482 0.400 0.847 0.000 0.018 0.015 0.040 BPNN 0.169 0.180 0.166 0.147 0.733 0.517 0.018 0.150 0.221 0.296 LR 0.815 0.968 0.225 0.344 0.000 0.002 0.004 0.004 C4.5 0.249 0.363 0.000 0.000 0.004 0.002 RBF 0.003 0.016 0.105 0.034 SOM 0.121 0.511 LVQ Table 5 Classification accuracy and kappa index on real case of gestational diabetes mellitus (unit: %). Acc. Kappa IGA 64.4737 0.0215 EM-1NN 67.1053 0.0277 IEM 73.0263 0.0389 SVM 69.0789 0.1434 BPNN 65.1316 0.1401 LR 69.0789 0.0758 C4.5 68.4211 0.2002 RBF 67.1053 0.1208 SOM 60.5263 0.0793 LVQ 67.7632 0.1317 Table 6 Feature selection results by EM-1NN. Fold Important features F 1 F 2 F 3 F 4 F 5 F 6 F 7 F 8 F 9 F 10 F 11 F 12 Fold 1 @ @ @ @ @ @ @ @ @ Fold 2 @ @ @ @ @ @ @ @ @ Fold 3 @ @ @ @ @ @ @ Fold 4 @ @ @ @ @ @ @ @ Fold 5 @ @ @ @ @ @ @ @ Fold 6 @ @ @ @ Fold 7 @ @ @ @ @ @ @ @ @ @ Fold 8 @ @ @ @ @ @ @ @ @ @ Fold 9 @ @ @ @ @ @ @ @ @ Fold 10 @ @ @ @ @ @ @ @ Frequency 6 9 9 10 7 5 4 8 9 0 8 7 An improved electromagnetism-like mechanism algorithm and its application to the prediction of diabetes mellitus Kung-Jeng Wang a \u204e kjwang@mail.ntust.edu.tw Angelia Melani Adrian a D9901806@mail.ntust.edu.tw Kun-Huang Chen a khchen@mail.ntust.edu.tw Kung-Min Wang b albert.hua@msa.hinet.net a Department of Industrial Management, National Taiwan University of Science and Technology, Daan District, Taipei 106, Taiwan, ROC Department of Industrial Management National Taiwan University of Science and Technology Daan District Taipei 106 Taiwan, ROC b Department of Surgery, Shin-Kong Wu Ho-Su Memorial Hospital, Shilin District, Taipei 111, Taiwan, ROC Department of Surgery Shin-Kong Wu Ho-Su Memorial Hospital Shilin District Taipei 111 Taiwan, ROC \u204e Corresponding author. Fax: +886 2 2737 6344. Graphical abstract Highlights \u2022 The utilization of ROST technique on EM algorithm with 1NN shows its superiority. \u2022 Statistical analysis reveals that our method outperforms all compared methods. \u2022 We have identified four risk factors for this disease. \u2022 Our research can help the diagnosis and prognosis of Type 2 DM. \u2022 The findings can help to reduce the morbidity and mortality rate caused by DM. Abstract Recently, the use of artificial intelligence based data mining techniques for massive medical data classification and diagnosis has gained its popularity, whereas the effectiveness and efficiency by feature selection is worthy to further investigate. In this paper, we presents a novel method for feature selection with the use of opposite sign test (OST) as a local search for the electromagnetism-like mechanism (EM) algorithm, denoted as improved electromagnetism-like mechanism (IEM) algorithm. Nearest neighbor algorithm is served as a classifier for the wrapper method. The proposed IEM algorithm is compared with nine popular feature selection and classification methods. Forty-six datasets from the UCI repository and eight gene expression microarray datasets are collected for comprehensive evaluation. Non-parametric statistical tests are conducted to justify the performance of the methods in terms of classification accuracy and Kappa index. The results confirm that the proposed IEM method is superior to the common state-of-art methods. Furthermore, we apply IEM to predict the occurrence of Type 2 diabetes mellitus (DM) after a gestational DM. Our research helps identify the risk factors for this disease; accordingly accurate diagnosis and prognosis can be achieved to reduce the morbidity and mortality rate caused by DM. Keywords Electromagnetism-like mechanism algorithm Nearest-neighbor heuristic Opposite sign test Feature selection Diabetes mellitus 1 Introduction The overwhelming amount of data makes most of the existing data mining algorithms inapplicable and inefficient to many real world problems, particularly those data with high dimensionality and features [14]. Feature selection depends on the determination of an optimal feature subset among all of the full features, and is constantly studied to improve computational efficiency and effectiveness by optimizing criteria, such as accuracy and total feature subset costs. However, this possesses another problem called exponential complexity [43] due to the exponential number of candidate subsets. Researchers addressed this problem through exhaustive search [31,1]. Yet, exhaustive search is computationally impractical, except if the total number of features is quite small. The use of metaheuristic algorithms as a solution to feature selection problems has gained significant attention lately. Among them, EM is a new popular optimization algorithm that has been known for its efficiency. EM is a heuristic approach proposed by Birbil and Fang [5] that mimics the attraction\u2013repulsion mechanism of electrically charged particles in the magnetic field. EM is capable of optimizing continuous and discreet problems. Chen et al. [9] first introduced opposite sign test (OST). It is a new local search technique that have the capability to handle the local optima trap problem. In their study, they demonstrated the abilities of OST to increase population diversity in the Particle Swarm Optimization (PSO) algorithm and to escape from local optimal trapped by refining the jump ability of flying particles. OST is implemented by carrying out simple test on the particular states of particle. The objective is to obtain a better solution for each particle. There are two kinds of OST: forward opposite sign test (FOST) and random opposite sign test (ROST). The FOST algorithm works by changing the particular states of particles in a forward manner, while the ROST algorithm randomly changes the particular states of particles. In this study we combine EM algorithm with nearest neighbor classifier (1NN) as the wrapper method. OST method is utilized as local search procedure to help EM algorithm explore for its best. This novel feature selection approach (denoted as IEM) can achieve high classification accuracy and Kappa index. A thorough investigation is conducted to evaluate the performance of the proposed IEM. Initially, we apply IEM on 54 public datasets that consist of 46 datasets from the UCI Repository [2] and 8 public microarray dataset. We conducted this preliminary test to justify our method can be applied to any kind of data size and dimensions. Subsequently, the results are compared with nine other popular feature selection techniques using a non-parametric statistical test. Diabetes mellitus (DM) is one of the disease that contributes to the high mortality rate in the world and also in Taiwan [13,35]. Gestational diabetes is one type of DM that occurs during or after pregnancy and are recognized as one of the most common pregnancy\u2019s complication. Therefore, this study aims at applying IEM on a real clinical dataset to predict the occurrence of Type 2 DM from a gestational diabetes mellitus (GDM) that occurs during or after pregnancy in Taiwan. The remainder of the paper is organized as follows: In Section 2, we review the related literature. Section 3 presents the proposed IEM algorithm. The experimental results and discussion are presented in Section 4. Section 5 concludes the paper. 2 Related literature 2.1 Feature selection problem Selecting an optimized subset from original features is the major task in the feature selection problem. In feature selection one needs to remove irrelevant or redundant features from our dataset. This process influences on the performance of the classification algorithm, particularly in improving accuracy and efficiency [37]. For a specific a dataset, feature selection helps analysts in understanding which features are important and how they are related [36]. As the dimensionality of a domain increases, the number of features N also increases. Finding an optimal feature subset is usually is not an easy task [21]. Many problems related to feature selection have been shown to be NP-hard [6]. This phenomenon is also known as the curse of dimensionality or the Hughes phenomenon. Several researchers have utilized feature selection based methods to predict the occurrence of a disease. Ban et al. [3] used SVM to predict the Type 2 DM in Korean population. Chandra and Gupta [8] used a features weight with Na\u00efve Bayes and SVM classifier to identify the most relevant genes that associate with diseases like leukemia, colon tumor, lung cancer, diffuse large B-cell lymphoma (DLBCL), and prostate cancer. Peng et al. [25] integrated filter and wrapper methods into a sequential search procedure to improve the classification performance of the selected features by using breast cancer and heart disease dataset from UCI repository. Cho et al. [10] proposed a linear SVM combined with wrapper or embedded feature selection methods and applied it to predict the onset of diabetic nephropathy. Huang et al. [18] proposed a feature selection method via supervised model construction for features ranking to predict the occurrence of Type 2 diabetes. 2.2 Electromagnetism-like mechanism algorithm The EM algorithm was first introduced as a stochastic global optimization technique on Birbil\u2019s PhD dissertation in 2002. Since then it has gained popularity due to its simplicity and efficiency in solving many engineering problems. There are four main phases exist on the EM algorithm: initialization, local search, force calculation, and particle movement. In the initialization phase, m particle points are randomly selected from the feasible region, which is an n dimensional hyper-solid features. Each feature of a point is assumed to be scattered between the corresponding upper bound and lower bound. The next step is local search. Hence the OST technique was used as the local search for EM algorithm. In the third phase, the total force exerted on each point is calculated based on the principle of electromagnetism theory. Each particle will calculate the charged value by using Eq. (1). For instance, F 1 is the force exerted by q 3 on q 1 (Fig. 1 ); that is, q 1 is repulsed by q 3 if the value of the objective function of q 1 is better than that of q 3. F 2 is the force exerted by q 2 on q 1; that is, q 1 is attracted by q 2 if the objective function value of q 1 is worse than that of q 2. Thus we can count the eventual force exerted on q 1 as F 1 = F 21 + F 31. Each point is viewed as a magnetic particle and contains a force of attraction or repulsion with respect to other particles. If the objective function value of one point is better than that of the other points, then it is attracted to those points. On the other hand, if the objective function value of one point is worse than that of the other particles, it is repulsed by them. The total force exerted on every point is calculated after all of the forces of attraction and repulsion are determined. The total force is calculated using Eq. (2): (1) q i = exp - n \u00d7 f ( x i ) - f ( x best ) \u2211 k = 1 m ( f ( x k ) - f ( x best ) ) , \u2200 i (2) F i = \u2211 j \u2260 i m q i q j x j - x i | x j - x i | 2 if f ( x j ) < f ( x i ) q i q j x i - x j | x j - x i | 2 if f ( x j ) \u2a7e f ( x i ) , \u2200 i The last phase implicates the movement according to the direction of the force. The total force of each point is calculated point, then this point moves at random step length in the direction of the force and causes the particles to move into any unvisited area in the search space. These procedure is repeated until a termination criterion is reached. The termination criterion can be set as the maximum number of iterations [5]. Despite the popularity of EM algorithm in solving engineering optimization problems, the utilization of EM algorithm in data mining is still few. Su and Lin [34] are the first to apply EM for feature selection. They use the EM algorithm to solve binary problems. In their proposal, EM is combined with the nearest-neighbor heuristics as the wrapper method. Experimental results on 13 public datasets indicate that their method outperforms other well-known algorithms in classification accuracy and feature selection efficiency for balanced data. Lin and Su [22] propose an EM algorithm combined with robust Bayes classifier, and apply it for feature selection with incomplete data. They conduct experiments on 11 public datasets, and show that the results from their proposed method are better than those from other methods, including GA. In our study, the proposed IEM algorithm is embedded with the OST techniques to help the algorithm explore for the global optima solution and escape from local optima trapped. 2.3 Nearest neighbor classifier (1NN) The nearest neighbor algorithm (specifically, 1NN) [12] is one of the successful techniques used in classification task in data mining area [32] and has been widely applied to solve various classification problems. It becomes a popular classifier due to the simplicity and high convergence speed. The 1NN using Euclidean distance to calculate the difference between attributes for continuous data [19]. The algorithm classifies the object by simply assigning it to the class of the single nearest neighbor. Despite its benefit, 1NN can cause the effects of curse of dimensionality which is one of the major issues in biomedical data analysis and mining [25]. In order to avoid that effect, 1NN is usually combined with some optimization algorithm, such as genetic algorithm (GA), PSO and other kind of search methods to improve classification performances. In this paper, we propose the EM algorithm to combine with 1NN as the classifier. 2.4 Opposite sign test (OST) The OST technique can help avoid local optima by improving the jump ability of flying particles. This technique has been utilized to exploit the region for a probable global optimization. Some recent literatures indicate the promising results of using OST techniques [38]. The OST technique entails the testing of the current state and the subsequent change of a feature (0\u21921 or 1\u21920). For particle 10100, for example, the first bit 1 was changed to 0 in the first state. Subsequently, the second bit 0 was changed to 1 in the second stage. This process continued until all bits are changed sequentially. The OST procedure is described as follows: Step 1: Set d: 1. Step 2: Set X i new : X i . Step 3: x id : 1 then x id new : 0 . If x id : 0 then x id new : 1 . Step 4: If the fitness value of X i < X i new then x id : x id new and X i : fitness value of X i new . Step 5: d: d +1. Step 6: If d < D, proceed to step 2; otherwise, stop. There are two OST techniques namely, FOST and ROST. The FOST algorithm is a simple test that aims to acquire better optimization for each particle. The algorithm sequentially changes the particular states of particle in a forward manner. In particle 10,100, for example, the first bit changed from 1 to 0 in the first step. If the fitness value of the old particle (Xi ) is less than that of the new particle ( X i new ), we accept the alteration of the new particle. Otherwise, we retain the alteration of the old particle. The second bit was then changed from 0 to 1 in the second step, and its fitness value is tested. This process continues until all bits were tested sequentially. Meanwhile, the ROST algorithm randomly changes particular particle states. Fig. 2 shows the illustration of ROST technique. In particle 10,100, as an example, we first generate a random key such as \u201835,421\u2019. Following the random key order, the third bit changes first from 1 to 0. If the fitness value of the old particle (Xi ) is less than that of the new particle ( X i new ), we accept the alteration of the new particle. If the results illustrate otherwise, we accept the alteration of the old particle. Subsequently, the fifth bit changed from 0 to 1. We test for the fitness value of the fifth bit. We continues this process until all bits are changed. By performing the OST technique, our proposed algorithm is able to find better particle before the particle movement. The aim of using it is to promote the correct direction. The OST technique has increased the population diversity in metaheuristics such as the PSO [9]. It is helpful for the EM algorithm to avoid local optima traps as well. Chen et al. [9] utilized both FOST and ROST in their proposed approach and exposed that ROST outperforms FOST. Therefore, this study will utilize the ROST technique to embed in our proposed method. 2.5 Feature selection and classification methods To justify the performance of our proposed IEM method, we compared it with different types of feature selection and classification methods. There are nine popular methods that are used as comparisons, i.e. improved genetic algorithm (IGA), standard version of EM with 1NN classifier, support vector machine (SVM), back propagation neural network (BPNN), logistic regression (LR), C4.5, radial basis function (RBF), self-organizing map (SOM), and learning vector quantitation (LVQ). The IGA is an improved version of genetic algorithm that utilized ROST techniques. The reason to make such comparison is to see the performance difference of GA and EM algorithms when the ROST is adopted. The comparison to a standard EM algorithm is to investigate the effect of ROST on a na\u00efve EM and the improved version. The SVM algorithm is a powerful machine learning tool using kernel. The SVM maps nonlinear inputs to a high-dimension feature space where a linear classification surface is constructed [11]. The BPNN is a common method of training artificial neural networks (ANNs). It was first introduced by Paul Werbos in the 1970s. The BPNN trains multi-layered neural networks such that it can learn the appropriate internal representations to allow it to learn any arbitrary mapping of input to output [28]. The LR is a type of probabilistic statistical classification model proposed in the 1970s as an alternative technique to overcome the limitations of ordinary least squares regression. It has been used extensively in numerous disciplines, including the medical and social science fields [30,16,41]. The C4.5 is a decision tree based classifier developed by Quinlan [27] and an extension of Quinlan\u2019s earlier ID3 algorithm. The decision trees generated by C4.5 can be used for classification, therefore it is often referred to as a statistical classifier. The RBF appears as a variant of neural network in the late 1980s. The RBF is embedded in a two-layer neural network, where each hidden unit implements a radial activated function. The input into an RBF network is a nonlinear while the output is linear. Its capabilities has been studied [24,26]. The self-organizing feature map (SOFM) or known as self-organizing map (SOM) is a type of ANNs that is trained using unsupervised learning to produce a low-dimensional, discretized representation of the input space of the training samples, called a map. The SOM is different from other ANNs since it uses a neighborhood function to preserve the topological properties of the input space. The model was first described as an ANN by the Teuvo Kohonen, and is sometimes called a Kohonen map or network [20]. SOM may be considered a nonlinear generalization of principal components analysis (PCA). It has been shown, using both artificial and real geophysical data, that SOM has many advantages over the conventional feature extraction methods [29,42]. LVQ is a prototype-based supervised classification algorithm that considered as a special case of an ANN. LVQ applies a winner-take-all Hebbian learning-based approach. It is a precursor to self-organizing maps (SOM). The LVQ was developed by Teuvo Kohonen. It can be applied to multi-class classification problems and has been widely used in a various practical applications. 3 The proposed improved electromagnetism like mechanism 3.1 Particle representation We use binary digits for feature representation in applying IEM to the feature selection problem. The bits consist of 0 and 1 digit, corresponding to non-selected and selected features respectively. Each particle is coded as a binary alphabetical string. For instance, particle 10,100 contains five features where only the first and the third features are selected. 3.2 Fitness measurement Accuracy is the most commonly used parameter in classifier performance assessment [40]. In the present study, the classification accuracy is determined through 1NN classification rate. Accuracy is used to evaluate classifier performance by defining the total number of good classifications over the total number of available examples. The classified test points can be divided into the following four categories, which are usually represented in the well-known confusion matrix [33]: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). The column of the matrix denotes the instances in a predicted class, while the row denotes the instances in an actual class. Given the four categories of the confusion matrix, accuracy is defined as the fitness function in 1NN. We calculate the fitness function using Eq. (3): (3) Accuracy = TP + TN TP + TN + FP + FN Fig. 3 shows the pseudo-code of the proposed IEM algorithm in solving feature selection problem and Fig. 4 shows the flowchart of IEM. 4 Experiments and results 4.1 Experimental framework 4.1.1 Dataset 4.1.1.1 UCI dataset To evaluate the effectiveness of the proposed IEM algorithm, we apply it on 46 datasets from the UCI Repository [2] and 8 public microarray datasets [7]. Table 1 summarizes the dataset characteristics. The datasets have various data sizes ranging from hundreds to thousands. All of the datasets have no missing values, and all of the features are numeric. 4.1.1.2 Gestational diabetes mellitus dataset Diabetes mellitus (DM) is a type of metabolic diseases where a person has high level of blood sugar. In 2012, World Health Organization (WHO) reveal that there are 347million people in the world suffering from DM and the mortality rate will be double from 2005 to 2030 [13]. In Taiwan, DM has known as one of the five leading cause of death and second leading cause for middle age woman [35]. There are three major types of diabetes mellitus, i.e. Type 1, Type 2 and gestational DM (GDM). As the third form of DM, gestational diabetes occurs on woman during pregnancy and are recognized as one of the most common pregnancy\u2019s complication. GDM is a condition where a pregnant woman without a previous diagnosis of diabetes develops a high blood glucose level. A woman with GDM still has a high chance of developing DM after childbirth even though the glucose metabolism and the insulin resistance will return to normal in most cases [23]. Due to the high morbidity and mortality and rate, many researchers focus on the diagnosis and prediction of DM by using data mining techniques. The data used in this study was collected from a general hospital located in Taipei, Taiwan. The hospital routinely performs 50-g oral glucose challenge test during the 24th to 28th week of gestation, followed by a 3-h 100-g oral glucose tolerance test if the 1-h 50-g glucose value was \u2a7e140mg/dL. According to the National Diabetes Data Group criterion, more than one of the following venous plasma glucose concentrations must be met for gestational DM diagnosis: (1) fasting value \u2a7e105mg/dL, (2) 1-h\u2a7e190mg/dL, (3) 2-h\u2a7e165mg/dL, and (4) 3-h\u2a7e145mg/dL. The data were collected from 1998 to 2002 and registered into the gestational DM registry. Table 2 shows the factors that were collected on the GDM women, and were used as the predictors of developing Type 2 DM after a gestational DM pregnancy. To investigate the Type 2 DM status after gestational DM, all pregnant women who showed gestational DM complications were advised to return for metabolic testing. A 2-h 75-g oral glucose tolerance test was conducted to examine Type 2 DM from 3 to 6months postpartum. Among the 558 gestational DM registries, there were 152 subjects who were available and who successfully completed the follow-up examination for Type 2 DM. The Type 2 DM examining results are grouped into three categories according to the criterion set by Department of Health, Taiwan: first, normal (fasting value<110mg/dL and 2-h 75-g oral glucose tolerance test <140mg/dL), second, pre-DM state (126mg/dL>fasting value110mg/dL or 200mg/dL>2-h 75-g oral glucose tolerance test>140mg/dL), and third, DM (fasting value126mg/dL or 2-h 75-g oral glucose tolerance test200mg/dL). In this dataset, there are a total of 152 sample data that are consisted of 10 DM, 32 pre-DM, and 110 normal. 4.1.2 Experiment setting We use ten-fold cross-validations for all of the datasets to ensure fair distribution among the data and to prevent bias results. The IEM parameter setting for these experiments are as follows: number of particles, 50; MAXITER, 300; and LISTER, 100. Nearest neighbor parameter, k =1. Our proposed IEM method is coded in C++ and run on a Core 2 Duo P8800 (2.2GHz) PC equipped with 4GB of RAM with Windows 7 operating system. 4.1.3 Benchmark methods To evaluate the effectiveness of the proposed IEM, we compare our result with those of nine popular feature selection methods, including several metaheuristic techniques. These methods are EM-1NN, IGA, SVM, BPNN, LR, C4.5, RBF, SOM, and LVQ. We obtain results for SVM, BPNN, LR, C4.5, RBF, SOM, and LVQ with the use of the WEKA software [17,39], while the EM-1NN and IGA are coded in C++ programming language and running on the same computing environment as IEM. 4.1.4 Statistical test method for performance comparisons Since the data did not follow perfect normality distribution, we perform a non-parametric statistical test to examine the effectiveness of all of the methods. Kruskal\u2013Wallis test is used to detect the mean difference among the methods. The mean difference is then detected through a p value 0.001< \u03b1: 0.05. We then use the Wilcoxon test to conduct pair-wise comparisons among all of the considered methods. In these experiments, the \u03b1-level is set to 0.05. 4.2 Results In this study there are two criterions for method performance evaluation, i.e. classification accuracy and the Cohen Kappa. Accuracy had been known as the most commonly used metric in classifier performance assessment [40]. The Cohen Kappa is known in classifications because of its simplicity and usefulness for multi-class problems and its ability to compensate random hits, which are similar to the AUC measure [4]. The kappa coefficient is denoted as K, where pr ( a ) is the relative observed agreement among raters, and pr ( e ) is the hypothetical probability of chance agreement. (4) Kappa coefficient ( \u03ba ) = p r ( a ) - p r ( e ) 1 - p r ( e ) The Wilcoxon statistical test [15] is used to identify which method is significantly different. This test is conducted in lieu of the 54 pair-wise combinations in this case. Table 3 shows the classification accuracy of IEM, EM-1NN, IGA, SVM, BPNN, LR, C4.5, RBF, SOM, and LVQ on the 54 datasets. IEM obtained the highest average accuracy 90.73 as well as the Kappa coefficient, 0.7903. The p-value of Wilcoxon pair test in Table 4 reveals that IEM performances are superior over the other methods on the 54 datasets, denoted by the p-value=0.000. Based on these superior results, we apply IEM to predict the occurrence of Type 2 DM after a GDM pregnancy. Table 5 shows that IEM obtains the highest accuracy and for the GDM dataset. Table 6 reveals that F 4, F 2, F 3, F 9, are the most frequent features that are essentially contribute to the occurrence of Type to DM from a GDM during pregnancy. These features F 4, F 2, F 3, F 9 are 1-h 100-g oral glucose tolerance test value, 50-g oral glucose challenge test value, fasting glucose value, and weight gain during pregnancy respectively. These results can lead us to make a better diagnosis and treatment plans for the patients. 4.3 Discussion In this study, 54 UCI datasets are used to evaluate the performance of various classification algorithms. These datasets are characterized according to data sizes, features, and classes. Several points ware drawn based on the results and analyses. (1) The IEM obtains the highest average classification accuracy and Kappa index for the 54 public datasets and the GDM dataset, this is due to the combination of EM algorithm with the OST technique that helps to explore for a global optimum solution. (2) The performance of IEM compared to IGA is not significantly different due to the use of ROST technique that embedded inside the algorithms. However, in terms of average accuracy and Kappa index, IEM obtains higher results than IGA. (3) The IEM shows better results compared to the standard version of EM algorithm. This result again confirmed the superior effect of ROST technique. (4) Among all methods we can rank the first three best methods as IEM, IGA and EM algorithm. (5) IEM shows a consistent performance for both 54 datasets and GDM dataset on both performance measurements. These results confirm that IEM is a reliable method. (6) The top four important risk factors for a Type 2 DM from a GDM are found in the study, including the value of 1-h 100-g oral glucose tolerance test, the value of 50-g oral glucose challenge test, the value of fasting glucose, and the weight gained during pregnancy. The first three factors are related to the screening test/diagnosis for GDM. In order to decrease the risk of GDM, a woman should have these following result for the GDM screening: (i) 1-h 100-g oral glucose tolerance test value should be below 190mg/dL, (ii) 50-g oral glucose challenge test value should be below 140mg/dL, (iii) fasting glucose value should be below 105mg/dL. If a woman are being overweight with a body mass index (BMI) of 30 or higher, then she is likely to developed GDM during or after her pregnancy. The first 3 factors can help doctors design a more friendly examination glucose test for the pregnant woman and prevent unnecessary screening test. These factors allow us to reduce the number of glucose tests to the patients and comfort the pregnant patients. Another interesting finding is the weight gained during pregnancy is one of the risk factors for this disease. The doctors and the nutrients advisor can design a meal plan for the pregnant woman to prevent them from a Type 2 DM. (7) IEM only require few parameters to adjust, therefore make it easy for the implementation compares to other features selection methods. Moreover the OST techniques makes IEM more effective for searching the best solution. 5 Conclusion In this study we proposed a novel method for feature selection by combining EM algorithm with the nearest neighbor classifier and OST as the local search. We applied the proposed IEM on 46 datasets collected from the UCI repository and 8 public microarray dataset to verify its performance on datasets with various characteristics, sizes, and features. Furthermore, we compared the IEM performance with those of other nine common feature selection methods. We performed a non-parametric statistical comparison using the Kruskal\u2013Wallis and Wilcoxon tests. The results show that the average accuracy and Kappa index of the proposed IEM is outperformed than those of the other methods. We also confirmed that the IEM mean accuracy and Kappa index are significantly different from those of the other methods, shows by the p-value=0.000. These results confirmed that IEM can be applied as an effective diagnosis tool for predict the Type 2 DM after a GDM pregnancy in Taiwan woman. This method can function as a support tool that can help doctors to diagnose the Type 2 DM for during or after pregnancy. Therefore, the effective treatment or prevention plan can be implemented early. Moreover, the important factors that contribute to the disease have been identified. These results will be useful to design a more friendly prevention or treatment plans for the patients. This paper highlights five contributions. First, we propose a novel and effective feature selection method by combining ROST technique on the EM algorithm with 1NN classifier. Second, we perform a thorough investigation of the IEM performance on data level. The IEM is applied to datasets with different characteristics, sizes, and features, the results shows that our method are generally applicable to various kind of data and effective for diseases\u2019 prediction. Third, we conduct exhaustive comparisons with various common feature selection methods. Fourth, we perform a non-parametric statistical test using the Kruskal\u2013Wallis and Wilcoxon tests to evaluate the IEM performance. Fifth, the utilization of ROST technique on the EM algorithm with 1NN classifier shows remarkable performance compared with the standard EM-1NN. Sixth, we have successfully applied IEM to predict the Type 2 DM from a gestational DM. Seventh, we have identified the risk factors for this disease, so that the prevention or treatment plan can be carried out early and effectively, not just for prolonging the patients\u2019 survival but also for improving patients\u2019 quality of life. Future study on the parameter setting with a comprehensive experimental design is recommended to conduct for the proposed IEM algorithm so as to optimize feature selection and parameters setting simultaneously. To investigate more advanced k-NN and other promising classifiers are important issue that requires further research. A trade-off between information burden due to the use of the number of features and the classification quality can be further investigated. Another issue worthy to investigate is the capability of our proposed method to deal with the imbalanced data problem. Acknowledgments This work is partially supported by the National Science Council Taiwan, ROC. References [1] H. Almuallim T. Dietterich Learning Boolean concepts in the presence of many irrelevant features Artif Intell 69 1994 279 305 [2] K. Bache M. Lichman UCI Machine Learning Repository 2013 University of California, School of Information and Computer Science Irvine, CA <http://archive.ics.uci.edu/ml> [3] H.J. Ban J.Y. Heo K.S. Oh Identification of Type 2 diabetes-associated combination of SNPs using support vector machine BMC Genet 11 26 2010 [4] A. Ben-David A lot of randomness is hiding in accuracy Eng Appl Artif Intell 20 2007 875 885 [5] I. Birbil S.C. Fang An electromagnetism-like mechanism for global optimization J Global Optim 25 2003 2003 263 282 [6] A.L. Blum R.L. Rivest Training a 3-node neural networks is NP-complete Neural Netw 5 1992 117 127 [7] Broad Institute TCGA Genome Data Analysis Center Cancer program data sets 2013 Broad Institute of MIT and Harvard <http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi> [8] B. Chandra M. Gupta An efficient statistical feature selection approach for classification of gene expression data J Biomed Inform 44 4 2011 529 535 [9] L.F. Chen C.T. Su K.H. Chen An improved particle swarm optimization for feature selection Intell Data Anal 16 2 2012 167 182 [10] B.H. Cho H. Yu K.W. Kim Application of irregular and unbalanced data to predict diabetic nephropathy using visualization and feature selection methods Artif Intell Med 42 1 2008 37 53 [11] C. Cortes V. Vapnik Support-vector networks Mach Learn 20 3 1995 273 297 [12] T.M. Cover P.E. Hart Nearest neighbor pattern classification IEEE Trans Inf Theory IT-13 1 1967 21 27 [13] G. Danaei M.M. Finucane Y. Lu G.M. Singh M.J. Cowan C.J. Paciorek National, regional, and global trends in fasting plasma glucose and diabetes prevalence since 1980: systematic analysis of health examination surveys and epidemiological studies with 370 country-years and 2.7 million participants Lancet 378 9785 2011 31 40 [14] A. de Haro-Garc\u00eda N. Garc\u00eda-Pedrajas J.A.R. del Castillo Large scale instance selection by means of federal instance selection Data Knowl Eng 75 2012 58 77 [15] J. Dem\u0161ar Statistical comparisons of classifiers over multiple data sets J Mach Learn Res 7 2006 1 30 [16] K.R. Greenop E.M. Blair C. Bower B.K. Armstrong E. Milne Factors relating to pregnancy and birth and the risk of childhood brain tumors: results from an Australian case-control study Pediatr Blood Cancer 61 3 2014 493 498 [17] M. Hall E. Frank G. Holmes B. Pfahringer P. Reutemann I.H. Witten The WEKA data mining software: an update SIGKDD Explor 11 1 2009 [18] Y. Huang P. McCullagh N. Black Feature selection and classification model construction on type 2 diabetic patients\u2019 data Artif Intell Med 41 3 2007 251 262 [19] T. Kawabe J.H. Phi M. Yamamoto D.G. Kim B.E. Barfod Y. Urakawa Treatment of brain metastasis from lung cancer Prog Neurol Surg 25 2004 148 155 [20] T. Kohonen Self-organized formation of topologically correct feature maps Biol Cybern 43 1982 59 69 [21] R. Kohavi G.H. John Wrappers for feature subset selection Artif Intell 97 1\u20132 1997 273 324 [22] H.C. Lin C.T. Su A selective Bayes classifier with meta-heuristics for incomplete data Neurocomputing 106 2013 95 102 [23] B. Metzger N. Cho S. Roston Prepregnancy weight and antepartum insulin secretion predict glucose tolerance five years after gestational diabetes mellitus Diabetes Care 16 12 1993 1598 1605 [24] J. Park J.W. Sandberg Universal approximation using radial basis function network Neural Comput 3 1991 246 257 [25] Y. Peng Z. Wu J. Jiang A novel feature selection approach for biomedical data classification J Biomed Inform 43 1 2010 15 23 [26] T. Poggio F. Girosi Networks for approximation learning Proc IEEE 78 9 1990 1481 1497 [27] J.R. Quinlan C4.5: programs for machine learning 1993 Morgan Kaufmann [28] D.E. Rumelhart G.E. Hinton R.J. Williams Learning representations by back-propagating errors Nature 323 6088 1986 533 536 [29] Saadatdoost R, Alex THS, Jafarkarimi H. Application of self organizing map for knowledge discovery based in higher education data. In: Proceeding of International Conference on IEEE Research and Innovation in Information Systems (ICRIIS); 2011. p. 1\u20136. [30] E. Singer M.P. Couper A. Fagerlin J. Van Hoewyk B.J. Zikmund-Fisher The role of perceived benefits and costs in patients\u2019 medical decisions Health Expect 17 1 2014 4 14 [31] Sheinvald J, Dom B, Niblack W. A modeling approach to feature selection. In: Proceedings of the 10th international conference on pattern recognition; 1990. p. 535\u20139. [32] M. Shouman T. Turner R. Stocker Applying k-nearest neighbor in diagnosing heart disease patients Int J Inf Educ Technol 2 3 2012 220 223 [33] Stephen.V. Stehman Selecting and interpreting measures of thematic classification accuracy Remote Sens Environ 62 1 1997 77 89 [34] C.T. Su H.C. Lin Applying electromagnetism-like mechanism for feature selection Inf Sci 181 5 2011 972 986 [35] C.T. Su Y.H. Hsiao Multiclass MTS for simultaneous feature selection and classification IEEE Trans Knowl Data Eng 21 2 2009 192 205 [36] C.F. Tsai W. Eberle C.Y. Chu Genetic algorithms in feature and instance selection Knowl-Based Syst 39 2013 240 247 [37] G.Q. Wang J.B. Jia X.Y. Li Research on feature selection based on improved particle swarm optimization Adv Mater Res 591\u2013593 2012 2651 2654 [38] K.-J. Wang K.H. Chen Angelia M. Adrian An improved artificial immune recognition system with the opposite sign test for feature selection Knowl-Based Syst 71 2014 126 145 [39] WEKA. <http://wekaclassalgos.sourceforge.net/>; 2014. [40] I.H. Witten E. Frank Data mining: practical machine learning tools and techniques 2005 Morgan Kaufmann [41] A.F. Yan C.C. Voorhees K.H. Beck M.Q. Wang A social ecological assessment of physical activity among urban adolescents Am J Health Behav 38 3 2014 379 391 [42] Hujun Yin Learning nonlinear principal manifolds by self-organising maps Alexander N. Gorban Bal\u00e1zs K\u00e9gl Donald C. Wunsch Andrei Zinovyev Principal manifolds for data visualization and dimension reduction Lecture Notes in Computer Science and Engineering (LNCSE) vol. 58 2007 Springer Berlin, Germany [43] C. Yuen B. Oh J. Yang J. Nang Feature subset selection based on bio-inspired algorithms J Inf Sci Eng 27 5 2011 1667 1686", "scopus-id": "85027532546", "coredata": {"eid": "1-s2.0-S1532046415000192", "dc:description": "Abstract Recently, the use of artificial intelligence based data mining techniques for massive medical data classification and diagnosis has gained its popularity, whereas the effectiveness and efficiency by feature selection is worthy to further investigate. In this paper, we presents a novel method for feature selection with the use of opposite sign test (OST) as a local search for the electromagnetism-like mechanism (EM) algorithm, denoted as improved electromagnetism-like mechanism (IEM) algorithm. Nearest neighbor algorithm is served as a classifier for the wrapper method. The proposed IEM algorithm is compared with nine popular feature selection and classification methods. Forty-six datasets from the UCI repository and eight gene expression microarray datasets are collected for comprehensive evaluation. Non-parametric statistical tests are conducted to justify the performance of the methods in terms of classification accuracy and Kappa index. The results confirm that the proposed IEM method is superior to the common state-of-art methods. Furthermore, we apply IEM to predict the occurrence of Type 2 diabetes mellitus (DM) after a gestational DM. Our research helps identify the risk factors for this disease; accordingly accurate diagnosis and prognosis can be achieved to reduce the morbidity and mortality rate caused by DM.", "openArchiveArticle": "true", "prism:coverDate": "2015-04-30", "openaccessUserLicense": "http://www.elsevier.com/open-access/userlicense/1.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1532046415000192", "dc:creator": [{"@_fa": "true", "$": "Wang, Kung-Jeng"}, {"@_fa": "true", "$": "Adrian, Angelia Melani"}, {"@_fa": "true", "$": "Chen, Kun-Huang"}, {"@_fa": "true", "$": "Wang, Kung-Min"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1532046415000192"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1532046415000192"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1532-0464(15)00019-2", "prism:volume": "54", "prism:publisher": "Elsevier Inc.", "dc:title": "An improved electromagnetism-like mechanism algorithm and its application to the prediction of diabetes mellitus", "prism:copyright": "Copyright \u00a9 2015 Elsevier Inc. All rights reserved.", "openaccess": "1", "prism:issn": "15320464", "dcterms:subject": [{"@_fa": "true", "$": "Electromagnetism-like mechanism algorithm"}, {"@_fa": "true", "$": "Nearest-neighbor heuristic"}, {"@_fa": "true", "$": "Opposite sign test"}, {"@_fa": "true", "$": "Feature selection"}, {"@_fa": "true", "$": "Diabetes mellitus"}], "openaccessArticle": "true", "prism:publicationName": "Journal of Biomedical Informatics", "openaccessSponsorType": "ElsevierBranded", "prism:pageRange": "220-229", "prism:endingPage": "229", "prism:coverDisplayDate": "April 2015", "prism:doi": "10.1016/j.jbi.2015.02.001", "prism:startingPage": "220", "dc:identifier": "doi:10.1016/j.jbi.2015.02.001", "openaccessSponsorName": null}, "objects": {"object": [{"@category": "thumbnail", "@height": "43", "@width": "261", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si14.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1587", "@ref": "si14", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "39", "@width": "232", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si13.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "1308", "@ref": "si13", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "64", "@width": "310", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si2.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2622", "@ref": "si2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "45", "@width": "332", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si1.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "2132", "@ref": "si1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "62", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si9.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "426", "@ref": "si9", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "70", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si8.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "434", "@ref": "si8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "17", "@width": "52", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si7.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "373", "@ref": "si7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "15", "@width": "43", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si6.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "325", "@ref": "si6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "54", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si5.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "411", "@ref": "si5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "14", "@width": "41", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si4.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "295", "@ref": "si4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "18", "@width": "61", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si3.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "397", "@ref": "si3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "34", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si12.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si12", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "34", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si11.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "318", "@ref": "si11", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "19", "@width": "181", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-si10.gif?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "ALTIMG", "@size": "952", "@ref": "si10", "@mimetype": "image/gif"}, {"@category": "high", "@height": "521", "@width": "984", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "38601", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "876", "@width": "2213", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "227441", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2974", "@width": "1124", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "189551", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2506", "@width": "1183", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "342298", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1348", "@width": "1720", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "254407", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "118", "@width": "222", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "13541", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "198", "@width": "500", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "33614", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "672", "@width": "254", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "25128", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "943", "@width": "445", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "93923", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "435", "@width": "555", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "89002", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "thumbnail", "@height": "116", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2058", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "87", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5075", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "62", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2719", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "77", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "2254", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "209", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1532046415000192-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7439", "@ref": "gr2", "@mimetype": "image/gif"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85027532546"}}
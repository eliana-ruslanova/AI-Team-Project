{"scopus-eid": "2-s2.0-84941217786", "originalText": "serial JL 272508 291210 291703 291738 291834 291905 31 90 NeuroImage NEUROIMAGE 2015-07-30 2015-07-30 2015-09-09 2015-09-09 2017-04-19T16:44:36 1-s2.0-S1053811915006862 S1053-8119(15)00686-2 S1053811915006862 10.1016/j.neuroimage.2015.07.066 S300 S300.2 FULL-TEXT 1-s2.0-S1053811915X00152 2017-04-19T12:47:42.748255-04:00 0 0 20151115 2015 2015-07-30T07:30:39.226404Z absattachment articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure table e-component body affil appendices articletitle auth authfirstini authfull authkeywords authlast footnotes grantnumber grantsponsor grantsponsorid highlightsabst primabst ref specialabst 1053-8119 10538119 UNLIMITED NIHGOLD true 122 122 C Volume 122 40 408 416 408 416 20151115 15 November 2015 2015-11-15 2015 article fla Copyright \u00a9 2015 Published by Elsevier Inc. INTERACTIONENVELOPELOCALSPATIALREPRESENTATIONSOBJECTSSCALESINSCENESELECTIVEREGIONS BAINBRIDGE W Introduction Materials and methods Participants Stimuli MRI acquisition and preprocessing Experimental design Regions of interest Results Establishing the large versus small entity ROIs Object interaction envelope sensitivity in large-scale ROIs irrespective of physical size ROI analyses Whole-brain analyses Object interaction envelope sensitivity regardless of task Discussion Object interaction envelope sensitivity in scene-selective regions Object interaction envelope and spatial definition Object interaction envelope: action or perception? Acknowledgments Appendix A Supplementary data References AMIT 2012 201 213 E AUGER 2012 e43620 S BAR 2003 347 358 M BRACCI 2013 18247 18258 S BRACCI 2010 3389 3397 S CATE 2011 109 122 A DILKS 2013 1331 1336 D DOWNING 2001 2470 2473 P EPSTEIN 2005 954 978 R EPSTEIN 1998 598 601 R EPSTEIN 2003 865 876 R FORMISANO 2006 481 503 E ADVANCEDIMAGEPROCESSINGINMAGNETICRESONANCEIMAGING FUNDAMENTALSDATAANALYSISMETHODSINFMRI GANADEN 2013 961 968 R GOODALE 1992 20 25 M GREZES 2003 2735 2740 J GRILLSPECTOR 1999 187 203 K HAREL 2014 E962 E971 A HAXBY 1991 1621 1625 J HOMMEL 2001 849 937 B JANZEN 2004 673 677 G KANWISHER 1997 4302 4311 N KIM 2009 2297 2305 J KONKLE 2012 1114 1124 T KOURTZI 2001 1506 1509 A MILNER 2008 774 785 A MULLALLY 2011 7441 7449 S MULLIN 2011 4174 4184 C PARK 2009 1747 1756 S PARK 2011 1333 1340 S PARK 2014 S RAJIMEHR 2011 e1000608 R TORRALBA 2003 391 412 A TROIANI 2012 V WOHLSCHLAGER 2000 925 930 A WOLFE 2011 77 84 J BAINBRIDGEX2015X408 BAINBRIDGEX2015X408X416 BAINBRIDGEX2015X408XW BAINBRIDGEX2015X408X416XW Full 2015-07-29T01:13:45Z FundingBody National Institutes of Health http://creativecommons.org/licenses/by-nc-nd/4.0/ 2016-09-09T00:00:00Z UnderEmbargo http://creativecommons.org/licenses/by-nc-nd/4.0/ item S1053-8119(15)00686-2 S1053811915006862 1-s2.0-S1053811915006862 10.1016/j.neuroimage.2015.07.066 272508 2017-04-19T12:47:42.748255-04:00 2015-11-15 UNLIMITED NIHGOLD 1-s2.0-S1053811915006862-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/MAIN/application/pdf/29b6355825db1bf63ef67f4660a49233/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/MAIN/application/pdf/29b6355825db1bf63ef67f4660a49233/main.pdf main.pdf pdf true 1982385 MAIN 9 1-s2.0-S1053811915006862-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/PREVIEW/image/png/8c4ae5b9fd3877d9edf5be7583540132/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/PREVIEW/image/png/8c4ae5b9fd3877d9edf5be7583540132/main_1.png main_1.png png 65358 849 656 IMAGE-WEB-PDF 1 1-s2.0-S1053811915006862-fx1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/fx1/THUMBNAIL/image/gif/1de0c69d0586b38c8a53fcbb2357f2d7/fx1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/fx1/THUMBNAIL/image/gif/1de0c69d0586b38c8a53fcbb2357f2d7/fx1.sml fx1 true fx1.sml sml 18948 164 164 IMAGE-THUMBNAIL 1-s2.0-S1053811915006862-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr1/THUMBNAIL/image/gif/81283391bd83d3a5fe4b65997b8f7f30/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr1/THUMBNAIL/image/gif/81283391bd83d3a5fe4b65997b8f7f30/gr1.sml gr1 gr1.sml sml 12373 164 130 IMAGE-THUMBNAIL 1-s2.0-S1053811915006862-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr2/THUMBNAIL/image/gif/e2562041cef79f208cab2438ff355561/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr2/THUMBNAIL/image/gif/e2562041cef79f208cab2438ff355561/gr2.sml gr2 gr2.sml sml 6499 90 219 IMAGE-THUMBNAIL 1-s2.0-S1053811915006862-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr3/THUMBNAIL/image/gif/6b3d1ecd104e2fddf7cfa4d5fdd02c99/gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr3/THUMBNAIL/image/gif/6b3d1ecd104e2fddf7cfa4d5fdd02c99/gr3.sml gr3 gr3.sml sml 8938 101 219 IMAGE-THUMBNAIL 1-s2.0-S1053811915006862-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr4/THUMBNAIL/image/gif/b3573b2a5cf815d6356038190c84be49/gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr4/THUMBNAIL/image/gif/b3573b2a5cf815d6356038190c84be49/gr4.sml gr4 gr4.sml sml 18431 164 188 IMAGE-THUMBNAIL 1-s2.0-S1053811915006862-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr5/THUMBNAIL/image/gif/b01911e5cb7be0bf9cc8387296cd1e22/gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr5/THUMBNAIL/image/gif/b01911e5cb7be0bf9cc8387296cd1e22/gr5.sml gr5 gr5.sml sml 8187 101 219 IMAGE-THUMBNAIL 1-s2.0-S1053811915006862-fx1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/fx1/DOWNSAMPLED/image/jpeg/6bbb5147c67f1ad1d90109c84cfa8777/fx1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/fx1/DOWNSAMPLED/image/jpeg/6bbb5147c67f1ad1d90109c84cfa8777/fx1.jpg fx1 true fx1.jpg jpg 23361 200 200 IMAGE-DOWNSAMPLED 1-s2.0-S1053811915006862-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr1/DOWNSAMPLED/image/jpeg/94a1e74a8049eb9c15026d42b90a4d2e/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr1/DOWNSAMPLED/image/jpeg/94a1e74a8049eb9c15026d42b90a4d2e/gr1.jpg gr1 gr1.jpg jpg 160897 789 625 IMAGE-DOWNSAMPLED 1-s2.0-S1053811915006862-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr2/DOWNSAMPLED/image/jpeg/adfd4461e44e4cf697d084829a1f7ac4/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr2/DOWNSAMPLED/image/jpeg/adfd4461e44e4cf697d084829a1f7ac4/gr2.jpg gr2 gr2.jpg jpg 31427 215 521 IMAGE-DOWNSAMPLED 1-s2.0-S1053811915006862-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr3/DOWNSAMPLED/image/jpeg/2a3813aa113ac6d1b8f8d572628da56e/gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr3/DOWNSAMPLED/image/jpeg/2a3813aa113ac6d1b8f8d572628da56e/gr3.jpg gr3 gr3.jpg jpg 46714 268 581 IMAGE-DOWNSAMPLED 1-s2.0-S1053811915006862-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr4/DOWNSAMPLED/image/jpeg/be0e005172957e31c49bb8ae15403435/gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr4/DOWNSAMPLED/image/jpeg/be0e005172957e31c49bb8ae15403435/gr4.jpg gr4 gr4.jpg jpg 103267 468 536 IMAGE-DOWNSAMPLED 1-s2.0-S1053811915006862-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr5/DOWNSAMPLED/image/jpeg/71622f34fd3a281c2230d85762d21039/gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr5/DOWNSAMPLED/image/jpeg/71622f34fd3a281c2230d85762d21039/gr5.jpg gr5 gr5.jpg jpg 50125 291 629 IMAGE-DOWNSAMPLED 1-s2.0-S1053811915006862-fx1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/fx1/HIGHRES/image/jpeg/d1d62fe27701f50a7097fd98d42ac822/fx1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/fx1/HIGHRES/image/jpeg/d1d62fe27701f50a7097fd98d42ac822/fx1_lrg.jpg fx1 true fx1_lrg.jpg jpg 250428 886 888 IMAGE-HIGH-RES 1-s2.0-S1053811915006862-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr1/HIGHRES/image/jpeg/89d148a87fbd2b857d6f381aff6c8541/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr1/HIGHRES/image/jpeg/89d148a87fbd2b857d6f381aff6c8541/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 1273115 3494 2768 IMAGE-HIGH-RES 1-s2.0-S1053811915006862-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr2/HIGHRES/image/jpeg/8849c5c2a761a14805c997bcfbae7bc7/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr2/HIGHRES/image/jpeg/8849c5c2a761a14805c997bcfbae7bc7/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 274144 952 2309 IMAGE-HIGH-RES 1-s2.0-S1053811915006862-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr3/HIGHRES/image/jpeg/5d5d3d3f10ba54805baa5c3484e0ae74/gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr3/HIGHRES/image/jpeg/5d5d3d3f10ba54805baa5c3484e0ae74/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 424849 1189 2574 IMAGE-HIGH-RES 1-s2.0-S1053811915006862-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr4/HIGHRES/image/jpeg/fd38202d632a3535e1afe892cbd18fda/gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr4/HIGHRES/image/jpeg/fd38202d632a3535e1afe892cbd18fda/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 1104337 2073 2376 IMAGE-HIGH-RES 1-s2.0-S1053811915006862-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/gr5/HIGHRES/image/jpeg/62c9cb687e2a2fb3ede3aa131a457e34/gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/gr5/HIGHRES/image/jpeg/62c9cb687e2a2fb3ede3aa131a457e34/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 447719 1288 2785 IMAGE-HIGH-RES 1-s2.0-S1053811915006862-mmc1.doc https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S1053811915006862/mmc1/MAIN/application/msword/e8694b3de6c0530542c46d6cde4aa918/mmc1.doc https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S1053811915006862/mmc1/MAIN/application/msword/e8694b3de6c0530542c46d6cde4aa918/mmc1.doc mmc1 mmc1.doc doc 171008 APPLICATION YNIMG 12457 S1053-8119(15)00686-2 10.1016/j.neuroimage.2015.07.066 Fig. 1 All 320 stimuli used in the fMRI experiments, grouped by condition. The first overarching analysis of the study contrasts activity for small versus big objects, but the main manipulation can be seen in the 2-factor design of the small objects, covarying physical size with interaction envelope size. Fig. 2 ROI analysis of percent signal change for viewing objects of small scale versus large scale. Regions are grouped based on whether they are more selective for larger entities (in blue: PPA, OPA, Big ROIs, RSC), smaller entities (in red: left Small ROIs, left LOS), or neither (LOC, FFA, EBA). Asterisks indicate significant differences in a paired t-test (all p <0.005), and error bars indicate standard error of the mean. Fig. 3 A chart of percent signal change for the ROI analysis in the Main Experiment. ROI graphs are grouped as in Fig. 2, with ROIs with selectivity to large entities in blue, ROIs for smaller entities in red, and other ROIs in gray. Error bars indicate standard error of the mean. Stars indicate a significant effect of interaction envelope, diamonds indicate a significant effect of physical size, and the star within the diamond indicates a significant effect of the statistical interaction of the factors. Significance was determined at a level of p <0.05. For each ROI, the highlighted symbol is the effect with the higher effect size. Fig. 4 A random-effects whole brain analysis (N=16). (Top) F-maps (a sagittal and coronal view) for a repeated-measures 2-way ANOVA, showing voxels with a significant main effect (p <0.005 uncorrected) for interaction envelope (blue) and physical size (red). (Bottom) T-maps for general linear models on the conditions. The intercorrelated condition map (left) shows the contrast of significant activation (p <0.005 uncorrected) for objects of both small physical size and envelope (red\u2014no voxels emerge) versus objects of both large physical size and envelope (blue). The orthogonalized conditions map (right) shows the contrast of significant activation of the other two conditions where size and interaction envelope are not correlated\u2014small physical size and large envelope size (blue) versus large physical size and small envelope size (red\u2014no voxels emerge). Fig. 5 A chart of percent signal change for each ROI in the Control Experiment, where participants are asked to attend to the size of each object while performing a 1-back task. This graph is read in the same way as Fig. 2. Table 1 Statistics for object properties across conditions. Intercorrelated Phys. & Env. Orthogonalized Phys. & Env. Phys. 1, Env. 1 (Mean) Phys. 2, Env. 2 (Mean) T-testp-value Phys. 2, Env. 1 (Mean) Phys. 1, Env. 2 (Mean) T-testp-value Physical dimensions Shipping size, 3D diagonal (in) 8.11 29.51\u204e 9.67\u00d710\u221215 25.55\u204e 11.84 9.67\u00d710\u22127 Shipping weight (lbs) 0.40 11.79\u204e 4.05\u00d710\u22124 3.35\u204e 1.19 6.72\u00d710\u22124 Subjective AMT ratings Size (1\u20137) 1.88 3.35\u204e 1.84\u00d710\u221214 2.68 2.49 0.25 Weight (1\u20137) 1.73 3.19\u204e 6.97\u00d710\u221212 2.38 2.25 0.50 Placeness (0\u20131) 0.003 0.063\u204e 0.0041 0.058 0.024 0.159 Fixedness (0\u20135) 1.04 1.80\u204e 1.25\u00d710\u221210 1.25 1.18 0.30 Context (\u22121.18\u20130) \u22120.373 \u22120.449 0.1791 \u22120.465 \u22120.431 0.55 Spatial definition (0\u20131) 0.241 0.389\u204e 4.43\u00d710\u22124 0.259 0.309 0.11 Notes\u2014Conditions with the higher mean in each pairing are bolded. If the difference is significant, a star is also added. In the intercorrelated conditions, where both physical size and envelope size are matched, all other properties are intercorrelated, and thus significantly higher for larger objects (other than context, which is non-significant). In contrast, in the orthogonalized conditions, where physical size and envelope size are pitted against each other, there is no significant difference between conditions (though, except for spatial definition and context, the properties all trend towards increasing with larger physical size). Thus, if any effects appear due to larger interaction envelope, it is unlikely that it will be due to any of these other factors. Interaction envelope: Local spatial representations of objects at all scales in scene-selective regions Wilma Alice Bainbridge a \u204e wilma@mit.edu Aude Oliva b oliva@mit.edu a Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, MA 02139, USA Department of Brain and Cognitive Sciences Massachusetts Institute of Technology 77 Massachusetts Ave Cambridge MA 02139 USA b Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, MA 02139, USA Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology 77 Massachusetts Ave Cambridge MA 02139 USA \u204e Corresponding author at: MIT 32-D430, 32 Vassar St, Cambridge, MA 02139, USA. Abstract While several cortical regions have been highlighted for their category selectivity (e.g., scene-selective regions like the parahippocampal place area, object selective regions like the lateral occipital complex), a growing trend in cognitive neuroscience has been to investigate what particular perceptual properties these regions calculate. Classical scene-selective regions have been particularly targeted in recent work as being sensitive to object size or other related properties. Here we test to which extent these regions are sensitive to spatial information of stimuli at any size. We introduce the spatial object property of \u201cinteraction envelope,\u201d defined as the space through which a user transverses to interact with an object. In two functional magnetic resonance imaging experiments, we examined activity in a comprehensive set of perceptual regions of interest for when human participants viewed object images varying along the dimensions of interaction envelope and physical size. Importantly, we controlled for confounding perceptual and semantic object properties. We find that scene-selective regions are in fact sensitive to object interaction envelope for small, manipulable objects regardless of real-world size and task. Meanwhile, small-scale entity regions maintain selectivity to stimulus physical size. These results indicate that regions traditionally associated with scene processing may not be solely sensitive to larger object and scene information, but instead are calculating local spatial information of objects and scenes of all sizes. Graphical abstract Highlights \u2022 We parameterize a spatial property of objects: \u201cinteraction envelope\u201d. \u2022 We run two fMRI studies orthogonalizing object interaction envelope and size. \u2022 We find scene-selective region sensitivity to object spatial properties. \u2022 Sensitivity remains regardless of object size, task, and other object properties. \u2022 Support for spatial processing in PPA and OPA for objects at all scales. Keywords Interaction envelope Scene-selective regions Parahippocampal place area Spatial object properties fMRI Introduction A simplified view of the human brain is that different modules exist for processing different image categories, such as objects and scenes. Object processing is the domain of the lateral occipital complex (LOC; Grill-Spector et al., 1999), while scene processing occurs in the parahippocampal place area (PPA; Epstein and Kanwisher, 1998), retrosplenial cortex (RSC; Auger et al., 2012), and occipital place area (OPA; Dilks et al., 2013). Indeed, various works have found evidence of dissociations between these two sets of regions, pointing towards separate processes (Mullin and Steeves, 2011; Wolfe et al., 2011; Ganaden et al., 2013). However, a growing trend in perceptual neuroscience is in characterizing how these categorical lines are blurred, and what perceptual properties, beyond categories, they are sensitive to. For example, the LOC is found to be sensitive to the property of object shape, rather than to the category of \u201cobjects\u201d itself (Kourtzi and Kanwisher, 2001; Kim et al., 2009), and recent work has found LOC sensitivity to scene-based information as well (Park et al., 2011). The story of scene-selective regions (e.g., PPA, OPA) is less clear\u2014while it is well-accepted that they are essential for spatial navigation in scenes (Epstein, 2005), it is unclear how this may extend to objects and other space-related object properties. Konkle and Oliva (2012) find that these regions in fact have increased activity for larger objects over smaller objects, with other work finding similar results in measures highly correlated with an object's physical size (Cate et al., 2011; Troiani et al., 2012). However, how can this selectivity to object size be consolidated with the traditional selectivity to scene information? These results could point to two distinct possibilities for the case of scene-selective regions\u2014either they are sensitive to categorically larger entities (i.e., large objects and scenes rather than small, manipulable objects), or they are sensitive to a property of a stimulus (whether an object or scene) that is related to object size. The key may be that these regions are in fact sensitive to the navigable local space around a stimulus, including both small, manipulable objects as well as larger scenes. Indeed, PPA activity for large objects is correlated with the object's rated \u201cspatial definition\u201d (Mullally & Maguire, 2011). Additionally, the PPA has been found to hold information about objects relevant for navigation (Janzen and van Turennout, 2004) as well as the functional clutter in a scene, which determines actions and potential for navigation within the scene (Park et al., 2014). While these results do not address what information the PPA might encode for small, isolated, manipulable objects (if any), these point towards the possibility that the PPA is representing a spatial property of stimuli related to how one might spatially interact with the stimulus (e.g., move through it, pick it up), rather than a categorical distinction based on the physical size of the object. To test this hypothesis, the current study examines cortical selectivity to local spatial information of small-scale objects, separating it from pure selectivity to large entities. Importantly, as the PPA is sensitive to geometric calculations of large scenes (Epstein et al., 2003; Park and Chun, 2009), we propose that the spatial processing of small-scale objects would similarly be determined by a functionally-defined space, related to the space around which we interact with an object. We call this local spatial information the interaction envelope of the object, defined as the space through which a user transverses to interact with this object. We operationalize object interaction envelope as the number of hands most often used to interact with an object, as it is easily quantifiable and delineates two very different, non-overlapping volumes of interactive space. For example, a hamburger is a small object whose mode of interaction should involve its whole surface area using both hands, eliciting a larger interaction envelope than a similarly-sized coffee cup that we typically pick up by the handle with a single hand. We test to which extent regions involved in scene processing hold representations of interaction envelope, even for small-scale entities. Additionally, we propose an orthogonal experimental design that allows us to disentangle interaction envelope and physical size (Konkle and Oliva, 2012; Cate et al., 2011), while keeping other important object properties constant (Bar and Aminoff, 2003; Mullally and Maguire, 2011; Auger et al., 2012). This design ensures that any effects are not solely driven by a categorical sensitivity to large objects, or an alternate object property. We hypothesize that scene-selective regions will maintain representations of local spatial information of objects at all physical scales, while object-selective regions (LOC) will be equally sensitive to all objects. For regions selective for small entities (Konkle and Oliva, 2012), it is unclear whether they will be sensitive to physical size or interaction envelope, as they are not part of a traditional scene-processing network. We conducted two functional magnetic resonance imaging (fMRI) studies to investigate sensitivity to interaction envelope in various regions of interest (ROIs selective to small-scale entities, large-scale entities, and control ROIs) using a crossed experimental design of small, manipulable object stimuli (Fig. 1 ) varying along two factors: physical size and interaction envelope. From this, we can determine if these ROIs do hold representations of small object local spatial information, rather than a solely categorical separation between large and small entities. Materials and methods Participants Thirty right-handed adults (18 females, ages 18\u201338) participated in two functional magnetic resonance imaging (fMRI) studies, (N=18 for the main experiment and a separate set of N=12 for the control experiment). All participants had normal or corrected vision. In addition, 431 individuals from Amazon Mechanical Turk (AMT) participated in object norming studies. All observers, including both fMRI study and AMT study participants, consented to participation according to the guidelines of the MIT Committee on the Use of Humans as Experimental Subjects. Two participants were excluded from the analyses of the main experiment due to inability to localize at least 50% of the relevant functional regions of interest (ROIs). Stimuli The full stimulus set is composed of 160 images of large-scale objects with both big physical size and a large interaction envelope, and 160 images of small-scale objects (Fig. 1). Within the small-scale set are four conditions of manipulable objects (the orthogonal 2\u00d72 experimental design illustrated in Fig. 1) that disentangle object physical size from envelope size, with 40 different objects per condition. Objects of physical size 1 and 2 significantly differ in their real-world physical size; the ground truth size for each object was determined by shipping dimensions from online marketplaces such as Amazon.com. Objects of envelope size 1 and 2 significantly differ in their interaction envelope space, operationalized by whether one or two hands are necessary to handle the object, and determined by an AMT experiment. 1 1 In this AMT study, 100 participants (15 responses for each object) were asked to answer how many hands they would use when first interacting with an object, and we confirmed that the one versus two hands sets were significantly different in their mean responses (p =1.25\u00d710\u221235). While these stimuli have been selected to be as closely orthogonalized as possible, conditions where object physical size and envelope size are highly correlated (objects of physical size 1 and envelope size 1, and well as objects of physical size 2 and envelope size 2) could potentially dominate effects found in analyses (as, indeed, their mean sizes are more separated than the other two conditions, see Table 1 ). Several analyses are thus also conducted on only the orthogonalized conditions (objects of physical size 1 and envelope size 2, and objects of physical size 2 and envelope size 1) to ensure that any results are truly due to an orthogonalization of the two object properties. The four conditions were not significantly different in visual statistics, such as average RGB color, vertical symmetry, amount of white space, luminance, and distribution of spatial frequency information (Rajimehr et al., 2011). 2 2 We compared the spectral energy of images across conditions at five increasing radii cutoffs of the images' power spectra, and selected stimuli so that there were no significant differences at any spectral range level (Torralba and Oliva, 2003). Images were all 350\u00d7350pixels in size, representing 7deg\u00d77deg of visual angle. We also ran AMT studies (N=291) to evaluate which other object properties previously identified in modulating PPA activity correlate with our small-scale object sets selection (Table 1). Fifteen participants per object were asked to characterize the objects on various properties, following the methodology of Troiani et al. (2012). Participants could respond for multiple objects, and were all screened so that they had at least a 95% AMT approval rate beforehand. Fixedness was assessed by asking participants on a 5-point Likert scale how easily they could pick up and move an object (Auger et al., 2012). Placeness measured the degree to which people classified an object as either a place or a thing, on a binary scale (Troiani et al., 2012). Spatial definition was determined based on whether participants felt an object evokes a strong sense of surrounding space and is hard to imagine in isolation (Mullally and Maguire, 2011). Lastly, context was determined based on the degree to which there is a consistent environment an object occurs in (Bar and Aminoff, 2003). Participants stated where they would normally find each object (e.g., a fork in a kitchen), and an entropy score was calculated to indicate degree of context. 3 3 Entropy is calculated using the formula E=\u01a9(p(x)\u00d7log(p(x))), for all different answers x, where p(x) is the proportion of responses that are x (Bar and Aminoff, 2003; Troiani et al., 2012). This score ranges from \u22121.18 (where all fifteen answers for an object are different) up to 0 (where all fifteen answers for an object are the same). Object distance has also been correlated with PPA activity (Amit et al., 2012), and we anticipate it has been controlled for by controlling for object size. A separate set of stimuli was used for independent functional localizers for the relevant regions of interest. These functional runs involved blocked images of: 1) isolated faces, balanced by race, gender, and facial expression, 2) scenes, with \u00bd manmade indoor images, \u00bc manmade outdoor images, and \u00bc natural outdoor images, 3) isolated hands, of various skin tones and positions, 4) isolated bodies in various positions without heads, 5) isolated objects, with balanced size and interaction envelope, and 6) scrambled images, done as a randomized mosaic of 20\u00d720 blocks of pixels from the object images. A separate set of object images was also used to identify the ROIs described in Konkle and Oliva (2012), using isolated images of unambiguously big (and large envelope) and small (and small envelope) objects against a white background. Objects in these localizers had no overlap with objects in the main task or the other localizers. MRI acquisition and preprocessing The experiment was conducted at the Athinoula A. Martinos Imaging Center at the MIT McGovern Institute for Brain Research. Imaging data were collected on a 3T Siemens fMRI scanner, using a 32-channel phased-array head coil. Anatomical images were acquired with a high-resolution (1\u00d71\u00d71mmvoxels) T1 MPRAGE structural scan, while functional images were obtained with a gradient echo-planar T2* sequence (33 axial slices parallel to the anterior commissure \u2013 posterior commissure line, no gap, TR=2s, 3.1\u00d73.1\u00d73.1mmvoxels). Functional data were preprocessed using BrainVoyager QX 2.6 (Brain Innovation, Formisano et al., 2006), including slice time correction, linear trend removal, trilinear motion correction, 1/128Hz temporal high pass filtering, and a 4mm spatial smoothing FWHM kernel. Functional data were aligned to the anatomical scans, which had white-matter based inhomogeneity correction and were transformed to fit the Talairach space. Experimental design A main experiment and a control experiment with two separate sets of participants were conducted with the same scanner task design. In the scanner, participants viewed sequential blocks of images and performed an orthogonal one-back task, where they pressed a button for a consecutively repeated image. The experiment consisted of eight runs, each taking 7.1min and consisting of 16 blocks, with 20 images per block. Each image was presented for 600ms, with 200ms fixation between images, and 10s fixation between blocks. Among the 16 blocks in a run, half were of the large-scale objects condition, while the other half were split amongst the four small-scale objects conditions (two blocks per condition). Image and condition order were shuffled randomly within a run, and each run contained all stimuli in the experiment. For the main experiment, while performing the one-back task, participants were asked to attend to how they might interact with each object, to encourage deeper processing of the images and to ensure participants did not solely focus on low-level visual cues. For the control experiment, participants were instead asked to attend to the physical size of each object in the real world. These two designs were used to ensure there was no top-down task-based influence on the results. Regions of interest Perceptual ROIs important to the processing of small entities, large entities, and a control set of ROIs were functionally localized for this study. The large entity category includes scene-selective regions PPA (Epstein and Kanwisher, 1998), retrosplenial cortex (RSC; Auger et al., 2012), and OPA (Dilks et al., 2013) which have been implicated in modulation by several object properties (Troiani et al., 2012), as well as regions in the PHC and TOS (Big-PHC and Big-TOS, or combined as \u201cBig ROIs\u201d) that show selectivity for large objects over small objects (Konkle and Oliva, 2012). The small entity category includes object-selective region lateral occipital complex (LOC; Grill-Spector et al., 1999) and regions in the occipitotemporal sulcus (OTS) and lateral occipital (LO) that show selectivity for small objects over large ones (Small-OTS and Small-LO, or \u201cSmall ROIs\u201d). Additionally, the hand-selective area in the left lateral occipital sulcus (LOS; Bracci et al, 2010) has been included as a potential \u201csmall entity\u201d region due to its selectivity to object effectors, or objects that extend a hand's reach (Bracci and Peelen, 2013). Lastly, two additional ROIs not commonly associated with object or scene processing were also included as control regions: the face-selective fusiform face area (FFA; Kanwisher et al., 1997), and the body-selective extrastriate body area (EBA; Downing et al., 2001). These ROIs were defined for each participant using independent localizers, following the guidelines of other published works (see Section 2.2). A first functional localizer run involved blocked images of six stimulus types: 1) isolated faces, 2) scenes, 3) isolated hands, 4) isolated bodies, 5) isolated objects, and 6) scrambled objects. As participants viewed these blocks of images, they performed a one-back task. This localizer run took 10.6min and consisted of 24 blocks total, or four each of the six stimulus types, arranged in random order. Like the main experiment, images were presented at 350\u00d7350pixels, and were shown for 600ms, with 200ms fixation between images and 10s fixation between blocks. A second localizer was composed of images of big objects (e.g., a pool table) and small objects (e.g., a dart) following the methodology of Konkle and Oliva (2012), in order to examine interaction envelope effects in regions previously identified for size selectivity. Participants viewed blocks of images and pressed a button when a red frame appeared around the image. The run took 8.83min, and consisted of ten blocks each of the two object sizes. Images were 500\u00d7500pixels in size, and were presented for 500ms, with 300ms fixation between images and 10s fixation between blocks. Of the sixteen participants in the main experiment, twelve completed two runs of this size localizer. Due to time constraints, two were only able to complete one run, and two were not able to complete any runs\u2014resulting in fewer participants with these ROIs than other ROIs. The ROIs were defined using BrainVoyager's ROI tool with the following contrasts: PPA, RSC, and OPA as scenes>objects; FFA as faces>scenes; LOC as objects>scrambled; EBA as body>scrambled; and LOS as hand>scrambled minus overlap with the EBA (Bracci et al., 2010). Big-PHC and Big-TOS were defined as big objects>small objects; and Small-OTS and Small-LO as small objects>big objects. ROIs were chosen as clusters at a level of false discovery rate (FDR)<0.05 or 0.1 (if there was no activity at the 0.05 level). The Big-PHC and Big-TOS were found to have the same patterns of activity, and so have been combined in the results section into the \u201cBig ROIs,\u201d and similarly the Small-OTS and Small-LO also have the same patterns of activity, and thus have been combined into the \u201cSmall ROIs\u201d. These Big and Small ROIs were found to spatially overlap with some of the other ROIs; this is important to note, as it means that effects found in these overlapping ROIs may not necessarily be independent. On average, 3.5% (SD=6.1%, N=9) of the Small-OTS was found to overlap with the LOS, 18.9% (SD=32.6, N=9) of the Small-LO was found to overlap with the LOC, 17.0% (SD=22.1%, N=13) of the Big-TOS was found to overlap with the OPA, and 60.8% (SD=34.0%, N=13) of the Big-PHC was found to overlap with the PPA. As one can see, there was high variance in degree of overlap between these ROIs. Each ROI was examined unilaterally, and when there was no significant difference in activity found between the two hemispheres, the ROIs were combined by taking the mean percent signal change between the left and right ROIs. Two regions were examined unilaterally: the Small ROIs, which have only been shown to have left-lateralized significant activity for smaller objects (Konkle and Oliva, 2012), and the LOS, which has also only shown left-lateralized activity for hand stimuli (Bracci et al., 2010). However, all results also generalize when these ROIs are examined bilaterally. Both unilateral and bilateral results for all ROIs are included in the Supplementary Material. Additionally, summaries of all of the ROIs' mean centroids and frequencies in participants can be found in the Supplementary Material. Results Establishing the large versus small entity ROIs First, cortical activity for a broad range of perceptual ROIs were compared for viewing small-scale objects (e.g., a pencil), versus large-scale objects (e.g., a car), to confirm selectivity of different regions based on large differences in scale and to ensure replicability of previous object size-based effects (Konkle and Oliva, 2012) with the current methodology. The ROIs can be grouped into three different categories: 1) ROIs mainly associated with large entities (scenes, big objects), 2) ROIs mainly associated with small entities (small objects, hands), and 3) other control regions of interest. Results of this ROI analysis can be seen in Fig. 2 . As expected, large-scale entity ROIs (PPA, OPA, the Big ROIs, and RSC) all show the same pattern of having significantly more blood-oxygen-level dependent (BOLD) response upon viewing large-scale objects versus small-scale objects (PPA: t(15)=11.03, p =1.36\u00d710\u22128, RSC: t(14)=5.60, p =6.58\u00d710\u22125, OPA: t(14)=8.10, p =1.18\u00d710\u22126, Big ROIs: t(12)=7.68, p =5.73\u00d710\u22126). Amongst the small-scale entity ROIs, indeed the Small ROIs and LOS show a significant preference for small-scale over large-scale objects (Unilaterally, left Small ROIs: t(12)=4.60, p =6.09\u00d710\u22124, left LOS: t(13)=3.76, p= 2.40\u00d710\u22123; bilaterally, Small ROIs: t(12)=4.43, p= 8.14\u00d710\u22124, LOS: t(13)=3.55, p= 3.60\u00d710\u22123). The LOS has been shown to have selectivity not only to pictures of hands, but also to objects that extend a hand's reach (Bracci and Peelen, 2013), and thus these results provide evidence that the LOS may be additionally involved in object representations. Lastly, several ROIs show no difference between activities for small versus large-scale objects. While LOC is an object-selective region, it does not show a preference for objects of any particular scale (p =0.297), supporting its role as a general object-processing region tuned to object shape (Grill-Spector et al., 1999). Additionally, two control regions not associated with object processing \u2013 the FFA (p =0.277) and EBA (p =0.524) \u2013 show no selectivity to object scale. These results confirm previous literature in ROI sensitivity to different scale stimuli (Troiani et al., 2012; Konkle and Oliva, 2012) and also establish the ROI preferences for the next critical analysis. We hypothesize that the large-scale entity ROIs will be sensitive to object interaction envelope even for small-scale objects. We do not expect this effect in LOC, FFA, or EBA because they show no sensitivity to the contrast of small-scale and large-scale objects, different in both size and interaction space. The small-scale entity ROIs could potentially hold representation of an object's physical size, its interaction envelope, or both. Object interaction envelope sensitivity in large-scale ROIs irrespective of physical size ROI analyses These same ROIs were then examined for significant effects of object interaction envelope size and physical size within the small-scale objects. We conducted 2-factor repeated-measures ANOVAs and also calculated eta-squared as effect size for each ROI. Fig. 3 shows the average percent signal change for each condition within each ROI, along with significant differences and effect sizes. The large-scale entity regions all show a significant preference for the larger interaction envelope factor (PPA: F(1,15)=65.45, p =7.50\u00d710\u22127, \u03b72 =0.134; RSC: F(1,14)=7.90, p =0.014, \u03b72 =0.038; OPA: F(1,14)=35.06, p =3.73\u00d710\u22125, \u03b72 =0.069; Big ROIs: F(1,12)=81.22, p =1.09\u00d710\u22126, \u03b72 =0.033). The PPA, OPA, and Big ROIs (i.e., Big-PHC and Big-TOS combined) also show a significant effect of size, but of smaller effect size (PPA: F(1,15)=12.44, p =0.003, \u03b72 =0.022; OPA: F(1,14)=11.35, p =0.005, \u03b72 =0.007; Big ROIs: F(1,12)=18.57, p =0.001, \u03b72 =0.01). There are no significant statistical interactions in these regions (PPA: p =0.661; RSC: p =0.425; OPA: p =0.109; Big ROIs: p =0.412). This indicates that these scene-selective and large-object regions are indeed sensitive to the local spatial information of small-scale objects in addition to physical size. On the other hand, within the small-scale entity regions, the Small ROIs (i.e., Small-OTS and Small-LO combined) show a significant preference for smaller physical size (Left: F(1,9)=13.49, p =0.005, \u03b72 =0.015; Bilateral: F(1,11)=6.87, p =0.024, \u03b72 =0.004). There is also a significant effect of the statistical interaction with interaction envelope and physical size, although of lower effect size (Left: F(1,9)=7.76, p =0.021, \u03b72 =0.006; Bilateral: F(1,11)=5.31, p =0.04, \u03b72 =0.013). The LOS (left or bilateral) shows no significant effect of either factor (for the left LOS, envelope size: p =0.871; physical size: p =0.178), but its pattern follows the trend of a small physical size preference. Lastly, for the remaining ROIs (LOC, FFA, EBA), there is no significant effect of either factor (physical size or envelope size\u2014all p >0.20), although there is a significant statistical interaction in LOC (F(1,14)=5.93, p =0.029, \u03b72 =0.004). These results indicate that small-scale entity regions are instead sensitive to object physical size than interaction envelope. These interaction envelope effects in the large-scale entity regions could potentially be driven by the two conditions where object physical size and interaction envelope are intercorrelated (i.e., physical size 1 and envelope size 1; physical size 2 and envelope size 2). To test this, separate independent t-tests were performed between those conditions, and the conditions where the object properties are fully orthogonalized (i.e., physical size 1 and envelope size 2; physical size 2 and envelope size 1). First, the intercorrelated conditions show significant effects of interaction envelope in the same regions as found with the main experiment, in the PPA (t(15)=7.44, p =2.09\u00d710\u22126), the RSC (t(15)=3.33, p =0.005), the OPA (t(15)=5.29, p =9.02\u00d710\u22125), and the Big ROIs (t(7)=2.86, p =0.024). However, the fully orthogonalized conditions also show significant effects of interaction envelope in key regions of the PPA (t(15)=4.12, p =9.03\u00d710\u22124), the OPA (t(15)=4.53, p =4.0\u00d710\u22124), and the Big ROIs (t(7)=2.74, p =0.029). There is no significant effect for the RSC (p =0.514). These results demonstrate that the PPA, OPA, and the Big ROIs in particular appear to be regions that maintain information about interaction envelope, regardless of object physical size. Whole-brain analyses The results that emerge in the ROI analyses can be further visualized in whole brain analyses of the data (see Fig. 4 ). In a 2-way repeated-measures ANOVA analysis for interaction envelope and physical size, a significant effect of interaction envelope can be found bilaterally in the posterior PHC and TOS, encompassing areas where the PPA, OPA, Big-PHC, and Big-TOS regions would fall for individual participants. While in Fig. 4 this effect is visualized at a level of p <0.005 uncorrected, it still also exists bilaterally at a FDR<0.05 level. Similarly, a significant effect of physical size can also be found in posterior PHC and TOS, however with smaller significant regions of activation, and no effects remain at a FDR<0.05 level. To see the degree of this response that remains when interaction envelope and physical size are orthogonalized, further t-tests were conducted (Fig. 4). Contrasting the two conditions where the two factors are intercorrelated (physical size 1, envelope size 1, and physical size 2, envelope size 2), as expected we find posterior PHC and TOS activity only for the condition of higher physical and interaction envelope size. However, the critical analysis is what patterns emerge when the two factors are orthogonalized (physical size 1, envelope size 2 versus physical size 2, envelope size 1). Will significant patterns appear for the condition with higher physical size, or for the condition with higher envelope size? We find that ultimately there is significant activation only for the condition with higher envelope size (physical size 1, envelope size 2), again bilaterally in the key regions of the posterior PHC and TOS. These results indicate that these traditional scene-selective regions maintain representations of object interaction envelope, regardless of object physical size. Object interaction envelope sensitivity regardless of task Several of these results replicate in the control study, where participants are asked to attend to each object's physical size (see Fig. 5 ). Indeed, one possible interpretation of the main experiment's results could be that attending to object interaction envelope in the task artificially inflates responses in scene-selective regions, as task-dependent activity for object processing has been found in other work (Harel et al., 2014). However, in this control study, PPA, OPA, and the Big ROIs still show a significant effect of interaction envelope size (PPA: F(1,11)=7.52, p =0.019, \u03b72 =0.036; OPA: F(1,11)=41.94, p =4.57\u00d710\u22125, \u03b72 =0.042; Big ROIs: F(1,4)=28.49, p =0.006, \u03b72 =0.025), though RSC is no longer significant (p =0.621). Similarly, PPA and the Big ROIs still show a significant effect of physical size with lower effect size (PPA: F(1,11)=6.66, p =0.026, \u03b72 =0.026; Big ROIs: F(1,4)=14.92, p =0.018, \u03b72 =0.006), and OPA is no longer significant for a size effect (p =0.096). The EBA now shows a significant preference for smaller interaction envelope (F(1,11)=5.291, p =0.042, \u03b72 =0.010). Small ROIs still show a significant preference for small physical size (Left: F(1,8)=10.49, p =0.012, \u03b72 =0.011; Bilateral: F(1,8)=8.34, p =0.020, \u03b72 =0.009). A significant effect of the statistical interaction between the factors can be found in the OPA (F(1,11)=5.23, p =0.043, \u03b72 =0.014) and the Big ROIs (F(1,4)=7.87, p =0.049, \u03b72 =0.003). If the two studies are combined into a 3-way independent measures ANOVA (experiment\u00d7interaction envelope\u00d7physical size), the PPA (F(1,104)=9.07, p =0.003) and the OPA (F(1,100)=5.68, p =0.019) still emerge as having a significant effect of interaction envelope (refer to the Supplementary Material). No regions emerge for a main effect of physical size (all p >0.10), although it must be noted that independent measures ANOVAs are more stringent than the repeated-measures ANOVAs used when analyzing within studies. Additionally, no regions emerge as significant for the interaction of the experiment and interaction envelope (all p >0.28), nor for the interaction of the experiment and physical size (all p >0.71). This lends further evidence that task is not modulating ROI sensitivity to interaction envelope. Overall, these results are consistent with the main study. The large-entity regions (except for the RSC) still show a robust significant effect of object interaction envelope, despite a task emphasizing physical size. Meanwhile, the small-entity regions still show a significant effect of object physical size in the control study. Discussion Object interaction envelope sensitivity in scene-selective regions Using a carefully controlled stimulus set in a visual fMRI task, we found that scene-selective regions (PPA, OPA, Big ROIs) are indeed selective to object interaction envelope, even for small, manipulable objects of equal real-world size. These results hold true even when participants are asked to focus on the real-world size of the objects, indicating that these effects are likely to be implicit and automatic, rather than top-down and task-dependent. While these regions also show effects of object physical size, these effects have a smaller statistical effect size and do not remain when interaction envelope is directly compared to physical size in a whole brain analysis. Amongst these regions, effects in the PPA and OPA remain in all analyses, even when completely orthogonalizing the stimulus conditions, comparing across the main and control experiments, and when analyzing whole-brain contrasts for interaction envelope. In contrast, small-scale entity processing regions (Small ROIs and LOS) show selectivity to objects of smaller real-world size, but not smaller object interaction envelope. Additionally, while other perceptual ROIs (LOC, FFA, EBA) show some effects that may warrant future investigation (e.g., LOC sensitivity to the statistical interaction of the two factors), they ultimately show no effects that are preserved across both studies and all analyses. Overall, these results highlight different calculations on image properties occurring in separate perceptual cortical regions, with the PPA and OPA sensitive to interactive spatial information for images ranging from scenes down to small objects, and the small-scale processing regions instead sensitive to object physical size. Sensitivity to object interaction envelope is specific to ROIs traditionally associated with selectivity to scenes, and these regions may be maintaining geometric calculations about local, functionally-defined space around objects of all scales as well as scenes. Object interaction envelope and spatial definition This large-entity region sensitivity to object interaction envelope aligns with the hypothesis presented by Mullally and Maguire (2011), that along with processing information about scenes and layouts (Epstein and Kanwisher, 1998; Epstein et al., 2003; Troiani et al., 2012), the PPA also has representations of local space around individual objects. While Mullally and Maguire define this local space as \u201cspatial definition,\u201d which is loosely defined and directly related to the volume of the objects, the current results provide an operationalization of spatial definition as a measure of the space through which we interact with objects (i.e., interaction envelope). These results also complement Park et al.'s (2014) recent work in scene processing that finds that scene size and clutter \u2013 both properties with a direct correspondence to interaction envelope with the scene \u2013 are encoded in the PHC. In fact, the selectivity of the PPA to scenes may not be the result of a strong dissociation between scenes and objects, but instead a continuum of interaction envelope, where smaller objects may present relatively limited interactions, larger objects may present more possibilities with increasing movement in a three-dimensional space, and scenes may provide the upper end with a wide range of interactive possibilities. These results with object interaction envelope may also explain results found with other object properties, as previous studies have used properties highly intercorrelated with all other object properties (Troiani et al., 2012), while the current study has studied object interaction envelope in isolation. The current study parameterizes object interaction envelope by whether the object can be interacted with on a small scale (i.e., with one hand) or a larger scale (i.e., with two hands). Further work would be to determine what calculations make up this perceptual property of interaction envelope. For example, possible calculations that could be incorporated into this property could include the amount of surface area of contact, points of contact, complexity of the interaction, and percentage of bodily involvement. Additionally, interaction envelope could also be applied beyond objects to the realm of scenes, to see if scene interactivity or navigability can be quantified in a similar way. Object interaction envelope: action or perception? These results also could hold possible implications for the action and perception two streams hypothesis. While lesion data and neuroimaging data have indicated that the ventral (perception) and dorsal (action) streams may act independently (Haxby et al., 1991; Goodale and Milner, 1992), other behavioral work has found evidence of action influencing perception (Wohlschl\u00e4ger, 2000; Hommel et al., 2001) and perception influencing action (Gr\u00e8zes et al., 2003). Object interaction envelope could potentially represent an action-based perceptual property, as it is related to the way in which someone interacts with or navigates around an object or scene. However, according to this current study, this property is implicitly encoded by the brain during a perceptual task, in perceptual regions (PPA and OPA). It could then be possible that this represents the encoding of an action-based property in the ventral visual stream. Indeed, Milner and Goodale's (2008) revisiting of the two-streams hypothesis supports the possibility of some abstract action planning occurring in the ventral stream, while the dorsal stream handles bottom-up motor control. However, it is possible that PPA and OPA sensitivity to interaction envelope is a more traditional perceptual property (e.g., the size of interaction envelope), and the interactivity is determined upstream of the ventral visual stream. More neuroimaging studies are needed to fully understand what properties or calculations make a property \u201cventral\u201d (i.e., perception) versus \u201cdorsal\u201d (i.e., action). For example, the task in the current study is a perceptual task\u2014participants are presented the stimuli for only a brief amount of time (600ms) and are asked to identify two repeated images in a row. Future work could study more motor-based tasks, such as mental imagery action tasks, to examine how object interaction envelope relates to action-related processing in the dorsal stream. This study serves as a step forward in understanding the properties that govern object representations in high-level ventral visual cortex, supporting the framework of an interconnected perceptual network, where different regions are co-opted for different geometric calculations (i.e., shape, size, patterns, spatial interaction) for processing a wide range of stimuli, ranging from small, isolated objects up to large, complex scenes. While small-entity regions are sensitive to object physical size, traditionally scene-selective regions are additionally maintaining representations of spatial properties of any object, big or small. Acknowledgments The authors would like to thank Radoslaw M. Cichy, Daniel D. Dilks, Seyed-Mahdi Khaligh-Razavi, and Talia Konkle for their comments on this work. This work was supported by the US National Eye Institute (grant number EY020484). W.A.B. is supported by the Department of Defense, through the National Defense Science & Engineering Graduate Fellowship (NDSEG) Program. Appendix A Supplementary data The Supplementary Material contain: 1) the participant frequencies and mean Talairach coordinates and sizes for each ROI, 2) statistics for the ROI analysis ANOVAs in each ROI (unilateral and bilateral), and 3) statistics for the ANOVAs comparing across experiments. All stimuli, stimulus statistics, and stimulus image statistical analysis tools are publicly available on the corresponding author's website: http://www.wilmabainbridge.com/datasets.html. Appendix A Supplementary data Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.neuroimage.2015.07.066. References Amit et al., 2012 E. Amit Y. Trope E. Mehudar G. Yovel Activation of ventral visual cortex supports distance representation Brain Cogn. 80 2012 201 213 Auger et al., 2012 S.D. Auger S.L. Mullally E.A. Maguire Retrosplenial cortex codes for permanent landmarks PLoS ONE 2012 e43620 Bar and Aminoff, 2003 M. Bar E. Aminoff Cortical analysis of visual context Neuron 38 2003 347 358 Bracci and Peelen, 2013 S. Bracci M. Peelen Body and object effectors: the organization of object representations in high-level visual cortex reflects body-object interactions J. Neurosci. 33 2013 18247 18258 Bracci et al., 2010 S. Bracci M. Ietswaart M.V. Peelen C. Cavina-Pratesi Dissociable neural responses to hands and non-hand body parts in the extrastriate visual cortex J. Neurophysiol. 103 2010 3389 3397 Cate et al., 2011 A.D. Cate M.A. Goodale S. K\u00f6hler The role of apparent size in building- and object-specific regions of ventral visual cortex Brain Res. 1388 2011 109 122 Dilks et al., 2013 D.D. Dilks J.B. Julian A.M. Paunov N. Kanwisher The occipital place area (OPA) is causally and selectively involved in scene perception J. Neurosci. 33 2013 1331 1336 Downing et al., 2001 P.E. Downing Y. Jiang M. Shuman N. Kanwisher A cortical area selective for visual processing of the human body Science 293 2001 2470 2473 Epstein, 2005 R. Epstein The cortical basis of visual scene processing Vis. Cogn. 12 2005 954 978 Epstein and Kanwisher, 1998 R. Epstein N. Kanwisher A cortical representation of the local visual environment Nature 392 1998 598 601 Epstein et al., 2003 R. Epstein K.S. Graham P.E. Downing Viewpoint-specific scene representations in human parahippocampal cortex Neuron 37 2003 865 876 Formisano et al., 2006 E. Formisano F. Di Salle R. Goebel Fundamentals of data analysis methods in fMRI L. Landini V. Positano M.F. Santarelli Advanced Image Processing in Magnetic Resonance Imaging 2006 CRC Press USA 481 503 Ganaden et al., 2013 R.E. Ganaden C.R. Mullin J.K. Steeves Transcranial magnetic stimulation to the transverse occipital sulcus affects scene but not object processing J. Cogn. Neurosci. 25 2013 961 968 Goodale and Milner, 1992 M.A. Goodale A.D. Milner Separate visual pathways for perception and action Trends Neurosci. 15 1992 20 25 Gr\u00e8zes et al., 2003 J. Gr\u00e8zes M. Tucker J. Armony R. Ellis R.E. Passingham Objects automatically potentiate action: an fMRI study of implicit processing Eur. J. Neurosci. 17 2003 2735 2740 Grill-Spector et al., 1999 K. Grill-Spector T. Kushnir S. Edelman G. Avidan Y. Itzchak R. Malach Differential processing of objects under various viewing conditions in the human lateral occipital complex Neuron 24 1999 187 203 Harel et al., 2014 A. Harel D.J. Kravitz C. Baker Task context impacts visual object processing differentially across the cortex PNAS 111 2014 E962 E971 Haxby et al., 1991 J.V. Haxby C.L. Grady B. Horwitz L.G. Ungerleider M. Mishkin R.E. Carson P. Herscovitch M.B. Schapiro S.I. Rapoport Dissociation of object and spatial visual processing pathways in human extrastriate cortex Proc. Natl. Acad. Sci. U. S. A. 88 1991 1621 1625 Hommel et al., 2001 B. Hommel J. M\u00fcsseler G. Aschersleben W. Prinz The Theory of Event Coding (TEC): a framework for perception and action planning Behav. Brain Sci. 24 2001 849 937 Janzen and van Turennout, 2004 G. Janzen M. van Turennout Selective neural representation of objects relevant for navigation Nat. Neurosci. 7 2004 673 677 Kanwisher et al., 1997 N. Kanwisher J. McDermott M.M. Chun The fusiform face area: a module in human extrastriate cortex specialized for face perception J. Neurosci. 17 1997 4302 4311 Kim et al., 2009 J.G. Kim I. Biederman M.D. Lescroart K.J. Hayworth Adaptation to objects in the lateral occipital complex (LOC): shape or semantics? Vis. Res. 49 2009 2297 2305 Konkle and Oliva, 2012 T. Konkle A. Oliva A real-world size organization of object responses in occipito-temporal cortex Neuron 74 2012 1114 1124 Kourtzi and Kanwisher, 2001 A. Kourtzi N. Kanwisher Representation of perceived object shape by the human lateral occipital complex Science 293 2001 1506 1509 Milner and Goodale, 2008 A.D. Milner M.A. Goodale Two visual systems re-viewed Neuropsychologia 46 2008 774 785 Mullally and Maguire, 2011 S.L. Mullally E.A. Maguire A new role for the parahippocampal cortex in representing space J. Neurosci. 31 2011 7441 7449 Mullin and Steeves, 2011 C.R. Mullin J.K. Steeves TMS to the lateral occipital cortex disrupts object processing but facilitates scene processing J. Cogn. Neurosci. 23 2011 4174 4184 Park and Chun, 2009 S. Park M.M. Chun Different roles of the parahippocampal place area (PPA) and retrosplenial cortex (RSC) in scene perception Neuroimage 2009 2009 1747 1756 Park et al., 2011 S. Park T.F. Brady M.R. Greene A. Oliva Disentangling scene content from spatial boundary: complementary roles for the PPA and LOC in representing real-world scenes J. Neurosci. 34 2011 1333 1340 Park et al., 2014 S. Park T. Konkle A. Oliva Parametric coding of the size and clutter of natural scenes in the human brain Cereb. Cortex 2014 10.1093/cercor/bht418 Rajimehr et al., 2011 R. Rajimehr K.J. Devaney N.Y. Bilenko J.C. Young R.B.H. Tootell The \u201cparahippocampal place area\u201d responds preferentially to high spatial frequencies in humans and monkeys PLoS Biol. 9 2011 e1000608 Torralba and Oliva, 2003 A. Torralba A. Oliva Statistics of natural image categories Network 14 2003 391 412 Troiani et al., 2012 V. Troiani A. Stigliani M.E. Smith R.A. Epstein Multiple object properties drive scene-selective regions Cereb. Cortex 2012 10.1093/cercor/bhs364 Wohlschl\u00e4ger, 2000 A. Wohlschl\u00e4ger Visual motion priming by invisible actions Vis. Res. 40 2000 925 930 Wolfe et al., 2011 J.M. Wolfe M.L.-H. V\u00f5 K.K. Evans M.R. Greene Visual search in scenes involves selective and nonselective pathways Trends Cogn. Sci. 15 2011 77 84", "scopus-id": "84941217786", "pubmed-id": "26236029", "coredata": {"eid": "1-s2.0-S1053811915006862", "dc:description": "Abstract While several cortical regions have been highlighted for their category selectivity (e.g., scene-selective regions like the parahippocampal place area, object selective regions like the lateral occipital complex), a growing trend in cognitive neuroscience has been to investigate what particular perceptual properties these regions calculate. Classical scene-selective regions have been particularly targeted in recent work as being sensitive to object size or other related properties. Here we test to which extent these regions are sensitive to spatial information of stimuli at any size. We introduce the spatial object property of \u201cinteraction envelope,\u201d defined as the space through which a user transverses to interact with an object. In two functional magnetic resonance imaging experiments, we examined activity in a comprehensive set of perceptual regions of interest for when human participants viewed object images varying along the dimensions of interaction envelope and physical size. Importantly, we controlled for confounding perceptual and semantic object properties. We find that scene-selective regions are in fact sensitive to object interaction envelope for small, manipulable objects regardless of real-world size and task. Meanwhile, small-scale entity regions maintain selectivity to stimulus physical size. These results indicate that regions traditionally associated with scene processing may not be solely sensitive to larger object and scene information, but instead are calculating local spatial information of objects and scenes of all sizes.", "openArchiveArticle": "false", "prism:coverDate": "2015-11-15", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S1053811915006862", "dc:creator": [{"@_fa": "true", "$": "Bainbridge, Wilma Alice"}, {"@_fa": "true", "$": "Oliva, Aude"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S1053811915006862"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S1053811915006862"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1053-8119(15)00686-2", "prism:volume": "122", "prism:publisher": "Published by Elsevier Inc.", "dc:title": "Interaction envelope: Local spatial representations of objects at all scales in scene-selective regions", "prism:copyright": "Copyright \u00a9 2015 Published by Elsevier Inc.", "openaccess": "1", "prism:issn": "10538119", "dcterms:subject": [{"@_fa": "true", "$": "Interaction envelope"}, {"@_fa": "true", "$": "Scene-selective regions"}, {"@_fa": "true", "$": "Parahippocampal place area"}, {"@_fa": "true", "$": "Spatial object properties"}, {"@_fa": "true", "$": "fMRI"}], "openaccessArticle": "true", "prism:publicationName": "NeuroImage", "openaccessSponsorType": "FundingBody", "prism:pageRange": "408-416", "prism:endingPage": "416", "prism:coverDisplayDate": "15 November 2015", "prism:doi": "10.1016/j.neuroimage.2015.07.066", "prism:startingPage": "408", "dc:identifier": "doi:10.1016/j.neuroimage.2015.07.066", "openaccessSponsorName": "National Institutes of Health"}, "objects": {"object": [{"@category": "thumbnail", "@height": "164", "@width": "164", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-fx1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "18948", "@ref": "fx1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "130", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "12373", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "90", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "6499", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "101", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8938", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "188", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "18431", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "101", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8187", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "200", "@width": "200", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-fx1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "23361", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "789", "@width": "625", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "160897", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "215", "@width": "521", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "31427", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "268", "@width": "581", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "46714", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "468", "@width": "536", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "103267", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "291", "@width": "629", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "50125", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "886", "@width": "888", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-fx1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "250428", "@ref": "fx1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "3494", "@width": "2768", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1273115", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "952", "@width": "2309", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "274144", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1189", "@width": "2574", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "424849", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2073", "@width": "2376", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1104337", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1288", "@width": "2785", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "447719", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S1053811915006862-mmc1.doc?httpAccept=%2A%2F%2A", "@multimediatype": "Microsoft Word file", "@type": "APPLICATION", "@size": "171008", "@ref": "mmc1", "@mimetype": "application/word"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84941217786"}}
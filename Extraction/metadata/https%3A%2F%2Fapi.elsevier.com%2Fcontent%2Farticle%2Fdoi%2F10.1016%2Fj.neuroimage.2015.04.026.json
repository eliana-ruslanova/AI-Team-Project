{"scopus-eid": "2-s2.0-84929703630", "originalText": "serial JL 272508 291210 291703 291738 291834 291905 31 90 NeuroImage NEUROIMAGE 2015-04-17 2015-04-17 2015-05-23 2015-05-23 2017-04-21T03:17:49 1-s2.0-S105381191500316X S1053-8119(15)00316-X S105381191500316X 10.1016/j.neuroimage.2015.04.026 S300 S300.5 FULL-TEXT 1-s2.0-S1053811915X00073 2017-04-20T22:46:23.637208-04:00 0 0 20150701 2015 2015-04-17T15:40:49.955059Z articleinfo articletitlenorm authfirstinitialnorm authfirstsurnamenorm cid cids contenttype copyright crossmark dateloaded dateloadedtxt datesearch datesort dateupdated dco docsubtype doctype doi eid ewtransactionid fundingbodyid hubeid indexeddate issn issnnorm itemstage itemtransactionid itemweight oauserlicense openaccess openarchive pg pgfirst pglast pii piinorm pubdatestart pubdatetxt pubyr sortorder sponsoredaccesstype srctitle srctitlenorm srctype ssids alllist content oa subj subheadings suppl tomb volfirst volissue volumelist webpdf webpdfpagecount yearnav figure e-component body acknowledge affil appendices articletitle auth authfirstini authfull authkeywords authlast grantnumber grantsponsor grantsponsorid orcid primabst ref 1053-8119 10538119 UNLIMITED ERCPMC true 114 114 C Volume 114 25 275 286 275 286 20150701 1 July 2015 2015-07-01 2015 article fla Copyright \u00a9 2015 Published by Elsevier Inc. VISUALREPRESENTATIONSDOMINATEDBYINTRINSICFLUCTUATIONSCORRELATEDBETWEENAREAS HENRIKSSON L Introduction Materials and methods Visual stimuli and fMRI data Representational similarity analysis Computational models Gabor wavelet pyramid Gist Animate\u2013inanimate distinction Searchlight analysis Trial averaging Simulations Results Visual areas contain image information and exhibit replicable representational geometries Gabor model explains early visual representation, LO exhibits categorical clusters RDMs are highly similar among visual areas when estimated from the same trials RDMs are distinct among visual areas when estimated from separate trials The Gabor model explains the stimulus-driven component of the V1 representation Coherent response fluctuations within visual cortex More dissimilar response patterns for trials more separated in time Higher similarity of same-trial RDMs is not eliminated by averaging more trials Representational dissimilarities in V1 are distinct from V2, and not fully explained by the Gabor model Discussion Coherent response-pattern fluctuations between visual areas Relating fMRI results to computational model predictions of the underlying visual representations across stages of processing Conclusion Acknowledgments Appendix A Supplementary data References ARIELI 1996 1868 1871 A BECKER 2011 11016 11027 R BENUCCI 2013 724 729 A CARANDINI 2005 10577 10597 M CAVANAUGH 2002 2530 2546 J CONNOLLY 2012 2608 2618 A DUNCAN 2003 659 671 R FISER 2004 573 578 J FOX 2007 700 711 M FOX 2006 23 25 M FREEMAN 2013 974 981 J KAY 2008 352 355 K KAY 2013 247 K KAY 2013 e1003079 K KHALIGHRAZAVI 2014 e1003915 S KIANI 2007 4296 4309 R KRIEGESKORTE 2009 363 373 N KRIEGESKORTE 2013 401 412 N KRIEGESKORTE 2011 N VISUALPOPULATIONCODESTOWARDACOMMONMULTIVARIATEFRAMEWORKFORCELLRECORDINGFUNCTIONALIMAGING KRIEGESKORTE 2006 3863 3868 N KRIEGESKORTE 2008 4 N KRIEGESKORTE 2008 1126 1141 N MULLER 1999 1405 1408 J NASELARIS 2009 902 915 T NASELARIS 2012 239 249 T NILI 2014 e1003553 H NIR 2006 1313 1324 Y NIR 2008 1100 1108 Y OLIVA 2001 145 175 A RESS 2000 940 945 D RITCHEY 2014 1085 1099 M SCHURGER 2010 97 99 A SHMUEL 2008 751 761 A WELIKY 2003 703 718 M XUE 2010 97 101 G HENRIKSSONX2015X275 HENRIKSSONX2015X275X286 HENRIKSSONX2015X275XL HENRIKSSONX2015X275X286XL Full 2015-04-22T18:32:32Z FundingBody European Research Council http://creativecommons.org/licenses/by-nc-nd/4.0/ 2016-05-23T00:00:00Z Open http://creativecommons.org/licenses/by-nc-nd/4.0/ item S1053-8119(15)00316-X S105381191500316X 1-s2.0-S105381191500316X 10.1016/j.neuroimage.2015.04.026 272508 2017-04-20T22:46:23.637208-04:00 2015-07-01 UNLIMITED ERCPMC 1-s2.0-S105381191500316X-main.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/MAIN/application/pdf/e86ecb39f832592e936ac2b4606d48de/main.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/MAIN/application/pdf/e86ecb39f832592e936ac2b4606d48de/main.pdf main.pdf pdf true 3624051 MAIN 12 1-s2.0-S105381191500316X-main_1.png https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/PREVIEW/image/png/5392c5cde3732a14ee691d6ced57a368/main_1.png https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/PREVIEW/image/png/5392c5cde3732a14ee691d6ced57a368/main_1.png main_1.png png 62696 849 656 IMAGE-WEB-PDF 1 1-s2.0-S105381191500316X-gr1.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr1/THUMBNAIL/image/gif/014d813f30e01da4404bc034d8626d86/gr1.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr1/THUMBNAIL/image/gif/014d813f30e01da4404bc034d8626d86/gr1.sml gr1 gr1.sml sml 16750 94 219 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr10.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr10/THUMBNAIL/image/gif/8c27ccd534a17f660fba50d1ec8331b4/gr10.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr10/THUMBNAIL/image/gif/8c27ccd534a17f660fba50d1ec8331b4/gr10.sml gr10 gr10.sml sml 8500 164 175 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr2.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr2/THUMBNAIL/image/gif/34931dcb300b2397916efc6f56111625/gr2.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr2/THUMBNAIL/image/gif/34931dcb300b2397916efc6f56111625/gr2.sml gr2 gr2.sml sml 13121 131 219 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr3.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr3/THUMBNAIL/image/gif/87d1f22d4c7b1fa69db6ad98e328578d/gr3.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr3/THUMBNAIL/image/gif/87d1f22d4c7b1fa69db6ad98e328578d/gr3.sml gr3 gr3.sml sml 27056 135 219 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr4.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr4/THUMBNAIL/image/gif/4004318e202909b4ea7bbbdc044f9091/gr4.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr4/THUMBNAIL/image/gif/4004318e202909b4ea7bbbdc044f9091/gr4.sml gr4 gr4.sml sml 7271 164 138 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr5.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr5/THUMBNAIL/image/gif/5f3c3bb36270bd4322b38cba180f7d8d/gr5.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr5/THUMBNAIL/image/gif/5f3c3bb36270bd4322b38cba180f7d8d/gr5.sml gr5 gr5.sml sml 17235 164 183 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr6.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr6/THUMBNAIL/image/gif/c233504fbe6876c89ca6195f4eca57ea/gr6.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr6/THUMBNAIL/image/gif/c233504fbe6876c89ca6195f4eca57ea/gr6.sml gr6 gr6.sml sml 10125 164 177 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr7.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr7/THUMBNAIL/image/gif/3f492ad7d693b216333bdf5b704c57b6/gr7.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr7/THUMBNAIL/image/gif/3f492ad7d693b216333bdf5b704c57b6/gr7.sml gr7 gr7.sml sml 5431 163 113 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr8.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr8/THUMBNAIL/image/gif/6dc118bae2901f2c2b9fd4b11645aa84/gr8.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr8/THUMBNAIL/image/gif/6dc118bae2901f2c2b9fd4b11645aa84/gr8.sml gr8 gr8.sml sml 16469 123 219 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr9.sml https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr9/THUMBNAIL/image/gif/f72433dcef326c7c2a8100c97b0060be/gr9.sml https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr9/THUMBNAIL/image/gif/f72433dcef326c7c2a8100c97b0060be/gr9.sml gr9 gr9.sml sml 15475 163 131 IMAGE-THUMBNAIL 1-s2.0-S105381191500316X-gr1.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr1/DOWNSAMPLED/image/jpeg/b117224234c28f2cd0ede357e79f6c75/gr1.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr1/DOWNSAMPLED/image/jpeg/b117224234c28f2cd0ede357e79f6c75/gr1.jpg gr1 gr1.jpg jpg 111406 307 714 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr10.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr10/DOWNSAMPLED/image/jpeg/839b9e923d8582e9b835ef54390ba753/gr10.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr10/DOWNSAMPLED/image/jpeg/839b9e923d8582e9b835ef54390ba753/gr10.jpg gr10 gr10.jpg jpg 99892 670 715 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr2.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr2/DOWNSAMPLED/image/jpeg/f4328f8ea839b58286c33835bca35c16/gr2.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr2/DOWNSAMPLED/image/jpeg/f4328f8ea839b58286c33835bca35c16/gr2.jpg gr2 gr2.jpg jpg 125574 483 804 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr3.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr3/DOWNSAMPLED/image/jpeg/d4ef151e1ac757428e59cd3d80d2a704/gr3.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr3/DOWNSAMPLED/image/jpeg/d4ef151e1ac757428e59cd3d80d2a704/gr3.jpg gr3 gr3.jpg jpg 166487 385 625 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr4.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr4/DOWNSAMPLED/image/jpeg/e22b980d60f6e4398ce8f9d2222e3186/gr4.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr4/DOWNSAMPLED/image/jpeg/e22b980d60f6e4398ce8f9d2222e3186/gr4.jpg gr4 gr4.jpg jpg 38918 464 390 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr5.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr5/DOWNSAMPLED/image/jpeg/c37f3f5fd56ac879dc5f1b57c48057ff/gr5.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr5/DOWNSAMPLED/image/jpeg/c37f3f5fd56ac879dc5f1b57c48057ff/gr5.jpg gr5 gr5.jpg jpg 140723 569 637 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr6.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr6/DOWNSAMPLED/image/jpeg/1515785d62938937b0b2ef6af3e365b4/gr6.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr6/DOWNSAMPLED/image/jpeg/1515785d62938937b0b2ef6af3e365b4/gr6.jpg gr6 gr6.jpg jpg 59979 536 579 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr7.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr7/DOWNSAMPLED/image/jpeg/f6d6428aa624f711b4f855986f319922/gr7.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr7/DOWNSAMPLED/image/jpeg/f6d6428aa624f711b4f855986f319922/gr7.jpg gr7 gr7.jpg jpg 42332 563 390 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr8.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr8/DOWNSAMPLED/image/jpeg/006a5cf4e429f4c78fe5da8359672b9b/gr8.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr8/DOWNSAMPLED/image/jpeg/006a5cf4e429f4c78fe5da8359672b9b/gr8.jpg gr8 gr8.jpg jpg 128475 400 714 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr9.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr9/DOWNSAMPLED/image/jpeg/2d59bf2303bd1d8255a41b015584e2a3/gr9.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr9/DOWNSAMPLED/image/jpeg/2d59bf2303bd1d8255a41b015584e2a3/gr9.jpg gr9 gr9.jpg jpg 184372 625 501 IMAGE-DOWNSAMPLED 1-s2.0-S105381191500316X-gr1_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr1/HIGHRES/image/jpeg/84f65412d20b4624ee12dd63608d7890/gr1_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr1/HIGHRES/image/jpeg/84f65412d20b4624ee12dd63608d7890/gr1_lrg.jpg gr1 gr1_lrg.jpg jpg 911206 1362 3163 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr10_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr10/HIGHRES/image/jpeg/67cefc22f128ad18dcf45efa1de42ca2/gr10_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr10/HIGHRES/image/jpeg/67cefc22f128ad18dcf45efa1de42ca2/gr10_lrg.jpg gr10 gr10_lrg.jpg jpg 829924 2967 3164 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr2_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr2/HIGHRES/image/jpeg/acceee7dff1662dc31eeb68710278b1f/gr2_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr2/HIGHRES/image/jpeg/acceee7dff1662dc31eeb68710278b1f/gr2_lrg.jpg gr2 gr2_lrg.jpg jpg 1229722 2136 3558 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr3_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr3/HIGHRES/image/jpeg/c105f0c40affa9a3d4916a99a0eec682/gr3_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr3/HIGHRES/image/jpeg/c105f0c40affa9a3d4916a99a0eec682/gr3_lrg.jpg gr3 gr3_lrg.jpg jpg 1591769 1702 2766 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr4_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr4/HIGHRES/image/jpeg/ba10fc3c423d91a9ce6024f93e461bbb/gr4_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr4/HIGHRES/image/jpeg/ba10fc3c423d91a9ce6024f93e461bbb/gr4_lrg.jpg gr4 gr4_lrg.jpg jpg 276280 2057 1729 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr5_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr5/HIGHRES/image/jpeg/251f21859d0f8f455209d6b067b3d3fa/gr5_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr5/HIGHRES/image/jpeg/251f21859d0f8f455209d6b067b3d3fa/gr5_lrg.jpg gr5 gr5_lrg.jpg jpg 1534062 2522 2821 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr6_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr6/HIGHRES/image/jpeg/9533faf663a6cbcc73377551b8242b53/gr6_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr6/HIGHRES/image/jpeg/9533faf663a6cbcc73377551b8242b53/gr6_lrg.jpg gr6 gr6_lrg.jpg jpg 452438 2372 2564 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr7_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr7/HIGHRES/image/jpeg/9380956ae3cdd59644911a0841903c48/gr7_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr7/HIGHRES/image/jpeg/9380956ae3cdd59644911a0841903c48/gr7_lrg.jpg gr7 gr7_lrg.jpg jpg 282462 2493 1726 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr8_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr8/HIGHRES/image/jpeg/0069058c593e9b04274bb058264e31bb/gr8_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr8/HIGHRES/image/jpeg/0069058c593e9b04274bb058264e31bb/gr8_lrg.jpg gr8 gr8_lrg.jpg jpg 1236790 1770 3163 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-gr9_lrg.jpg https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/gr9/HIGHRES/image/jpeg/802d3adcfa89325296015feb07ce7e2f/gr9_lrg.jpg https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/gr9/HIGHRES/image/jpeg/802d3adcfa89325296015feb07ce7e2f/gr9_lrg.jpg gr9 gr9_lrg.jpg jpg 2024612 2768 2218 IMAGE-HIGH-RES 1-s2.0-S105381191500316X-mmc1.pdf https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S105381191500316X/mmc1/MAIN/application/pdf/8c3207e95f835fff8f69e86466498816/mmc1.pdf https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S105381191500316X/mmc1/MAIN/application/pdf/8c3207e95f835fff8f69e86466498816/mmc1.pdf mmc1 mmc1.pdf pdf false 5296595 APPLICATION YNIMG 12151 S1053-8119(15)00316-X 10.1016/j.neuroimage.2015.04.026 Fig. 1 Simulation on the effects of coherent response fluctuations on RDM similarity. A) Simulated primary visual cortex (V1; 150voxels) responds equally strongly to three categories of stimuli (B=bodies, F=faces, O=objects). The representational similarity matrix (RDM) captures the pair-wise representational distance between the response patterns for each stimulus with the V1 RDM showing no interesting structure. The simulated fusiform face area (FFA; 100voxels) shows preference for face-stimuli (F) and responds slightly more strongly also to the bodies (B) than to objects (O). This is reflected in the FFA RDM showing most similar response-patterns for the Faces. The V1 RDM and the FFA RDM are clearly different (Spearman's rank correlation r=0.07, not significant; condition-label randomization test (Kriegeskorte et al., 2008a)). B) A coherent response fluctuation component was added to V1 and FFA responses (for details, see the Materials and methods section). The stimulus-driven patterns remained the same but the visual areas now shared the fluctuation in the overall responsiveness across time. As a result, the RDMs of the two visual areas are highly similar (Spearman's rank correlation r=0.69, p<0.001; condition-label randomization test (Kriegeskorte et al., 2008a)). This shows that coherent response-pattern fluctuations can have a significant effect on visual representations as reflected in response-pattern dissimilarities. Fig. 2 Coherent response-pattern fluctuations in natural image data. A) The response amplitudes for 5 natural images are shown for a subset of voxels in visual areas V1 and V2 of subject S1. The responses in all voxels in both V1 and V2 were low for the first stimulus, stronger for the second stimulus and again lower for the fourth stimulus. That is, the visual areas showed coherent dynamics in their response patterns. B) The mean and variance of the response pattern amplitudes for 70 natural stimuli are shown for visual areas V1 and V2. Both showed highly coherent dynamics between the visual areas. C) The matrices show the mean correlations between response-pattern-means (top row) and variances (bottom row) between all pair-wise comparisons of the visual areas. The matrices are also visualized using multidimensional-scaling arrangement. What emerged from the coherence of the response-pattern fluctuations is the hierarchy of visual areas. D\u2013F) When the comparisons were done between repeated presentations of the same stimuli (separate trials), the correlations in the response-pattern-mean and variance were much lower. As shown with the simulations in Fig. 1, this suggests a significant contribution of the coherent response fluctuations on the similarity of the RDMs from different visual areas in this data. Fig. 3 Representational similarity analysis and computational model predictions of natural image representations. A) An example stimulus image is shown. B) An example representational similarity matrix (RDM) is shown for visual area V1 of subject S1. The RDM captures the pair-wise dissimilarities between the response patterns elicited by the stimuli, here 70 different natural images. By definition, the RDM is symmetric and has a zero diagonal. C) In a split-data RDM, the dissimilarities are computed between separate presentations of the same set of stimuli. The diagonal of the split-data RDM reflects the replicability of the response patterns between the first and second stimulus presentation. D) Example RDMs for the four different models are shown for a set of 70 natural images (GWP=Gabor wavelet pyramid). Fig. 4 Distinct fMRI response patterns and replicable similarity structures for natural image stimuli. A) Results on the distinctiveness of the response patterns for the natural images are shown separately for the seven visual areas in each of the three subjects (S1, S2, S3). The error-bars indicate SEMs across the 25 experimental runs. The black dots below the bars indicate statistically significant results (t-test, p<0.05). B) Results on the replicability of the representational similarity structure for the natural image stimuli are shown separately for the visual areas and subjects. The error-bars indicate SEMs across the 25 experimental runs. The black dots below the bars indicate statistically significant results (t-test, p<0.05). Fig. 5 Relating computational models to cortical representations. A\u2013C) Results on the comparisons between computational model predictions on the response pattern dissimilarities and the empirical results of different visual areas are shown separately for the three subjects. Each bar indicates the mean rank correlation between a model RDM (GWP=Gabor wavelet pyramid, Gist=spatial envelope model, Anim=categorical animate\u2013inanimate distinction) and a brain RDM. The error-bars indicate SEMs across the 25 experimental runs. The black dots below the bars indicate statistically significant results (t-test, p<0.05). D) A multidimensional-scaling arrangement reflects the response-pattern dissimilarities in V1 and LO for the 1750 natural images (dissimilarity: 1 - Pearson's linear correlation, criterion: metric stress) labeled as animate (red) or inanimate (blue). The results are shown separately for each subject. A clear categorical clustering is evident in area LO of subject S1, but not in V1 in any of the subjects. Fig. 6 Relating natural image representations between different visual areas, subjects and model predictions. A) A second-order similarity matrix of RDMs of visual areas (V1, V2, V3, V4, LO) in all three subjects (S1, S2, S3) and the two best-fitting models (GWP=Gabor wavelet pyramid, Anim=categorical animate\u2013inanimate model) is shown, and B) the corresponding multidimensional-scaling arrangement (metric-stress) of the representational dissimilarities. The distances reflect the representational distance between the representations. The visual areas in the three subjects are color-coded in different colors. C) A second-order similarity matrix of RDMs, where the effects of coherent trial-to-trial fluctuations were removed by comparing RDMs from separate trials, and D) the corresponding multidimensional-scaling visualization (metric-stress) of the representational relationships. Note that when the comparison was made between the visual-area RMDs constructed from the same trials (sharing intrinsic dynamics; A\u2013B), the representations were most similar between the visual areas within the same subject. Whereas, when the comparison was made between visual-area RDMs constructed from separate trials (sharing only stimulus-driven effects; C\u2013D), the V1 representations of all subjects, for example, were more similar to the GWP model than to the representations in the higher-level visual areas. Fig. 7 Same-trial RDM similarity is mostly driven by effects unrelated to the stimuli. A) GWP model and same-trial RDM comparisons. The red bars show the mean Kendall's tau-a rank-correlation between single-trial V1-RDM and the GWP model. The dark gray bars show the mean rank-correlation between the single-trial V1 RDM and the single-trial V2 RDM constructed from the same trials. The light gray bars show the mean rank-correlation between the V1 RDMs of different subjects constructed from trials with same temporal structure. The black line shows results on V1 RDM replicability, that is, the correlation between V1 RDMs constructed from separate trials and thus the stimulus-driven effects. The results are shown separately for each subject (in different rows) and the error-bars indicate SEMs across the 25 experimental runs. B) Separate-trial RDM comparisons. The red bars (GWP model comparison) and black lines (V1 RDM replicability results) are the same as in (A), note the different y-axis. The dark gray bars show the mean rank-correlation between the V1 and V2 RDMs constructed from separate trials. The light gray bars show the mean rank-correlation between V1 RDMs of different subjects constructed from trials with different temporal sequence. C) Effects of mean-response and temporal distance on RDMs. The blue bars show the mean rank-correlation between the V1-RDM and mean-response RDM. In this simple model of the coherent response-pattern-fluctuations, each cell in the RDM contains the absolute difference between the response-pattern-means divided by the sum of the absolute values of the response-pattern-means between a pair of stimuli. The green bars show the mean rank-correlation between the V1-RDM and the temporal distance RDM, in which each cell contains the temporal distance between the presentations of a pair of stimuli. The black lines (V1 RDM replicability results) are the same as in (A\u2013B), note the different y-axis. Fig. 8 Searchlight analysis of the response-pattern fluctuations and RDM correlations across the visual cortex. A) The trial-to-trial response-pattern-mean signals from the right LO (subject S1) were correlated with trial-to-trial response-pattern-mean signals within a spherical searchlight at each location. The expected false-discovery rate maps show the significance of the correlations as evaluated from the 25 experimental runs and FDR corrected for multiple comparisons. The upper row shows the results for same-trial pattern mean correlations and the bottom row for separate-trial pattern-mean correlations. Note the widespread response-pattern fluctuations in the same-trial responses across the visual cortex, and especially between the corresponding regions in the two hemispheres. B) The RDM of the right LO was correlated with RDMs within a spherical searchlight at each location. The upper row shows the results for same-trial RDM correlations and the bottom row for separate-trial RDM correlations. When the reference-RDM was constructed from separate trials (bottom row), the searchlight analysis identified similar representations only in corresponding regions in the two hemispheres. Note the similarity of the same-trial RDM and same-trial response-pattern fluctuations across the visual cortex (upper rows A\u2013B), likely reflecting the contribution from intrinsic cortical dynamics. Fig. 9 Trial-to-trial variability in response-patterns: more dissimilar response-patterns for trials more separated in time. A) A V1 RDM of subject S1 is shown for the first experimental run, where the two trials for each of the 70 stimuli were treated as separate conditions. The ordering of the condition labels in the RDM follows the original stimulus image numbering (1\u202670) with the second presentations of the same image set following the first presentation. B) The RDM shown in (A) is reordered to follow the temporal sequence of the presentation order of the 140 natural image stimuli. C) The reordered RDMs (as in B) were averaged across experimental runs. In each run, the stimuli were different, but the temporal sequence of the presentation order was the same (see Supplementary Fig. 1 for other visual areas and subjects). The two black rectangles represent the two zoom-in regions. D) The reference RDM predicts identical response patterns for the repeated presentation of the same stimuli and different response patterns for other stimulus comparisons. The two black rectangles represent the two zoom-in regions. The arrows in the zoom-in regions point to one of the repeated presentations of the same stimulus (similar response patterns). Fig. 10 Trial averaging weakens non-stimulus-related effects and strengthens stimulus-related effects. Results on the representational similarity of V1 to other visual areas are shown for different numbers of trials averaged for the RDMs. Results for the three subjects are shown separately (three rows). The first column compares the V1 to other visual areas when the RDMs were constructed from the same trials (sharing intrinsic cortical dynamics). The x-axis shows the number of trials averaged for the RDMs. The second column compares the V1 to other visual areas when the RDMs were constructed from separate trials (only stimulus-driven effects shared among visual areas). Note the opposite effects of the trial averaging on the results shown in the first (same-trial) and second (separate-trial) columns. The third column compares the V1 representation in one subject to the representations in the other subjects (a different temporal sequence for stimulus presentation; only stimulus driven effects shared). The last column compares the V1 representation to the representational similarity predicted by the GWP model. Visual representations are dominated by intrinsic fluctuations correlated between areas Linda Henriksson a b \u204e linda.henriksson@aalto.fi Seyed-Mahdi Khaligh-Razavi a c Kendrick Kay d Nikolaus Kriegeskorte a a MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK MRC Cognition and Brain Sciences Unit Cambridge CB2 7EF UK b Brain Research Unit, Department of Neuroscience and Biomedical Engineering, Aalto University, 02150 Espoo, Finland Brain Research Unit Department of Neuroscience and Biomedical Engineering Aalto University Espoo 02150 Finland c Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA Computer Science & Artificial Intelligence Laboratory Massachusetts Institute of Technology Cambridge MA 02139 USA d Department of Psychology, Washington University in St. Louis, St. Louis, MO 63130, USA Department of Psychology Washington University in St. Louis St. Louis MO 63130 USA \u204e Corresponding author at: Department of Neuroscience and Biomedical Engineering, Aalto University, PO Box 15100, 00076 Aalto, Finland. Fax: +358 9 470 22969. Abstract Intrinsic cortical dynamics are thought to underlie trial-to-trial variability of visually evoked responses in animal models. Understanding their function in the context of sensory processing and representation is a major current challenge. Here we report that intrinsic cortical dynamics strongly affect the representational geometry of a brain region, as reflected in response-pattern dissimilarities, and exaggerate the similarity of representations between brain regions. We characterized the representations in several human visual areas by representational dissimilarity matrices (RDMs) constructed from fMRI response-patterns for natural image stimuli. The RDMs of different visual areas were highly similar when the response-patterns were estimated on the basis of the same trials (sharing intrinsic cortical dynamics), and quite distinct when patterns were estimated on the basis of separate trials (sharing only the stimulus-driven component). We show that the greater similarity of the representational geometries can be explained by coherent fluctuations of regional-mean activation within visual cortex, reflecting intrinsic dynamics. Using separate trials to study stimulus-driven representations revealed clearer distinctions between the representational geometries: a Gabor wavelet pyramid model explained representational geometry in visual areas V1\u20133 and a categorical animate\u2013inanimate model in the object-responsive lateral occipital cortex. Keywords Functional MRI Visual cortex Intrinsic dynamics Natural images Pattern information Representational similarity Introduction Visual stimulation has been shown in animal models to only slightly modulate ongoing cortical dynamics in the visual cortex (Arieli et al., 1996; Fiser et al., 2004). Trial-to-trial variability of evoked fMRI responses in human cortex has also been related to coherent intrinsic fluctuations of activity (Becker et al., 2011; Fox et al., 2006). However, the effect of intrinsic dynamics on visual representations and their functional role is not well understood. The representational content of neuronal population codes is increasingly being investigated with pattern-information techniques (Kriegeskorte and Kreiman, 2011). In this approach, stimulus-related activity patterns are interpreted as distributed representations of the stimuli. Functional magnetic resonance imaging (fMRI) enables us to image many areas simultaneously and to investigate the transformation of the representational space across stages of processing. However, previous studies have ignored the effect of intrinsic dynamics on comparisons of representations between different areas. That is, visual areas show prominent coherent fluctuations in spontaneous activity between the areas in the absence of visual stimulation (Shmuel and Leopold, 2008), a phenomenon typically referred to in human brain imaging as functional connectivity (Fox and Raichle, 2007; Nir et al., 2006). Resting-state functional connectivity between brain regions has also been shown to be highly similar to connectivity estimated based on fMRI response-pattern dissimilarities during task-performance (Ritchey et al., 2014). This has been interpreted as evidence for sub-networks of brain regions contributing to specific tasks. Resting-state functional connectivity measures and stimulus-related response-pattern dissimilarities may, however, have a common underlying component that has remained unrecognized. Here we show that estimates of stimulus-related response-pattern dissimilarities can be strongly affected by ongoing cortical dynamics. The representational geometry of a visual area can be characterized by a representational dissimilarity matrix (RDM), which contains a representational distance for each pair of stimulus-related fMRI response patterns (Kriegeskorte and Kievit, 2013; Kriegeskorte et al., 2008a). Representations in two brain regions can be compared by computing the correlation between their RDMs (Kriegeskorte, 2009; Nili et al., 2014). Likewise, a brain RDM can be directly compared to a model RDM that captures the response-pattern dissimilarities in the internal representation of a computational model that processes the stimuli (Khaligh-Razavi and Kriegeskorte, 2014; Kriegeskorte, 2009). Comparing visual representations between brain areas and processing stages in computational models can help us better understand the functional organization of the human visual cortex. The goal is to understand how the representational space is transformed across stages of processing. However, as shown here, coherent fluctuations of overall activation between two regions can make the apparent representational geometries of visual areas much more similar than the true underlying visual representations. Fig. 1 illustrates the effect of coherent intrinsic response fluctuations on RDMs. In this simple simulation, primary visual cortex (V1) responded equally to three categories of stimuli (bodies, faces, objects) whereas face-responsive fusiform face area (FFA) showed preference for faces. The difference between the response profiles is reflected in their RDMs shown in Fig. 1A. In Fig. 1B, a coherent fluctuation component was added to the responses. The underlying stimulus-driven pattern variances remained the same but the visual areas now shared the fluctuation in the overall responsiveness across time. As a result, the RDMs of the two visual areas are highly similar (Fig. 1B), thus challenging the interpretation of the differences between the stimulus representations and highlighting the contribution of shared intrinsic response fluctuations on representational geometries. In this study, we explored fMRI responses in human visual cortex to a large set (1750) of natural images (Kay et al., 2008). Fig. 2 shows results illustrating coherent response fluctuations between visual areas in this data\u2014both the mean and the variance of the response-patterns fluctuate synchronously across visual cortex. Areas closer in cortex, and in the visual hierarchy, tended to exhibit greater functional connectivity (Fig. 2C). These fluctuations were unrelated to the stimuli and thus likely reflected intrinsic cortical dynamics (Figs. 2D\u2013F). We will show that the coherent fluctuations have a strong effect on the representational similarity between visual areas, and that the true stimulus-driven component can be revealed by comparing RDMs constructed from response-patterns estimated on the basis of separate trials. Materials and methods Visual stimuli and fMRI data The current study used fMRI data from a previously published study; for details on the visual stimuli, data acquisition and data pre-processing, please see Kay et al. (2008) and Naselaris et al. (2009). This data had been used as training data for voxel-receptive-field modeling. In short, the stimuli were 1750 gray-scale natural photographs that were masked with a 20\u00b0-diameter circle (for an example, see Fig. 1A) and were presented for 1s (flashed three times ON (200ms)\u2013OFF (200ms)\u2013ON (200ms)\u2013OFF (200ms)\u2013ON (200ms)) with a 3-s fixation-only period between successive photographs and every eight trial being a null trial. Data from three subjects were analyzed (S1\u2013S3). For each subject, the data had been collected in five separate scanning sessions with five experimental runs in each. Each experimental run consisted of 70 different natural images, each presented two times. The data were pre-processed using an updated protocol which included slice-timing correction, motion correction, upsampling to (1.5mm)3 resolution and improved co-registration between the functional data sets. The data were modeled with a variant of the general linear model including discrete cosine basis set for the hemodynamic response function (HRF) estimation. Low-frequency noise fluctuations, such as scanner drift, were accounted for by polynomials (for details, please see Kay et al. (2008)). The beta weights characterizing the amplitude of the BOLD response to each stimulus were transformed to Z scores. The regions-of-interests V1, V2, V3, V4, LO, V3A and V3B were based on independent localizer data based on retinotopic criteria (Naselaris et al., 2009). The analysis was restricted to voxels with signal-to-noise ratio greater than 1.5 (median value observed across all images). The regions-of-interest contained no overlapping voxels. Representational similarity analysis The fMRI response patterns evoked by the different natural images were compared to each other using correlation distance, and all pairwise comparisons were assembled in a representational dissimilarity matrix (RDM) for each region (Kriegeskorte et al., 2008a; Nili et al., 2014). Fig. 3B shows an example RDM. The RDMs were calculated separately for each experimental run with 70 different natural images in each. The measure for dissimilarity was correlation distance (1\u2212Pearson linear correlation) between the response patterns. To study the ability to discriminate the natural images from the fMRI response patterns, we used split-data RDMs, where the pair-wise dissimilarities were computed between the two response patterns that were measured on different trials. Fig. 3C shows an example of such RDM, where the diagonal reflects the dissimilarity of the response patterns between the first and second presentations of the same natural image. An index for the natural image discriminability was calculated as the subtraction of the mean of the diagonal values from the mean of the off-diagonal values. Exemplar discrimination index greater than zero indicates distinguishable response patterns for the natural images. The replicability of the similarity structure captured by an RDM was assessed by comparing single-trial RDMs based on the two separate presentations of the same set of images. The RDMs were compared using Kendall's tau-a rank correlation distances of the values in the upper (or equivalently the lower) triangle of the RDMs (for details on the different correlation-distance measures, please see Nili et al. (2014)). Computational models The visual area RDMs were compared to three different model predictions on the representational similarity structure: Gabor wavelet pyramid model, Gist and animate\u2013inanimate distinction. In a model RDM, each cell reflects the dissimilarity of an image pair predicted by the computational model. Examples of the model RDMs are shown in Fig. 3D. The comparison between a brain RDM and a model RDM was based on Kendall's tau-a rank correlation distance of the values in the upper triangles of the RDMs (Nili et al., 2014). Gabor wavelet pyramid The Gabor wavelet pyramid model was adopted from Kay et al. (2008). Each image was represented by a set of Gabor wavelets of six spatial frequencies, eight orientations and two phases (quadrature pair) at a regular grid of positions over the image. To control gain differences across wavelets at different spatial scales, the gain of each wavelet was scaled such that the response of that wavelet to an optimal full-contrast sinusoidal grating is equal to 1. The response of each quadrature pair of wavelets was combined to reflect the contrast energy of that wavelet pair. The outputs of all wavelet pairs were concatenated to have a representational vector for each image. The pair-wise dissimilarities (1\u2212correlation) of these vectors were computed to obtain the Gabor wavelet model RDMs for the natural images. Gist The spatial envelope or gist model aims to characterize the global similarity of natural scenes (Oliva and Torralba, 2001). The gist descriptor is obtained by dividing the input image into 16 bins, and applying oriented Gabor filters in 8 orientations over different scales in each bin, and finally calculating the average filter energy in each bin. The gist descriptors for each natural image were compared to each other to obtain the Gist RDMs. Animate\u2013inanimate distinction A categorical distinction based on animate and inanimate objects has been suggested to be a fundamental organization principle of the higher-level object-responsive cortex (Connolly et al., 2012; Kiani et al., 2007; Kriegeskorte et al., 2008b; Naselaris et al., 2012). The natural image stimuli were labeled as animate if they contained one or several humans or animals, bodies of humans or animals, or human or animal faces. In the animate\u2013inanimate model RDM, the dissimilarities are either 0 (identical responses) if both images are of the same category (animate or inanimate) or 1 (different responses) if one image is animate and the other is inanimate. Searchlight analysis The main analyses were performed using pre-defined ROIs. To explore the effects more generally within the whole scanned brain volume, we performed searchlight analysis (Kriegeskorte et al., 2006). A spherical searchlight of 4.5-voxel radius was positioned at each location of the scanned brain volume. Within each location, the response-pattern-means and RDMs were extracted and correlated with the corresponding metrics from a reference ROI. Correlation maps were constructed from the results. This was repeated for the 25 experimental runs. The results were FDR corrected for multiple comparisons. Trial averaging The effect of the number of fMRI response trials averaged was studied using a second set of fMRI data from the same subjects, where we had 13 trials for 120 natural images (for details, see the image identification data in Kay et al. (2008)). The representational similarity analysis was applied separately for data from each experimental run with 12 different natural images. The trials were divided to two independent data sets (odd and even trials, the 13th trial excluded from the analysis), and the number of response patterns averaged was varied between 1 and 6. The averaged response patterns were used for representational similarity analysis. Simulations We simulated the effect of coherent response fluctuations on RDM similarity of two regions-of-interest: the primary visual cortex (V1; 150voxels) and fusiform face area (FFA; 100voxels). The simulated FFA showed different response profiles for \u2018faces\u2019 (mean response-pattern amplitude: 6, response-pattern variance: 2), \u2018bodies\u2019 (mean: 2, variance: 1) and \u2018objects\u2019 (mean: 1, variance: 2). The simulated V1 showed no preference for any stimulus category. Gaussian noise was added to the simulated ground-truth response-patterns. The responsiveness of the voxels within V1/FFA was modeled by a gain field. Next, coherent intrinsic fluctuations were simulated by adding a component to the response-patterns that has the same amplitude fluctuations across time in both V1 and FFA. Because the responsiveness of each voxel to the fluctuations was also modulated by the gain fields, the additive component sufficed to cause similar RDMs between V1 and FFA. Results Visual areas contain image information and exhibit replicable representational geometries We studied fMRI response patterns for 1750 natural images in visual areas V1, V2, V3, V4, V3A, V3B, and LO. A portion of this data set has previously been analyzed with voxel-receptive-field modeling (Kay et al., 2008). The previous analysis showed that fMRI signals from the human visual cortex can be modeled by a Gabor wavelet pyramid. The distinct response patterns for the natural images were captured here by RDMs. Fig. 3B shows, as an example, a V1 RDM in which each cell compares the V1 response-patterns elicited by two different natural images. An RDM captures the pairwise dissimilarities of the response patterns and can thus be directly compared to an RDM of a different brain region (without any need for voxel-to-voxel matching of the response patterns) or to an RDM describing the representational geometry of a computational model (Kriegeskorte et al., 2008a). First to confirm the suitability of the data for representational similarity analysis, the distinctness of the response patterns for the natural images was studied using split-data RDMs in which each cell compares the response patterns between different trials for the same images (for an example, see Fig. 1C). The diagonal of the split-data RDM reflects the replicability of the response patterns for the repeated presentation of the same stimulus images. An exemplar-discriminability index was calculated by subtracting the mean of the diagonal values from the mean of the off-diagonal values. Fig. 4A shows the results on exemplar discriminability. For all three subjects, the most distinct response patterns were found in V1. The exemplar discriminability indices were greater than zero in all studied visual areas (p<0.05, one-sample t-test, for each visual area in each subject). This indicates that response patterns contain information about the stimuli. Beyond the mere presence of information about the image presented, we asked whether the RDMs were replicable. RDM replicability was assessed by rank correlation. RDM replicability would indicate that pairs of images are not all equally distinctly represented, but that some pairs are reliably represented as more similar than others. Fig. 4B shows results on the replicability of the response-pattern dissimilarity structure. Here we compared single-trial RDMs based on two separate presentations of the stimuli. In all subjects, the RDM was best replicated in V1. For subject S1, the RDMs showed replicable structure in all studied visual areas (p<0.05, one-sample t-test, n=25). For subject S2, the single-trial RDMs did not show replicable structure in areas LO and V3A (p>0.05). For subject S3, the RDMs did not show replicable structure in LO (p>0.05) but the results for all other studied areas were significant (p<0.05). Taken together, these results confirmed that this data set with its rich sample of stimuli is suitable for representational similarity analysis. Gabor model explains early visual representation, LO exhibits categorical clusters We compared the visual-area RDMs to RDMs constructed based on three different models: Gabor wavelet pyramid model (GWP), Gist and categorical animate\u2013inanimate distinction. Examples of the model RDMs are shown in Fig. 3D. The Gabor wavelet pyramid is considered as the standard model of visual area V1 (Carandini et al., 2005). The Gist model has been suggested to capture the global features of natural scenes relevant for scene categorization (Oliva and Torralba, 2001). The categorical animate\u2013inanimate model was chosen based on previous studies suggesting this as a fundamental organizing principle of higher-level object responsive areas (Kiani et al., 2007; Kriegeskorte et al., 2008b; Naselaris et al., 2012). Fig. 5 shows the results on the model fits to the empirical RDMs of different visual areas. The model fit was assessed using Kendall's tau-a rank correlation between a visual-area RDM and a model RDM. This measure reflects how well the ranking of the response-pattern dissimilarities for a visual area was explained by the ranking of the dissimilarities of the model's response patterns. In contrast to the voxel-receptive-field modeling approach (Kay et al., 2008), where each voxel response is predicted as a linear combination of model responses, the RSA approach obviates the need to estimate any parameters from the data here. In all subjects (Fig. 5), the V1 RDM was best explained by the Gabor wavelet pyramid model. The Gist model also captured some of the response variance but was not as good fit as the GWP. The GWP was also the best model for the response profiles of visual areas V2 and V3. In V4, all models produced comparable model fits. The animate\u2013inanimate model was the best-fitting model for area LO, especially for subject S1 (Fig. 5A). For subjects S2 and S3, the results on the RDM replicability (Fig. 4B) already suggested noisy LO data. Area LO was localized based on retinotopic criteria (see the Materials and methods section for details), and therefore, the LO in subjects S2 and S3 may only partially overlap with the object-responsive lateral occipital cortex. Visualizations of the response-pattern dissimilarities for all 1750 natural images for visual areas V1 and LO are shown in Fig. 5D. The stimuli were color-coded based on the animate\u2013inanimate distinction. Each dot represents an individual stimulus. The distances between the dots reflect response-pattern dissimilarities. This multidimensional scaling visualization of the response-pattern dissimilarities is unsupervised (i.e., without any assumptions of a categorical structure), and hence any observed distinctions are data-driven. None of the subjects shows categorical clustering of the animate and inanimate stimuli in V1. In contrast, a global grouping of the stimuli reflecting the categorical clustering between animate (red dots) and inanimate (blue dots) natural images is evident in area LO, especially in subject S1 (Fig. 5D, top row). Our results show that the animate/inanimate distinction emerges at a later processing stage and is not due to low-level visual-similarity effect between the categories that would be present already at the level of V1. The shift from the GWP to the categorical animate\u2013inanimate distinction appears a plausible characterization of the changes in the representations of natural images across hierarchy of visual areas. Next we address how much of the response variance the selected models explain. Do the best-fitting models explain all replicable variance in the data, or is a replicable component left unexplained? This leads us to the question of the relative contributions of the intrinsic response fluctuations and stimulus-driven effects on response-pattern similarity. RDMs are highly similar among visual areas when estimated from the same trials The transformation of representational similarity structure along the ventral visual stream can be investigated by comparing RDMs between visual areas. Fig. 6 shows second-order dissimilarity matrices, where the RDMs of visual areas were compared to each other both within and between subjects, and to the two best-fitting model RDMs (GWP and animate\u2013inanimate). In Fig. 6A the visual area comparisons were done between RDMs constructed from response patterns that were estimated on the basis of the same (first) trials. Fig. 6B shows the corresponding multidimensional scaling (MDS) arrangement where the RDMs of different subjects and of the two models are shown with different colors (S1=blue, S2=green, S3=purple, Gabor wavelet pyramid model=black, categorical animate\u2013inanimate model=red). The structure in the RDM as well as the MDS visualization show grouping of the visual areas based on the subject, not visual hierarchy. That is, the visual area RDMs were always most similar to the RDMs of other visual areas of the same subject. This would suggest that the models do not explain the stimulus representations in the visual areas very well. However, the following analyses show that the within-subject similarity of the RDMs was driven by the intrinsic dynamics (which are shared among areas within, but not between, subjects). RDMs are distinct among visual areas when estimated from separate trials Next we compared the visual area RDMs constructed from response patterns that were estimated on the basis of separate trials. That is, the compared RDMs only shared the stimulus-driven component. Fig. 6C shows the second-order dissimilarity matrix and Fig. 6D the corresponding MDS arrangement of the RDM relationships. The results are very different from the same-trial results shown in Figs. 6A\u2013B. The use of separate trials to compare the RDMs revealed clearer distinctions between the visual areas and broke the grouping based on individual subjects. This shows that the clustering of the RDMs by subject in the previous analysis (Fig. 6B) did not result from each subject having an idiosyncratic stimulus-driven representation that is similar across his or her visual areas. Instead, intrinsic dynamics unrelated to the stimuli (which are not shared between repeated presentations of the same stimulus or between subjects) account for the RDM clusters. When the effect of intrinsic dynamics is controlled for by comparing only RDM estimates based on separate sets of trials between cortical areas, the transformation of the stimulus-driven representations can be accurately assessed. Fig. 6D shows a multidimensional scaling arrangement that reveals the relationships among areas and models. RDMs now cluster by visual area, instead of by subject. The V1 RDMs of all subjects cluster around the GWP-model RDM. The LO RDMs of all subjects cluster around the animate\u2013inanimate model RDM. With the similarities among visual-area RDMs no longer inflated by intrinsic dynamics, the arrangement reflects the stimulus-driven representations and accurately depicts the relationships among visual areas and models. The Gabor model explains the stimulus-driven component of the V1 representation Fig. 7 shows results of quantitative analyses of how well the V1 RDM was explained by the GWP model compared to other visual areas and to non-stimulus-driven effects. In each subject, the response-pattern dissimilarity structure of area V2 explained the V1 RDM far better than the GWP model when the V1 and V2 RDMs were constructed from the same trials (sharing intrinsic dynamics; compare red and dark gray bars in Fig. 7A). However, when the RDMs were constructed from separate trials, the similarity between V1 and V2 was much lower (Fig. 7B), confirming that most of the similarity between V1 and V2 RDMs was not driven by similar stimulus representations but by intrinsic dynamics and possibly other artefactual factors shared by the RDMs when same trials are used for estimating the RDMs. Fig. 7 (black lines) also shows the similarity between V1 RDM with its replication constructed from separate trials. When constructed from the separate trials, the correlations between the visual area RDMs are in the same range with the GWP model (Fig. 7B). The GWP model actually outperformed the replication V1 RDM in each subject, reflecting the fact that both estimates of the V1 RDMs are noisy, whereas the GWP model is noise-free (no acquisition noise). Coherent response fluctuations within visual cortex Correlated fMRI response fluctuations in the absence of sensory stimulation are assumed to reflect intrinsic activity fluctuations within connected brain regions. We performed a searchlight analysis to explore the extent and specificity of the coherent response-pattern fluctuations and RDM correlations in our data. A spherical searchlight was positioned at each location of the scanned brain volume (Kriegeskorte et al., 2006). Within each location, the trial-to-trial response-pattern-mean (averaged across the voxels within the searchlight) as well as the RDM (correlation distances between the response-patterns for the stimuli within the searchlight) were extracted and correlated with the corresponding metrics from a reference ROI. The right LO was selected as the reference ROI, i.e., the \u201cseed region\u201d. A high correlation of response fluctuations was expected within visual cortex and especially with the corresponding region in the left hemisphere. In addition, left LO and right LO were expected to show similar stimulus-driven representations as reflected in similar RDMs estimated on the basis of separate trials. Similar visual representations cannot be assumed for low-level visual areas, where left and right visual fields are represented in opposite hemispheres. Fig. 8A shows the results on trial-to-trial response-pattern-mean correlations (Pearson's linear correlation). The upper panel is equivalent to a functional connectivity analysis, where the seed \u201ctime course\u201d is the trial-to-trial pattern mean from the right LO and this is correlated with trial-to-trial pattern mean of a spherical searchlight at each location. The correlations were high especially within the visual cortex. When the analysis was done between trial-to-trial mean signals for the same stimuli from different trials (lower panel in Fig. 8A), the correlations were significant only around the location of the reference ROI. This suggests that there is a small stimulus-driven component also in response-pattern-means, but most of the same-trial response-mean correlations are not stimulus-driven. This finding is consistent with the presence of coherent intrinsic response fluctuations within the visual cortex. Fig. 8B shows the searchlight analysis for RDM similarity. The RDM of the right LO was correlated (Spearman's rank correlation) with RDM of a spherical searchlight at each location. The results for the same-trial RDM correlations (upper panel) resemble the results on the same-trial response-pattern-mean correlations shown in the upper panel of Fig. 8A. The lower panel of the Fig. 8B shows the results when the reference RDM from the right LO was correlated with RDMs constructed from response patterns within the spherical searchlights estimated on the basis of different trials for the same stimuli. This searchlight analysis picked up the right LO and the corresponding region in the opposite hemisphere, suggesting similar stimulus representations in these regions. These results support the conclusion that intrinsic cortical dynamics inflate the similarity of visual area RDMs and that the stimulus-driven similarity between the representations in different areas can be revealed by studying separate trials for the same stimuli. More dissimilar response patterns for trials more separated in time In addition to the coherent fluctuations of the overall activity within the visual cortex, are there other non-stimulus related factors affecting the RDM similarity? We did find that the temporal sequence of stimulus presentation also had an effect on RDM similarity. In this data, the stimulus images in all experimental runs were different but they were presented using the same sequence (including timing of null trials and timing of the repetitions of the same stimuli). The appearance of an RDM depends on the chosen stimulus order. If an RDM is ordered to follow the presentation sequence of the stimuli, is there a visible effect of the temporal structure on the response-pattern dissimilarity? Fig. 9A shows a V1 RDM where the two trials for the 70 natural images within an experimental run were treated as separate conditions (RDM dimensions: 140\u00d7140). Here the ordering of the conditions in the RDM follows the numbering of the stimulus images (1\u201370). The first half corresponds to the first presentations of the images, the second half to the second presentations. In Fig. 9B, the condition labels were reordered based on the temporal sequence of the stimulus presentation. In Fig. 9C, these reordered RDMs were averaged across experimental runs. Because different natural images were shown using the same temporal sequence in all runs, the result should resemble an RDM, where the response patterns are similar for repeated presentations of the stimuli and dissimilar for all other comparisons (Fig. 9D). This is indeed observed (detail 1 in Figs. 9C, D). However, the RDM also exhibits a prominent structure of low dissimilarities around the diagonal, which indicates that response patterns for stimuli presented close in time evoked more similar response patterns than stimuli presented further apart. The similarity of response patterns acquired close together in time is consistent with a slow drift in pattern space that could be related to head motion and/or drifts of the state of the scanner and the subject's physiological state. A similar drift was also seen in RDMs from other visual areas (Supplementary Fig. 1; and for more detailed analysis of the drifts, Supplementary Fig. 2). These global pattern drifts most likely contribute to the high correlation between RDMs of neighboring visual areas (Figs. 6A, 7A) when same-trial RDMs are compared. Fig. 7C shows results of quantitative analyses of how well the V1 RDM in each subject was explained by the temporal-distance between the stimuli (green bars). This result likely also explains the difference in the results of the between-subject V1 correlation in Figs. 7A and B (light gray bars): the use of the same stimulus sequence inflated the between-subject RDM similarity (Fig. 7A). In addition, a simple quantification of the contribution of the coherent response fluctuations is included in Fig. 7C (blue bars). The effect of the coherent response fluctuations was modeled as the absolute difference of the mean-responses divided by the sum of the absolute values of the mean-responses (mean-response RDM). This is a simple quantification of the response dynamics and a more comprehensive modeling of the phenomenon remains for future work. In summary, same-trial RDM comparisons between brain regions are confounded by both the correlated response fluctuations and the temporal sequence-related pattern dissimilarity structure. This further reinforces the importance of using independent trials when drawing conclusions from exploratory analysis of RDM similarity between brain regions. Higher similarity of same-trial RDMs is not eliminated by averaging more trials Thus far, our conclusions are based on single-trial RDM comparisons. Could the contribution of the coherent response fluctuations on RDM similarity between neighboring brain regions be eliminated by averaging more trials? We addressed this question with a data set where we had 12 responses for 120 natural images (Kay et al., 2008). The results are shown in Fig. 10 . The similarity of the same-trial RDMs was decreased when more trials were averaged (first column in Fig. 10). This is consistent with a contribution from correlated intrinsic fluctuations, which is expected to be reduced by averaging. At the same time, the similarity of RDMs estimated on the basis of separate trials was increased when more trials were averaged (second column in Fig. 10). Nevertheless, the correlation between the same-trial V1 and V2 RDMs remained much higher than the correlation between the RDMs estimated from separate trials. Hence, trial averaging appears insufficient to remove the non-stimulus-driven same-trial effects on RDM similarity. Representational dissimilarities in V1 are distinct from V2, and not fully explained by the Gabor model Trial-averaging revealed a clear ordering of the RDM correlations (Fig. 10). The separate-trial RDM correlations are interpretable in terms of stimulus representational geometry. The V1 RDM was best explained by its replication in the same subject, followed by the same-subject V2 RDM and the other-subject V1 RDM. This suggests that the representational geometries are individually unique in V1. Finally, the basic GWP model's representational geometry could not fully explain the V1 representation. In summary, although trial averaging reduced non-stimulus-driven effects on the response patterns, it did not remove the effect of the same-trial coherent response fluctuations on the representational similarity between neighboring visual areas of the same subject. Using RDMs constructed from response patterns estimated on the basis of separate trials, we were able to reveal subject-unique representational geometries, differences in representation between different visual areas, and the limits of the Gabor model in explaining V1. Discussion Intrinsic cortical dynamics are a major feature of cortical activity. Our results suggest five main conclusions: (1) Intrinsic dynamics exert a major influence on estimates of stimulus-related activity patterns and their dissimilarity structure. (2) The influence is such that representational dissimilarity matrices appear much more similar between two brain areas when estimated on the basis of the same trials than when estimated on the basis of a separate set of trials for each area. (3) A particular variant of intrinsic dynamics described in the literature, coherent fluctuations of activity across multiple areas, can account for this assimilation of the apparent representational geometries of two areas. Future studies will be needed to assess the intrinsic dimensionality of the intrinsic fluctuations and their functional role. (4) Response pattern estimates are also affected by substantial pattern drifts, which might be related to head motion, scanner state, or the subject's physiological, emotional, or cognitive state. As a result of the pattern drift, two stimuli presented further apart in time will tend to be associated with more dissimilar pattern estimates. Single-trial-based RDM estimates therefore exhibit a stimulus-sequence-related component, which also creates spurious RDM correlations between different areas, when the same sequences have been used to estimate the RDMs. (5) The stimulus-driven component of the representation of a set of stimuli in two brain areas can be compared using a separate set of trials, which have been presented in independent random orders, to estimate the response patterns for each area. This approach avoids both the confound of correlated intrinsic fluctuations and the confound of sequence-related pattern similarity structure. Coherent response-pattern fluctuations between visual areas From our data, we can only speculate the source of the coherent response-pattern fluctuations between the visual areas. A likely interpretation is the trial-to-trial variability in fMRI signal correlations that reflects underlying intrinsic spontaneous neural activity (Nir et al., 2008). The simulation and the observed coherent response-pattern fluctuations within the visual cortex support this conclusion. We proposed that the contribution of the intrinsic fluctuations can be removed by comparing RDMs constructed of separate trials. The strong effect of correlated fluctuations suggests that explicitly modeling and regressing out such effects before pattern analyses might strongly reduce the noise and improve the estimates. This is achieved, for example, by the GLMdenoise method (Kay et al., 2013a). Because modeling out the correlated fluctuations will never work perfectly, formal comparisons between regional representational geometries will likely still require RDM estimates from separate sets of trials acquired with independent random sequences. Similarities between RDMs of the same visual area in different subjects can also reveal the amount of stimulus-related effects in the RDM. In between-subject RDM comparisons, each subject should have different random stimulus presentation order, that is, the stimuli should be counterbalanced. This will prevent the temporal proximities of the stimuli from causing artefactual correlation of the pattern dissimilarities between the subjects. We have emphasized that the intrinsic trial-to-trial variability in the response-pattern similarity can obscure the underlying stimulus-driven effects and thus confound results on representational similarities between brain regions. However, the trial-to-trial response fluctuations most likely have functional significance. Presumably the fluctuations are related to changes in the subject's instantaneous state, such as attention and vigilance, and affect also the perception of the stimuli. Better reproducibility of fMRI response patterns has been previously associated with conscious perception (Schurger et al., 2010) and better memory (Xue et al., 2010) of visual stimuli. Furthermore, the effects of the temporal context of the stimuli on the response-pattern similarity could also be addressed in more detail in future studies. Visual cortex has been shown to show rapid adaptation effects to the structure of image stimuli at the single-neuron level (Muller et al., 1999) and at the level of neural populations (Benucci et al., 2013). This is likely also reflected in the pattern representations as measured with fMRI. Future work is needed to characterize the non-stimulus driven component of the response-patterns in more detail and to study its functional significance. The present experimental design of passive viewing of natural images is not suited to characterize for example the effects of attention (see, e.g., Ress et al., 2000) on the response-pattern similarity structure between visual areas. Relating fMRI results to computational model predictions of the underlying visual representations across stages of processing RSA (Kriegeskorte, 2009; Kriegeskorte et al., 2008a; Nili et al., 2014) and voxel-receptive-field modeling (Kay et al., 2008; Kay et al., 2013b) are two complementary approaches to directly relate computational models with fMRI data. Voxel-receptive-field modeling aims to construct a computational model for each fMRI voxel and predict the responses for new stimuli, whereas RSA aims to predict the response-pattern similarity for a set of stimuli. We employed data that had been previously used as training data in voxel-receptive-field modeling. RSA does not require separate training data when the models have no free parameters to be estimated from the data. The model fit is determined by the correlation between the model RDM and a brain RDM. Here the stimulus set differed from previous RSA studies in that it was richer (>1000 images, as opposed to 96 in Kriegeskorte et al. (2008b); for a review, see Kriegeskorte and Kievit (2013)). Our results confirm that this type of stimuli can be used with RSA to address questions on how representation of visual information is transformed along stages of the visual system and to test alternative computational models. Our results on the model fits are consistent with previous studies showing that the representation of natural images in V1 can be explained by a Gabor wavelet model at the level of neural population codes (Weliky et al., 2003) and fMRI response patterns (Kay et al., 2008; Naselaris et al., 2009). The categorical clustering of responses for animate and inanimate objects in higher-level visual area is also consistent with previous work (Connolly et al., 2012; Kiani et al., 2007; Kriegeskorte et al., 2008b; Naselaris et al., 2012). The present implementation of the GWP model is a simplification of what we already know about V1; the model does not include properties such as surround suppression (Cavanaugh et al., 2002) or cortical magnification (Duncan and Boynton, 2003). However, taking into account the noise level in the data, it does a fairly good job at explaining the response dissimilarity in V1. However, when more trials were averaged for the RDMs, the limits of the GWP model in explaining the response variance became evident. Future studies should seek a computational account of both the prominent category divisions and the within-category representational geometry of LO. This might be achieved by testing a wider range of computational models (including newer models such as those of Freeman et al. (2013) and Kay et al. (2013b)), with the aim also of characterizing the representational organizing principles of the intermediate-level visual areas (V2\u20134), in more detail. This would lead to a better understanding of the processing steps between the local, low-level image processing in V1 and the more global, category-selective representations in the higher-level visual areas. Conclusion We found that coherent fMRI response-pattern fluctuations between visual areas can dominate representational similarities over stimulus-driven effects. Hence we suggest that representational similarity of brain regions should be addressed using response patterns estimated on the basis of separate fMRI trials. Here this approach revealed clear distinctions between the regions. More generally, our findings indicate that intrinsic cortical dynamics may have a significant contribution to representations as studied using multi-voxel fMRI pattern analysis. Acknowledgments This work was supported by the Aalto University, the European Research Council (Advanced Grant #232946 to R. Hari) and the Academy of Finland Postdoctoral Researcher Grant (278957) to LH, and a European Research Council Starting Grant (261352) to NK. The authors declare no competing financial interests. Appendix A Supplementary data Supplementary figures. Appendix A Supplementary data Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.neuroimage.2015.04.026. References Arieli et al., 1996 A. Arieli A. Sterkin A. Grinvald A. Aertsen Dynamics of ongoing activity: explanation of the large variability in evoked cortical responses Science 273 1996 1868 1871 Becker et al., 2011 R. Becker M. Reinacher F. Freyer A. Villringer P. Ritter How ongoing neuronal oscillations account for evoked fMRI variability J. Neurosci. 31 2011 11016 11027 Benucci et al., 2013 A. Benucci A.B. Saleem M. Carandini Adaptation maintains population homeostasis in primary visual cortex Nat. Neurosci. 16 2013 724 729 Carandini et al., 2005 M. Carandini J.B. Demb V. Mante D.J. Tolhurst Y. Dan B.A. Olshausen J.L. Gallant N.C. Rust Do we know what the early visual system does? J. Neurosci. 25 2005 10577 10597 Cavanaugh et al., 2002 J.R. Cavanaugh W. Bair J.A. Movshon Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons J. Neurophysiol. 88 2002 2530 2546 Connolly et al., 2012 A.C. Connolly J.S. Guntupalli J. Gors M. Hanke Y.O. Halchenko Y.C. Wu H. Abdi J.V. Haxby The representation of biological classes in the human brain J. Neurosci. 32 2012 2608 2618 Duncan and Boynton, 2003 R.O. Duncan G.M. Boynton Cortical magnification within human primary visual cortex correlates with acuity thresholds Neuron 38 2003 659 671 Fiser et al., 2004 J. Fiser C. Chiu M. Weliky Small modulation of ongoing cortical dynamics by sensory input during natural vision Nature 431 2004 573 578 Fox and Raichle, 2007 M.D. Fox M.E. Raichle Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging Nat. Rev. Neurosci. 8 2007 700 711 Fox et al., 2006 M.D. Fox A.Z. Snyder J.M. Zacks M.E. Raichle Coherent spontaneous activity accounts for trial-to-trial variability in human evoked brain responses Nat. Neurosci. 9 2006 23 25 Freeman et al., 2013 J. Freeman C.M. Ziemba D.J. Heeger E.P. Simoncelli J.A. Movshon A functional and perceptual signature of the second visual area in primates Nat. Neurosci. 16 2013 974 981 Kay et al., 2008 K.N. Kay T. Naselaris R.J. Prenger J.L. Gallant Identifying natural images from human brain activity Nature 452 2008 352 355 Kay et al., 2013a K.N. Kay A. Rokem J. Winawer R.F. Dougherty B.A. Wandell GLMdenoise: a fast, automated technique for denoising task-based fMRI data Front. Neurosci. 7 2013 247 Kay et al., 2013b K.N. Kay J. Winawer A. Rokem A. Mezer B.A. Wandell A two-stage cascade model of BOLD responses in human visual cortex PLoS Comput. Biol. 9 2013 e1003079 Khaligh-Razavi and Kriegeskorte, 2014 S.M. Khaligh-Razavi N. Kriegeskorte Deep supervised, but not unsupervised, models may explain IT cortical representation PLoS Comput. Biol. 10 2014 e1003915 Kiani et al., 2007 R. Kiani H. Esteky K. Mirpour K. Tanaka Object category structure in response patterns of neuronal population in monkey inferior temporal cortex J. Neurophysiol. 97 2007 4296 4309 Kriegeskorte, 2009 N. Kriegeskorte Relating population-code representations between man, monkey, and computational models Front. Neurosci. 3 2009 363 373 Kriegeskorte and Kievit, 2013 N. Kriegeskorte R.A. Kievit Representational geometry: integrating cognition, computation, and the brain Trends Cogn. Sci. 17 2013 401 412 Kriegeskorte and Kreiman, 2011 N. Kriegeskorte G. Kreiman Visual Population Codes \u2014 Toward a Common Multivariate Framework for Cell Recording and Functional Imaging 2011 MIT Press Cambridge Kriegeskorte et al., 2006 N. Kriegeskorte R. Goebel P. Bandettini Information-based functional brain mapping Proc. Natl. Acad. Sci. U. S. A. 103 2006 3863 3868 Kriegeskorte et al., 2008a N. Kriegeskorte M. Mur P. Bandettini Representational similarity analysis \u2014 connecting the branches of systems neuroscience Front. Syst. Neurosci. 2 2008 4 Kriegeskorte et al., 2008b N. Kriegeskorte M. Mur D.A. Ruff R. Kiani J. Bodurka H. Esteky K. Tanaka P.A. Bandettini Matching categorical object representations in inferior temporal cortex of man and monkey Neuron 60 2008 1126 1141 Muller et al., 1999 J.R. Muller A.B. Metha J. Krauskopf P. Lennie Rapid adaptation in visual cortex to the structure of images Science 285 1999 1405 1408 Naselaris et al., 2009 T. Naselaris R.J. Prenger K.N. Kay M. Oliver J.L. Gallant Bayesian reconstruction of natural images from human brain activity Neuron 63 2009 902 915 Naselaris et al., 2012 T. Naselaris D.E. Stansbury J.L. Gallant Cortical representation of animate and inanimate objects in complex natural scenes J. Physiol. Paris 106 2012 239 249 Nili et al., 2014 H. Nili C. Wingfield A. Walther L. Su W. Marslen-Wilson N. Kriegeskorte A toolbox for representational similarity analysis PLoS Comput. Biol. 10 2014 e1003553 Nir et al., 2006 Y. Nir U. Hasson I. Levy Y. Yeshurun R. Malach Widespread functional connectivity and fMRI fluctuations in human visual cortex in the absence of visual stimulation NeuroImage 30 2006 1313 1324 Nir et al., 2008 Y. Nir R. Mukamel I. Dinstein E. Privman M. Harel L. Fisch H. Gelbard-Sagiv S. Kipervasser F. Andelman M.Y. Neufeld U. Kramer A. Arieli I. Fried R. Malach Interhemispheric correlations of slow spontaneous neuronal fluctuations revealed in human sensory cortex Nat. Neurosci. 11 2008 1100 1108 Oliva and Torralba, 2001 A. Oliva A. Torralba Modeling the shape of the scene: a holistic representation of the spatial envelope Int. J. Comput. Vis. 42 2001 145 175 Ress et al., 2000 D. Ress B.T. Backus D.J. Heeger Activity in primary visual cortex predicts performance in a visual detection task Nat. Neurosci. 3 2000 940 945 Ritchey et al., 2014 M. Ritchey A.P. Yonelinas C. Ranganath Functional connectivity relationships predict similarities in task activation and pattern information during associative memory encoding J. Cogn. Neurosci. 26 2014 1085 1099 Schurger et al., 2010 A. Schurger F. Pereira A. Treisman J.D. Cohen Reproducibility distinguishes conscious from nonconscious neural representations Science 327 2010 97 99 Shmuel and Leopold, 2008 A. Shmuel D.A. Leopold Neuronal correlates of spontaneous fluctuations in fMRI signals in monkey visual cortex: implications for functional connectivity at rest Hum. Brain Mapp. 29 2008 751 761 Weliky et al., 2003 M. Weliky J. Fiser R.H. Hunt D.N. Wagner Coding of natural scenes in primary visual cortex Neuron 37 2003 703 718 Xue et al., 2010 G. Xue Q. Dong C. Chen Z. Lu J.A. Mumford R.A. Poldrack Greater neural pattern similarity across repetitions is associated with better memory Science 330 2010 97 101", "scopus-id": "84929703630", "pubmed-id": "25896934", "coredata": {"eid": "1-s2.0-S105381191500316X", "dc:description": "Abstract Intrinsic cortical dynamics are thought to underlie trial-to-trial variability of visually evoked responses in animal models. Understanding their function in the context of sensory processing and representation is a major current challenge. Here we report that intrinsic cortical dynamics strongly affect the representational geometry of a brain region, as reflected in response-pattern dissimilarities, and exaggerate the similarity of representations between brain regions. We characterized the representations in several human visual areas by representational dissimilarity matrices (RDMs) constructed from fMRI response-patterns for natural image stimuli. The RDMs of different visual areas were highly similar when the response-patterns were estimated on the basis of the same trials (sharing intrinsic cortical dynamics), and quite distinct when patterns were estimated on the basis of separate trials (sharing only the stimulus-driven component). We show that the greater similarity of the representational geometries can be explained by coherent fluctuations of regional-mean activation within visual cortex, reflecting intrinsic dynamics. Using separate trials to study stimulus-driven representations revealed clearer distinctions between the representational geometries: a Gabor wavelet pyramid model explained representational geometry in visual areas V1\u20133 and a categorical animate\u2013inanimate model in the object-responsive lateral occipital cortex.", "openArchiveArticle": "false", "prism:coverDate": "2015-07-01", "openaccessUserLicense": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "prism:aggregationType": "Journal", "prism:url": "https://api.elsevier.com/content/article/pii/S105381191500316X", "dc:creator": [{"@_fa": "true", "$": "Henriksson, Linda"}, {"@_fa": "true", "$": "Khaligh-Razavi, Seyed-Mahdi"}, {"@_fa": "true", "$": "Kay, Kendrick"}, {"@_fa": "true", "$": "Kriegeskorte, Nikolaus"}], "link": [{"@_fa": "true", "@rel": "self", "@href": "https://api.elsevier.com/content/article/pii/S105381191500316X"}, {"@_fa": "true", "@rel": "scidir", "@href": "https://www.sciencedirect.com/science/article/pii/S105381191500316X"}], "dc:format": "application/json", "openaccessType": "Full", "pii": "S1053-8119(15)00316-X", "prism:volume": "114", "prism:publisher": "Published by Elsevier Inc.", "dc:title": "Visual representations are dominated by intrinsic fluctuations correlated between areas", "prism:copyright": "Copyright \u00a9 2015 Published by Elsevier Inc.", "openaccess": "1", "prism:issn": "10538119", "dcterms:subject": [{"@_fa": "true", "$": "Functional MRI"}, {"@_fa": "true", "$": "Visual cortex"}, {"@_fa": "true", "$": "Intrinsic dynamics"}, {"@_fa": "true", "$": "Natural images"}, {"@_fa": "true", "$": "Pattern information"}, {"@_fa": "true", "$": "Representational similarity"}], "openaccessArticle": "true", "prism:publicationName": "NeuroImage", "openaccessSponsorType": "FundingBody", "prism:pageRange": "275-286", "prism:endingPage": "286", "prism:coverDisplayDate": "1 July 2015", "prism:doi": "10.1016/j.neuroimage.2015.04.026", "prism:startingPage": "275", "dc:identifier": "doi:10.1016/j.neuroimage.2015.04.026", "openaccessSponsorName": "European Research Council"}, "objects": {"object": [{"@category": "thumbnail", "@height": "94", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr1.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "16750", "@ref": "gr1", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "175", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr10.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "8500", "@ref": "gr10", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "131", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr2.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "13121", "@ref": "gr2", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "135", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr3.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "27056", "@ref": "gr3", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "138", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr4.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "7271", "@ref": "gr4", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "183", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr5.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "17235", "@ref": "gr5", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "164", "@width": "177", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr6.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "10125", "@ref": "gr6", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "113", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr7.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "5431", "@ref": "gr7", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "123", "@width": "219", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr8.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "16469", "@ref": "gr8", "@mimetype": "image/gif"}, {"@category": "thumbnail", "@height": "163", "@width": "131", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr9.sml?httpAccept=%2A%2F%2A", "@multimediatype": "GIF image file", "@type": "IMAGE-THUMBNAIL", "@size": "15475", "@ref": "gr9", "@mimetype": "image/gif"}, {"@category": "standard", "@height": "307", "@width": "714", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr1.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "111406", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "670", "@width": "715", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr10.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "99892", "@ref": "gr10", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "483", "@width": "804", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr2.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "125574", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "385", "@width": "625", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr3.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "166487", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "464", "@width": "390", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr4.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "38918", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "569", "@width": "637", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr5.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "140723", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "536", "@width": "579", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr6.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "59979", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "563", "@width": "390", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr7.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "42332", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "400", "@width": "714", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr8.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "128475", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "standard", "@height": "625", "@width": "501", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr9.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-DOWNSAMPLED", "@size": "184372", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1362", "@width": "3163", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr1_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "911206", "@ref": "gr1", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2967", "@width": "3164", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr10_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "829924", "@ref": "gr10", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2136", "@width": "3558", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr2_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1229722", "@ref": "gr2", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1702", "@width": "2766", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr3_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1591769", "@ref": "gr3", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2057", "@width": "1729", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr4_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "276280", "@ref": "gr4", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2522", "@width": "2821", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr5_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1534062", "@ref": "gr5", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2372", "@width": "2564", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr6_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "452438", "@ref": "gr6", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2493", "@width": "1726", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr7_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "282462", "@ref": "gr7", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "1770", "@width": "3163", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr8_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "1236790", "@ref": "gr8", "@mimetype": "image/jpeg"}, {"@category": "high", "@height": "2768", "@width": "2218", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-gr9_lrg.jpg?httpAccept=%2A%2F%2A", "@multimediatype": "JPEG image file", "@type": "IMAGE-HIGH-RES", "@size": "2024612", "@ref": "gr9", "@mimetype": "image/jpeg"}, {"@category": "standard", "@_fa": "true", "$": "https://api.elsevier.com/content/object/eid/1-s2.0-S105381191500316X-mmc1.pdf?httpAccept=%2A%2F%2A", "@multimediatype": "Acrobat PDF file", "@type": "APPLICATION", "@size": "5296595", "@ref": "mmc1", "@mimetype": "application/pdf"}]}, "link": {"@rel": "abstract", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84929703630"}}